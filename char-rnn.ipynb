{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "from six.moves import cPickle\n",
    "import collections\n",
    "import numpy as np\n",
    "import codecs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 读取和预处理数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_dir = \"./data/sherlock/\"\n",
    "\n",
    "\n",
    "input_file = os.path.join(data_dir, \"input.txt\")\n",
    "vocab_file = os.path.join(data_dir, \"vocab.pkl\")\n",
    "tensor_file = os.path.join(data_dir, \"data.npy\")\n",
    "    \n",
    "\n",
    "with codecs.open(input_file, \"r\", encoding=\"utf-8\") as f:\n",
    "    data = f.read()\n",
    "counter = collections.Counter(data)\n",
    "counter_pairs = sorted(counter.items(), key=lambda x: -x[1])\n",
    "chars, _ = zip(*counter_pairs)\n",
    "vocab_size = len(chars)\n",
    "vocab = dict(zip(chars, range(len(chars))))\n",
    "tensor = np.array(list(map(vocab.get, data)))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 把数据处理成batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 50\n",
    "seq_length = 50\n",
    "num_batches = int(tensor.size / (batch_size * seq_length))\n",
    "if num_batches == 0:\n",
    "    assert False, \"Not enough data. Make seq_length and batch_size small.\"\n",
    "tensor = tensor[:num_batches * batch_size * seq_length]\n",
    "xdata = tensor\n",
    "ydata = np.copy(tensor)\n",
    "ydata[:-1] = xdata[1:]\n",
    "ydata[-1] = xdata[0]\n",
    "x_batches = np.split(xdata.reshape(batch_size, -1), num_batches, 1)\n",
    "y_batches = np.split(ydata.reshape(batch_size, -1), num_batches, 1)\n",
    "pointer = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义RNN模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.contrib import rnn\n",
    "from tensorflow.contrib import legacy_seq2seq\n",
    "\n",
    "\n",
    "class Model():\n",
    "    def __init__(self, training=True):\n",
    "        self.batch_size = 50\n",
    "        self.seq_length = 50\n",
    "        if not training:\n",
    "            self.batch_size = 1\n",
    "            self.seq_length = 1\n",
    "            \n",
    "        self.rnn_size = 128\n",
    "        self.num_layers = 2\n",
    "        self.input_keep_prob = 1.0\n",
    "        self.output_keep_prob = 1.0\n",
    "        self.grad_clip = 5.0\n",
    "        self.training = 1\n",
    "\n",
    "        cell_fn = rnn.BasicRNNCell\n",
    "\n",
    "        cells = []\n",
    "        for _ in range(self.num_layers):\n",
    "            cell = cell_fn(self.rnn_size)\n",
    "            # dropout\n",
    "            if training and (self.input_keep_prob < 1.0 or self.output_keep_prob < 1.0):\n",
    "                cell = rnn.DropoutWrapper(cell, input_keep_prob=self.input_keep_prob,\n",
    "                                         output_keep_prob=self.output_keep_prob)\n",
    "            cells.append(cell)\n",
    "\n",
    "        self.cell = cell = rnn.MultiRNNCell(cells, state_is_tuple=True)\n",
    "\n",
    "        # placeholder for input and output\n",
    "        self.input_data = tf.placeholder(tf.int32, [self.batch_size, self.seq_length])\n",
    "        self.output_data = tf.placeholder(tf.int32, [self.batch_size, self.seq_length])\n",
    "        self.initial_state = cell.zero_state(self.batch_size, tf.float32)\n",
    "        with tf.variable_scope(\"rnnlm\"):\n",
    "            softmax_w = tf.get_variable(\"softmax_w\", [self.rnn_size, vocab_size])\n",
    "            softmax_b = tf.get_variable(\"softmax_b\", [vocab_size])\n",
    "        embedding = tf.get_variable(\"embedding\", [vocab_size, self.rnn_size])\n",
    "        inputs = tf.nn.embedding_lookup(embedding, self.input_data)\n",
    "        if training and self.output_keep_prob:\n",
    "            inputs = tf.nn.dropout(inputs, self.output_keep_prob)\n",
    "\n",
    "        inputs = tf.split(inputs, self.seq_length, 1)\n",
    "        inputs = [tf.squeeze(input_, [1]) for input_ in inputs]\n",
    "\n",
    "        def loop(prev, _):\n",
    "            prev = tf.matmul(prev, softmax_w) + softmax_b\n",
    "            prev_symbol = tf.stop_gradient(tf.argmax(prev, 1))\n",
    "            return tf.nn.embedding_lookup(embedding, prev_symbol)\n",
    "\n",
    "        outputs, last_state = legacy_seq2seq.rnn_decoder(inputs, self.initial_state, cell, \n",
    "                                                         loop_function=loop if not training else None, scope=\"rnnlm\")\n",
    "        output = tf.reshape(tf.concat(outputs, 1), [-1, self.rnn_size])\n",
    "        self.logits = tf.matmul(output, softmax_w) + softmax_b\n",
    "        self.probs = tf.nn.softmax(self.logits)\n",
    "        loss = legacy_seq2seq.sequence_loss_by_example([self.logits],\n",
    "                                                      [tf.reshape(self.output_data, [-1])],\n",
    "                                                      [tf.ones([self.batch_size * self.seq_length])])\n",
    "        with tf.name_scope(\"cost\"):\n",
    "            self.cost = tf.reduce_sum(loss) / batch_size / seq_length\n",
    "        self.final_state = last_state\n",
    "        self.lr = tf.Variable(0.0, trainable=False)\n",
    "        # gradient clipping on trainable variables\n",
    "        tvars = tf.trainable_variables()\n",
    "        grads, _ = tf.clip_by_global_norm(tf.gradients(self.cost, tvars), self.grad_clip)\n",
    "\n",
    "        # optimizer and train\n",
    "        with tf.name_scope(\"optimizer\"):\n",
    "            optimizer = tf.train.AdamOptimizer(self.lr)\n",
    "        self.train_op = optimizer.apply_gradients(zip(grads, tvars))\n",
    "    \n",
    "    def sample(self, sess, chars, vocab, num=200, prime=\"The \"):\n",
    "        state = sess.run(self.cell.zero_state(1, tf.float32))\n",
    "        for char in prime[:-1]:\n",
    "            x = np.zeros((1,1))\n",
    "            x[0, 0] = vocab[char]\n",
    "            feed = {self.input_data: x, self.initial_state: state}\n",
    "            [state] = sess.run([self.final_state], feed)\n",
    "\n",
    "        def weighted_pick(weights):\n",
    "            t = np.cumsum(weights)\n",
    "            s = np.sum(weights)\n",
    "            return (int(np.searchsorted(t, np.random.rand(1)*s)))\n",
    "\n",
    "        ret = prime\n",
    "        char = prime[-1]\n",
    "        for n in range(num):\n",
    "            x = np.zeros((1,1))\n",
    "            x[0, 0] = vocab[char]\n",
    "            feed = {self.input_data: x, self.initial_state: state}\n",
    "            [p, state] = sess.run([self.probs, self.final_state], feed)\n",
    "            p = p[0]\n",
    "            sample = weighted_pick(p)\n",
    "\n",
    "            pred = chars[sample]\n",
    "            ret += pred\n",
    "            char = pred\n",
    "        return ret\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 开始训练RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/67600 (epoch 0), train_loss = 4.570, time/batch=0.157\n",
      "model saved to ./save/model.ckpt\n",
      "1/67600 (epoch 0), train_loss = 4.346, time/batch=0.059\n",
      "2/67600 (epoch 0), train_loss = 3.888, time/batch=0.070\n",
      "3/67600 (epoch 0), train_loss = 3.604, time/batch=0.065\n",
      "4/67600 (epoch 0), train_loss = 3.391, time/batch=0.072\n",
      "5/67600 (epoch 0), train_loss = 3.303, time/batch=0.054\n",
      "6/67600 (epoch 0), train_loss = 3.195, time/batch=0.055\n",
      "7/67600 (epoch 0), train_loss = 3.135, time/batch=0.052\n",
      "8/67600 (epoch 0), train_loss = 3.109, time/batch=0.061\n",
      "9/67600 (epoch 0), train_loss = 3.043, time/batch=0.066\n",
      "10/67600 (epoch 0), train_loss = 2.999, time/batch=0.052\n",
      "11/67600 (epoch 0), train_loss = 3.015, time/batch=0.052\n",
      "12/67600 (epoch 0), train_loss = 3.027, time/batch=0.063\n",
      "13/67600 (epoch 0), train_loss = 3.009, time/batch=0.063\n",
      "14/67600 (epoch 0), train_loss = 3.025, time/batch=0.056\n",
      "15/67600 (epoch 0), train_loss = 2.966, time/batch=0.055\n",
      "16/67600 (epoch 0), train_loss = 2.997, time/batch=0.076\n",
      "17/67600 (epoch 0), train_loss = 3.004, time/batch=0.078\n",
      "18/67600 (epoch 0), train_loss = 2.971, time/batch=0.064\n",
      "19/67600 (epoch 0), train_loss = 2.978, time/batch=0.054\n",
      "20/67600 (epoch 0), train_loss = 2.925, time/batch=0.097\n",
      "21/67600 (epoch 0), train_loss = 2.969, time/batch=0.055\n",
      "22/67600 (epoch 0), train_loss = 2.966, time/batch=0.064\n",
      "23/67600 (epoch 0), train_loss = 2.927, time/batch=0.057\n",
      "24/67600 (epoch 0), train_loss = 2.985, time/batch=0.069\n",
      "25/67600 (epoch 0), train_loss = 2.926, time/batch=0.054\n",
      "26/67600 (epoch 0), train_loss = 2.928, time/batch=0.054\n",
      "27/67600 (epoch 0), train_loss = 2.945, time/batch=0.054\n",
      "28/67600 (epoch 0), train_loss = 2.912, time/batch=0.060\n",
      "29/67600 (epoch 0), train_loss = 2.839, time/batch=0.065\n",
      "30/67600 (epoch 0), train_loss = 2.861, time/batch=0.056\n",
      "31/67600 (epoch 0), train_loss = 3.042, time/batch=0.055\n",
      "32/67600 (epoch 0), train_loss = 2.891, time/batch=0.075\n",
      "33/67600 (epoch 0), train_loss = 2.851, time/batch=0.122\n",
      "34/67600 (epoch 0), train_loss = 2.855, time/batch=0.128\n",
      "35/67600 (epoch 0), train_loss = 2.828, time/batch=0.094\n",
      "36/67600 (epoch 0), train_loss = 2.775, time/batch=0.107\n",
      "37/67600 (epoch 0), train_loss = 2.808, time/batch=0.094\n",
      "38/67600 (epoch 0), train_loss = 2.813, time/batch=0.115\n",
      "39/67600 (epoch 0), train_loss = 2.773, time/batch=0.081\n",
      "40/67600 (epoch 0), train_loss = 2.748, time/batch=0.144\n",
      "41/67600 (epoch 0), train_loss = 2.761, time/batch=0.077\n",
      "42/67600 (epoch 0), train_loss = 2.749, time/batch=0.082\n",
      "43/67600 (epoch 0), train_loss = 2.750, time/batch=0.084\n",
      "44/67600 (epoch 0), train_loss = 2.747, time/batch=0.097\n",
      "45/67600 (epoch 0), train_loss = 2.715, time/batch=0.069\n",
      "46/67600 (epoch 0), train_loss = 2.688, time/batch=0.069\n",
      "47/67600 (epoch 0), train_loss = 2.686, time/batch=0.071\n",
      "48/67600 (epoch 0), train_loss = 2.621, time/batch=0.064\n",
      "49/67600 (epoch 0), train_loss = 2.582, time/batch=0.060\n",
      "50/67600 (epoch 0), train_loss = 2.683, time/batch=0.077\n",
      "51/67600 (epoch 0), train_loss = 2.624, time/batch=0.075\n",
      "52/67600 (epoch 0), train_loss = 2.565, time/batch=0.098\n",
      "53/67600 (epoch 0), train_loss = 2.643, time/batch=0.130\n",
      "54/67600 (epoch 0), train_loss = 2.598, time/batch=0.097\n",
      "55/67600 (epoch 0), train_loss = 2.517, time/batch=0.185\n",
      "56/67600 (epoch 0), train_loss = 2.576, time/batch=0.120\n",
      "57/67600 (epoch 0), train_loss = 2.580, time/batch=0.096\n",
      "58/67600 (epoch 0), train_loss = 2.484, time/batch=0.069\n",
      "59/67600 (epoch 0), train_loss = 2.489, time/batch=0.111\n",
      "60/67600 (epoch 0), train_loss = 2.458, time/batch=0.080\n",
      "61/67600 (epoch 0), train_loss = 2.479, time/batch=0.075\n",
      "62/67600 (epoch 0), train_loss = 2.495, time/batch=0.089\n",
      "63/67600 (epoch 0), train_loss = 2.428, time/batch=0.131\n",
      "64/67600 (epoch 0), train_loss = 2.411, time/batch=0.101\n",
      "65/67600 (epoch 0), train_loss = 2.444, time/batch=0.101\n",
      "66/67600 (epoch 0), train_loss = 2.364, time/batch=0.108\n",
      "67/67600 (epoch 0), train_loss = 2.440, time/batch=0.087\n",
      "68/67600 (epoch 0), train_loss = 2.428, time/batch=0.059\n",
      "69/67600 (epoch 0), train_loss = 2.337, time/batch=0.056\n",
      "70/67600 (epoch 0), train_loss = 2.387, time/batch=0.075\n",
      "71/67600 (epoch 0), train_loss = 2.358, time/batch=0.059\n",
      "72/67600 (epoch 0), train_loss = 2.356, time/batch=0.077\n",
      "73/67600 (epoch 0), train_loss = 2.370, time/batch=0.143\n",
      "74/67600 (epoch 0), train_loss = 2.266, time/batch=0.104\n",
      "75/67600 (epoch 0), train_loss = 2.363, time/batch=0.105\n",
      "76/67600 (epoch 0), train_loss = 2.358, time/batch=0.104\n",
      "77/67600 (epoch 0), train_loss = 2.406, time/batch=0.205\n",
      "78/67600 (epoch 0), train_loss = 2.328, time/batch=0.087\n",
      "79/67600 (epoch 0), train_loss = 2.326, time/batch=0.066\n",
      "80/67600 (epoch 0), train_loss = 2.283, time/batch=0.071\n",
      "81/67600 (epoch 0), train_loss = 2.314, time/batch=0.068\n",
      "82/67600 (epoch 0), train_loss = 2.301, time/batch=0.057\n",
      "83/67600 (epoch 0), train_loss = 2.283, time/batch=0.067\n",
      "84/67600 (epoch 0), train_loss = 2.276, time/batch=0.076\n",
      "85/67600 (epoch 0), train_loss = 2.237, time/batch=0.118\n",
      "86/67600 (epoch 0), train_loss = 2.195, time/batch=0.093\n",
      "87/67600 (epoch 0), train_loss = 2.233, time/batch=0.092\n",
      "88/67600 (epoch 0), train_loss = 2.281, time/batch=0.099\n",
      "89/67600 (epoch 0), train_loss = 2.249, time/batch=0.088\n",
      "90/67600 (epoch 0), train_loss = 2.233, time/batch=0.194\n",
      "91/67600 (epoch 0), train_loss = 2.212, time/batch=0.091\n",
      "92/67600 (epoch 0), train_loss = 2.181, time/batch=0.130\n",
      "93/67600 (epoch 0), train_loss = 2.171, time/batch=0.106\n",
      "94/67600 (epoch 0), train_loss = 2.170, time/batch=0.085\n",
      "95/67600 (epoch 0), train_loss = 2.189, time/batch=0.208\n",
      "96/67600 (epoch 0), train_loss = 2.161, time/batch=0.124\n",
      "97/67600 (epoch 0), train_loss = 2.178, time/batch=0.118\n",
      "98/67600 (epoch 0), train_loss = 2.164, time/batch=0.082\n",
      "99/67600 (epoch 0), train_loss = 2.239, time/batch=0.065\n",
      "100/67600 (epoch 0), train_loss = 2.125, time/batch=0.063\n",
      "101/67600 (epoch 0), train_loss = 2.188, time/batch=0.137\n",
      "102/67600 (epoch 0), train_loss = 2.177, time/batch=0.102\n",
      "103/67600 (epoch 0), train_loss = 2.166, time/batch=0.128\n",
      "104/67600 (epoch 0), train_loss = 2.158, time/batch=0.088\n",
      "105/67600 (epoch 0), train_loss = 2.207, time/batch=0.095\n",
      "106/67600 (epoch 0), train_loss = 2.207, time/batch=0.096\n",
      "107/67600 (epoch 0), train_loss = 2.174, time/batch=0.084\n",
      "108/67600 (epoch 0), train_loss = 2.183, time/batch=0.067\n",
      "109/67600 (epoch 0), train_loss = 2.166, time/batch=0.064\n",
      "110/67600 (epoch 0), train_loss = 2.233, time/batch=0.059\n",
      "111/67600 (epoch 0), train_loss = 2.196, time/batch=0.080\n",
      "112/67600 (epoch 0), train_loss = 2.150, time/batch=0.134\n",
      "113/67600 (epoch 0), train_loss = 2.157, time/batch=0.130\n",
      "114/67600 (epoch 0), train_loss = 2.160, time/batch=0.110\n",
      "115/67600 (epoch 0), train_loss = 2.100, time/batch=0.063\n",
      "116/67600 (epoch 0), train_loss = 2.100, time/batch=0.069\n",
      "117/67600 (epoch 0), train_loss = 2.108, time/batch=0.072\n",
      "118/67600 (epoch 0), train_loss = 2.113, time/batch=0.060\n",
      "119/67600 (epoch 0), train_loss = 2.120, time/batch=0.063\n",
      "120/67600 (epoch 0), train_loss = 2.125, time/batch=0.162\n",
      "121/67600 (epoch 0), train_loss = 2.117, time/batch=0.231\n",
      "122/67600 (epoch 0), train_loss = 2.136, time/batch=0.088\n",
      "123/67600 (epoch 0), train_loss = 2.072, time/batch=0.194\n",
      "124/67600 (epoch 0), train_loss = 2.075, time/batch=0.087\n",
      "125/67600 (epoch 0), train_loss = 2.077, time/batch=0.082\n",
      "126/67600 (epoch 0), train_loss = 2.092, time/batch=0.088\n",
      "127/67600 (epoch 0), train_loss = 2.143, time/batch=0.224\n",
      "128/67600 (epoch 0), train_loss = 2.098, time/batch=0.089\n",
      "129/67600 (epoch 0), train_loss = 2.090, time/batch=0.081\n",
      "130/67600 (epoch 0), train_loss = 2.110, time/batch=0.096\n",
      "131/67600 (epoch 0), train_loss = 2.031, time/batch=0.193\n",
      "132/67600 (epoch 0), train_loss = 2.103, time/batch=0.114\n",
      "133/67600 (epoch 0), train_loss = 2.079, time/batch=0.062\n",
      "134/67600 (epoch 0), train_loss = 2.096, time/batch=0.062\n",
      "135/67600 (epoch 0), train_loss = 2.093, time/batch=0.058\n",
      "136/67600 (epoch 0), train_loss = 2.077, time/batch=0.064\n",
      "137/67600 (epoch 0), train_loss = 2.008, time/batch=0.073\n",
      "138/67600 (epoch 0), train_loss = 2.081, time/batch=0.067\n",
      "139/67600 (epoch 0), train_loss = 2.029, time/batch=0.076\n",
      "140/67600 (epoch 0), train_loss = 1.996, time/batch=0.088\n",
      "141/67600 (epoch 0), train_loss = 2.034, time/batch=0.073\n",
      "142/67600 (epoch 0), train_loss = 2.044, time/batch=0.085\n",
      "143/67600 (epoch 0), train_loss = 1.997, time/batch=0.135\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144/67600 (epoch 0), train_loss = 2.028, time/batch=0.100\n",
      "145/67600 (epoch 0), train_loss = 2.071, time/batch=0.114\n",
      "146/67600 (epoch 0), train_loss = 2.014, time/batch=0.109\n",
      "147/67600 (epoch 0), train_loss = 2.026, time/batch=0.121\n",
      "148/67600 (epoch 0), train_loss = 2.063, time/batch=0.094\n",
      "149/67600 (epoch 0), train_loss = 1.960, time/batch=0.081\n",
      "150/67600 (epoch 0), train_loss = 2.033, time/batch=0.063\n",
      "151/67600 (epoch 0), train_loss = 2.002, time/batch=0.065\n",
      "152/67600 (epoch 0), train_loss = 1.974, time/batch=0.067\n",
      "153/67600 (epoch 0), train_loss = 2.044, time/batch=0.069\n",
      "154/67600 (epoch 0), train_loss = 1.956, time/batch=0.067\n",
      "155/67600 (epoch 0), train_loss = 2.043, time/batch=0.081\n",
      "156/67600 (epoch 0), train_loss = 2.048, time/batch=0.103\n",
      "157/67600 (epoch 0), train_loss = 2.024, time/batch=0.086\n",
      "158/67600 (epoch 0), train_loss = 1.957, time/batch=0.092\n",
      "159/67600 (epoch 0), train_loss = 2.016, time/batch=0.074\n",
      "160/67600 (epoch 0), train_loss = 1.972, time/batch=0.064\n",
      "161/67600 (epoch 0), train_loss = 1.940, time/batch=0.061\n",
      "162/67600 (epoch 0), train_loss = 1.991, time/batch=0.091\n",
      "163/67600 (epoch 0), train_loss = 1.968, time/batch=0.118\n",
      "164/67600 (epoch 0), train_loss = 1.953, time/batch=0.216\n",
      "165/67600 (epoch 0), train_loss = 2.034, time/batch=0.060\n",
      "166/67600 (epoch 0), train_loss = 1.944, time/batch=0.061\n",
      "167/67600 (epoch 0), train_loss = 1.996, time/batch=0.066\n",
      "168/67600 (epoch 0), train_loss = 1.974, time/batch=0.077\n",
      "169/67600 (epoch 0), train_loss = 1.923, time/batch=0.067\n",
      "170/67600 (epoch 0), train_loss = 1.923, time/batch=0.060\n",
      "171/67600 (epoch 0), train_loss = 1.950, time/batch=0.061\n",
      "172/67600 (epoch 0), train_loss = 1.994, time/batch=0.078\n",
      "173/67600 (epoch 0), train_loss = 1.928, time/batch=0.129\n",
      "174/67600 (epoch 0), train_loss = 1.953, time/batch=0.089\n",
      "175/67600 (epoch 0), train_loss = 1.974, time/batch=0.109\n",
      "176/67600 (epoch 0), train_loss = 2.021, time/batch=0.107\n",
      "177/67600 (epoch 0), train_loss = 1.988, time/batch=0.109\n",
      "178/67600 (epoch 0), train_loss = 1.889, time/batch=0.068\n",
      "179/67600 (epoch 0), train_loss = 1.944, time/batch=0.082\n",
      "180/67600 (epoch 0), train_loss = 1.910, time/batch=0.068\n",
      "181/67600 (epoch 0), train_loss = 1.878, time/batch=0.067\n",
      "182/67600 (epoch 0), train_loss = 1.959, time/batch=0.074\n",
      "183/67600 (epoch 0), train_loss = 1.986, time/batch=0.121\n",
      "184/67600 (epoch 0), train_loss = 2.022, time/batch=0.113\n",
      "185/67600 (epoch 0), train_loss = 1.986, time/batch=0.136\n",
      "186/67600 (epoch 0), train_loss = 2.005, time/batch=0.209\n",
      "187/67600 (epoch 0), train_loss = 1.970, time/batch=0.109\n",
      "188/67600 (epoch 0), train_loss = 1.926, time/batch=0.117\n",
      "189/67600 (epoch 0), train_loss = 1.872, time/batch=0.097\n",
      "190/67600 (epoch 0), train_loss = 2.009, time/batch=0.114\n",
      "191/67600 (epoch 0), train_loss = 1.958, time/batch=0.136\n",
      "192/67600 (epoch 0), train_loss = 1.962, time/batch=0.118\n",
      "193/67600 (epoch 0), train_loss = 1.941, time/batch=0.076\n",
      "194/67600 (epoch 0), train_loss = 1.931, time/batch=0.080\n",
      "195/67600 (epoch 0), train_loss = 1.909, time/batch=0.160\n",
      "196/67600 (epoch 0), train_loss = 1.899, time/batch=0.101\n",
      "197/67600 (epoch 0), train_loss = 1.915, time/batch=0.117\n",
      "198/67600 (epoch 0), train_loss = 1.917, time/batch=0.189\n",
      "199/67600 (epoch 0), train_loss = 1.898, time/batch=0.112\n",
      "200/67600 (epoch 0), train_loss = 1.920, time/batch=0.064\n",
      "201/67600 (epoch 0), train_loss = 1.910, time/batch=0.063\n",
      "202/67600 (epoch 0), train_loss = 1.941, time/batch=0.078\n",
      "203/67600 (epoch 0), train_loss = 1.906, time/batch=0.103\n",
      "204/67600 (epoch 0), train_loss = 1.865, time/batch=0.109\n",
      "205/67600 (epoch 0), train_loss = 1.859, time/batch=0.102\n",
      "206/67600 (epoch 0), train_loss = 1.885, time/batch=0.129\n",
      "207/67600 (epoch 0), train_loss = 1.888, time/batch=0.219\n",
      "208/67600 (epoch 0), train_loss = 1.864, time/batch=0.067\n",
      "209/67600 (epoch 0), train_loss = 1.903, time/batch=0.061\n",
      "210/67600 (epoch 0), train_loss = 1.869, time/batch=0.080\n",
      "211/67600 (epoch 0), train_loss = 1.970, time/batch=0.094\n",
      "212/67600 (epoch 0), train_loss = 1.871, time/batch=0.086\n",
      "213/67600 (epoch 0), train_loss = 1.922, time/batch=0.115\n",
      "214/67600 (epoch 0), train_loss = 1.933, time/batch=0.105\n",
      "215/67600 (epoch 0), train_loss = 1.946, time/batch=0.096\n",
      "216/67600 (epoch 0), train_loss = 1.869, time/batch=0.101\n",
      "217/67600 (epoch 0), train_loss = 1.865, time/batch=0.096\n",
      "218/67600 (epoch 0), train_loss = 1.866, time/batch=0.094\n",
      "219/67600 (epoch 0), train_loss = 1.874, time/batch=0.093\n",
      "220/67600 (epoch 0), train_loss = 1.992, time/batch=0.090\n",
      "221/67600 (epoch 0), train_loss = 1.864, time/batch=0.088\n",
      "222/67600 (epoch 0), train_loss = 1.882, time/batch=0.086\n",
      "223/67600 (epoch 0), train_loss = 1.875, time/batch=0.110\n",
      "224/67600 (epoch 0), train_loss = 1.890, time/batch=0.085\n",
      "225/67600 (epoch 0), train_loss = 1.887, time/batch=0.115\n",
      "226/67600 (epoch 0), train_loss = 1.928, time/batch=0.089\n",
      "227/67600 (epoch 0), train_loss = 1.864, time/batch=0.069\n",
      "228/67600 (epoch 0), train_loss = 1.873, time/batch=0.071\n",
      "229/67600 (epoch 0), train_loss = 1.826, time/batch=0.116\n",
      "230/67600 (epoch 0), train_loss = 1.891, time/batch=0.101\n",
      "231/67600 (epoch 0), train_loss = 1.861, time/batch=0.096\n",
      "232/67600 (epoch 0), train_loss = 1.849, time/batch=0.093\n",
      "233/67600 (epoch 0), train_loss = 1.834, time/batch=0.087\n",
      "234/67600 (epoch 0), train_loss = 1.876, time/batch=0.100\n",
      "235/67600 (epoch 0), train_loss = 1.849, time/batch=0.100\n",
      "236/67600 (epoch 0), train_loss = 1.844, time/batch=0.091\n",
      "237/67600 (epoch 0), train_loss = 1.825, time/batch=0.072\n",
      "238/67600 (epoch 0), train_loss = 1.919, time/batch=0.073\n",
      "239/67600 (epoch 0), train_loss = 1.866, time/batch=0.094\n",
      "240/67600 (epoch 0), train_loss = 1.945, time/batch=0.091\n",
      "241/67600 (epoch 0), train_loss = 1.824, time/batch=0.092\n",
      "242/67600 (epoch 0), train_loss = 1.828, time/batch=0.087\n",
      "243/67600 (epoch 0), train_loss = 1.859, time/batch=0.111\n",
      "244/67600 (epoch 0), train_loss = 1.846, time/batch=0.100\n",
      "245/67600 (epoch 0), train_loss = 1.865, time/batch=0.076\n",
      "246/67600 (epoch 0), train_loss = 1.819, time/batch=0.060\n",
      "247/67600 (epoch 0), train_loss = 1.834, time/batch=0.060\n",
      "248/67600 (epoch 0), train_loss = 1.842, time/batch=0.080\n",
      "249/67600 (epoch 0), train_loss = 1.810, time/batch=0.068\n",
      "250/67600 (epoch 0), train_loss = 1.803, time/batch=0.065\n",
      "251/67600 (epoch 0), train_loss = 1.881, time/batch=0.058\n",
      "252/67600 (epoch 0), train_loss = 1.819, time/batch=0.076\n",
      "253/67600 (epoch 0), train_loss = 1.809, time/batch=0.090\n",
      "254/67600 (epoch 0), train_loss = 1.864, time/batch=0.085\n",
      "255/67600 (epoch 0), train_loss = 1.859, time/batch=0.108\n",
      "256/67600 (epoch 0), train_loss = 1.845, time/batch=0.083\n",
      "257/67600 (epoch 0), train_loss = 1.852, time/batch=0.087\n",
      "258/67600 (epoch 0), train_loss = 1.779, time/batch=0.082\n",
      "259/67600 (epoch 0), train_loss = 1.820, time/batch=0.110\n",
      "260/67600 (epoch 0), train_loss = 1.771, time/batch=0.065\n",
      "261/67600 (epoch 0), train_loss = 1.826, time/batch=0.081\n",
      "262/67600 (epoch 0), train_loss = 1.817, time/batch=0.066\n",
      "263/67600 (epoch 0), train_loss = 1.802, time/batch=0.066\n",
      "264/67600 (epoch 0), train_loss = 1.772, time/batch=0.065\n",
      "265/67600 (epoch 0), train_loss = 1.805, time/batch=0.081\n",
      "266/67600 (epoch 0), train_loss = 1.794, time/batch=0.074\n",
      "267/67600 (epoch 0), train_loss = 1.780, time/batch=0.074\n",
      "268/67600 (epoch 0), train_loss = 1.796, time/batch=0.080\n",
      "269/67600 (epoch 0), train_loss = 1.789, time/batch=0.223\n",
      "270/67600 (epoch 0), train_loss = 1.844, time/batch=0.095\n",
      "271/67600 (epoch 0), train_loss = 1.788, time/batch=0.103\n",
      "272/67600 (epoch 0), train_loss = 1.831, time/batch=0.083\n",
      "273/67600 (epoch 0), train_loss = 1.851, time/batch=0.114\n",
      "274/67600 (epoch 0), train_loss = 1.803, time/batch=0.099\n",
      "275/67600 (epoch 0), train_loss = 1.840, time/batch=0.083\n",
      "276/67600 (epoch 0), train_loss = 1.854, time/batch=0.105\n",
      "277/67600 (epoch 0), train_loss = 1.770, time/batch=0.082\n",
      "278/67600 (epoch 0), train_loss = 1.766, time/batch=0.068\n",
      "279/67600 (epoch 0), train_loss = 1.845, time/batch=0.096\n",
      "280/67600 (epoch 0), train_loss = 1.865, time/batch=0.179\n",
      "281/67600 (epoch 0), train_loss = 1.794, time/batch=0.103\n",
      "282/67600 (epoch 0), train_loss = 1.719, time/batch=0.085\n",
      "283/67600 (epoch 0), train_loss = 1.857, time/batch=0.090\n",
      "284/67600 (epoch 0), train_loss = 1.825, time/batch=0.092\n",
      "285/67600 (epoch 0), train_loss = 1.837, time/batch=0.083\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "286/67600 (epoch 0), train_loss = 1.814, time/batch=0.083\n",
      "287/67600 (epoch 0), train_loss = 1.841, time/batch=0.088\n",
      "288/67600 (epoch 0), train_loss = 1.821, time/batch=0.101\n",
      "289/67600 (epoch 0), train_loss = 1.888, time/batch=0.095\n",
      "290/67600 (epoch 0), train_loss = 1.826, time/batch=0.064\n",
      "291/67600 (epoch 0), train_loss = 1.782, time/batch=0.060\n",
      "292/67600 (epoch 0), train_loss = 1.803, time/batch=0.082\n",
      "293/67600 (epoch 0), train_loss = 1.806, time/batch=0.230\n",
      "294/67600 (epoch 0), train_loss = 1.840, time/batch=0.087\n",
      "295/67600 (epoch 0), train_loss = 1.832, time/batch=0.072\n",
      "296/67600 (epoch 0), train_loss = 1.797, time/batch=0.072\n",
      "297/67600 (epoch 0), train_loss = 1.780, time/batch=0.062\n",
      "298/67600 (epoch 0), train_loss = 1.767, time/batch=0.061\n",
      "299/67600 (epoch 0), train_loss = 1.854, time/batch=0.064\n",
      "300/67600 (epoch 0), train_loss = 1.803, time/batch=0.071\n",
      "301/67600 (epoch 0), train_loss = 1.828, time/batch=0.058\n",
      "302/67600 (epoch 0), train_loss = 1.806, time/batch=0.061\n",
      "303/67600 (epoch 0), train_loss = 1.782, time/batch=0.107\n",
      "304/67600 (epoch 0), train_loss = 1.828, time/batch=0.086\n",
      "305/67600 (epoch 0), train_loss = 1.828, time/batch=0.082\n",
      "306/67600 (epoch 0), train_loss = 1.785, time/batch=0.110\n",
      "307/67600 (epoch 0), train_loss = 1.778, time/batch=0.094\n",
      "308/67600 (epoch 0), train_loss = 1.834, time/batch=0.091\n",
      "309/67600 (epoch 0), train_loss = 1.809, time/batch=0.093\n",
      "310/67600 (epoch 0), train_loss = 1.771, time/batch=0.065\n",
      "311/67600 (epoch 0), train_loss = 1.805, time/batch=0.065\n",
      "312/67600 (epoch 0), train_loss = 1.734, time/batch=0.059\n",
      "313/67600 (epoch 0), train_loss = 1.780, time/batch=0.069\n",
      "314/67600 (epoch 0), train_loss = 1.795, time/batch=0.083\n",
      "315/67600 (epoch 0), train_loss = 1.855, time/batch=0.092\n",
      "316/67600 (epoch 0), train_loss = 1.839, time/batch=0.109\n",
      "317/67600 (epoch 0), train_loss = 1.785, time/batch=0.113\n",
      "318/67600 (epoch 0), train_loss = 1.803, time/batch=0.060\n",
      "319/67600 (epoch 0), train_loss = 1.837, time/batch=0.074\n",
      "320/67600 (epoch 0), train_loss = 1.860, time/batch=0.086\n",
      "321/67600 (epoch 0), train_loss = 1.766, time/batch=0.217\n",
      "322/67600 (epoch 0), train_loss = 1.760, time/batch=0.077\n",
      "323/67600 (epoch 0), train_loss = 1.780, time/batch=0.088\n",
      "324/67600 (epoch 0), train_loss = 1.787, time/batch=0.083\n",
      "325/67600 (epoch 0), train_loss = 1.793, time/batch=0.113\n",
      "326/67600 (epoch 0), train_loss = 1.772, time/batch=0.085\n",
      "327/67600 (epoch 0), train_loss = 1.766, time/batch=0.094\n",
      "328/67600 (epoch 0), train_loss = 1.751, time/batch=0.068\n",
      "329/67600 (epoch 0), train_loss = 1.851, time/batch=0.064\n",
      "330/67600 (epoch 0), train_loss = 1.775, time/batch=0.066\n",
      "331/67600 (epoch 0), train_loss = 1.743, time/batch=0.078\n",
      "332/67600 (epoch 0), train_loss = 1.814, time/batch=0.068\n",
      "333/67600 (epoch 0), train_loss = 1.739, time/batch=0.068\n",
      "334/67600 (epoch 0), train_loss = 1.737, time/batch=0.064\n",
      "335/67600 (epoch 0), train_loss = 1.748, time/batch=0.101\n",
      "336/67600 (epoch 0), train_loss = 1.760, time/batch=0.088\n",
      "337/67600 (epoch 0), train_loss = 1.773, time/batch=0.081\n",
      "338/67600 (epoch 0), train_loss = 1.816, time/batch=0.095\n",
      "339/67600 (epoch 0), train_loss = 1.770, time/batch=0.062\n",
      "340/67600 (epoch 0), train_loss = 1.722, time/batch=0.059\n",
      "341/67600 (epoch 0), train_loss = 1.783, time/batch=0.061\n",
      "342/67600 (epoch 0), train_loss = 1.696, time/batch=0.079\n",
      "343/67600 (epoch 0), train_loss = 1.701, time/batch=0.062\n",
      "344/67600 (epoch 0), train_loss = 1.764, time/batch=0.072\n",
      "345/67600 (epoch 0), train_loss = 1.828, time/batch=0.184\n",
      "346/67600 (epoch 0), train_loss = 1.773, time/batch=0.083\n",
      "347/67600 (epoch 0), train_loss = 1.736, time/batch=0.074\n",
      "348/67600 (epoch 0), train_loss = 1.811, time/batch=0.083\n",
      "349/67600 (epoch 0), train_loss = 1.774, time/batch=0.077\n",
      "350/67600 (epoch 0), train_loss = 1.742, time/batch=0.071\n",
      "351/67600 (epoch 0), train_loss = 1.698, time/batch=0.082\n",
      "352/67600 (epoch 0), train_loss = 1.705, time/batch=0.078\n",
      "353/67600 (epoch 0), train_loss = 1.709, time/batch=0.068\n",
      "354/67600 (epoch 0), train_loss = 1.720, time/batch=0.072\n",
      "355/67600 (epoch 0), train_loss = 1.776, time/batch=0.080\n",
      "356/67600 (epoch 0), train_loss = 1.742, time/batch=0.068\n",
      "357/67600 (epoch 0), train_loss = 1.687, time/batch=0.068\n",
      "358/67600 (epoch 0), train_loss = 1.676, time/batch=0.082\n",
      "359/67600 (epoch 0), train_loss = 1.816, time/batch=0.068\n",
      "360/67600 (epoch 0), train_loss = 1.803, time/batch=0.074\n",
      "361/67600 (epoch 0), train_loss = 1.669, time/batch=0.077\n",
      "362/67600 (epoch 0), train_loss = 1.721, time/batch=0.069\n",
      "363/67600 (epoch 0), train_loss = 1.770, time/batch=0.080\n",
      "364/67600 (epoch 0), train_loss = 1.770, time/batch=0.073\n",
      "365/67600 (epoch 0), train_loss = 1.764, time/batch=0.061\n",
      "366/67600 (epoch 0), train_loss = 1.744, time/batch=0.093\n",
      "367/67600 (epoch 0), train_loss = 1.665, time/batch=0.092\n",
      "368/67600 (epoch 0), train_loss = 1.716, time/batch=0.066\n",
      "369/67600 (epoch 0), train_loss = 1.794, time/batch=0.075\n",
      "370/67600 (epoch 0), train_loss = 1.719, time/batch=0.085\n",
      "371/67600 (epoch 0), train_loss = 1.786, time/batch=0.070\n",
      "372/67600 (epoch 0), train_loss = 1.756, time/batch=0.125\n",
      "373/67600 (epoch 0), train_loss = 1.724, time/batch=0.068\n",
      "374/67600 (epoch 0), train_loss = 1.774, time/batch=0.070\n",
      "375/67600 (epoch 0), train_loss = 1.806, time/batch=0.074\n",
      "376/67600 (epoch 0), train_loss = 1.759, time/batch=0.087\n",
      "377/67600 (epoch 0), train_loss = 1.702, time/batch=0.075\n",
      "378/67600 (epoch 0), train_loss = 1.738, time/batch=0.127\n",
      "379/67600 (epoch 0), train_loss = 1.791, time/batch=0.083\n",
      "380/67600 (epoch 0), train_loss = 1.745, time/batch=0.078\n",
      "381/67600 (epoch 0), train_loss = 1.720, time/batch=0.109\n",
      "382/67600 (epoch 0), train_loss = 1.756, time/batch=0.078\n",
      "383/67600 (epoch 0), train_loss = 1.718, time/batch=0.065\n",
      "384/67600 (epoch 0), train_loss = 1.826, time/batch=0.069\n",
      "385/67600 (epoch 0), train_loss = 1.704, time/batch=0.088\n",
      "386/67600 (epoch 0), train_loss = 1.730, time/batch=0.069\n",
      "387/67600 (epoch 0), train_loss = 1.728, time/batch=0.078\n",
      "388/67600 (epoch 0), train_loss = 1.706, time/batch=0.073\n",
      "389/67600 (epoch 0), train_loss = 1.699, time/batch=0.069\n",
      "390/67600 (epoch 0), train_loss = 1.715, time/batch=0.068\n",
      "391/67600 (epoch 0), train_loss = 1.692, time/batch=0.080\n",
      "392/67600 (epoch 0), train_loss = 1.679, time/batch=0.067\n",
      "393/67600 (epoch 0), train_loss = 1.748, time/batch=0.078\n",
      "394/67600 (epoch 0), train_loss = 1.715, time/batch=0.076\n",
      "395/67600 (epoch 0), train_loss = 1.717, time/batch=0.066\n",
      "396/67600 (epoch 0), train_loss = 1.753, time/batch=0.067\n",
      "397/67600 (epoch 0), train_loss = 1.798, time/batch=0.082\n",
      "398/67600 (epoch 0), train_loss = 1.667, time/batch=0.063\n",
      "399/67600 (epoch 0), train_loss = 1.711, time/batch=0.076\n",
      "400/67600 (epoch 0), train_loss = 1.787, time/batch=0.079\n",
      "401/67600 (epoch 0), train_loss = 1.807, time/batch=0.062\n",
      "402/67600 (epoch 0), train_loss = 1.770, time/batch=0.065\n",
      "403/67600 (epoch 0), train_loss = 1.716, time/batch=0.084\n",
      "404/67600 (epoch 0), train_loss = 1.790, time/batch=0.066\n",
      "405/67600 (epoch 0), train_loss = 1.747, time/batch=0.064\n",
      "406/67600 (epoch 0), train_loss = 1.862, time/batch=0.081\n",
      "407/67600 (epoch 0), train_loss = 1.714, time/batch=0.065\n",
      "408/67600 (epoch 0), train_loss = 1.719, time/batch=0.063\n",
      "409/67600 (epoch 0), train_loss = 1.763, time/batch=0.083\n",
      "410/67600 (epoch 0), train_loss = 1.690, time/batch=0.065\n",
      "411/67600 (epoch 0), train_loss = 1.673, time/batch=0.065\n",
      "412/67600 (epoch 0), train_loss = 1.718, time/batch=0.079\n",
      "413/67600 (epoch 0), train_loss = 1.724, time/batch=0.067\n",
      "414/67600 (epoch 0), train_loss = 1.707, time/batch=0.064\n",
      "415/67600 (epoch 0), train_loss = 1.754, time/batch=0.080\n",
      "416/67600 (epoch 0), train_loss = 1.706, time/batch=0.065\n",
      "417/67600 (epoch 0), train_loss = 1.713, time/batch=0.068\n",
      "418/67600 (epoch 0), train_loss = 1.744, time/batch=0.076\n",
      "419/67600 (epoch 0), train_loss = 1.740, time/batch=0.062\n",
      "420/67600 (epoch 0), train_loss = 1.691, time/batch=0.068\n",
      "421/67600 (epoch 0), train_loss = 1.687, time/batch=0.077\n",
      "422/67600 (epoch 0), train_loss = 1.678, time/batch=0.063\n",
      "423/67600 (epoch 0), train_loss = 1.704, time/batch=0.069\n",
      "424/67600 (epoch 0), train_loss = 1.731, time/batch=0.084\n",
      "425/67600 (epoch 0), train_loss = 1.699, time/batch=0.061\n",
      "426/67600 (epoch 0), train_loss = 1.730, time/batch=0.073\n",
      "427/67600 (epoch 0), train_loss = 1.695, time/batch=0.079\n",
      "428/67600 (epoch 0), train_loss = 1.616, time/batch=0.064\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "429/67600 (epoch 0), train_loss = 1.688, time/batch=0.075\n",
      "430/67600 (epoch 0), train_loss = 1.766, time/batch=0.079\n",
      "431/67600 (epoch 0), train_loss = 1.685, time/batch=0.107\n",
      "432/67600 (epoch 0), train_loss = 1.705, time/batch=0.092\n",
      "433/67600 (epoch 0), train_loss = 1.698, time/batch=0.060\n",
      "434/67600 (epoch 0), train_loss = 1.683, time/batch=0.085\n",
      "435/67600 (epoch 0), train_loss = 1.779, time/batch=0.067\n",
      "436/67600 (epoch 0), train_loss = 1.727, time/batch=0.074\n",
      "437/67600 (epoch 0), train_loss = 1.709, time/batch=0.065\n",
      "438/67600 (epoch 0), train_loss = 1.736, time/batch=0.067\n",
      "439/67600 (epoch 0), train_loss = 1.735, time/batch=0.069\n",
      "440/67600 (epoch 0), train_loss = 1.686, time/batch=0.059\n",
      "441/67600 (epoch 0), train_loss = 1.709, time/batch=0.065\n",
      "442/67600 (epoch 0), train_loss = 1.677, time/batch=0.079\n",
      "443/67600 (epoch 0), train_loss = 1.669, time/batch=0.064\n",
      "444/67600 (epoch 0), train_loss = 1.673, time/batch=0.067\n",
      "445/67600 (epoch 0), train_loss = 1.746, time/batch=0.062\n",
      "446/67600 (epoch 0), train_loss = 1.678, time/batch=0.069\n",
      "447/67600 (epoch 0), train_loss = 1.647, time/batch=0.082\n",
      "448/67600 (epoch 0), train_loss = 1.653, time/batch=0.064\n",
      "449/67600 (epoch 0), train_loss = 1.655, time/batch=0.060\n",
      "450/67600 (epoch 0), train_loss = 1.623, time/batch=0.067\n",
      "451/67600 (epoch 0), train_loss = 1.762, time/batch=0.063\n",
      "452/67600 (epoch 0), train_loss = 1.713, time/batch=0.058\n",
      "453/67600 (epoch 0), train_loss = 1.640, time/batch=0.071\n",
      "454/67600 (epoch 0), train_loss = 1.638, time/batch=0.060\n",
      "455/67600 (epoch 0), train_loss = 1.682, time/batch=0.059\n",
      "456/67600 (epoch 0), train_loss = 1.697, time/batch=0.061\n",
      "457/67600 (epoch 0), train_loss = 1.694, time/batch=0.073\n",
      "458/67600 (epoch 0), train_loss = 1.711, time/batch=0.065\n",
      "459/67600 (epoch 0), train_loss = 1.706, time/batch=0.069\n",
      "460/67600 (epoch 0), train_loss = 1.680, time/batch=0.062\n",
      "461/67600 (epoch 0), train_loss = 1.624, time/batch=0.073\n",
      "462/67600 (epoch 0), train_loss = 1.700, time/batch=0.067\n",
      "463/67600 (epoch 0), train_loss = 1.722, time/batch=0.062\n",
      "464/67600 (epoch 0), train_loss = 1.646, time/batch=0.071\n",
      "465/67600 (epoch 0), train_loss = 1.662, time/batch=0.075\n",
      "466/67600 (epoch 0), train_loss = 1.700, time/batch=0.065\n",
      "467/67600 (epoch 0), train_loss = 1.735, time/batch=0.061\n",
      "468/67600 (epoch 0), train_loss = 1.708, time/batch=0.062\n",
      "469/67600 (epoch 0), train_loss = 1.674, time/batch=0.112\n",
      "470/67600 (epoch 0), train_loss = 1.691, time/batch=0.097\n",
      "471/67600 (epoch 0), train_loss = 1.667, time/batch=0.104\n",
      "472/67600 (epoch 0), train_loss = 1.641, time/batch=0.223\n",
      "473/67600 (epoch 0), train_loss = 1.664, time/batch=0.103\n",
      "474/67600 (epoch 0), train_loss = 1.663, time/batch=0.086\n",
      "475/67600 (epoch 0), train_loss = 1.640, time/batch=0.140\n",
      "476/67600 (epoch 0), train_loss = 1.662, time/batch=0.109\n",
      "477/67600 (epoch 0), train_loss = 1.668, time/batch=0.108\n",
      "478/67600 (epoch 0), train_loss = 1.685, time/batch=0.087\n",
      "479/67600 (epoch 0), train_loss = 1.716, time/batch=0.087\n",
      "480/67600 (epoch 0), train_loss = 1.610, time/batch=0.129\n",
      "481/67600 (epoch 0), train_loss = 1.645, time/batch=0.114\n",
      "482/67600 (epoch 0), train_loss = 1.655, time/batch=0.120\n",
      "483/67600 (epoch 0), train_loss = 1.637, time/batch=0.123\n",
      "484/67600 (epoch 0), train_loss = 1.620, time/batch=0.111\n",
      "485/67600 (epoch 0), train_loss = 1.697, time/batch=0.146\n",
      "486/67600 (epoch 0), train_loss = 1.667, time/batch=0.101\n",
      "487/67600 (epoch 0), train_loss = 1.648, time/batch=0.114\n",
      "488/67600 (epoch 0), train_loss = 1.698, time/batch=0.092\n",
      "489/67600 (epoch 0), train_loss = 1.703, time/batch=0.099\n",
      "490/67600 (epoch 0), train_loss = 1.587, time/batch=0.097\n",
      "491/67600 (epoch 0), train_loss = 1.663, time/batch=0.093\n",
      "492/67600 (epoch 0), train_loss = 1.669, time/batch=0.114\n",
      "493/67600 (epoch 0), train_loss = 1.599, time/batch=0.078\n",
      "494/67600 (epoch 0), train_loss = 1.693, time/batch=0.101\n",
      "495/67600 (epoch 0), train_loss = 1.652, time/batch=0.131\n",
      "496/67600 (epoch 0), train_loss = 1.638, time/batch=0.124\n",
      "497/67600 (epoch 0), train_loss = 1.627, time/batch=0.094\n",
      "498/67600 (epoch 0), train_loss = 1.663, time/batch=0.075\n",
      "499/67600 (epoch 0), train_loss = 1.628, time/batch=0.071\n",
      "500/67600 (epoch 0), train_loss = 1.620, time/batch=0.065\n",
      "model saved to ./save/model.ckpt\n",
      "501/67600 (epoch 0), train_loss = 1.580, time/batch=0.126\n",
      "502/67600 (epoch 0), train_loss = 1.664, time/batch=0.077\n",
      "503/67600 (epoch 0), train_loss = 1.670, time/batch=0.092\n",
      "504/67600 (epoch 0), train_loss = 1.661, time/batch=0.182\n",
      "505/67600 (epoch 0), train_loss = 1.703, time/batch=0.080\n",
      "506/67600 (epoch 0), train_loss = 1.644, time/batch=0.063\n",
      "507/67600 (epoch 0), train_loss = 1.654, time/batch=0.058\n",
      "508/67600 (epoch 0), train_loss = 1.601, time/batch=0.082\n",
      "509/67600 (epoch 0), train_loss = 1.607, time/batch=0.123\n",
      "510/67600 (epoch 0), train_loss = 1.711, time/batch=0.103\n",
      "511/67600 (epoch 0), train_loss = 1.684, time/batch=0.127\n",
      "512/67600 (epoch 0), train_loss = 1.647, time/batch=0.110\n",
      "513/67600 (epoch 0), train_loss = 1.627, time/batch=0.104\n",
      "514/67600 (epoch 0), train_loss = 1.660, time/batch=0.070\n",
      "515/67600 (epoch 0), train_loss = 1.671, time/batch=0.079\n",
      "516/67600 (epoch 0), train_loss = 1.662, time/batch=0.067\n",
      "517/67600 (epoch 0), train_loss = 1.669, time/batch=0.092\n",
      "518/67600 (epoch 0), train_loss = 1.657, time/batch=0.074\n",
      "519/67600 (epoch 0), train_loss = 1.555, time/batch=0.069\n",
      "520/67600 (epoch 0), train_loss = 1.656, time/batch=0.102\n",
      "521/67600 (epoch 0), train_loss = 1.669, time/batch=0.158\n",
      "522/67600 (epoch 0), train_loss = 1.675, time/batch=0.103\n",
      "523/67600 (epoch 0), train_loss = 1.606, time/batch=0.066\n",
      "524/67600 (epoch 0), train_loss = 1.650, time/batch=0.064\n",
      "525/67600 (epoch 0), train_loss = 1.626, time/batch=0.078\n",
      "526/67600 (epoch 0), train_loss = 1.629, time/batch=0.066\n",
      "527/67600 (epoch 0), train_loss = 1.648, time/batch=0.059\n",
      "528/67600 (epoch 0), train_loss = 1.693, time/batch=0.081\n",
      "529/67600 (epoch 0), train_loss = 1.611, time/batch=0.076\n",
      "530/67600 (epoch 0), train_loss = 1.672, time/batch=0.099\n",
      "531/67600 (epoch 0), train_loss = 1.701, time/batch=0.112\n",
      "532/67600 (epoch 0), train_loss = 1.627, time/batch=0.080\n",
      "533/67600 (epoch 0), train_loss = 1.617, time/batch=0.146\n",
      "534/67600 (epoch 0), train_loss = 1.597, time/batch=0.126\n",
      "535/67600 (epoch 0), train_loss = 1.591, time/batch=0.072\n",
      "536/67600 (epoch 0), train_loss = 1.637, time/batch=0.193\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-6c3ccfbde0c1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0mfeed\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitial_state\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m             \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinal_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m             print(\"{}/{} (epoch {}), train_loss = {:.3f}, time/batch={:.3f}\".format(\n",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1122\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1124\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1125\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1321\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1325\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1304\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1305\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1306\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1308\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "num_epochs = 50\n",
    "learning_rate = 0.002\n",
    "decay_rate = 0.97\n",
    "save_dir = \"./save/\"\n",
    "save_every = 500\n",
    "\n",
    "\n",
    "tf.reset_default_graph()\n",
    "model = Model() \n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())   \n",
    "    saver = tf.train.Saver(tf.global_variables())\n",
    "\n",
    "    for e in range(num_epochs):\n",
    "        sess.run(tf.assign(model.lr, learning_rate*(decay_rate ** e)))\n",
    "        # reset the pointer to load from the beginning\n",
    "        pointer = 0\n",
    "        state = sess.run(model.initial_state)\n",
    "        for b in range(num_batches):\n",
    "            start = time.time()\n",
    "            x, y = x_batches[pointer], y_batches[pointer]\n",
    "            pointer += 1\n",
    "            feed = {model.input_data: x, model.output_data: y}\n",
    "            feed[model.initial_state] = state\n",
    "                \n",
    "            train_loss, state, _ = sess.run([model.cost, model.final_state, model.train_op], feed)\n",
    "            end = time.time()\n",
    "            print(\"{}/{} (epoch {}), train_loss = {:.3f}, time/batch={:.3f}\".format(\n",
    "                e * num_batches + b, num_epochs * num_batches, e, train_loss, end-start))\n",
    "            \n",
    "            if ( e * num_batches + b ) % save_every == 0 or ( \n",
    "                e == num_epochs - 1 and b == num_batches - 1):\n",
    "                checkpoint_path = os.path.join(save_dir, \"model.ckpt\")\n",
    "                saver.save(sess, checkpoint_path, global_step=e*num_batches + b)\n",
    "                print(\"model saved to {}\".format(checkpoint_path))\n",
    "                \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saver.saver_def.filename_tensor_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 产生一些句子试一试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./save/model.ckpt-500\n",
      "b' and interess.\"\\n\\n     \"Louted-rooked to thone co we-with foo hervers the deadper, deroubn, for the tage.\\n\\n     \"Boordinathere whot stanted an\\n     nenlifer, frabobing and feong to ond\\n     the\\n     tell offred tushingow It rage wh\\n     his musuppleds threr is gin come\\'s the kevericelds, and a redorness, and a dees\\n     rearse\\n     pfors a saged and thrred to With on\\n     the poring the wimed th he pater of mary he \"What he glought upond upon cloopen ofred heriging up. To the strateen to the paces'\n"
     ]
    }
   ],
   "source": [
    "n = 500\n",
    "prime = \" \"\n",
    "\n",
    "tf.reset_default_graph()\n",
    "model = Model(training=False)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    tf.global_variables_initializer().run()\n",
    "    saver = tf.train.Saver(tf.global_variables())\n",
    "    ckpt = tf.train.get_checkpoint_state(save_dir)\n",
    "    if ckpt and ckpt.model_checkpoint_path:\n",
    "        saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "        print(model.sample(sess, chars, vocab, n, prime).encode(\"utf-8\"))\n",
    "\n",
    "\n",
    "# with open(os.path.join(save_dir, \"config.pkl\"), \"rb\") as f:\n",
    "#     saved_args = cPickle.load(f)\n",
    "# with open(os.path.join(save_dir, \"chars_vocab.pkl\"), \"rb\") as f:\n",
    "#     chars, vocab = cPickle.load(f)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
