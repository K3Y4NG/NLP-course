{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "from six.moves import cPickle\n",
    "import collections\n",
    "import numpy as np\n",
    "import codecs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 读取和预处理数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "请打开terminal并cd到当前notebook所在目录，执行下列命令\n",
    "```\n",
    "mkdir data\n",
    "cd data\n",
    "mkdir sherlock\n",
    "cd sherlock\n",
    "wget https://sherlock-holm.es/stories/plain-text/cnus.txt\n",
    "mv cnus.txt input.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"./data/sherlock/\"\n",
    "\n",
    "\n",
    "input_file = os.path.join(data_dir, \"input.txt\")\n",
    "vocab_file = os.path.join(data_dir, \"vocab.pkl\")\n",
    "tensor_file = os.path.join(data_dir, \"data.npy\")\n",
    "    \n",
    "\n",
    "with codecs.open(input_file, \"r\", encoding=\"utf-8\") as f:\n",
    "    data = f.read()\n",
    "counter = collections.Counter(data)\n",
    "counter_pairs = sorted(counter.items(), key=lambda x: -x[1])\n",
    "chars, _ = zip(*counter_pairs)\n",
    "vocab_size = len(chars)\n",
    "vocab = dict(zip(chars, range(len(chars))))\n",
    "tensor = np.array(list(map(vocab.get, data)))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 把数据处理成batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 50\n",
    "seq_length = 50\n",
    "num_batches = int(tensor.size / (batch_size * seq_length))\n",
    "if num_batches == 0:\n",
    "    assert False, \"Not enough data. Make seq_length and batch_size small.\"\n",
    "tensor = tensor[:num_batches * batch_size * seq_length]\n",
    "xdata = tensor\n",
    "ydata = np.copy(tensor)\n",
    "ydata[:-1] = xdata[1:]\n",
    "ydata[-1] = xdata[0]\n",
    "x_batches = np.split(xdata.reshape(batch_size, -1), num_batches, 1)\n",
    "y_batches = np.split(ydata.reshape(batch_size, -1), num_batches, 1)\n",
    "pointer = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义RNN模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.contrib import rnn\n",
    "from tensorflow.contrib import legacy_seq2seq\n",
    "\n",
    "\n",
    "class Model():\n",
    "    def __init__(self, training=True):\n",
    "        self.batch_size = 50\n",
    "        self.seq_length = 50\n",
    "        if not training:\n",
    "            self.batch_size = 1\n",
    "            self.seq_length = 1\n",
    "            \n",
    "        self.rnn_size = 128\n",
    "        self.num_layers = 2\n",
    "        self.input_keep_prob = 1.0\n",
    "        self.output_keep_prob = 1.0\n",
    "        self.grad_clip = 5.0\n",
    "        self.training = 1\n",
    "\n",
    "        cell_fn = rnn.BasicRNNCell\n",
    "\n",
    "        cells = []\n",
    "        for _ in range(self.num_layers):\n",
    "            cell = cell_fn(self.rnn_size)\n",
    "            # dropout\n",
    "            if training and (self.input_keep_prob < 1.0 or self.output_keep_prob < 1.0):\n",
    "                cell = rnn.DropoutWrapper(cell, input_keep_prob=self.input_keep_prob,\n",
    "                                         output_keep_prob=self.output_keep_prob)\n",
    "            cells.append(cell)\n",
    "\n",
    "        self.cell = cell = rnn.MultiRNNCell(cells, state_is_tuple=True)\n",
    "\n",
    "        # placeholder for input and output\n",
    "        self.input_data = tf.placeholder(tf.int32, [self.batch_size, self.seq_length])\n",
    "        self.output_data = tf.placeholder(tf.int32, [self.batch_size, self.seq_length])\n",
    "        self.initial_state = cell.zero_state(self.batch_size, tf.float32)\n",
    "        with tf.variable_scope(\"rnnlm\"):\n",
    "            softmax_w = tf.get_variable(\"softmax_w\", [self.rnn_size, vocab_size])\n",
    "            softmax_b = tf.get_variable(\"softmax_b\", [vocab_size])\n",
    "        embedding = tf.get_variable(\"embedding\", [vocab_size, self.rnn_size])\n",
    "        inputs = tf.nn.embedding_lookup(embedding, self.input_data)\n",
    "        if training and self.output_keep_prob:\n",
    "            inputs = tf.nn.dropout(inputs, self.output_keep_prob)\n",
    "\n",
    "        inputs = tf.split(inputs, self.seq_length, 1)\n",
    "        inputs = [tf.squeeze(input_, [1]) for input_ in inputs]\n",
    "\n",
    "        def loop(prev, _):\n",
    "            prev = tf.matmul(prev, softmax_w) + softmax_b\n",
    "            prev_symbol = tf.stop_gradient(tf.argmax(prev, 1))\n",
    "            return tf.nn.embedding_lookup(embedding, prev_symbol)\n",
    "\n",
    "        outputs, last_state = legacy_seq2seq.rnn_decoder(inputs, self.initial_state, cell, \n",
    "                                                         loop_function=loop if not training else None, scope=\"rnnlm\")\n",
    "        output = tf.reshape(tf.concat(outputs, 1), [-1, self.rnn_size])\n",
    "        self.logits = tf.matmul(output, softmax_w) + softmax_b\n",
    "        self.probs = tf.nn.softmax(self.logits)\n",
    "        loss = legacy_seq2seq.sequence_loss_by_example([self.logits],\n",
    "                                                      [tf.reshape(self.output_data, [-1])],\n",
    "                                                      [tf.ones([self.batch_size * self.seq_length])])\n",
    "        with tf.name_scope(\"cost\"):\n",
    "            self.cost = tf.reduce_sum(loss) / batch_size / seq_length\n",
    "        self.final_state = last_state\n",
    "        self.lr = tf.Variable(0.0, trainable=False)\n",
    "        # gradient clipping on trainable variables\n",
    "        tvars = tf.trainable_variables()\n",
    "        grads, _ = tf.clip_by_global_norm(tf.gradients(self.cost, tvars), self.grad_clip)\n",
    "\n",
    "        # optimizer and train\n",
    "        with tf.name_scope(\"optimizer\"):\n",
    "            optimizer = tf.train.AdamOptimizer(self.lr)\n",
    "        self.train_op = optimizer.apply_gradients(zip(grads, tvars))\n",
    "    \n",
    "    def sample(self, sess, chars, vocab, num=200, prime=\"The \"):\n",
    "        state = sess.run(self.cell.zero_state(1, tf.float32))\n",
    "        for char in prime[:-1]:\n",
    "            x = np.zeros((1,1))\n",
    "            x[0, 0] = vocab[char]\n",
    "            feed = {self.input_data: x, self.initial_state: state}\n",
    "            [state] = sess.run([self.final_state], feed)\n",
    "\n",
    "        def weighted_pick(weights):\n",
    "            t = np.cumsum(weights)\n",
    "            s = np.sum(weights)\n",
    "            return (int(np.searchsorted(t, np.random.rand(1)*s)))\n",
    "\n",
    "        ret = prime\n",
    "        char = prime[-1]\n",
    "        for n in range(num):\n",
    "            x = np.zeros((1,1))\n",
    "            x[0, 0] = vocab[char]\n",
    "            feed = {self.input_data: x, self.initial_state: state}\n",
    "            [p, state] = sess.run([self.probs, self.final_state], feed)\n",
    "            p = p[0]\n",
    "            sample = weighted_pick(p)\n",
    "\n",
    "            pred = chars[sample]\n",
    "            ret += pred\n",
    "            char = pred\n",
    "        return ret\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 开始训练RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/67600 (epoch 0), train_loss = 4.606, time/batch=0.441\n",
      "model saved to ./save/model.ckpt\n",
      "1/67600 (epoch 0), train_loss = 4.428, time/batch=0.073\n",
      "2/67600 (epoch 0), train_loss = 4.092, time/batch=0.075\n",
      "3/67600 (epoch 0), train_loss = 3.728, time/batch=0.073\n",
      "4/67600 (epoch 0), train_loss = 3.528, time/batch=0.147\n",
      "5/67600 (epoch 0), train_loss = 3.380, time/batch=0.169\n",
      "6/67600 (epoch 0), train_loss = 3.286, time/batch=0.093\n",
      "7/67600 (epoch 0), train_loss = 3.208, time/batch=0.069\n",
      "8/67600 (epoch 0), train_loss = 3.147, time/batch=0.072\n",
      "9/67600 (epoch 0), train_loss = 3.075, time/batch=0.076\n",
      "10/67600 (epoch 0), train_loss = 3.015, time/batch=0.082\n",
      "11/67600 (epoch 0), train_loss = 3.030, time/batch=0.072\n",
      "12/67600 (epoch 0), train_loss = 3.025, time/batch=0.071\n",
      "13/67600 (epoch 0), train_loss = 3.005, time/batch=0.079\n",
      "14/67600 (epoch 0), train_loss = 3.018, time/batch=0.073\n",
      "15/67600 (epoch 0), train_loss = 2.967, time/batch=0.069\n",
      "16/67600 (epoch 0), train_loss = 3.000, time/batch=0.194\n",
      "17/67600 (epoch 0), train_loss = 2.998, time/batch=0.096\n",
      "18/67600 (epoch 0), train_loss = 2.970, time/batch=0.081\n",
      "19/67600 (epoch 0), train_loss = 2.982, time/batch=0.071\n",
      "20/67600 (epoch 0), train_loss = 2.920, time/batch=0.071\n",
      "21/67600 (epoch 0), train_loss = 2.964, time/batch=0.072\n",
      "22/67600 (epoch 0), train_loss = 2.962, time/batch=0.079\n",
      "23/67600 (epoch 0), train_loss = 2.924, time/batch=0.071\n",
      "24/67600 (epoch 0), train_loss = 2.984, time/batch=0.070\n",
      "25/67600 (epoch 0), train_loss = 2.921, time/batch=0.074\n",
      "26/67600 (epoch 0), train_loss = 2.917, time/batch=0.074\n",
      "27/67600 (epoch 0), train_loss = 2.941, time/batch=0.070\n",
      "28/67600 (epoch 0), train_loss = 2.905, time/batch=0.221\n",
      "29/67600 (epoch 0), train_loss = 2.838, time/batch=0.076\n",
      "30/67600 (epoch 0), train_loss = 2.861, time/batch=0.071\n",
      "31/67600 (epoch 0), train_loss = 2.888, time/batch=0.073\n",
      "32/67600 (epoch 0), train_loss = 2.848, time/batch=0.069\n",
      "33/67600 (epoch 0), train_loss = 2.819, time/batch=0.080\n",
      "34/67600 (epoch 0), train_loss = 2.817, time/batch=0.112\n",
      "35/67600 (epoch 0), train_loss = 2.790, time/batch=0.150\n",
      "36/67600 (epoch 0), train_loss = 2.740, time/batch=0.127\n",
      "37/67600 (epoch 0), train_loss = 2.758, time/batch=0.109\n",
      "38/67600 (epoch 0), train_loss = 2.768, time/batch=0.074\n",
      "39/67600 (epoch 0), train_loss = 2.729, time/batch=0.072\n",
      "40/67600 (epoch 0), train_loss = 2.684, time/batch=0.077\n",
      "41/67600 (epoch 0), train_loss = 2.699, time/batch=0.071\n",
      "42/67600 (epoch 0), train_loss = 2.688, time/batch=0.073\n",
      "43/67600 (epoch 0), train_loss = 2.689, time/batch=0.075\n",
      "44/67600 (epoch 0), train_loss = 2.675, time/batch=0.069\n",
      "45/67600 (epoch 0), train_loss = 2.647, time/batch=0.078\n",
      "46/67600 (epoch 0), train_loss = 2.609, time/batch=0.075\n",
      "47/67600 (epoch 0), train_loss = 2.616, time/batch=0.194\n",
      "48/67600 (epoch 0), train_loss = 2.536, time/batch=0.072\n",
      "49/67600 (epoch 0), train_loss = 2.503, time/batch=0.110\n",
      "50/67600 (epoch 0), train_loss = 2.617, time/batch=0.073\n",
      "51/67600 (epoch 0), train_loss = 2.550, time/batch=0.073\n",
      "52/67600 (epoch 0), train_loss = 2.482, time/batch=0.075\n",
      "53/67600 (epoch 0), train_loss = 2.549, time/batch=0.075\n",
      "54/67600 (epoch 0), train_loss = 2.518, time/batch=0.080\n",
      "55/67600 (epoch 0), train_loss = 2.423, time/batch=0.076\n",
      "56/67600 (epoch 0), train_loss = 2.465, time/batch=0.104\n",
      "57/67600 (epoch 0), train_loss = 2.474, time/batch=0.087\n",
      "58/67600 (epoch 0), train_loss = 2.386, time/batch=0.199\n",
      "59/67600 (epoch 0), train_loss = 2.404, time/batch=0.131\n",
      "60/67600 (epoch 0), train_loss = 2.374, time/batch=0.076\n",
      "61/67600 (epoch 0), train_loss = 2.382, time/batch=0.070\n",
      "62/67600 (epoch 0), train_loss = 2.413, time/batch=0.102\n",
      "63/67600 (epoch 0), train_loss = 2.367, time/batch=0.072\n",
      "64/67600 (epoch 0), train_loss = 2.334, time/batch=0.071\n",
      "65/67600 (epoch 0), train_loss = 2.376, time/batch=0.074\n",
      "66/67600 (epoch 0), train_loss = 2.289, time/batch=0.094\n",
      "67/67600 (epoch 0), train_loss = 2.360, time/batch=0.079\n",
      "68/67600 (epoch 0), train_loss = 2.352, time/batch=0.229\n",
      "69/67600 (epoch 0), train_loss = 2.271, time/batch=0.097\n",
      "70/67600 (epoch 0), train_loss = 2.315, time/batch=0.071\n",
      "71/67600 (epoch 0), train_loss = 2.304, time/batch=0.075\n",
      "72/67600 (epoch 0), train_loss = 2.286, time/batch=0.079\n",
      "73/67600 (epoch 0), train_loss = 2.332, time/batch=0.087\n",
      "74/67600 (epoch 0), train_loss = 2.203, time/batch=0.072\n",
      "75/67600 (epoch 0), train_loss = 2.308, time/batch=0.071\n",
      "76/67600 (epoch 0), train_loss = 2.303, time/batch=0.094\n",
      "77/67600 (epoch 0), train_loss = 2.357, time/batch=0.077\n",
      "78/67600 (epoch 0), train_loss = 2.289, time/batch=0.072\n",
      "79/67600 (epoch 0), train_loss = 2.255, time/batch=0.239\n",
      "80/67600 (epoch 0), train_loss = 2.220, time/batch=0.086\n",
      "81/67600 (epoch 0), train_loss = 2.264, time/batch=0.071\n",
      "82/67600 (epoch 0), train_loss = 2.251, time/batch=0.094\n",
      "83/67600 (epoch 0), train_loss = 2.240, time/batch=0.077\n",
      "84/67600 (epoch 0), train_loss = 2.248, time/batch=0.076\n",
      "85/67600 (epoch 0), train_loss = 2.182, time/batch=0.071\n",
      "86/67600 (epoch 0), train_loss = 2.141, time/batch=0.116\n",
      "87/67600 (epoch 0), train_loss = 2.189, time/batch=0.125\n",
      "88/67600 (epoch 0), train_loss = 2.222, time/batch=0.107\n",
      "89/67600 (epoch 0), train_loss = 2.200, time/batch=0.072\n",
      "90/67600 (epoch 0), train_loss = 2.192, time/batch=0.076\n",
      "91/67600 (epoch 0), train_loss = 2.164, time/batch=0.075\n",
      "92/67600 (epoch 0), train_loss = 2.121, time/batch=0.070\n",
      "93/67600 (epoch 0), train_loss = 2.115, time/batch=0.083\n",
      "94/67600 (epoch 0), train_loss = 2.124, time/batch=0.083\n",
      "95/67600 (epoch 0), train_loss = 2.146, time/batch=0.069\n",
      "96/67600 (epoch 0), train_loss = 2.111, time/batch=0.070\n",
      "97/67600 (epoch 0), train_loss = 2.128, time/batch=0.074\n",
      "98/67600 (epoch 0), train_loss = 2.108, time/batch=0.185\n",
      "99/67600 (epoch 0), train_loss = 2.192, time/batch=0.073\n",
      "100/67600 (epoch 0), train_loss = 2.059, time/batch=0.077\n",
      "101/67600 (epoch 0), train_loss = 2.151, time/batch=0.149\n",
      "102/67600 (epoch 0), train_loss = 2.128, time/batch=0.096\n",
      "103/67600 (epoch 0), train_loss = 2.128, time/batch=0.103\n",
      "104/67600 (epoch 0), train_loss = 2.102, time/batch=0.118\n",
      "105/67600 (epoch 0), train_loss = 2.171, time/batch=0.112\n",
      "106/67600 (epoch 0), train_loss = 2.160, time/batch=0.101\n",
      "107/67600 (epoch 0), train_loss = 2.128, time/batch=0.240\n",
      "108/67600 (epoch 0), train_loss = 2.120, time/batch=0.155\n",
      "109/67600 (epoch 0), train_loss = 2.124, time/batch=0.096\n",
      "110/67600 (epoch 0), train_loss = 2.207, time/batch=0.098\n",
      "111/67600 (epoch 0), train_loss = 2.167, time/batch=0.088\n",
      "112/67600 (epoch 0), train_loss = 2.123, time/batch=0.095\n",
      "113/67600 (epoch 0), train_loss = 2.113, time/batch=0.089\n",
      "114/67600 (epoch 0), train_loss = 2.121, time/batch=0.075\n",
      "115/67600 (epoch 0), train_loss = 2.063, time/batch=0.072\n",
      "116/67600 (epoch 0), train_loss = 2.061, time/batch=0.208\n",
      "117/67600 (epoch 0), train_loss = 2.075, time/batch=0.088\n",
      "118/67600 (epoch 0), train_loss = 2.069, time/batch=0.069\n",
      "119/67600 (epoch 0), train_loss = 2.070, time/batch=0.069\n",
      "120/67600 (epoch 0), train_loss = 2.088, time/batch=0.075\n",
      "121/67600 (epoch 0), train_loss = 2.092, time/batch=0.073\n",
      "122/67600 (epoch 0), train_loss = 2.097, time/batch=0.072\n",
      "123/67600 (epoch 0), train_loss = 2.030, time/batch=0.070\n",
      "124/67600 (epoch 0), train_loss = 2.068, time/batch=0.071\n",
      "125/67600 (epoch 0), train_loss = 2.045, time/batch=0.071\n",
      "126/67600 (epoch 0), train_loss = 2.077, time/batch=0.070\n",
      "127/67600 (epoch 0), train_loss = 2.130, time/batch=0.078\n",
      "128/67600 (epoch 0), train_loss = 2.074, time/batch=0.213\n",
      "129/67600 (epoch 0), train_loss = 2.059, time/batch=0.084\n",
      "130/67600 (epoch 0), train_loss = 2.085, time/batch=0.073\n",
      "131/67600 (epoch 0), train_loss = 2.009, time/batch=0.072\n",
      "132/67600 (epoch 0), train_loss = 2.083, time/batch=0.071\n",
      "133/67600 (epoch 0), train_loss = 2.079, time/batch=0.072\n",
      "134/67600 (epoch 0), train_loss = 2.079, time/batch=0.079\n",
      "135/67600 (epoch 0), train_loss = 2.071, time/batch=0.071\n",
      "136/67600 (epoch 0), train_loss = 2.060, time/batch=0.072\n",
      "137/67600 (epoch 0), train_loss = 1.975, time/batch=0.071\n",
      "138/67600 (epoch 0), train_loss = 2.063, time/batch=0.070\n",
      "139/67600 (epoch 0), train_loss = 2.012, time/batch=0.201\n",
      "140/67600 (epoch 0), train_loss = 1.982, time/batch=0.094\n",
      "141/67600 (epoch 0), train_loss = 2.001, time/batch=0.076\n",
      "142/67600 (epoch 0), train_loss = 2.039, time/batch=0.072\n",
      "143/67600 (epoch 0), train_loss = 1.971, time/batch=0.069\n",
      "144/67600 (epoch 0), train_loss = 2.009, time/batch=0.070\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "145/67600 (epoch 0), train_loss = 2.063, time/batch=0.071\n",
      "146/67600 (epoch 0), train_loss = 2.001, time/batch=0.075\n",
      "147/67600 (epoch 0), train_loss = 2.009, time/batch=0.070\n",
      "148/67600 (epoch 0), train_loss = 2.052, time/batch=0.117\n",
      "149/67600 (epoch 0), train_loss = 1.935, time/batch=0.071\n",
      "150/67600 (epoch 0), train_loss = 2.010, time/batch=0.071\n",
      "151/67600 (epoch 0), train_loss = 1.979, time/batch=0.073\n",
      "152/67600 (epoch 0), train_loss = 1.963, time/batch=0.069\n",
      "153/67600 (epoch 0), train_loss = 2.025, time/batch=0.075\n",
      "154/67600 (epoch 0), train_loss = 1.948, time/batch=0.073\n",
      "155/67600 (epoch 0), train_loss = 2.017, time/batch=0.069\n",
      "156/67600 (epoch 0), train_loss = 2.032, time/batch=0.069\n",
      "157/67600 (epoch 0), train_loss = 2.016, time/batch=0.077\n",
      "158/67600 (epoch 0), train_loss = 1.942, time/batch=0.233\n",
      "159/67600 (epoch 0), train_loss = 1.999, time/batch=0.073\n",
      "160/67600 (epoch 0), train_loss = 1.977, time/batch=0.088\n",
      "161/67600 (epoch 0), train_loss = 1.915, time/batch=0.068\n",
      "162/67600 (epoch 0), train_loss = 2.000, time/batch=0.069\n",
      "163/67600 (epoch 0), train_loss = 1.971, time/batch=0.069\n",
      "164/67600 (epoch 0), train_loss = 1.926, time/batch=0.074\n",
      "165/67600 (epoch 0), train_loss = 2.012, time/batch=0.072\n",
      "166/67600 (epoch 0), train_loss = 1.922, time/batch=0.072\n",
      "167/67600 (epoch 0), train_loss = 1.978, time/batch=0.071\n",
      "168/67600 (epoch 0), train_loss = 1.965, time/batch=0.068\n",
      "169/67600 (epoch 0), train_loss = 1.923, time/batch=0.067\n",
      "170/67600 (epoch 0), train_loss = 1.910, time/batch=0.216\n",
      "171/67600 (epoch 0), train_loss = 1.940, time/batch=0.077\n",
      "172/67600 (epoch 0), train_loss = 1.994, time/batch=0.071\n",
      "173/67600 (epoch 0), train_loss = 1.911, time/batch=0.070\n",
      "174/67600 (epoch 0), train_loss = 1.947, time/batch=0.082\n",
      "175/67600 (epoch 0), train_loss = 1.950, time/batch=0.073\n",
      "176/67600 (epoch 0), train_loss = 2.002, time/batch=0.071\n",
      "177/67600 (epoch 0), train_loss = 1.977, time/batch=0.072\n",
      "178/67600 (epoch 0), train_loss = 1.880, time/batch=0.164\n",
      "179/67600 (epoch 0), train_loss = 1.939, time/batch=0.090\n",
      "180/67600 (epoch 0), train_loss = 1.894, time/batch=0.114\n",
      "181/67600 (epoch 0), train_loss = 1.863, time/batch=0.072\n",
      "182/67600 (epoch 0), train_loss = 1.942, time/batch=0.071\n",
      "183/67600 (epoch 0), train_loss = 1.989, time/batch=0.096\n",
      "184/67600 (epoch 0), train_loss = 2.021, time/batch=0.071\n",
      "185/67600 (epoch 0), train_loss = 1.970, time/batch=0.074\n",
      "186/67600 (epoch 0), train_loss = 1.987, time/batch=0.074\n",
      "187/67600 (epoch 0), train_loss = 1.953, time/batch=0.071\n",
      "188/67600 (epoch 0), train_loss = 1.904, time/batch=0.071\n",
      "189/67600 (epoch 0), train_loss = 1.864, time/batch=0.072\n",
      "190/67600 (epoch 0), train_loss = 2.001, time/batch=0.181\n",
      "191/67600 (epoch 0), train_loss = 1.961, time/batch=0.081\n",
      "192/67600 (epoch 0), train_loss = 1.949, time/batch=0.108\n",
      "193/67600 (epoch 0), train_loss = 1.928, time/batch=0.073\n",
      "194/67600 (epoch 0), train_loss = 1.927, time/batch=0.070\n",
      "195/67600 (epoch 0), train_loss = 1.901, time/batch=0.076\n",
      "196/67600 (epoch 0), train_loss = 1.895, time/batch=0.071\n",
      "197/67600 (epoch 0), train_loss = 1.906, time/batch=0.076\n",
      "198/67600 (epoch 0), train_loss = 1.902, time/batch=0.072\n",
      "199/67600 (epoch 0), train_loss = 1.887, time/batch=0.069\n",
      "200/67600 (epoch 0), train_loss = 1.905, time/batch=0.072\n",
      "201/67600 (epoch 0), train_loss = 1.902, time/batch=0.092\n",
      "202/67600 (epoch 0), train_loss = 1.936, time/batch=0.167\n",
      "203/67600 (epoch 0), train_loss = 1.895, time/batch=0.112\n",
      "204/67600 (epoch 0), train_loss = 1.867, time/batch=0.076\n",
      "205/67600 (epoch 0), train_loss = 1.852, time/batch=0.072\n",
      "206/67600 (epoch 0), train_loss = 1.877, time/batch=0.073\n",
      "207/67600 (epoch 0), train_loss = 1.871, time/batch=0.068\n",
      "208/67600 (epoch 0), train_loss = 1.867, time/batch=0.072\n",
      "209/67600 (epoch 0), train_loss = 1.895, time/batch=0.072\n",
      "210/67600 (epoch 0), train_loss = 1.856, time/batch=0.076\n",
      "211/67600 (epoch 0), train_loss = 1.965, time/batch=0.071\n",
      "212/67600 (epoch 0), train_loss = 1.855, time/batch=0.071\n",
      "213/67600 (epoch 0), train_loss = 1.907, time/batch=0.171\n",
      "214/67600 (epoch 0), train_loss = 1.915, time/batch=0.085\n",
      "215/67600 (epoch 0), train_loss = 1.931, time/batch=0.102\n",
      "216/67600 (epoch 0), train_loss = 1.844, time/batch=0.071\n",
      "217/67600 (epoch 0), train_loss = 1.871, time/batch=0.070\n",
      "218/67600 (epoch 0), train_loss = 1.861, time/batch=0.071\n",
      "219/67600 (epoch 0), train_loss = 1.873, time/batch=0.068\n",
      "220/67600 (epoch 0), train_loss = 1.981, time/batch=0.067\n",
      "221/67600 (epoch 0), train_loss = 1.841, time/batch=0.073\n",
      "222/67600 (epoch 0), train_loss = 1.863, time/batch=0.075\n",
      "223/67600 (epoch 0), train_loss = 1.872, time/batch=0.068\n",
      "224/67600 (epoch 0), train_loss = 1.867, time/batch=0.073\n",
      "225/67600 (epoch 0), train_loss = 1.888, time/batch=0.173\n",
      "226/67600 (epoch 0), train_loss = 1.913, time/batch=0.109\n",
      "227/67600 (epoch 0), train_loss = 1.844, time/batch=0.084\n",
      "228/67600 (epoch 0), train_loss = 1.853, time/batch=0.070\n",
      "229/67600 (epoch 0), train_loss = 1.823, time/batch=0.072\n",
      "230/67600 (epoch 0), train_loss = 1.888, time/batch=0.074\n",
      "231/67600 (epoch 0), train_loss = 1.844, time/batch=0.070\n",
      "232/67600 (epoch 0), train_loss = 1.850, time/batch=0.070\n",
      "233/67600 (epoch 0), train_loss = 1.813, time/batch=0.072\n",
      "234/67600 (epoch 0), train_loss = 1.863, time/batch=0.084\n",
      "235/67600 (epoch 0), train_loss = 1.847, time/batch=0.067\n",
      "236/67600 (epoch 0), train_loss = 1.832, time/batch=0.069\n",
      "237/67600 (epoch 0), train_loss = 1.820, time/batch=0.201\n",
      "238/67600 (epoch 0), train_loss = 1.883, time/batch=0.075\n",
      "239/67600 (epoch 0), train_loss = 1.852, time/batch=0.083\n",
      "240/67600 (epoch 0), train_loss = 1.946, time/batch=0.072\n",
      "241/67600 (epoch 0), train_loss = 1.806, time/batch=0.070\n",
      "242/67600 (epoch 0), train_loss = 1.817, time/batch=0.071\n",
      "243/67600 (epoch 0), train_loss = 1.840, time/batch=0.070\n",
      "244/67600 (epoch 0), train_loss = 1.834, time/batch=0.071\n",
      "245/67600 (epoch 0), train_loss = 1.851, time/batch=0.073\n",
      "246/67600 (epoch 0), train_loss = 1.813, time/batch=0.174\n",
      "247/67600 (epoch 0), train_loss = 1.820, time/batch=0.073\n",
      "248/67600 (epoch 0), train_loss = 1.828, time/batch=0.109\n",
      "249/67600 (epoch 0), train_loss = 1.798, time/batch=0.071\n",
      "250/67600 (epoch 0), train_loss = 1.790, time/batch=0.072\n",
      "251/67600 (epoch 0), train_loss = 1.864, time/batch=0.075\n",
      "252/67600 (epoch 0), train_loss = 1.815, time/batch=0.073\n",
      "253/67600 (epoch 0), train_loss = 1.802, time/batch=0.073\n",
      "254/67600 (epoch 0), train_loss = 1.856, time/batch=0.070\n",
      "255/67600 (epoch 0), train_loss = 1.845, time/batch=0.073\n",
      "256/67600 (epoch 0), train_loss = 1.847, time/batch=0.071\n",
      "257/67600 (epoch 0), train_loss = 1.842, time/batch=0.071\n",
      "258/67600 (epoch 0), train_loss = 1.773, time/batch=0.181\n",
      "259/67600 (epoch 0), train_loss = 1.809, time/batch=0.078\n",
      "260/67600 (epoch 0), train_loss = 1.763, time/batch=0.096\n",
      "261/67600 (epoch 0), train_loss = 1.801, time/batch=0.071\n",
      "262/67600 (epoch 0), train_loss = 1.815, time/batch=0.081\n",
      "263/67600 (epoch 0), train_loss = 1.786, time/batch=0.069\n",
      "264/67600 (epoch 0), train_loss = 1.771, time/batch=0.073\n",
      "265/67600 (epoch 0), train_loss = 1.810, time/batch=0.072\n",
      "266/67600 (epoch 0), train_loss = 1.784, time/batch=0.069\n",
      "267/67600 (epoch 0), train_loss = 1.783, time/batch=0.072\n",
      "268/67600 (epoch 0), train_loss = 1.772, time/batch=0.072\n",
      "269/67600 (epoch 0), train_loss = 1.781, time/batch=0.078\n",
      "270/67600 (epoch 0), train_loss = 1.842, time/batch=0.180\n",
      "271/67600 (epoch 0), train_loss = 1.779, time/batch=0.101\n",
      "272/67600 (epoch 0), train_loss = 1.809, time/batch=0.072\n",
      "273/67600 (epoch 0), train_loss = 1.844, time/batch=0.075\n",
      "274/67600 (epoch 0), train_loss = 1.801, time/batch=0.073\n",
      "275/67600 (epoch 0), train_loss = 1.839, time/batch=0.071\n",
      "276/67600 (epoch 0), train_loss = 1.842, time/batch=0.073\n",
      "277/67600 (epoch 0), train_loss = 1.765, time/batch=0.076\n",
      "278/67600 (epoch 0), train_loss = 1.764, time/batch=0.069\n",
      "279/67600 (epoch 0), train_loss = 1.844, time/batch=0.070\n",
      "280/67600 (epoch 0), train_loss = 1.849, time/batch=0.071\n",
      "281/67600 (epoch 0), train_loss = 1.790, time/batch=0.115\n",
      "282/67600 (epoch 0), train_loss = 1.719, time/batch=0.156\n",
      "283/67600 (epoch 0), train_loss = 1.841, time/batch=0.090\n",
      "284/67600 (epoch 0), train_loss = 1.823, time/batch=0.068\n",
      "285/67600 (epoch 0), train_loss = 1.824, time/batch=0.073\n",
      "286/67600 (epoch 0), train_loss = 1.796, time/batch=0.070\n",
      "287/67600 (epoch 0), train_loss = 1.816, time/batch=0.072\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "288/67600 (epoch 0), train_loss = 1.800, time/batch=0.071\n",
      "289/67600 (epoch 0), train_loss = 1.878, time/batch=0.071\n",
      "290/67600 (epoch 0), train_loss = 1.817, time/batch=0.085\n",
      "291/67600 (epoch 0), train_loss = 1.781, time/batch=0.072\n",
      "292/67600 (epoch 0), train_loss = 1.799, time/batch=0.070\n",
      "293/67600 (epoch 0), train_loss = 1.804, time/batch=0.189\n",
      "294/67600 (epoch 0), train_loss = 1.828, time/batch=0.100\n",
      "295/67600 (epoch 0), train_loss = 1.823, time/batch=0.085\n",
      "296/67600 (epoch 0), train_loss = 1.785, time/batch=0.068\n",
      "297/67600 (epoch 0), train_loss = 1.775, time/batch=0.071\n",
      "298/67600 (epoch 0), train_loss = 1.757, time/batch=0.074\n",
      "299/67600 (epoch 0), train_loss = 1.835, time/batch=0.070\n",
      "300/67600 (epoch 0), train_loss = 1.779, time/batch=0.070\n",
      "301/67600 (epoch 0), train_loss = 1.815, time/batch=0.073\n",
      "302/67600 (epoch 0), train_loss = 1.792, time/batch=0.073\n",
      "303/67600 (epoch 0), train_loss = 1.768, time/batch=0.069\n",
      "304/67600 (epoch 0), train_loss = 1.820, time/batch=0.072\n",
      "305/67600 (epoch 0), train_loss = 1.825, time/batch=0.225\n",
      "306/67600 (epoch 0), train_loss = 1.783, time/batch=0.075\n",
      "307/67600 (epoch 0), train_loss = 1.773, time/batch=0.070\n",
      "308/67600 (epoch 0), train_loss = 1.819, time/batch=0.074\n",
      "309/67600 (epoch 0), train_loss = 1.818, time/batch=0.067\n",
      "310/67600 (epoch 0), train_loss = 1.772, time/batch=0.071\n",
      "311/67600 (epoch 0), train_loss = 1.774, time/batch=0.070\n",
      "312/67600 (epoch 0), train_loss = 1.732, time/batch=0.069\n",
      "313/67600 (epoch 0), train_loss = 1.769, time/batch=0.084\n",
      "314/67600 (epoch 0), train_loss = 1.792, time/batch=0.100\n",
      "315/67600 (epoch 0), train_loss = 1.850, time/batch=0.074\n",
      "316/67600 (epoch 0), train_loss = 1.847, time/batch=0.069\n",
      "317/67600 (epoch 0), train_loss = 1.781, time/batch=0.071\n",
      "318/67600 (epoch 0), train_loss = 1.791, time/batch=0.071\n",
      "319/67600 (epoch 0), train_loss = 1.816, time/batch=0.070\n",
      "320/67600 (epoch 0), train_loss = 1.843, time/batch=0.074\n",
      "321/67600 (epoch 0), train_loss = 1.768, time/batch=0.071\n",
      "322/67600 (epoch 0), train_loss = 1.744, time/batch=0.074\n",
      "323/67600 (epoch 0), train_loss = 1.771, time/batch=0.225\n",
      "324/67600 (epoch 0), train_loss = 1.788, time/batch=0.118\n",
      "325/67600 (epoch 0), train_loss = 1.783, time/batch=0.089\n",
      "326/67600 (epoch 0), train_loss = 1.759, time/batch=0.079\n",
      "327/67600 (epoch 0), train_loss = 1.756, time/batch=0.073\n",
      "328/67600 (epoch 0), train_loss = 1.742, time/batch=0.072\n",
      "329/67600 (epoch 0), train_loss = 1.840, time/batch=0.073\n",
      "330/67600 (epoch 0), train_loss = 1.755, time/batch=0.071\n",
      "331/67600 (epoch 0), train_loss = 1.738, time/batch=0.073\n",
      "332/67600 (epoch 0), train_loss = 1.817, time/batch=0.070\n",
      "333/67600 (epoch 0), train_loss = 1.724, time/batch=0.072\n",
      "334/67600 (epoch 0), train_loss = 1.725, time/batch=0.075\n",
      "335/67600 (epoch 0), train_loss = 1.750, time/batch=0.211\n",
      "336/67600 (epoch 0), train_loss = 1.754, time/batch=0.095\n",
      "337/67600 (epoch 0), train_loss = 1.752, time/batch=0.072\n",
      "338/67600 (epoch 0), train_loss = 1.794, time/batch=0.076\n",
      "339/67600 (epoch 0), train_loss = 1.756, time/batch=0.075\n",
      "340/67600 (epoch 0), train_loss = 1.720, time/batch=0.070\n",
      "341/67600 (epoch 0), train_loss = 1.796, time/batch=0.072\n",
      "342/67600 (epoch 0), train_loss = 1.687, time/batch=0.071\n",
      "343/67600 (epoch 0), train_loss = 1.705, time/batch=0.179\n",
      "344/67600 (epoch 0), train_loss = 1.760, time/batch=0.076\n",
      "345/67600 (epoch 0), train_loss = 1.824, time/batch=0.100\n",
      "346/67600 (epoch 0), train_loss = 1.761, time/batch=0.070\n",
      "347/67600 (epoch 0), train_loss = 1.731, time/batch=0.068\n",
      "348/67600 (epoch 0), train_loss = 1.804, time/batch=0.091\n",
      "349/67600 (epoch 0), train_loss = 1.770, time/batch=0.075\n",
      "350/67600 (epoch 0), train_loss = 1.717, time/batch=0.070\n",
      "351/67600 (epoch 0), train_loss = 1.687, time/batch=0.074\n",
      "352/67600 (epoch 0), train_loss = 1.693, time/batch=0.070\n",
      "353/67600 (epoch 0), train_loss = 1.717, time/batch=0.070\n",
      "354/67600 (epoch 0), train_loss = 1.718, time/batch=0.072\n",
      "355/67600 (epoch 0), train_loss = 1.764, time/batch=0.175\n",
      "356/67600 (epoch 0), train_loss = 1.732, time/batch=0.071\n",
      "357/67600 (epoch 0), train_loss = 1.675, time/batch=0.112\n",
      "358/67600 (epoch 0), train_loss = 1.662, time/batch=0.072\n",
      "359/67600 (epoch 0), train_loss = 1.805, time/batch=0.071\n",
      "360/67600 (epoch 0), train_loss = 1.786, time/batch=0.072\n",
      "361/67600 (epoch 0), train_loss = 1.663, time/batch=0.074\n",
      "362/67600 (epoch 0), train_loss = 1.711, time/batch=0.075\n",
      "363/67600 (epoch 0), train_loss = 1.752, time/batch=0.071\n",
      "364/67600 (epoch 0), train_loss = 1.758, time/batch=0.075\n",
      "365/67600 (epoch 0), train_loss = 1.758, time/batch=0.067\n",
      "366/67600 (epoch 0), train_loss = 1.746, time/batch=0.069\n",
      "367/67600 (epoch 0), train_loss = 1.665, time/batch=0.195\n",
      "368/67600 (epoch 0), train_loss = 1.716, time/batch=0.076\n",
      "369/67600 (epoch 0), train_loss = 1.794, time/batch=0.105\n",
      "370/67600 (epoch 0), train_loss = 1.720, time/batch=0.073\n",
      "371/67600 (epoch 0), train_loss = 1.773, time/batch=0.074\n",
      "372/67600 (epoch 0), train_loss = 1.740, time/batch=0.070\n",
      "373/67600 (epoch 0), train_loss = 1.707, time/batch=0.073\n",
      "374/67600 (epoch 0), train_loss = 1.779, time/batch=0.080\n",
      "375/67600 (epoch 0), train_loss = 1.798, time/batch=0.073\n",
      "376/67600 (epoch 0), train_loss = 1.750, time/batch=0.076\n",
      "377/67600 (epoch 0), train_loss = 1.702, time/batch=0.073\n",
      "378/67600 (epoch 0), train_loss = 1.735, time/batch=0.156\n",
      "379/67600 (epoch 0), train_loss = 1.780, time/batch=0.102\n",
      "380/67600 (epoch 0), train_loss = 1.744, time/batch=0.102\n",
      "381/67600 (epoch 0), train_loss = 1.715, time/batch=0.072\n",
      "382/67600 (epoch 0), train_loss = 1.740, time/batch=0.071\n",
      "383/67600 (epoch 0), train_loss = 1.714, time/batch=0.072\n",
      "384/67600 (epoch 0), train_loss = 1.813, time/batch=0.073\n",
      "385/67600 (epoch 0), train_loss = 1.694, time/batch=0.073\n",
      "386/67600 (epoch 0), train_loss = 1.725, time/batch=0.076\n",
      "387/67600 (epoch 0), train_loss = 1.722, time/batch=0.084\n",
      "388/67600 (epoch 0), train_loss = 1.705, time/batch=0.072\n",
      "389/67600 (epoch 0), train_loss = 1.685, time/batch=0.077\n",
      "390/67600 (epoch 0), train_loss = 1.717, time/batch=0.215\n",
      "391/67600 (epoch 0), train_loss = 1.663, time/batch=0.077\n",
      "392/67600 (epoch 0), train_loss = 1.681, time/batch=0.073\n",
      "393/67600 (epoch 0), train_loss = 1.743, time/batch=0.083\n",
      "394/67600 (epoch 0), train_loss = 1.719, time/batch=0.081\n",
      "395/67600 (epoch 0), train_loss = 1.692, time/batch=0.075\n",
      "396/67600 (epoch 0), train_loss = 1.742, time/batch=0.081\n",
      "397/67600 (epoch 0), train_loss = 1.782, time/batch=0.074\n",
      "398/67600 (epoch 0), train_loss = 1.658, time/batch=0.075\n",
      "399/67600 (epoch 0), train_loss = 1.700, time/batch=0.072\n",
      "400/67600 (epoch 0), train_loss = 1.761, time/batch=0.339\n",
      "401/67600 (epoch 0), train_loss = 1.789, time/batch=0.138\n",
      "402/67600 (epoch 0), train_loss = 1.755, time/batch=0.075\n",
      "403/67600 (epoch 0), train_loss = 1.713, time/batch=0.105\n",
      "404/67600 (epoch 0), train_loss = 1.779, time/batch=0.078\n",
      "405/67600 (epoch 0), train_loss = 1.738, time/batch=0.071\n",
      "406/67600 (epoch 0), train_loss = 1.842, time/batch=0.071\n",
      "407/67600 (epoch 0), train_loss = 1.723, time/batch=0.168\n",
      "408/67600 (epoch 0), train_loss = 1.730, time/batch=0.070\n",
      "409/67600 (epoch 0), train_loss = 1.758, time/batch=0.105\n",
      "410/67600 (epoch 0), train_loss = 1.682, time/batch=0.081\n",
      "411/67600 (epoch 0), train_loss = 1.663, time/batch=0.106\n",
      "412/67600 (epoch 0), train_loss = 1.715, time/batch=0.093\n",
      "413/67600 (epoch 0), train_loss = 1.717, time/batch=0.087\n",
      "414/67600 (epoch 0), train_loss = 1.699, time/batch=0.085\n",
      "415/67600 (epoch 0), train_loss = 1.743, time/batch=0.077\n",
      "416/67600 (epoch 0), train_loss = 1.702, time/batch=0.089\n",
      "417/67600 (epoch 0), train_loss = 1.705, time/batch=0.201\n",
      "418/67600 (epoch 0), train_loss = 1.724, time/batch=0.075\n",
      "419/67600 (epoch 0), train_loss = 1.729, time/batch=0.104\n",
      "420/67600 (epoch 0), train_loss = 1.684, time/batch=0.086\n",
      "421/67600 (epoch 0), train_loss = 1.676, time/batch=0.083\n",
      "422/67600 (epoch 0), train_loss = 1.673, time/batch=0.079\n",
      "423/67600 (epoch 0), train_loss = 1.679, time/batch=0.085\n",
      "424/67600 (epoch 0), train_loss = 1.730, time/batch=0.070\n",
      "425/67600 (epoch 0), train_loss = 1.682, time/batch=0.075\n",
      "426/67600 (epoch 0), train_loss = 1.725, time/batch=0.096\n",
      "427/67600 (epoch 0), train_loss = 1.692, time/batch=0.074\n",
      "428/67600 (epoch 0), train_loss = 1.609, time/batch=0.221\n",
      "429/67600 (epoch 0), train_loss = 1.680, time/batch=0.113\n",
      "430/67600 (epoch 0), train_loss = 1.766, time/batch=0.072\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "431/67600 (epoch 0), train_loss = 1.684, time/batch=0.087\n",
      "432/67600 (epoch 0), train_loss = 1.685, time/batch=0.071\n",
      "433/67600 (epoch 0), train_loss = 1.687, time/batch=0.080\n",
      "434/67600 (epoch 0), train_loss = 1.677, time/batch=0.075\n",
      "435/67600 (epoch 0), train_loss = 1.768, time/batch=0.070\n",
      "436/67600 (epoch 0), train_loss = 1.717, time/batch=0.080\n",
      "437/67600 (epoch 0), train_loss = 1.693, time/batch=0.094\n",
      "438/67600 (epoch 0), train_loss = 1.714, time/batch=0.221\n",
      "439/67600 (epoch 0), train_loss = 1.719, time/batch=0.069\n",
      "440/67600 (epoch 0), train_loss = 1.677, time/batch=0.111\n",
      "441/67600 (epoch 0), train_loss = 1.691, time/batch=0.071\n",
      "442/67600 (epoch 0), train_loss = 1.662, time/batch=0.072\n",
      "443/67600 (epoch 0), train_loss = 1.668, time/batch=0.133\n",
      "444/67600 (epoch 0), train_loss = 1.667, time/batch=0.108\n",
      "445/67600 (epoch 0), train_loss = 1.743, time/batch=0.072\n",
      "446/67600 (epoch 0), train_loss = 1.670, time/batch=0.079\n",
      "447/67600 (epoch 0), train_loss = 1.643, time/batch=0.076\n",
      "448/67600 (epoch 0), train_loss = 1.660, time/batch=0.325\n",
      "449/67600 (epoch 0), train_loss = 1.640, time/batch=0.108\n",
      "450/67600 (epoch 0), train_loss = 1.623, time/batch=0.096\n",
      "451/67600 (epoch 0), train_loss = 1.760, time/batch=0.090\n",
      "452/67600 (epoch 0), train_loss = 1.711, time/batch=0.096\n",
      "453/67600 (epoch 0), train_loss = 1.631, time/batch=0.214\n",
      "454/67600 (epoch 0), train_loss = 1.626, time/batch=0.111\n",
      "455/67600 (epoch 0), train_loss = 1.673, time/batch=0.137\n",
      "456/67600 (epoch 0), train_loss = 1.691, time/batch=0.096\n",
      "457/67600 (epoch 0), train_loss = 1.685, time/batch=0.106\n",
      "458/67600 (epoch 0), train_loss = 1.708, time/batch=0.097\n",
      "459/67600 (epoch 0), train_loss = 1.707, time/batch=0.093\n",
      "460/67600 (epoch 0), train_loss = 1.674, time/batch=0.089\n",
      "461/67600 (epoch 0), train_loss = 1.605, time/batch=0.092\n",
      "462/67600 (epoch 0), train_loss = 1.698, time/batch=0.207\n",
      "463/67600 (epoch 0), train_loss = 1.696, time/batch=0.090\n",
      "464/67600 (epoch 0), train_loss = 1.632, time/batch=0.091\n",
      "465/67600 (epoch 0), train_loss = 1.640, time/batch=0.090\n",
      "466/67600 (epoch 0), train_loss = 1.690, time/batch=0.095\n",
      "467/67600 (epoch 0), train_loss = 1.714, time/batch=0.094\n",
      "468/67600 (epoch 0), train_loss = 1.690, time/batch=0.092\n",
      "469/67600 (epoch 0), train_loss = 1.668, time/batch=0.262\n",
      "470/67600 (epoch 0), train_loss = 1.674, time/batch=0.142\n",
      "471/67600 (epoch 0), train_loss = 1.651, time/batch=0.118\n",
      "472/67600 (epoch 0), train_loss = 1.634, time/batch=0.072\n",
      "473/67600 (epoch 0), train_loss = 1.671, time/batch=0.090\n",
      "474/67600 (epoch 0), train_loss = 1.653, time/batch=0.077\n",
      "475/67600 (epoch 0), train_loss = 1.625, time/batch=0.075\n",
      "476/67600 (epoch 0), train_loss = 1.654, time/batch=0.069\n",
      "477/67600 (epoch 0), train_loss = 1.655, time/batch=0.071\n",
      "478/67600 (epoch 0), train_loss = 1.689, time/batch=0.087\n",
      "479/67600 (epoch 0), train_loss = 1.705, time/batch=0.251\n",
      "480/67600 (epoch 0), train_loss = 1.588, time/batch=0.104\n",
      "481/67600 (epoch 0), train_loss = 1.654, time/batch=0.091\n",
      "482/67600 (epoch 0), train_loss = 1.641, time/batch=0.098\n",
      "483/67600 (epoch 0), train_loss = 1.627, time/batch=0.116\n",
      "484/67600 (epoch 0), train_loss = 1.619, time/batch=0.101\n",
      "485/67600 (epoch 0), train_loss = 1.682, time/batch=0.090\n",
      "486/67600 (epoch 0), train_loss = 1.663, time/batch=0.090\n",
      "487/67600 (epoch 0), train_loss = 1.647, time/batch=0.092\n",
      "488/67600 (epoch 0), train_loss = 1.695, time/batch=0.231\n",
      "489/67600 (epoch 0), train_loss = 1.682, time/batch=0.152\n",
      "490/67600 (epoch 0), train_loss = 1.581, time/batch=0.115\n",
      "491/67600 (epoch 0), train_loss = 1.646, time/batch=0.089\n",
      "492/67600 (epoch 0), train_loss = 1.670, time/batch=0.091\n",
      "493/67600 (epoch 0), train_loss = 1.605, time/batch=0.128\n",
      "494/67600 (epoch 0), train_loss = 1.688, time/batch=0.160\n",
      "495/67600 (epoch 0), train_loss = 1.647, time/batch=0.156\n",
      "496/67600 (epoch 0), train_loss = 1.628, time/batch=0.108\n",
      "497/67600 (epoch 0), train_loss = 1.631, time/batch=0.090\n",
      "498/67600 (epoch 0), train_loss = 1.668, time/batch=0.078\n",
      "499/67600 (epoch 0), train_loss = 1.627, time/batch=0.075\n",
      "500/67600 (epoch 0), train_loss = 1.599, time/batch=0.079\n",
      "model saved to ./save/model.ckpt\n",
      "501/67600 (epoch 0), train_loss = 1.572, time/batch=0.177\n",
      "502/67600 (epoch 0), train_loss = 1.665, time/batch=0.118\n",
      "503/67600 (epoch 0), train_loss = 1.665, time/batch=0.083\n",
      "504/67600 (epoch 0), train_loss = 1.654, time/batch=0.077\n",
      "505/67600 (epoch 0), train_loss = 1.699, time/batch=0.080\n",
      "506/67600 (epoch 0), train_loss = 1.648, time/batch=0.076\n",
      "507/67600 (epoch 0), train_loss = 1.649, time/batch=0.071\n",
      "508/67600 (epoch 0), train_loss = 1.591, time/batch=0.071\n",
      "509/67600 (epoch 0), train_loss = 1.610, time/batch=0.165\n",
      "510/67600 (epoch 0), train_loss = 1.699, time/batch=0.082\n",
      "511/67600 (epoch 0), train_loss = 1.655, time/batch=0.108\n",
      "512/67600 (epoch 0), train_loss = 1.643, time/batch=0.071\n",
      "513/67600 (epoch 0), train_loss = 1.621, time/batch=0.076\n",
      "514/67600 (epoch 0), train_loss = 1.634, time/batch=0.077\n",
      "515/67600 (epoch 0), train_loss = 1.669, time/batch=0.074\n",
      "516/67600 (epoch 0), train_loss = 1.649, time/batch=0.075\n",
      "517/67600 (epoch 0), train_loss = 1.665, time/batch=0.087\n",
      "518/67600 (epoch 0), train_loss = 1.657, time/batch=0.075\n",
      "519/67600 (epoch 0), train_loss = 1.548, time/batch=0.072\n",
      "520/67600 (epoch 0), train_loss = 1.651, time/batch=0.074\n",
      "521/67600 (epoch 0), train_loss = 1.641, time/batch=0.186\n",
      "522/67600 (epoch 0), train_loss = 1.677, time/batch=0.071\n",
      "523/67600 (epoch 0), train_loss = 1.606, time/batch=0.098\n",
      "524/67600 (epoch 0), train_loss = 1.644, time/batch=0.078\n",
      "525/67600 (epoch 0), train_loss = 1.630, time/batch=0.072\n",
      "526/67600 (epoch 0), train_loss = 1.631, time/batch=0.073\n",
      "527/67600 (epoch 0), train_loss = 1.637, time/batch=0.076\n",
      "528/67600 (epoch 0), train_loss = 1.701, time/batch=0.085\n",
      "529/67600 (epoch 0), train_loss = 1.608, time/batch=0.083\n",
      "530/67600 (epoch 0), train_loss = 1.653, time/batch=0.079\n",
      "531/67600 (epoch 0), train_loss = 1.704, time/batch=0.070\n",
      "532/67600 (epoch 0), train_loss = 1.613, time/batch=0.181\n",
      "533/67600 (epoch 0), train_loss = 1.599, time/batch=0.089\n",
      "534/67600 (epoch 0), train_loss = 1.606, time/batch=0.106\n",
      "535/67600 (epoch 0), train_loss = 1.593, time/batch=0.073\n",
      "536/67600 (epoch 0), train_loss = 1.645, time/batch=0.069\n",
      "537/67600 (epoch 0), train_loss = 1.645, time/batch=0.074\n",
      "538/67600 (epoch 0), train_loss = 1.624, time/batch=0.073\n",
      "539/67600 (epoch 0), train_loss = 1.670, time/batch=0.073\n",
      "540/67600 (epoch 0), train_loss = 1.613, time/batch=0.074\n",
      "541/67600 (epoch 0), train_loss = 1.579, time/batch=0.074\n",
      "542/67600 (epoch 0), train_loss = 1.627, time/batch=0.070\n",
      "543/67600 (epoch 0), train_loss = 1.545, time/batch=0.070\n",
      "544/67600 (epoch 0), train_loss = 1.630, time/batch=0.202\n",
      "545/67600 (epoch 0), train_loss = 1.615, time/batch=0.086\n",
      "546/67600 (epoch 0), train_loss = 1.631, time/batch=0.072\n",
      "547/67600 (epoch 0), train_loss = 1.602, time/batch=0.074\n",
      "548/67600 (epoch 0), train_loss = 1.747, time/batch=0.069\n",
      "549/67600 (epoch 0), train_loss = 1.641, time/batch=0.071\n",
      "550/67600 (epoch 0), train_loss = 1.618, time/batch=0.071\n",
      "551/67600 (epoch 0), train_loss = 1.653, time/batch=0.069\n",
      "552/67600 (epoch 0), train_loss = 1.572, time/batch=0.071\n",
      "553/67600 (epoch 0), train_loss = 1.621, time/batch=0.073\n",
      "554/67600 (epoch 0), train_loss = 1.643, time/batch=0.069\n",
      "555/67600 (epoch 0), train_loss = 1.599, time/batch=0.072\n",
      "556/67600 (epoch 0), train_loss = 1.636, time/batch=0.214\n",
      "557/67600 (epoch 0), train_loss = 1.607, time/batch=0.083\n",
      "558/67600 (epoch 0), train_loss = 1.575, time/batch=0.072\n",
      "559/67600 (epoch 0), train_loss = 1.576, time/batch=0.080\n",
      "560/67600 (epoch 0), train_loss = 1.592, time/batch=0.070\n",
      "561/67600 (epoch 0), train_loss = 1.598, time/batch=0.073\n",
      "562/67600 (epoch 0), train_loss = 1.605, time/batch=0.072\n",
      "563/67600 (epoch 0), train_loss = 1.609, time/batch=0.071\n",
      "564/67600 (epoch 0), train_loss = 1.597, time/batch=0.072\n",
      "565/67600 (epoch 0), train_loss = 1.601, time/batch=0.073\n",
      "566/67600 (epoch 0), train_loss = 1.617, time/batch=0.069\n",
      "567/67600 (epoch 0), train_loss = 1.669, time/batch=0.068\n",
      "568/67600 (epoch 0), train_loss = 1.618, time/batch=0.213\n",
      "569/67600 (epoch 0), train_loss = 1.572, time/batch=0.078\n",
      "570/67600 (epoch 0), train_loss = 1.580, time/batch=0.070\n",
      "571/67600 (epoch 0), train_loss = 1.606, time/batch=0.072\n",
      "572/67600 (epoch 0), train_loss = 1.605, time/batch=0.070\n",
      "573/67600 (epoch 0), train_loss = 1.613, time/batch=0.069\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "574/67600 (epoch 0), train_loss = 1.617, time/batch=0.072\n",
      "575/67600 (epoch 0), train_loss = 1.604, time/batch=0.070\n",
      "576/67600 (epoch 0), train_loss = 1.642, time/batch=0.125\n",
      "577/67600 (epoch 0), train_loss = 1.635, time/batch=0.072\n",
      "578/67600 (epoch 0), train_loss = 1.683, time/batch=0.070\n",
      "579/67600 (epoch 0), train_loss = 1.617, time/batch=0.071\n",
      "580/67600 (epoch 0), train_loss = 1.587, time/batch=0.071\n",
      "581/67600 (epoch 0), train_loss = 1.621, time/batch=0.071\n",
      "582/67600 (epoch 0), train_loss = 1.579, time/batch=0.068\n",
      "583/67600 (epoch 0), train_loss = 1.565, time/batch=0.073\n",
      "584/67600 (epoch 0), train_loss = 1.630, time/batch=0.069\n",
      "585/67600 (epoch 0), train_loss = 1.660, time/batch=0.071\n",
      "586/67600 (epoch 0), train_loss = 1.575, time/batch=0.221\n",
      "587/67600 (epoch 0), train_loss = 1.680, time/batch=0.088\n",
      "588/67600 (epoch 0), train_loss = 1.578, time/batch=0.093\n",
      "589/67600 (epoch 0), train_loss = 1.596, time/batch=0.073\n",
      "590/67600 (epoch 0), train_loss = 1.662, time/batch=0.070\n",
      "591/67600 (epoch 0), train_loss = 1.581, time/batch=0.069\n",
      "592/67600 (epoch 0), train_loss = 1.596, time/batch=0.070\n",
      "593/67600 (epoch 0), train_loss = 1.602, time/batch=0.078\n",
      "594/67600 (epoch 0), train_loss = 1.543, time/batch=0.068\n",
      "595/67600 (epoch 0), train_loss = 1.593, time/batch=0.073\n",
      "596/67600 (epoch 0), train_loss = 1.584, time/batch=0.070\n",
      "597/67600 (epoch 0), train_loss = 1.581, time/batch=0.069\n",
      "598/67600 (epoch 0), train_loss = 1.559, time/batch=0.179\n",
      "599/67600 (epoch 0), train_loss = 1.574, time/batch=0.111\n",
      "600/67600 (epoch 0), train_loss = 1.622, time/batch=0.089\n",
      "601/67600 (epoch 0), train_loss = 1.580, time/batch=0.072\n",
      "602/67600 (epoch 0), train_loss = 1.587, time/batch=0.068\n",
      "603/67600 (epoch 0), train_loss = 1.594, time/batch=0.071\n",
      "604/67600 (epoch 0), train_loss = 1.644, time/batch=0.072\n",
      "605/67600 (epoch 0), train_loss = 1.589, time/batch=0.072\n",
      "606/67600 (epoch 0), train_loss = 1.668, time/batch=0.071\n",
      "607/67600 (epoch 0), train_loss = 1.560, time/batch=0.076\n",
      "608/67600 (epoch 0), train_loss = 1.642, time/batch=0.070\n",
      "609/67600 (epoch 0), train_loss = 1.601, time/batch=0.071\n",
      "610/67600 (epoch 0), train_loss = 1.565, time/batch=0.222\n",
      "611/67600 (epoch 0), train_loss = 1.663, time/batch=0.070\n",
      "612/67600 (epoch 0), train_loss = 1.615, time/batch=0.072\n",
      "613/67600 (epoch 0), train_loss = 1.567, time/batch=0.075\n",
      "614/67600 (epoch 0), train_loss = 1.579, time/batch=0.070\n",
      "615/67600 (epoch 0), train_loss = 1.668, time/batch=0.072\n",
      "616/67600 (epoch 0), train_loss = 1.609, time/batch=0.071\n",
      "617/67600 (epoch 0), train_loss = 1.680, time/batch=0.071\n",
      "618/67600 (epoch 0), train_loss = 1.592, time/batch=0.098\n",
      "619/67600 (epoch 0), train_loss = 1.564, time/batch=0.166\n",
      "620/67600 (epoch 0), train_loss = 1.572, time/batch=0.105\n",
      "621/67600 (epoch 0), train_loss = 1.573, time/batch=0.068\n",
      "622/67600 (epoch 0), train_loss = 1.604, time/batch=0.074\n",
      "623/67600 (epoch 0), train_loss = 1.573, time/batch=0.082\n",
      "624/67600 (epoch 0), train_loss = 1.590, time/batch=0.070\n",
      "625/67600 (epoch 0), train_loss = 1.583, time/batch=0.070\n",
      "626/67600 (epoch 0), train_loss = 1.583, time/batch=0.083\n",
      "627/67600 (epoch 0), train_loss = 1.669, time/batch=0.071\n",
      "628/67600 (epoch 0), train_loss = 1.621, time/batch=0.071\n",
      "629/67600 (epoch 0), train_loss = 1.568, time/batch=0.067\n",
      "630/67600 (epoch 0), train_loss = 1.645, time/batch=0.187\n",
      "631/67600 (epoch 0), train_loss = 1.653, time/batch=0.068\n",
      "632/67600 (epoch 0), train_loss = 1.578, time/batch=0.122\n",
      "633/67600 (epoch 0), train_loss = 1.698, time/batch=0.073\n",
      "634/67600 (epoch 0), train_loss = 1.660, time/batch=0.078\n",
      "635/67600 (epoch 0), train_loss = 1.575, time/batch=0.069\n",
      "636/67600 (epoch 0), train_loss = 1.687, time/batch=0.070\n",
      "637/67600 (epoch 0), train_loss = 1.573, time/batch=0.068\n",
      "638/67600 (epoch 0), train_loss = 1.536, time/batch=0.074\n",
      "639/67600 (epoch 0), train_loss = 1.535, time/batch=0.073\n",
      "640/67600 (epoch 0), train_loss = 1.609, time/batch=0.070\n",
      "641/67600 (epoch 0), train_loss = 1.600, time/batch=0.070\n",
      "642/67600 (epoch 0), train_loss = 1.600, time/batch=0.185\n",
      "643/67600 (epoch 0), train_loss = 1.648, time/batch=0.069\n",
      "644/67600 (epoch 0), train_loss = 1.653, time/batch=0.100\n",
      "645/67600 (epoch 0), train_loss = 1.570, time/batch=0.074\n",
      "646/67600 (epoch 0), train_loss = 1.584, time/batch=0.070\n",
      "647/67600 (epoch 0), train_loss = 1.593, time/batch=0.073\n",
      "648/67600 (epoch 0), train_loss = 1.603, time/batch=0.076\n",
      "649/67600 (epoch 0), train_loss = 1.602, time/batch=0.071\n",
      "650/67600 (epoch 0), train_loss = 1.648, time/batch=0.070\n",
      "651/67600 (epoch 0), train_loss = 1.620, time/batch=0.069\n",
      "652/67600 (epoch 0), train_loss = 1.574, time/batch=0.072\n",
      "653/67600 (epoch 0), train_loss = 1.570, time/batch=0.073\n",
      "654/67600 (epoch 0), train_loss = 1.584, time/batch=0.202\n",
      "655/67600 (epoch 0), train_loss = 1.560, time/batch=0.089\n",
      "656/67600 (epoch 0), train_loss = 1.562, time/batch=0.066\n",
      "657/67600 (epoch 0), train_loss = 1.626, time/batch=0.076\n",
      "658/67600 (epoch 0), train_loss = 1.609, time/batch=0.069\n",
      "659/67600 (epoch 0), train_loss = 1.521, time/batch=0.072\n",
      "660/67600 (epoch 0), train_loss = 1.597, time/batch=0.071\n",
      "661/67600 (epoch 0), train_loss = 1.562, time/batch=0.071\n",
      "662/67600 (epoch 0), train_loss = 1.533, time/batch=0.074\n",
      "663/67600 (epoch 0), train_loss = 1.517, time/batch=0.071\n",
      "664/67600 (epoch 0), train_loss = 1.594, time/batch=0.070\n",
      "665/67600 (epoch 0), train_loss = 1.567, time/batch=0.069\n",
      "666/67600 (epoch 0), train_loss = 1.578, time/batch=0.204\n",
      "667/67600 (epoch 0), train_loss = 1.576, time/batch=0.072\n",
      "668/67600 (epoch 0), train_loss = 1.624, time/batch=0.069\n",
      "669/67600 (epoch 0), train_loss = 1.496, time/batch=0.075\n",
      "670/67600 (epoch 0), train_loss = 1.500, time/batch=0.071\n",
      "671/67600 (epoch 0), train_loss = 1.567, time/batch=0.071\n",
      "672/67600 (epoch 0), train_loss = 1.494, time/batch=0.076\n",
      "673/67600 (epoch 0), train_loss = 1.627, time/batch=0.072\n",
      "674/67600 (epoch 0), train_loss = 1.632, time/batch=0.148\n",
      "675/67600 (epoch 0), train_loss = 1.546, time/batch=0.096\n",
      "676/67600 (epoch 0), train_loss = 1.581, time/batch=0.107\n",
      "677/67600 (epoch 0), train_loss = 1.593, time/batch=0.068\n",
      "678/67600 (epoch 0), train_loss = 1.574, time/batch=0.068\n",
      "679/67600 (epoch 0), train_loss = 1.571, time/batch=0.072\n",
      "680/67600 (epoch 0), train_loss = 1.552, time/batch=0.070\n",
      "681/67600 (epoch 0), train_loss = 1.597, time/batch=0.070\n",
      "682/67600 (epoch 0), train_loss = 1.560, time/batch=0.067\n",
      "683/67600 (epoch 0), train_loss = 1.571, time/batch=0.070\n",
      "684/67600 (epoch 0), train_loss = 1.575, time/batch=0.070\n",
      "685/67600 (epoch 0), train_loss = 1.605, time/batch=0.071\n",
      "686/67600 (epoch 0), train_loss = 1.600, time/batch=0.068\n",
      "687/67600 (epoch 0), train_loss = 1.556, time/batch=0.184\n",
      "688/67600 (epoch 0), train_loss = 1.557, time/batch=0.071\n",
      "689/67600 (epoch 0), train_loss = 1.566, time/batch=0.105\n",
      "690/67600 (epoch 0), train_loss = 1.570, time/batch=0.074\n",
      "691/67600 (epoch 0), train_loss = 1.577, time/batch=0.069\n",
      "692/67600 (epoch 0), train_loss = 1.547, time/batch=0.071\n",
      "693/67600 (epoch 0), train_loss = 1.594, time/batch=0.076\n",
      "694/67600 (epoch 0), train_loss = 1.553, time/batch=0.071\n",
      "695/67600 (epoch 0), train_loss = 1.521, time/batch=0.071\n",
      "696/67600 (epoch 0), train_loss = 1.575, time/batch=0.074\n",
      "697/67600 (epoch 0), train_loss = 1.618, time/batch=0.069\n",
      "698/67600 (epoch 0), train_loss = 1.533, time/batch=0.072\n",
      "699/67600 (epoch 0), train_loss = 1.534, time/batch=0.185\n",
      "700/67600 (epoch 0), train_loss = 1.590, time/batch=0.079\n",
      "701/67600 (epoch 0), train_loss = 1.597, time/batch=0.087\n",
      "702/67600 (epoch 0), train_loss = 1.563, time/batch=0.078\n",
      "703/67600 (epoch 0), train_loss = 1.519, time/batch=0.071\n",
      "704/67600 (epoch 0), train_loss = 1.523, time/batch=0.070\n",
      "705/67600 (epoch 0), train_loss = 1.559, time/batch=0.070\n",
      "706/67600 (epoch 0), train_loss = 1.561, time/batch=0.067\n",
      "707/67600 (epoch 0), train_loss = 1.583, time/batch=0.081\n",
      "708/67600 (epoch 0), train_loss = 1.579, time/batch=0.076\n",
      "709/67600 (epoch 0), train_loss = 1.534, time/batch=0.070\n",
      "710/67600 (epoch 0), train_loss = 1.550, time/batch=0.078\n",
      "711/67600 (epoch 0), train_loss = 1.508, time/batch=0.187\n",
      "712/67600 (epoch 0), train_loss = 1.570, time/batch=0.086\n",
      "713/67600 (epoch 0), train_loss = 1.603, time/batch=0.069\n",
      "714/67600 (epoch 0), train_loss = 1.536, time/batch=0.071\n",
      "715/67600 (epoch 0), train_loss = 1.590, time/batch=0.068\n",
      "716/67600 (epoch 0), train_loss = 1.498, time/batch=0.070\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "717/67600 (epoch 0), train_loss = 1.555, time/batch=0.074\n",
      "718/67600 (epoch 0), train_loss = 1.512, time/batch=0.073\n",
      "719/67600 (epoch 0), train_loss = 1.524, time/batch=0.071\n",
      "720/67600 (epoch 0), train_loss = 1.527, time/batch=0.071\n",
      "721/67600 (epoch 0), train_loss = 1.596, time/batch=0.072\n",
      "722/67600 (epoch 0), train_loss = 1.545, time/batch=0.070\n",
      "723/67600 (epoch 0), train_loss = 1.574, time/batch=0.223\n",
      "724/67600 (epoch 0), train_loss = 1.537, time/batch=0.092\n",
      "725/67600 (epoch 0), train_loss = 1.593, time/batch=0.081\n",
      "726/67600 (epoch 0), train_loss = 1.585, time/batch=0.078\n",
      "727/67600 (epoch 0), train_loss = 1.579, time/batch=0.071\n",
      "728/67600 (epoch 0), train_loss = 1.576, time/batch=0.089\n",
      "729/67600 (epoch 0), train_loss = 1.525, time/batch=0.096\n",
      "730/67600 (epoch 0), train_loss = 1.536, time/batch=0.203\n",
      "731/67600 (epoch 0), train_loss = 1.566, time/batch=0.076\n",
      "732/67600 (epoch 0), train_loss = 1.542, time/batch=0.101\n",
      "733/67600 (epoch 0), train_loss = 1.537, time/batch=0.074\n",
      "734/67600 (epoch 0), train_loss = 1.544, time/batch=0.074\n",
      "735/67600 (epoch 0), train_loss = 1.502, time/batch=0.093\n",
      "736/67600 (epoch 0), train_loss = 1.591, time/batch=0.074\n",
      "737/67600 (epoch 0), train_loss = 1.521, time/batch=0.075\n",
      "738/67600 (epoch 0), train_loss = 1.499, time/batch=0.070\n",
      "739/67600 (epoch 0), train_loss = 1.577, time/batch=0.070\n",
      "740/67600 (epoch 0), train_loss = 1.469, time/batch=0.074\n",
      "741/67600 (epoch 0), train_loss = 1.520, time/batch=0.116\n",
      "742/67600 (epoch 0), train_loss = 1.484, time/batch=0.074\n",
      "743/67600 (epoch 0), train_loss = 1.540, time/batch=0.075\n",
      "744/67600 (epoch 0), train_loss = 1.552, time/batch=0.072\n",
      "745/67600 (epoch 0), train_loss = 1.576, time/batch=0.071\n",
      "746/67600 (epoch 0), train_loss = 1.531, time/batch=0.076\n",
      "747/67600 (epoch 0), train_loss = 1.534, time/batch=0.072\n",
      "748/67600 (epoch 0), train_loss = 1.573, time/batch=0.094\n",
      "749/67600 (epoch 0), train_loss = 1.543, time/batch=0.079\n",
      "750/67600 (epoch 0), train_loss = 1.536, time/batch=0.086\n",
      "751/67600 (epoch 0), train_loss = 1.499, time/batch=0.288\n",
      "752/67600 (epoch 0), train_loss = 1.523, time/batch=0.116\n",
      "753/67600 (epoch 0), train_loss = 1.581, time/batch=0.081\n",
      "754/67600 (epoch 0), train_loss = 1.487, time/batch=0.077\n",
      "755/67600 (epoch 0), train_loss = 1.512, time/batch=0.075\n",
      "756/67600 (epoch 0), train_loss = 1.603, time/batch=0.077\n",
      "757/67600 (epoch 0), train_loss = 1.569, time/batch=0.076\n",
      "758/67600 (epoch 0), train_loss = 1.516, time/batch=0.070\n",
      "759/67600 (epoch 0), train_loss = 1.486, time/batch=0.069\n",
      "760/67600 (epoch 0), train_loss = 1.596, time/batch=0.077\n",
      "761/67600 (epoch 0), train_loss = 1.524, time/batch=0.273\n",
      "762/67600 (epoch 0), train_loss = 1.505, time/batch=0.074\n",
      "763/67600 (epoch 0), train_loss = 1.571, time/batch=0.070\n",
      "764/67600 (epoch 0), train_loss = 1.633, time/batch=0.072\n",
      "765/67600 (epoch 0), train_loss = 1.489, time/batch=0.070\n",
      "766/67600 (epoch 0), train_loss = 1.585, time/batch=0.105\n",
      "767/67600 (epoch 0), train_loss = 1.547, time/batch=0.082\n",
      "768/67600 (epoch 0), train_loss = 1.503, time/batch=0.171\n",
      "769/67600 (epoch 0), train_loss = 1.612, time/batch=0.156\n",
      "770/67600 (epoch 0), train_loss = 1.530, time/batch=0.091\n",
      "771/67600 (epoch 0), train_loss = 1.578, time/batch=0.077\n",
      "772/67600 (epoch 0), train_loss = 1.584, time/batch=0.099\n",
      "773/67600 (epoch 0), train_loss = 1.543, time/batch=0.078\n",
      "774/67600 (epoch 0), train_loss = 1.612, time/batch=0.072\n",
      "775/67600 (epoch 0), train_loss = 1.611, time/batch=0.074\n",
      "776/67600 (epoch 0), train_loss = 1.554, time/batch=0.076\n",
      "777/67600 (epoch 0), train_loss = 1.553, time/batch=0.074\n",
      "778/67600 (epoch 0), train_loss = 1.535, time/batch=0.098\n",
      "779/67600 (epoch 0), train_loss = 1.585, time/batch=0.206\n",
      "780/67600 (epoch 0), train_loss = 1.596, time/batch=0.114\n",
      "781/67600 (epoch 0), train_loss = 1.619, time/batch=0.070\n",
      "782/67600 (epoch 0), train_loss = 1.518, time/batch=0.077\n",
      "783/67600 (epoch 0), train_loss = 1.563, time/batch=0.077\n",
      "784/67600 (epoch 0), train_loss = 1.552, time/batch=0.071\n",
      "785/67600 (epoch 0), train_loss = 1.590, time/batch=0.073\n",
      "786/67600 (epoch 0), train_loss = 1.574, time/batch=0.072\n",
      "787/67600 (epoch 0), train_loss = 1.565, time/batch=0.070\n",
      "788/67600 (epoch 0), train_loss = 1.552, time/batch=0.070\n",
      "789/67600 (epoch 0), train_loss = 1.517, time/batch=0.072\n",
      "790/67600 (epoch 0), train_loss = 1.526, time/batch=0.183\n",
      "791/67600 (epoch 0), train_loss = 1.516, time/batch=0.074\n",
      "792/67600 (epoch 0), train_loss = 1.524, time/batch=0.132\n",
      "793/67600 (epoch 0), train_loss = 1.577, time/batch=0.079\n",
      "794/67600 (epoch 0), train_loss = 1.520, time/batch=0.072\n",
      "795/67600 (epoch 0), train_loss = 1.545, time/batch=0.072\n",
      "796/67600 (epoch 0), train_loss = 1.586, time/batch=0.070\n",
      "797/67600 (epoch 0), train_loss = 1.568, time/batch=0.068\n",
      "798/67600 (epoch 0), train_loss = 1.544, time/batch=0.076\n",
      "799/67600 (epoch 0), train_loss = 1.527, time/batch=0.073\n",
      "800/67600 (epoch 0), train_loss = 1.546, time/batch=0.071\n",
      "801/67600 (epoch 0), train_loss = 1.559, time/batch=0.187\n",
      "802/67600 (epoch 0), train_loss = 1.558, time/batch=0.075\n",
      "803/67600 (epoch 0), train_loss = 1.566, time/batch=0.102\n",
      "804/67600 (epoch 0), train_loss = 1.495, time/batch=0.080\n",
      "805/67600 (epoch 0), train_loss = 1.500, time/batch=0.073\n",
      "806/67600 (epoch 0), train_loss = 1.556, time/batch=0.069\n",
      "807/67600 (epoch 0), train_loss = 1.512, time/batch=0.072\n",
      "808/67600 (epoch 0), train_loss = 1.474, time/batch=0.069\n",
      "809/67600 (epoch 0), train_loss = 1.553, time/batch=0.065\n",
      "810/67600 (epoch 0), train_loss = 1.518, time/batch=0.072\n",
      "811/67600 (epoch 0), train_loss = 1.603, time/batch=0.071\n",
      "812/67600 (epoch 0), train_loss = 1.536, time/batch=0.066\n",
      "813/67600 (epoch 0), train_loss = 1.566, time/batch=0.175\n",
      "814/67600 (epoch 0), train_loss = 1.564, time/batch=0.096\n",
      "815/67600 (epoch 0), train_loss = 1.498, time/batch=0.092\n",
      "816/67600 (epoch 0), train_loss = 1.583, time/batch=0.093\n",
      "817/67600 (epoch 0), train_loss = 1.478, time/batch=0.092\n",
      "818/67600 (epoch 0), train_loss = 1.519, time/batch=0.084\n",
      "819/67600 (epoch 0), train_loss = 1.532, time/batch=0.070\n",
      "820/67600 (epoch 0), train_loss = 1.457, time/batch=0.070\n",
      "821/67600 (epoch 0), train_loss = 1.554, time/batch=0.071\n",
      "822/67600 (epoch 0), train_loss = 1.539, time/batch=0.068\n",
      "823/67600 (epoch 0), train_loss = 1.571, time/batch=0.070\n",
      "824/67600 (epoch 0), train_loss = 1.515, time/batch=0.092\n",
      "825/67600 (epoch 0), train_loss = 1.552, time/batch=0.186\n",
      "826/67600 (epoch 0), train_loss = 1.669, time/batch=0.075\n",
      "827/67600 (epoch 0), train_loss = 1.526, time/batch=0.067\n",
      "828/67600 (epoch 0), train_loss = 1.538, time/batch=0.073\n",
      "829/67600 (epoch 0), train_loss = 1.520, time/batch=0.076\n",
      "830/67600 (epoch 0), train_loss = 1.555, time/batch=0.068\n",
      "831/67600 (epoch 0), train_loss = 1.543, time/batch=0.075\n",
      "832/67600 (epoch 0), train_loss = 1.560, time/batch=0.072\n",
      "833/67600 (epoch 0), train_loss = 1.566, time/batch=0.212\n",
      "834/67600 (epoch 0), train_loss = 1.483, time/batch=0.115\n",
      "835/67600 (epoch 0), train_loss = 1.568, time/batch=0.068\n",
      "836/67600 (epoch 0), train_loss = 1.434, time/batch=0.067\n",
      "837/67600 (epoch 0), train_loss = 1.574, time/batch=0.118\n",
      "838/67600 (epoch 0), train_loss = 1.440, time/batch=0.079\n",
      "839/67600 (epoch 0), train_loss = 1.545, time/batch=0.073\n",
      "840/67600 (epoch 0), train_loss = 1.590, time/batch=0.074\n",
      "841/67600 (epoch 0), train_loss = 1.549, time/batch=0.076\n",
      "842/67600 (epoch 0), train_loss = 1.519, time/batch=0.068\n",
      "843/67600 (epoch 0), train_loss = 1.564, time/batch=0.066\n",
      "844/67600 (epoch 0), train_loss = 1.534, time/batch=0.205\n",
      "845/67600 (epoch 0), train_loss = 1.515, time/batch=0.148\n",
      "846/67600 (epoch 0), train_loss = 1.545, time/batch=0.100\n",
      "847/67600 (epoch 0), train_loss = 1.499, time/batch=0.085\n",
      "848/67600 (epoch 0), train_loss = 1.554, time/batch=0.087\n",
      "849/67600 (epoch 0), train_loss = 1.520, time/batch=0.073\n",
      "850/67600 (epoch 0), train_loss = 1.505, time/batch=0.096\n",
      "851/67600 (epoch 0), train_loss = 1.576, time/batch=0.074\n",
      "852/67600 (epoch 0), train_loss = 1.581, time/batch=0.080\n",
      "853/67600 (epoch 0), train_loss = 1.568, time/batch=0.235\n",
      "854/67600 (epoch 0), train_loss = 1.511, time/batch=0.135\n",
      "855/67600 (epoch 0), train_loss = 1.569, time/batch=0.099\n",
      "856/67600 (epoch 0), train_loss = 1.539, time/batch=0.083\n",
      "857/67600 (epoch 0), train_loss = 1.515, time/batch=0.076\n",
      "858/67600 (epoch 0), train_loss = 1.570, time/batch=0.069\n",
      "859/67600 (epoch 0), train_loss = 1.565, time/batch=0.075\n",
      "860/67600 (epoch 0), train_loss = 1.550, time/batch=0.080\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "861/67600 (epoch 0), train_loss = 1.599, time/batch=0.074\n",
      "862/67600 (epoch 0), train_loss = 1.595, time/batch=0.067\n",
      "863/67600 (epoch 0), train_loss = 1.598, time/batch=0.073\n",
      "864/67600 (epoch 0), train_loss = 1.498, time/batch=0.206\n",
      "865/67600 (epoch 0), train_loss = 1.605, time/batch=0.112\n",
      "866/67600 (epoch 0), train_loss = 1.592, time/batch=0.082\n",
      "867/67600 (epoch 0), train_loss = 1.475, time/batch=0.099\n",
      "868/67600 (epoch 0), train_loss = 1.521, time/batch=0.119\n",
      "869/67600 (epoch 0), train_loss = 1.531, time/batch=0.099\n",
      "870/67600 (epoch 0), train_loss = 1.505, time/batch=0.073\n",
      "871/67600 (epoch 0), train_loss = 1.524, time/batch=0.072\n",
      "872/67600 (epoch 0), train_loss = 1.536, time/batch=0.074\n",
      "873/67600 (epoch 0), train_loss = 1.525, time/batch=0.088\n",
      "874/67600 (epoch 0), train_loss = 1.527, time/batch=0.189\n",
      "875/67600 (epoch 0), train_loss = 1.579, time/batch=0.085\n",
      "876/67600 (epoch 0), train_loss = 1.540, time/batch=0.069\n",
      "877/67600 (epoch 0), train_loss = 1.426, time/batch=0.073\n",
      "878/67600 (epoch 0), train_loss = 1.524, time/batch=0.073\n",
      "879/67600 (epoch 0), train_loss = 1.459, time/batch=0.072\n",
      "880/67600 (epoch 0), train_loss = 1.476, time/batch=0.075\n",
      "881/67600 (epoch 0), train_loss = 1.494, time/batch=0.067\n",
      "882/67600 (epoch 0), train_loss = 1.496, time/batch=0.069\n",
      "883/67600 (epoch 0), train_loss = 1.512, time/batch=0.075\n",
      "884/67600 (epoch 0), train_loss = 1.495, time/batch=0.071\n",
      "885/67600 (epoch 0), train_loss = 1.524, time/batch=0.122\n",
      "886/67600 (epoch 0), train_loss = 1.487, time/batch=0.163\n",
      "887/67600 (epoch 0), train_loss = 1.414, time/batch=0.069\n",
      "888/67600 (epoch 0), train_loss = 1.611, time/batch=0.072\n",
      "889/67600 (epoch 0), train_loss = 1.557, time/batch=0.076\n",
      "890/67600 (epoch 0), train_loss = 1.590, time/batch=0.069\n",
      "891/67600 (epoch 0), train_loss = 1.560, time/batch=0.076\n",
      "892/67600 (epoch 0), train_loss = 1.524, time/batch=0.075\n",
      "893/67600 (epoch 0), train_loss = 1.531, time/batch=0.071\n",
      "894/67600 (epoch 0), train_loss = 1.531, time/batch=0.115\n",
      "895/67600 (epoch 0), train_loss = 1.507, time/batch=0.069\n",
      "896/67600 (epoch 0), train_loss = 1.522, time/batch=0.073\n",
      "897/67600 (epoch 0), train_loss = 1.550, time/batch=0.072\n",
      "898/67600 (epoch 0), train_loss = 1.548, time/batch=0.074\n",
      "899/67600 (epoch 0), train_loss = 1.562, time/batch=0.070\n",
      "900/67600 (epoch 0), train_loss = 1.513, time/batch=0.072\n",
      "901/67600 (epoch 0), train_loss = 1.576, time/batch=0.074\n",
      "902/67600 (epoch 0), train_loss = 1.583, time/batch=0.069\n",
      "903/67600 (epoch 0), train_loss = 1.506, time/batch=0.071\n",
      "904/67600 (epoch 0), train_loss = 1.512, time/batch=0.237\n",
      "905/67600 (epoch 0), train_loss = 1.536, time/batch=0.069\n",
      "906/67600 (epoch 0), train_loss = 1.517, time/batch=0.089\n",
      "907/67600 (epoch 0), train_loss = 1.506, time/batch=0.071\n",
      "908/67600 (epoch 0), train_loss = 1.564, time/batch=0.068\n",
      "909/67600 (epoch 0), train_loss = 1.499, time/batch=0.070\n",
      "910/67600 (epoch 0), train_loss = 1.496, time/batch=0.095\n",
      "911/67600 (epoch 0), train_loss = 1.566, time/batch=0.080\n",
      "912/67600 (epoch 0), train_loss = 1.502, time/batch=0.069\n",
      "913/67600 (epoch 0), train_loss = 1.541, time/batch=0.074\n",
      "914/67600 (epoch 0), train_loss = 1.549, time/batch=0.073\n",
      "915/67600 (epoch 0), train_loss = 1.471, time/batch=0.073\n",
      "916/67600 (epoch 0), train_loss = 1.517, time/batch=0.223\n",
      "917/67600 (epoch 0), train_loss = 1.488, time/batch=0.083\n",
      "918/67600 (epoch 0), train_loss = 1.489, time/batch=0.068\n",
      "919/67600 (epoch 0), train_loss = 1.504, time/batch=0.073\n",
      "920/67600 (epoch 0), train_loss = 1.528, time/batch=0.074\n",
      "921/67600 (epoch 0), train_loss = 1.504, time/batch=0.085\n",
      "922/67600 (epoch 0), train_loss = 1.552, time/batch=0.095\n",
      "923/67600 (epoch 0), train_loss = 1.493, time/batch=0.088\n",
      "924/67600 (epoch 0), train_loss = 1.471, time/batch=0.087\n",
      "925/67600 (epoch 0), train_loss = 1.544, time/batch=0.096\n",
      "926/67600 (epoch 0), train_loss = 1.501, time/batch=0.271\n",
      "927/67600 (epoch 0), train_loss = 1.520, time/batch=0.079\n",
      "928/67600 (epoch 0), train_loss = 1.493, time/batch=0.067\n",
      "929/67600 (epoch 0), train_loss = 1.520, time/batch=0.072\n",
      "930/67600 (epoch 0), train_loss = 1.459, time/batch=0.071\n",
      "931/67600 (epoch 0), train_loss = 1.542, time/batch=0.070\n",
      "932/67600 (epoch 0), train_loss = 1.506, time/batch=0.071\n",
      "933/67600 (epoch 0), train_loss = 1.456, time/batch=0.072\n",
      "934/67600 (epoch 0), train_loss = 1.478, time/batch=0.178\n",
      "935/67600 (epoch 0), train_loss = 1.483, time/batch=0.072\n",
      "936/67600 (epoch 0), train_loss = 1.536, time/batch=0.113\n",
      "937/67600 (epoch 0), train_loss = 1.477, time/batch=0.073\n",
      "938/67600 (epoch 0), train_loss = 1.467, time/batch=0.072\n",
      "939/67600 (epoch 0), train_loss = 1.498, time/batch=0.076\n",
      "940/67600 (epoch 0), train_loss = 1.510, time/batch=0.071\n",
      "941/67600 (epoch 0), train_loss = 1.453, time/batch=0.071\n",
      "942/67600 (epoch 0), train_loss = 1.426, time/batch=0.071\n",
      "943/67600 (epoch 0), train_loss = 1.534, time/batch=0.072\n",
      "944/67600 (epoch 0), train_loss = 1.488, time/batch=0.071\n",
      "945/67600 (epoch 0), train_loss = 1.583, time/batch=0.078\n",
      "946/67600 (epoch 0), train_loss = 1.492, time/batch=0.181\n",
      "947/67600 (epoch 0), train_loss = 1.475, time/batch=0.119\n",
      "948/67600 (epoch 0), train_loss = 1.540, time/batch=0.070\n",
      "949/67600 (epoch 0), train_loss = 1.492, time/batch=0.069\n",
      "950/67600 (epoch 0), train_loss = 1.543, time/batch=0.075\n",
      "951/67600 (epoch 0), train_loss = 1.468, time/batch=0.070\n",
      "952/67600 (epoch 0), train_loss = 1.547, time/batch=0.072\n",
      "953/67600 (epoch 0), train_loss = 1.470, time/batch=0.069\n",
      "954/67600 (epoch 0), train_loss = 1.430, time/batch=0.070\n",
      "955/67600 (epoch 0), train_loss = 1.520, time/batch=0.083\n",
      "956/67600 (epoch 0), train_loss = 1.516, time/batch=0.074\n",
      "957/67600 (epoch 0), train_loss = 1.546, time/batch=0.182\n",
      "958/67600 (epoch 0), train_loss = 1.485, time/batch=0.076\n",
      "959/67600 (epoch 0), train_loss = 1.496, time/batch=0.102\n",
      "960/67600 (epoch 0), train_loss = 1.485, time/batch=0.071\n",
      "961/67600 (epoch 0), train_loss = 1.400, time/batch=0.069\n",
      "962/67600 (epoch 0), train_loss = 1.437, time/batch=0.071\n",
      "963/67600 (epoch 0), train_loss = 1.462, time/batch=0.070\n",
      "964/67600 (epoch 0), train_loss = 1.415, time/batch=0.066\n",
      "965/67600 (epoch 0), train_loss = 1.502, time/batch=0.069\n",
      "966/67600 (epoch 0), train_loss = 1.522, time/batch=0.075\n",
      "967/67600 (epoch 0), train_loss = 1.458, time/batch=0.072\n",
      "968/67600 (epoch 0), train_loss = 1.467, time/batch=0.069\n",
      "969/67600 (epoch 0), train_loss = 1.426, time/batch=0.157\n",
      "970/67600 (epoch 0), train_loss = 1.513, time/batch=0.109\n",
      "971/67600 (epoch 0), train_loss = 1.522, time/batch=0.089\n",
      "972/67600 (epoch 0), train_loss = 1.438, time/batch=0.072\n",
      "973/67600 (epoch 0), train_loss = 1.505, time/batch=0.069\n",
      "974/67600 (epoch 0), train_loss = 1.538, time/batch=0.071\n",
      "975/67600 (epoch 0), train_loss = 1.420, time/batch=0.073\n",
      "976/67600 (epoch 0), train_loss = 1.431, time/batch=0.070\n",
      "977/67600 (epoch 0), train_loss = 1.466, time/batch=0.075\n",
      "978/67600 (epoch 0), train_loss = 1.532, time/batch=0.071\n",
      "979/67600 (epoch 0), train_loss = 1.508, time/batch=0.068\n",
      "980/67600 (epoch 0), train_loss = 1.529, time/batch=0.070\n",
      "981/67600 (epoch 0), train_loss = 1.472, time/batch=0.119\n",
      "982/67600 (epoch 0), train_loss = 1.448, time/batch=0.155\n",
      "983/67600 (epoch 0), train_loss = 1.505, time/batch=0.080\n",
      "984/67600 (epoch 0), train_loss = 1.480, time/batch=0.069\n",
      "985/67600 (epoch 0), train_loss = 1.600, time/batch=0.072\n",
      "986/67600 (epoch 0), train_loss = 1.498, time/batch=0.073\n",
      "987/67600 (epoch 0), train_loss = 1.564, time/batch=0.070\n",
      "988/67600 (epoch 0), train_loss = 1.486, time/batch=0.069\n",
      "989/67600 (epoch 0), train_loss = 1.456, time/batch=0.071\n",
      "990/67600 (epoch 0), train_loss = 1.515, time/batch=0.211\n",
      "991/67600 (epoch 0), train_loss = 1.445, time/batch=0.122\n",
      "992/67600 (epoch 0), train_loss = 1.540, time/batch=0.070\n",
      "993/67600 (epoch 0), train_loss = 1.477, time/batch=0.075\n",
      "994/67600 (epoch 0), train_loss = 1.494, time/batch=0.077\n",
      "995/67600 (epoch 0), train_loss = 1.503, time/batch=0.069\n",
      "996/67600 (epoch 0), train_loss = 1.505, time/batch=0.071\n",
      "997/67600 (epoch 0), train_loss = 1.538, time/batch=0.066\n",
      "998/67600 (epoch 0), train_loss = 1.438, time/batch=0.079\n",
      "999/67600 (epoch 0), train_loss = 1.442, time/batch=0.097\n",
      "1000/67600 (epoch 0), train_loss = 1.497, time/batch=0.069\n",
      "model saved to ./save/model.ckpt\n",
      "1001/67600 (epoch 0), train_loss = 1.519, time/batch=0.075\n",
      "1002/67600 (epoch 0), train_loss = 1.450, time/batch=0.070\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1003/67600 (epoch 0), train_loss = 1.502, time/batch=0.070\n",
      "1004/67600 (epoch 0), train_loss = 1.442, time/batch=0.070\n",
      "1005/67600 (epoch 0), train_loss = 1.501, time/batch=0.070\n",
      "1006/67600 (epoch 0), train_loss = 1.479, time/batch=0.072\n",
      "1007/67600 (epoch 0), train_loss = 1.434, time/batch=0.071\n",
      "1008/67600 (epoch 0), train_loss = 1.501, time/batch=0.069\n",
      "1009/67600 (epoch 0), train_loss = 1.430, time/batch=0.080\n",
      "1010/67600 (epoch 0), train_loss = 1.486, time/batch=0.083\n",
      "1011/67600 (epoch 0), train_loss = 1.467, time/batch=0.210\n",
      "1012/67600 (epoch 0), train_loss = 1.449, time/batch=0.084\n",
      "1013/67600 (epoch 0), train_loss = 1.425, time/batch=0.070\n",
      "1014/67600 (epoch 0), train_loss = 1.481, time/batch=0.072\n",
      "1015/67600 (epoch 0), train_loss = 1.471, time/batch=0.070\n",
      "1016/67600 (epoch 0), train_loss = 1.469, time/batch=0.074\n",
      "1017/67600 (epoch 0), train_loss = 1.510, time/batch=0.090\n",
      "1018/67600 (epoch 0), train_loss = 1.472, time/batch=0.089\n",
      "1019/67600 (epoch 0), train_loss = 1.477, time/batch=0.082\n",
      "1020/67600 (epoch 0), train_loss = 1.477, time/batch=0.081\n",
      "1021/67600 (epoch 0), train_loss = 1.450, time/batch=0.074\n",
      "1022/67600 (epoch 0), train_loss = 1.453, time/batch=0.222\n",
      "1023/67600 (epoch 0), train_loss = 1.470, time/batch=0.070\n",
      "1024/67600 (epoch 0), train_loss = 1.486, time/batch=0.078\n",
      "1025/67600 (epoch 0), train_loss = 1.431, time/batch=0.085\n",
      "1026/67600 (epoch 0), train_loss = 1.504, time/batch=0.073\n",
      "1027/67600 (epoch 0), train_loss = 1.438, time/batch=0.069\n",
      "1028/67600 (epoch 0), train_loss = 1.552, time/batch=0.073\n",
      "1029/67600 (epoch 0), train_loss = 1.532, time/batch=0.071\n",
      "1030/67600 (epoch 0), train_loss = 1.516, time/batch=0.115\n",
      "1031/67600 (epoch 0), train_loss = 1.531, time/batch=0.074\n",
      "1032/67600 (epoch 0), train_loss = 1.478, time/batch=0.068\n",
      "1033/67600 (epoch 0), train_loss = 1.452, time/batch=0.074\n",
      "1034/67600 (epoch 0), train_loss = 1.487, time/batch=0.072\n",
      "1035/67600 (epoch 0), train_loss = 1.463, time/batch=0.069\n",
      "1036/67600 (epoch 0), train_loss = 1.421, time/batch=0.070\n",
      "1037/67600 (epoch 0), train_loss = 1.422, time/batch=0.071\n",
      "1038/67600 (epoch 0), train_loss = 1.460, time/batch=0.073\n",
      "1039/67600 (epoch 0), train_loss = 1.478, time/batch=0.103\n",
      "1040/67600 (epoch 0), train_loss = 1.489, time/batch=0.228\n",
      "1041/67600 (epoch 0), train_loss = 1.448, time/batch=0.076\n",
      "1042/67600 (epoch 0), train_loss = 1.515, time/batch=0.116\n",
      "1043/67600 (epoch 0), train_loss = 1.383, time/batch=0.088\n",
      "1044/67600 (epoch 0), train_loss = 1.469, time/batch=0.069\n",
      "1045/67600 (epoch 0), train_loss = 1.444, time/batch=0.072\n",
      "1046/67600 (epoch 0), train_loss = 1.480, time/batch=0.072\n",
      "1047/67600 (epoch 0), train_loss = 1.534, time/batch=0.073\n",
      "1048/67600 (epoch 0), train_loss = 1.507, time/batch=0.070\n",
      "1049/67600 (epoch 0), train_loss = 1.499, time/batch=0.075\n",
      "1050/67600 (epoch 0), train_loss = 1.481, time/batch=0.076\n",
      "1051/67600 (epoch 0), train_loss = 1.432, time/batch=0.214\n",
      "1052/67600 (epoch 0), train_loss = 1.494, time/batch=0.071\n",
      "1053/67600 (epoch 0), train_loss = 1.458, time/batch=0.085\n",
      "1054/67600 (epoch 0), train_loss = 1.508, time/batch=0.070\n",
      "1055/67600 (epoch 0), train_loss = 1.482, time/batch=0.070\n",
      "1056/67600 (epoch 0), train_loss = 1.420, time/batch=0.071\n",
      "1057/67600 (epoch 0), train_loss = 1.507, time/batch=0.073\n",
      "1058/67600 (epoch 0), train_loss = 1.536, time/batch=0.071\n",
      "1059/67600 (epoch 0), train_loss = 1.452, time/batch=0.069\n",
      "1060/67600 (epoch 0), train_loss = 1.476, time/batch=0.073\n",
      "1061/67600 (epoch 0), train_loss = 1.492, time/batch=0.076\n",
      "1062/67600 (epoch 0), train_loss = 1.463, time/batch=0.072\n",
      "1063/67600 (epoch 0), train_loss = 1.421, time/batch=0.221\n",
      "1064/67600 (epoch 0), train_loss = 1.477, time/batch=0.078\n",
      "1065/67600 (epoch 0), train_loss = 1.479, time/batch=0.068\n",
      "1066/67600 (epoch 0), train_loss = 1.448, time/batch=0.070\n",
      "1067/67600 (epoch 0), train_loss = 1.525, time/batch=0.071\n",
      "1068/67600 (epoch 0), train_loss = 1.460, time/batch=0.070\n",
      "1069/67600 (epoch 0), train_loss = 1.507, time/batch=0.072\n",
      "1070/67600 (epoch 0), train_loss = 1.496, time/batch=0.070\n",
      "1071/67600 (epoch 0), train_loss = 1.516, time/batch=0.109\n",
      "1072/67600 (epoch 0), train_loss = 1.468, time/batch=0.149\n",
      "1073/67600 (epoch 0), train_loss = 1.476, time/batch=0.107\n",
      "1074/67600 (epoch 0), train_loss = 1.438, time/batch=0.070\n",
      "1075/67600 (epoch 0), train_loss = 1.458, time/batch=0.075\n",
      "1076/67600 (epoch 0), train_loss = 1.472, time/batch=0.094\n",
      "1077/67600 (epoch 0), train_loss = 1.463, time/batch=0.087\n",
      "1078/67600 (epoch 0), train_loss = 1.506, time/batch=0.071\n",
      "1079/67600 (epoch 0), train_loss = 1.521, time/batch=0.069\n",
      "1080/67600 (epoch 0), train_loss = 1.517, time/batch=0.072\n",
      "1081/67600 (epoch 0), train_loss = 1.456, time/batch=0.083\n",
      "1082/67600 (epoch 0), train_loss = 1.513, time/batch=0.143\n",
      "1083/67600 (epoch 0), train_loss = 1.455, time/batch=0.128\n",
      "1084/67600 (epoch 0), train_loss = 1.448, time/batch=0.130\n",
      "1085/67600 (epoch 0), train_loss = 1.566, time/batch=0.071\n",
      "1086/67600 (epoch 0), train_loss = 1.484, time/batch=0.068\n",
      "1087/67600 (epoch 0), train_loss = 1.410, time/batch=0.072\n",
      "1088/67600 (epoch 0), train_loss = 1.449, time/batch=0.072\n",
      "1089/67600 (epoch 0), train_loss = 1.436, time/batch=0.068\n",
      "1090/67600 (epoch 0), train_loss = 1.511, time/batch=0.069\n",
      "1091/67600 (epoch 0), train_loss = 1.496, time/batch=0.090\n",
      "1092/67600 (epoch 0), train_loss = 1.520, time/batch=0.104\n",
      "1093/67600 (epoch 0), train_loss = 1.449, time/batch=0.206\n",
      "1094/67600 (epoch 0), train_loss = 1.464, time/batch=0.092\n",
      "1095/67600 (epoch 0), train_loss = 1.479, time/batch=0.107\n",
      "1096/67600 (epoch 0), train_loss = 1.477, time/batch=0.107\n",
      "1097/67600 (epoch 0), train_loss = 1.488, time/batch=0.082\n",
      "1098/67600 (epoch 0), train_loss = 1.447, time/batch=0.074\n",
      "1099/67600 (epoch 0), train_loss = 1.408, time/batch=0.101\n",
      "1100/67600 (epoch 0), train_loss = 1.451, time/batch=0.082\n",
      "1101/67600 (epoch 0), train_loss = 1.447, time/batch=0.076\n",
      "1102/67600 (epoch 0), train_loss = 1.435, time/batch=0.085\n",
      "1103/67600 (epoch 0), train_loss = 1.409, time/batch=0.216\n",
      "1104/67600 (epoch 0), train_loss = 1.550, time/batch=0.093\n",
      "1105/67600 (epoch 0), train_loss = 1.434, time/batch=0.077\n",
      "1106/67600 (epoch 0), train_loss = 1.466, time/batch=0.078\n",
      "1107/67600 (epoch 0), train_loss = 1.483, time/batch=0.074\n",
      "1108/67600 (epoch 0), train_loss = 1.464, time/batch=0.078\n",
      "1109/67600 (epoch 0), train_loss = 1.485, time/batch=0.072\n",
      "1110/67600 (epoch 0), train_loss = 1.463, time/batch=0.075\n",
      "1111/67600 (epoch 0), train_loss = 1.477, time/batch=0.080\n",
      "1112/67600 (epoch 0), train_loss = 1.508, time/batch=0.079\n",
      "1113/67600 (epoch 0), train_loss = 1.527, time/batch=0.068\n",
      "1114/67600 (epoch 0), train_loss = 1.500, time/batch=0.234\n",
      "1115/67600 (epoch 0), train_loss = 1.581, time/batch=0.077\n",
      "1116/67600 (epoch 0), train_loss = 1.435, time/batch=0.075\n",
      "1117/67600 (epoch 0), train_loss = 1.506, time/batch=0.080\n",
      "1118/67600 (epoch 0), train_loss = 1.460, time/batch=0.075\n",
      "1119/67600 (epoch 0), train_loss = 1.569, time/batch=0.074\n",
      "1120/67600 (epoch 0), train_loss = 1.476, time/batch=0.072\n",
      "1121/67600 (epoch 0), train_loss = 1.511, time/batch=0.071\n",
      "1122/67600 (epoch 0), train_loss = 1.583, time/batch=0.175\n",
      "1123/67600 (epoch 0), train_loss = 1.467, time/batch=0.078\n",
      "1124/67600 (epoch 0), train_loss = 1.454, time/batch=0.119\n",
      "1125/67600 (epoch 0), train_loss = 1.476, time/batch=0.072\n",
      "1126/67600 (epoch 0), train_loss = 1.547, time/batch=0.085\n",
      "1127/67600 (epoch 0), train_loss = 1.454, time/batch=0.090\n",
      "1128/67600 (epoch 0), train_loss = 1.496, time/batch=0.076\n",
      "1129/67600 (epoch 0), train_loss = 1.455, time/batch=0.073\n",
      "1130/67600 (epoch 0), train_loss = 1.488, time/batch=0.074\n",
      "1131/67600 (epoch 0), train_loss = 1.496, time/batch=0.079\n",
      "1132/67600 (epoch 0), train_loss = 1.449, time/batch=0.071\n",
      "1133/67600 (epoch 0), train_loss = 1.500, time/batch=0.157\n",
      "1134/67600 (epoch 0), train_loss = 1.532, time/batch=0.101\n",
      "1135/67600 (epoch 0), train_loss = 1.524, time/batch=0.214\n",
      "1136/67600 (epoch 0), train_loss = 1.514, time/batch=0.103\n",
      "1137/67600 (epoch 0), train_loss = 1.469, time/batch=0.074\n",
      "1138/67600 (epoch 0), train_loss = 1.485, time/batch=0.079\n",
      "1139/67600 (epoch 0), train_loss = 1.496, time/batch=0.079\n",
      "1140/67600 (epoch 0), train_loss = 1.488, time/batch=0.074\n",
      "1141/67600 (epoch 0), train_loss = 1.490, time/batch=0.108\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1142/67600 (epoch 0), train_loss = 1.525, time/batch=0.210\n",
      "1143/67600 (epoch 0), train_loss = 1.516, time/batch=0.071\n",
      "1144/67600 (epoch 0), train_loss = 1.474, time/batch=0.104\n",
      "1145/67600 (epoch 0), train_loss = 1.471, time/batch=0.075\n",
      "1146/67600 (epoch 0), train_loss = 1.462, time/batch=0.079\n",
      "1147/67600 (epoch 0), train_loss = 1.468, time/batch=0.074\n",
      "1148/67600 (epoch 0), train_loss = 1.430, time/batch=0.073\n",
      "1149/67600 (epoch 0), train_loss = 1.475, time/batch=0.072\n",
      "1150/67600 (epoch 0), train_loss = 1.414, time/batch=0.073\n",
      "1151/67600 (epoch 0), train_loss = 1.483, time/batch=0.072\n",
      "1152/67600 (epoch 0), train_loss = 1.451, time/batch=0.104\n",
      "1153/67600 (epoch 0), train_loss = 1.428, time/batch=0.244\n",
      "1154/67600 (epoch 0), train_loss = 1.468, time/batch=0.109\n",
      "1155/67600 (epoch 0), train_loss = 1.473, time/batch=0.093\n",
      "1156/67600 (epoch 0), train_loss = 1.456, time/batch=0.083\n",
      "1157/67600 (epoch 0), train_loss = 1.398, time/batch=0.070\n",
      "1158/67600 (epoch 0), train_loss = 1.499, time/batch=0.075\n",
      "1159/67600 (epoch 0), train_loss = 1.478, time/batch=0.071\n",
      "1160/67600 (epoch 0), train_loss = 1.437, time/batch=0.075\n",
      "1161/67600 (epoch 0), train_loss = 1.443, time/batch=0.070\n",
      "1162/67600 (epoch 0), train_loss = 1.428, time/batch=0.074\n",
      "1163/67600 (epoch 0), train_loss = 1.432, time/batch=0.073\n",
      "1164/67600 (epoch 0), train_loss = 1.494, time/batch=0.210\n",
      "1165/67600 (epoch 0), train_loss = 1.416, time/batch=0.086\n",
      "1166/67600 (epoch 0), train_loss = 1.415, time/batch=0.071\n",
      "1167/67600 (epoch 0), train_loss = 1.445, time/batch=0.081\n",
      "1168/67600 (epoch 0), train_loss = 1.481, time/batch=0.071\n",
      "1169/67600 (epoch 0), train_loss = 1.421, time/batch=0.075\n",
      "1170/67600 (epoch 0), train_loss = 1.439, time/batch=0.070\n",
      "1171/67600 (epoch 0), train_loss = 1.435, time/batch=0.070\n",
      "1172/67600 (epoch 0), train_loss = 1.433, time/batch=0.072\n",
      "1173/67600 (epoch 0), train_loss = 1.423, time/batch=0.068\n",
      "1174/67600 (epoch 0), train_loss = 1.429, time/batch=0.068\n",
      "1175/67600 (epoch 0), train_loss = 1.459, time/batch=0.070\n",
      "1176/67600 (epoch 0), train_loss = 1.473, time/batch=0.220\n",
      "1177/67600 (epoch 0), train_loss = 1.474, time/batch=0.071\n",
      "1178/67600 (epoch 0), train_loss = 1.471, time/batch=0.069\n",
      "1179/67600 (epoch 0), train_loss = 1.574, time/batch=0.071\n",
      "1180/67600 (epoch 0), train_loss = 1.547, time/batch=0.071\n",
      "1181/67600 (epoch 0), train_loss = 1.507, time/batch=0.070\n",
      "1182/67600 (epoch 0), train_loss = 1.440, time/batch=0.075\n",
      "1183/67600 (epoch 0), train_loss = 1.460, time/batch=0.076\n",
      "1184/67600 (epoch 0), train_loss = 1.492, time/batch=0.121\n",
      "1185/67600 (epoch 0), train_loss = 1.411, time/batch=0.078\n",
      "1186/67600 (epoch 0), train_loss = 1.421, time/batch=0.071\n",
      "1187/67600 (epoch 0), train_loss = 1.513, time/batch=0.070\n",
      "1188/67600 (epoch 0), train_loss = 1.444, time/batch=0.077\n",
      "1189/67600 (epoch 0), train_loss = 1.445, time/batch=0.076\n",
      "1190/67600 (epoch 0), train_loss = 1.449, time/batch=0.070\n",
      "1191/67600 (epoch 0), train_loss = 1.452, time/batch=0.075\n",
      "1192/67600 (epoch 0), train_loss = 1.426, time/batch=0.074\n",
      "1193/67600 (epoch 0), train_loss = 1.444, time/batch=0.075\n",
      "1194/67600 (epoch 0), train_loss = 1.418, time/batch=0.273\n",
      "1195/67600 (epoch 0), train_loss = 1.414, time/batch=0.098\n",
      "1196/67600 (epoch 0), train_loss = 1.482, time/batch=0.071\n",
      "1197/67600 (epoch 0), train_loss = 1.470, time/batch=0.077\n",
      "1198/67600 (epoch 0), train_loss = 1.476, time/batch=0.071\n",
      "1199/67600 (epoch 0), train_loss = 1.444, time/batch=0.072\n",
      "1200/67600 (epoch 0), train_loss = 1.455, time/batch=0.074\n",
      "1201/67600 (epoch 0), train_loss = 1.419, time/batch=0.074\n",
      "1202/67600 (epoch 0), train_loss = 1.449, time/batch=0.071\n",
      "1203/67600 (epoch 0), train_loss = 1.427, time/batch=0.073\n",
      "1204/67600 (epoch 0), train_loss = 1.538, time/batch=0.070\n",
      "1205/67600 (epoch 0), train_loss = 1.445, time/batch=0.231\n",
      "1206/67600 (epoch 0), train_loss = 1.413, time/batch=0.077\n",
      "1207/67600 (epoch 0), train_loss = 1.470, time/batch=0.078\n",
      "1208/67600 (epoch 0), train_loss = 1.421, time/batch=0.073\n",
      "1209/67600 (epoch 0), train_loss = 1.397, time/batch=0.070\n",
      "1210/67600 (epoch 0), train_loss = 1.454, time/batch=0.072\n",
      "1211/67600 (epoch 0), train_loss = 1.419, time/batch=0.071\n",
      "1212/67600 (epoch 0), train_loss = 1.399, time/batch=0.073\n",
      "1213/67600 (epoch 0), train_loss = 1.483, time/batch=0.088\n",
      "1214/67600 (epoch 0), train_loss = 1.492, time/batch=0.074\n",
      "1215/67600 (epoch 0), train_loss = 1.430, time/batch=0.071\n",
      "1216/67600 (epoch 0), train_loss = 1.437, time/batch=0.067\n",
      "1217/67600 (epoch 0), train_loss = 1.451, time/batch=0.220\n",
      "1218/67600 (epoch 0), train_loss = 1.440, time/batch=0.076\n",
      "1219/67600 (epoch 0), train_loss = 1.450, time/batch=0.071\n",
      "1220/67600 (epoch 0), train_loss = 1.459, time/batch=0.077\n",
      "1221/67600 (epoch 0), train_loss = 1.434, time/batch=0.067\n",
      "1222/67600 (epoch 0), train_loss = 1.475, time/batch=0.071\n",
      "1223/67600 (epoch 0), train_loss = 1.422, time/batch=0.071\n",
      "1224/67600 (epoch 0), train_loss = 1.493, time/batch=0.072\n",
      "1225/67600 (epoch 0), train_loss = 1.495, time/batch=0.189\n",
      "1226/67600 (epoch 0), train_loss = 1.468, time/batch=0.072\n",
      "1227/67600 (epoch 0), train_loss = 1.465, time/batch=0.106\n",
      "1228/67600 (epoch 0), train_loss = 1.480, time/batch=0.073\n",
      "1229/67600 (epoch 0), train_loss = 1.418, time/batch=0.072\n",
      "1230/67600 (epoch 0), train_loss = 1.467, time/batch=0.079\n",
      "1231/67600 (epoch 0), train_loss = 1.478, time/batch=0.072\n",
      "1232/67600 (epoch 0), train_loss = 1.550, time/batch=0.070\n",
      "1233/67600 (epoch 0), train_loss = 1.492, time/batch=0.071\n",
      "1234/67600 (epoch 0), train_loss = 1.402, time/batch=0.072\n",
      "1235/67600 (epoch 0), train_loss = 1.447, time/batch=0.076\n",
      "1236/67600 (epoch 0), train_loss = 1.451, time/batch=0.071\n",
      "1237/67600 (epoch 0), train_loss = 1.455, time/batch=0.195\n",
      "1238/67600 (epoch 0), train_loss = 1.435, time/batch=0.084\n",
      "1239/67600 (epoch 0), train_loss = 1.429, time/batch=0.089\n",
      "1240/67600 (epoch 0), train_loss = 1.513, time/batch=0.073\n",
      "1241/67600 (epoch 0), train_loss = 1.439, time/batch=0.071\n",
      "1242/67600 (epoch 0), train_loss = 1.451, time/batch=0.071\n",
      "1243/67600 (epoch 0), train_loss = 1.468, time/batch=0.073\n",
      "1244/67600 (epoch 0), train_loss = 1.566, time/batch=0.070\n",
      "1245/67600 (epoch 0), train_loss = 1.443, time/batch=0.071\n",
      "1246/67600 (epoch 0), train_loss = 1.410, time/batch=0.072\n",
      "1247/67600 (epoch 0), train_loss = 1.462, time/batch=0.074\n",
      "1248/67600 (epoch 0), train_loss = 1.489, time/batch=0.088\n",
      "1249/67600 (epoch 0), train_loss = 1.479, time/batch=0.187\n",
      "1250/67600 (epoch 0), train_loss = 1.419, time/batch=0.094\n",
      "1251/67600 (epoch 0), train_loss = 1.523, time/batch=0.080\n",
      "1252/67600 (epoch 0), train_loss = 1.402, time/batch=0.073\n",
      "1253/67600 (epoch 0), train_loss = 1.520, time/batch=0.072\n",
      "1254/67600 (epoch 0), train_loss = 1.450, time/batch=0.076\n",
      "1255/67600 (epoch 0), train_loss = 1.492, time/batch=0.072\n",
      "1256/67600 (epoch 0), train_loss = 1.475, time/batch=0.072\n",
      "1257/67600 (epoch 0), train_loss = 1.472, time/batch=0.071\n",
      "1258/67600 (epoch 0), train_loss = 1.508, time/batch=0.072\n",
      "1259/67600 (epoch 0), train_loss = 1.448, time/batch=0.074\n",
      "1260/67600 (epoch 0), train_loss = 1.461, time/batch=0.212\n",
      "1261/67600 (epoch 0), train_loss = 1.398, time/batch=0.070\n",
      "1262/67600 (epoch 0), train_loss = 1.515, time/batch=0.089\n",
      "1263/67600 (epoch 0), train_loss = 1.526, time/batch=0.071\n",
      "1264/67600 (epoch 0), train_loss = 1.512, time/batch=0.071\n",
      "1265/67600 (epoch 0), train_loss = 1.453, time/batch=0.071\n",
      "1266/67600 (epoch 0), train_loss = 1.553, time/batch=0.075\n",
      "1267/67600 (epoch 0), train_loss = 1.445, time/batch=0.077\n",
      "1268/67600 (epoch 0), train_loss = 1.403, time/batch=0.080\n",
      "1269/67600 (epoch 0), train_loss = 1.461, time/batch=0.071\n",
      "1270/67600 (epoch 0), train_loss = 1.453, time/batch=0.070\n",
      "1271/67600 (epoch 0), train_loss = 1.429, time/batch=0.069\n",
      "1272/67600 (epoch 0), train_loss = 1.457, time/batch=0.209\n",
      "1273/67600 (epoch 0), train_loss = 1.485, time/batch=0.077\n",
      "1274/67600 (epoch 0), train_loss = 1.493, time/batch=0.066\n",
      "1275/67600 (epoch 0), train_loss = 1.492, time/batch=0.071\n",
      "1276/67600 (epoch 0), train_loss = 1.488, time/batch=0.070\n",
      "1277/67600 (epoch 0), train_loss = 1.453, time/batch=0.074\n",
      "1278/67600 (epoch 0), train_loss = 1.414, time/batch=0.075\n",
      "1279/67600 (epoch 0), train_loss = 1.387, time/batch=0.072\n",
      "1280/67600 (epoch 0), train_loss = 1.431, time/batch=0.173\n",
      "1281/67600 (epoch 0), train_loss = 1.500, time/batch=0.075\n",
      "1282/67600 (epoch 0), train_loss = 1.419, time/batch=0.111\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1283/67600 (epoch 0), train_loss = 1.484, time/batch=0.073\n",
      "1284/67600 (epoch 0), train_loss = 1.470, time/batch=0.069\n",
      "1285/67600 (epoch 0), train_loss = 1.446, time/batch=0.083\n",
      "1286/67600 (epoch 0), train_loss = 1.389, time/batch=0.074\n",
      "1287/67600 (epoch 0), train_loss = 1.501, time/batch=0.071\n",
      "1288/67600 (epoch 0), train_loss = 1.442, time/batch=0.075\n",
      "1289/67600 (epoch 0), train_loss = 1.487, time/batch=0.073\n",
      "1290/67600 (epoch 0), train_loss = 1.526, time/batch=0.070\n",
      "1291/67600 (epoch 0), train_loss = 1.486, time/batch=0.071\n",
      "1292/67600 (epoch 0), train_loss = 1.422, time/batch=0.185\n",
      "1293/67600 (epoch 0), train_loss = 1.477, time/batch=0.076\n",
      "1294/67600 (epoch 0), train_loss = 1.454, time/batch=0.110\n",
      "1295/67600 (epoch 0), train_loss = 1.417, time/batch=0.069\n",
      "1296/67600 (epoch 0), train_loss = 1.441, time/batch=0.072\n",
      "1297/67600 (epoch 0), train_loss = 1.449, time/batch=0.074\n",
      "1298/67600 (epoch 0), train_loss = 1.401, time/batch=0.076\n",
      "1299/67600 (epoch 0), train_loss = 1.474, time/batch=0.071\n",
      "1300/67600 (epoch 0), train_loss = 1.501, time/batch=0.075\n",
      "1301/67600 (epoch 0), train_loss = 1.455, time/batch=0.082\n",
      "1302/67600 (epoch 0), train_loss = 1.407, time/batch=0.072\n",
      "1303/67600 (epoch 0), train_loss = 1.436, time/batch=0.070\n",
      "1304/67600 (epoch 0), train_loss = 1.461, time/batch=0.198\n",
      "1305/67600 (epoch 0), train_loss = 1.398, time/batch=0.102\n",
      "1306/67600 (epoch 0), train_loss = 1.458, time/batch=0.072\n",
      "1307/67600 (epoch 0), train_loss = 1.451, time/batch=0.073\n",
      "1308/67600 (epoch 0), train_loss = 1.455, time/batch=0.074\n",
      "1309/67600 (epoch 0), train_loss = 1.435, time/batch=0.072\n",
      "1310/67600 (epoch 0), train_loss = 1.446, time/batch=0.078\n",
      "1311/67600 (epoch 0), train_loss = 1.465, time/batch=0.070\n",
      "1312/67600 (epoch 0), train_loss = 1.456, time/batch=0.074\n",
      "1313/67600 (epoch 0), train_loss = 1.479, time/batch=0.073\n",
      "1314/67600 (epoch 0), train_loss = 1.498, time/batch=0.069\n",
      "1315/67600 (epoch 0), train_loss = 1.449, time/batch=0.136\n",
      "1316/67600 (epoch 0), train_loss = 1.474, time/batch=0.137\n",
      "1317/67600 (epoch 0), train_loss = 1.481, time/batch=0.089\n",
      "1318/67600 (epoch 0), train_loss = 1.451, time/batch=0.069\n",
      "1319/67600 (epoch 0), train_loss = 1.449, time/batch=0.072\n",
      "1320/67600 (epoch 0), train_loss = 1.439, time/batch=0.073\n",
      "1321/67600 (epoch 0), train_loss = 1.463, time/batch=0.071\n",
      "1322/67600 (epoch 0), train_loss = 1.409, time/batch=0.074\n",
      "1323/67600 (epoch 0), train_loss = 1.444, time/batch=0.073\n",
      "1324/67600 (epoch 0), train_loss = 1.512, time/batch=0.072\n",
      "1325/67600 (epoch 0), train_loss = 1.429, time/batch=0.071\n",
      "1326/67600 (epoch 0), train_loss = 1.450, time/batch=0.073\n",
      "1327/67600 (epoch 0), train_loss = 1.448, time/batch=0.182\n",
      "1328/67600 (epoch 0), train_loss = 1.442, time/batch=0.107\n",
      "1329/67600 (epoch 0), train_loss = 1.468, time/batch=0.084\n",
      "1330/67600 (epoch 0), train_loss = 1.499, time/batch=0.071\n",
      "1331/67600 (epoch 0), train_loss = 1.505, time/batch=0.073\n",
      "1332/67600 (epoch 0), train_loss = 1.452, time/batch=0.078\n",
      "1333/67600 (epoch 0), train_loss = 1.428, time/batch=0.071\n",
      "1334/67600 (epoch 0), train_loss = 1.391, time/batch=0.072\n",
      "1335/67600 (epoch 0), train_loss = 1.455, time/batch=0.077\n",
      "1336/67600 (epoch 0), train_loss = 1.477, time/batch=0.070\n",
      "1337/67600 (epoch 0), train_loss = 1.449, time/batch=0.072\n",
      "1338/67600 (epoch 0), train_loss = 1.486, time/batch=0.070\n",
      "1339/67600 (epoch 0), train_loss = 1.443, time/batch=0.223\n",
      "1340/67600 (epoch 0), train_loss = 1.439, time/batch=0.075\n",
      "1341/67600 (epoch 0), train_loss = 1.467, time/batch=0.072\n",
      "1342/67600 (epoch 0), train_loss = 1.472, time/batch=0.072\n",
      "1343/67600 (epoch 0), train_loss = 1.434, time/batch=0.071\n",
      "1344/67600 (epoch 0), train_loss = 1.437, time/batch=0.072\n",
      "1345/67600 (epoch 0), train_loss = 1.463, time/batch=0.074\n",
      "1346/67600 (epoch 0), train_loss = 1.409, time/batch=0.071\n",
      "1347/67600 (epoch 0), train_loss = 1.453, time/batch=0.122\n",
      "1348/67600 (epoch 0), train_loss = 1.509, time/batch=0.073\n",
      "1349/67600 (epoch 0), train_loss = 1.535, time/batch=0.070\n",
      "1350/67600 (epoch 0), train_loss = 1.445, time/batch=0.072\n",
      "1351/67600 (epoch 0), train_loss = 1.462, time/batch=0.071\n",
      "1352/67600 (epoch 1), train_loss = 1.612, time/batch=0.081\n",
      "1353/67600 (epoch 1), train_loss = 1.387, time/batch=0.073\n",
      "1354/67600 (epoch 1), train_loss = 1.475, time/batch=0.072\n",
      "1355/67600 (epoch 1), train_loss = 1.413, time/batch=0.071\n",
      "1356/67600 (epoch 1), train_loss = 1.452, time/batch=0.212\n",
      "1357/67600 (epoch 1), train_loss = 1.459, time/batch=0.098\n",
      "1358/67600 (epoch 1), train_loss = 1.425, time/batch=0.094\n",
      "1359/67600 (epoch 1), train_loss = 1.455, time/batch=0.074\n",
      "1360/67600 (epoch 1), train_loss = 1.481, time/batch=0.071\n",
      "1361/67600 (epoch 1), train_loss = 1.434, time/batch=0.070\n",
      "1362/67600 (epoch 1), train_loss = 1.408, time/batch=0.070\n",
      "1363/67600 (epoch 1), train_loss = 1.415, time/batch=0.073\n",
      "1364/67600 (epoch 1), train_loss = 1.440, time/batch=0.071\n",
      "1365/67600 (epoch 1), train_loss = 1.463, time/batch=0.076\n",
      "1366/67600 (epoch 1), train_loss = 1.461, time/batch=0.069\n",
      "1367/67600 (epoch 1), train_loss = 1.414, time/batch=0.069\n",
      "1368/67600 (epoch 1), train_loss = 1.436, time/batch=0.165\n",
      "1369/67600 (epoch 1), train_loss = 1.474, time/batch=0.123\n",
      "1370/67600 (epoch 1), train_loss = 1.453, time/batch=0.074\n",
      "1371/67600 (epoch 1), train_loss = 1.449, time/batch=0.077\n",
      "1372/67600 (epoch 1), train_loss = 1.453, time/batch=0.075\n",
      "1373/67600 (epoch 1), train_loss = 1.391, time/batch=0.078\n",
      "1374/67600 (epoch 1), train_loss = 1.488, time/batch=0.080\n",
      "1375/67600 (epoch 1), train_loss = 1.480, time/batch=0.075\n",
      "1376/67600 (epoch 1), train_loss = 1.521, time/batch=0.176\n",
      "1377/67600 (epoch 1), train_loss = 1.344, time/batch=0.092\n",
      "1378/67600 (epoch 1), train_loss = 1.454, time/batch=0.108\n",
      "1379/67600 (epoch 1), train_loss = 1.475, time/batch=0.071\n",
      "1380/67600 (epoch 1), train_loss = 1.502, time/batch=0.073\n",
      "1381/67600 (epoch 1), train_loss = 1.443, time/batch=0.098\n",
      "1382/67600 (epoch 1), train_loss = 1.427, time/batch=0.076\n",
      "1383/67600 (epoch 1), train_loss = 1.509, time/batch=0.079\n",
      "1384/67600 (epoch 1), train_loss = 1.440, time/batch=0.134\n",
      "1385/67600 (epoch 1), train_loss = 1.471, time/batch=0.084\n",
      "1386/67600 (epoch 1), train_loss = 1.476, time/batch=0.195\n",
      "1387/67600 (epoch 1), train_loss = 1.455, time/batch=0.111\n",
      "1388/67600 (epoch 1), train_loss = 1.384, time/batch=0.139\n",
      "1389/67600 (epoch 1), train_loss = 1.492, time/batch=0.093\n",
      "1390/67600 (epoch 1), train_loss = 1.460, time/batch=0.095\n",
      "1391/67600 (epoch 1), train_loss = 1.448, time/batch=0.114\n",
      "1392/67600 (epoch 1), train_loss = 1.373, time/batch=0.102\n",
      "1393/67600 (epoch 1), train_loss = 1.487, time/batch=0.076\n",
      "1394/67600 (epoch 1), train_loss = 1.461, time/batch=0.083\n",
      "1395/67600 (epoch 1), train_loss = 1.458, time/batch=0.183\n",
      "1396/67600 (epoch 1), train_loss = 1.483, time/batch=0.107\n",
      "1397/67600 (epoch 1), train_loss = 1.455, time/batch=0.113\n",
      "1398/67600 (epoch 1), train_loss = 1.398, time/batch=0.072\n",
      "1399/67600 (epoch 1), train_loss = 1.431, time/batch=0.094\n",
      "1400/67600 (epoch 1), train_loss = 1.412, time/batch=0.078\n",
      "1401/67600 (epoch 1), train_loss = 1.385, time/batch=0.074\n",
      "1402/67600 (epoch 1), train_loss = 1.515, time/batch=0.088\n",
      "1403/67600 (epoch 1), train_loss = 1.423, time/batch=0.087\n",
      "1404/67600 (epoch 1), train_loss = 1.433, time/batch=0.084\n",
      "1405/67600 (epoch 1), train_loss = 1.525, time/batch=0.260\n",
      "1406/67600 (epoch 1), train_loss = 1.499, time/batch=0.137\n",
      "1407/67600 (epoch 1), train_loss = 1.450, time/batch=0.086\n",
      "1408/67600 (epoch 1), train_loss = 1.456, time/batch=0.083\n",
      "1409/67600 (epoch 1), train_loss = 1.436, time/batch=0.112\n",
      "1410/67600 (epoch 1), train_loss = 1.421, time/batch=0.098\n",
      "1411/67600 (epoch 1), train_loss = 1.454, time/batch=0.076\n",
      "1412/67600 (epoch 1), train_loss = 1.438, time/batch=0.105\n",
      "1413/67600 (epoch 1), train_loss = 1.409, time/batch=0.092\n",
      "1414/67600 (epoch 1), train_loss = 1.464, time/batch=0.260\n",
      "1415/67600 (epoch 1), train_loss = 1.461, time/batch=0.104\n",
      "1416/67600 (epoch 1), train_loss = 1.426, time/batch=0.111\n",
      "1417/67600 (epoch 1), train_loss = 1.427, time/batch=0.089\n",
      "1418/67600 (epoch 1), train_loss = 1.420, time/batch=0.098\n",
      "1419/67600 (epoch 1), train_loss = 1.473, time/batch=0.100\n",
      "1420/67600 (epoch 1), train_loss = 1.454, time/batch=0.076\n",
      "1421/67600 (epoch 1), train_loss = 1.442, time/batch=0.074\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1422/67600 (epoch 1), train_loss = 1.455, time/batch=0.074\n",
      "1423/67600 (epoch 1), train_loss = 1.458, time/batch=0.234\n",
      "1424/67600 (epoch 1), train_loss = 1.436, time/batch=0.089\n",
      "1425/67600 (epoch 1), train_loss = 1.514, time/batch=0.070\n",
      "1426/67600 (epoch 1), train_loss = 1.434, time/batch=0.086\n",
      "1427/67600 (epoch 1), train_loss = 1.499, time/batch=0.086\n",
      "1428/67600 (epoch 1), train_loss = 1.486, time/batch=0.070\n",
      "1429/67600 (epoch 1), train_loss = 1.558, time/batch=0.081\n",
      "1430/67600 (epoch 1), train_loss = 1.480, time/batch=0.075\n",
      "1431/67600 (epoch 1), train_loss = 1.421, time/batch=0.197\n",
      "1432/67600 (epoch 1), train_loss = 1.410, time/batch=0.127\n",
      "1433/67600 (epoch 1), train_loss = 1.452, time/batch=0.103\n",
      "1434/67600 (epoch 1), train_loss = 1.444, time/batch=0.080\n",
      "1435/67600 (epoch 1), train_loss = 1.470, time/batch=0.145\n",
      "1436/67600 (epoch 1), train_loss = 1.491, time/batch=0.093\n",
      "1437/67600 (epoch 1), train_loss = 1.426, time/batch=0.095\n",
      "1438/67600 (epoch 1), train_loss = 1.358, time/batch=0.123\n",
      "1439/67600 (epoch 1), train_loss = 1.502, time/batch=0.286\n",
      "1440/67600 (epoch 1), train_loss = 1.464, time/batch=0.169\n",
      "1441/67600 (epoch 1), train_loss = 1.475, time/batch=0.114\n",
      "1442/67600 (epoch 1), train_loss = 1.441, time/batch=0.122\n",
      "1443/67600 (epoch 1), train_loss = 1.465, time/batch=0.103\n",
      "1444/67600 (epoch 1), train_loss = 1.388, time/batch=0.081\n",
      "1445/67600 (epoch 1), train_loss = 1.386, time/batch=0.132\n",
      "1446/67600 (epoch 1), train_loss = 1.374, time/batch=0.282\n",
      "1447/67600 (epoch 1), train_loss = 1.353, time/batch=0.113\n",
      "1448/67600 (epoch 1), train_loss = 1.378, time/batch=0.083\n",
      "1449/67600 (epoch 1), train_loss = 1.434, time/batch=0.083\n",
      "1450/67600 (epoch 1), train_loss = 1.410, time/batch=0.076\n",
      "1451/67600 (epoch 1), train_loss = 1.487, time/batch=0.069\n",
      "1452/67600 (epoch 1), train_loss = 1.346, time/batch=0.089\n",
      "1453/67600 (epoch 1), train_loss = 1.430, time/batch=0.073\n",
      "1454/67600 (epoch 1), train_loss = 1.465, time/batch=0.089\n",
      "1455/67600 (epoch 1), train_loss = 1.395, time/batch=0.256\n",
      "1456/67600 (epoch 1), train_loss = 1.400, time/batch=0.095\n",
      "1457/67600 (epoch 1), train_loss = 1.465, time/batch=0.102\n",
      "1458/67600 (epoch 1), train_loss = 1.409, time/batch=0.091\n",
      "1459/67600 (epoch 1), train_loss = 1.444, time/batch=0.071\n",
      "1460/67600 (epoch 1), train_loss = 1.461, time/batch=0.091\n",
      "1461/67600 (epoch 1), train_loss = 1.437, time/batch=0.098\n",
      "1462/67600 (epoch 1), train_loss = 1.420, time/batch=0.271\n",
      "1463/67600 (epoch 1), train_loss = 1.459, time/batch=0.125\n",
      "1464/67600 (epoch 1), train_loss = 1.419, time/batch=0.073\n",
      "1465/67600 (epoch 1), train_loss = 1.447, time/batch=0.125\n",
      "1466/67600 (epoch 1), train_loss = 1.447, time/batch=0.075\n",
      "1467/67600 (epoch 1), train_loss = 1.385, time/batch=0.077\n",
      "1468/67600 (epoch 1), train_loss = 1.388, time/batch=0.088\n",
      "1469/67600 (epoch 1), train_loss = 1.420, time/batch=0.081\n",
      "1470/67600 (epoch 1), train_loss = 1.440, time/batch=0.073\n",
      "1471/67600 (epoch 1), train_loss = 1.463, time/batch=0.087\n",
      "1472/67600 (epoch 1), train_loss = 1.429, time/batch=0.075\n",
      "1473/67600 (epoch 1), train_loss = 1.455, time/batch=0.073\n",
      "1474/67600 (epoch 1), train_loss = 1.431, time/batch=0.296\n",
      "1475/67600 (epoch 1), train_loss = 1.398, time/batch=0.088\n",
      "1476/67600 (epoch 1), train_loss = 1.419, time/batch=0.074\n",
      "1477/67600 (epoch 1), train_loss = 1.359, time/batch=0.086\n",
      "1478/67600 (epoch 1), train_loss = 1.436, time/batch=0.085\n",
      "1479/67600 (epoch 1), train_loss = 1.486, time/batch=0.099\n",
      "1480/67600 (epoch 1), train_loss = 1.408, time/batch=0.106\n",
      "1481/67600 (epoch 1), train_loss = 1.431, time/batch=0.100\n",
      "1482/67600 (epoch 1), train_loss = 1.448, time/batch=0.072\n",
      "1483/67600 (epoch 1), train_loss = 1.423, time/batch=0.087\n",
      "1484/67600 (epoch 1), train_loss = 1.474, time/batch=0.073\n",
      "1485/67600 (epoch 1), train_loss = 1.428, time/batch=0.071\n",
      "1486/67600 (epoch 1), train_loss = 1.472, time/batch=0.088\n",
      "1487/67600 (epoch 1), train_loss = 1.453, time/batch=0.123\n",
      "1488/67600 (epoch 1), train_loss = 1.446, time/batch=0.080\n",
      "1489/67600 (epoch 1), train_loss = 1.425, time/batch=0.270\n",
      "1490/67600 (epoch 1), train_loss = 1.434, time/batch=0.077\n",
      "1491/67600 (epoch 1), train_loss = 1.406, time/batch=0.097\n",
      "1492/67600 (epoch 1), train_loss = 1.393, time/batch=0.089\n",
      "1493/67600 (epoch 1), train_loss = 1.369, time/batch=0.098\n",
      "1494/67600 (epoch 1), train_loss = 1.460, time/batch=0.089\n",
      "1495/67600 (epoch 1), train_loss = 1.375, time/batch=0.085\n",
      "1496/67600 (epoch 1), train_loss = 1.456, time/batch=0.082\n",
      "1497/67600 (epoch 1), train_loss = 1.510, time/batch=0.074\n",
      "1498/67600 (epoch 1), train_loss = 1.424, time/batch=0.081\n",
      "1499/67600 (epoch 1), train_loss = 1.447, time/batch=0.248\n",
      "1500/67600 (epoch 1), train_loss = 1.482, time/batch=0.090\n",
      "model saved to ./save/model.ckpt\n",
      "1501/67600 (epoch 1), train_loss = 1.366, time/batch=0.117\n",
      "1502/67600 (epoch 1), train_loss = 1.439, time/batch=0.075\n",
      "1503/67600 (epoch 1), train_loss = 1.412, time/batch=0.095\n",
      "1504/67600 (epoch 1), train_loss = 1.376, time/batch=0.072\n",
      "1505/67600 (epoch 1), train_loss = 1.444, time/batch=0.071\n",
      "1506/67600 (epoch 1), train_loss = 1.376, time/batch=0.074\n",
      "1507/67600 (epoch 1), train_loss = 1.457, time/batch=0.090\n",
      "1508/67600 (epoch 1), train_loss = 1.461, time/batch=0.104\n",
      "1509/67600 (epoch 1), train_loss = 1.456, time/batch=0.114\n",
      "1510/67600 (epoch 1), train_loss = 1.425, time/batch=0.216\n",
      "1511/67600 (epoch 1), train_loss = 1.423, time/batch=0.128\n",
      "1512/67600 (epoch 1), train_loss = 1.415, time/batch=0.074\n",
      "1513/67600 (epoch 1), train_loss = 1.358, time/batch=0.083\n",
      "1514/67600 (epoch 1), train_loss = 1.436, time/batch=0.075\n",
      "1515/67600 (epoch 1), train_loss = 1.437, time/batch=0.082\n",
      "1516/67600 (epoch 1), train_loss = 1.333, time/batch=0.082\n",
      "1517/67600 (epoch 1), train_loss = 1.447, time/batch=0.077\n",
      "1518/67600 (epoch 1), train_loss = 1.411, time/batch=0.089\n",
      "1519/67600 (epoch 1), train_loss = 1.390, time/batch=0.257\n",
      "1520/67600 (epoch 1), train_loss = 1.431, time/batch=0.097\n",
      "1521/67600 (epoch 1), train_loss = 1.421, time/batch=0.069\n",
      "1522/67600 (epoch 1), train_loss = 1.405, time/batch=0.073\n",
      "1523/67600 (epoch 1), train_loss = 1.380, time/batch=0.080\n",
      "1524/67600 (epoch 1), train_loss = 1.467, time/batch=0.100\n",
      "1525/67600 (epoch 1), train_loss = 1.383, time/batch=0.079\n",
      "1526/67600 (epoch 1), train_loss = 1.392, time/batch=0.079\n",
      "1527/67600 (epoch 1), train_loss = 1.432, time/batch=0.074\n",
      "1528/67600 (epoch 1), train_loss = 1.432, time/batch=0.085\n",
      "1529/67600 (epoch 1), train_loss = 1.475, time/batch=0.132\n",
      "1530/67600 (epoch 1), train_loss = 1.381, time/batch=0.237\n",
      "1531/67600 (epoch 1), train_loss = 1.408, time/batch=0.097\n",
      "1532/67600 (epoch 1), train_loss = 1.348, time/batch=0.075\n",
      "1533/67600 (epoch 1), train_loss = 1.353, time/batch=0.114\n",
      "1534/67600 (epoch 1), train_loss = 1.423, time/batch=0.071\n",
      "1535/67600 (epoch 1), train_loss = 1.511, time/batch=0.085\n",
      "1536/67600 (epoch 1), train_loss = 1.526, time/batch=0.203\n",
      "1537/67600 (epoch 1), train_loss = 1.503, time/batch=0.113\n",
      "1538/67600 (epoch 1), train_loss = 1.507, time/batch=0.076\n",
      "1539/67600 (epoch 1), train_loss = 1.439, time/batch=0.093\n",
      "1540/67600 (epoch 1), train_loss = 1.430, time/batch=0.082\n",
      "1541/67600 (epoch 1), train_loss = 1.394, time/batch=0.072\n",
      "1542/67600 (epoch 1), train_loss = 1.493, time/batch=0.086\n",
      "1543/67600 (epoch 1), train_loss = 1.460, time/batch=0.099\n",
      "1544/67600 (epoch 1), train_loss = 1.437, time/batch=0.074\n",
      "1545/67600 (epoch 1), train_loss = 1.425, time/batch=0.095\n",
      "1546/67600 (epoch 1), train_loss = 1.438, time/batch=0.213\n",
      "1547/67600 (epoch 1), train_loss = 1.423, time/batch=0.196\n",
      "1548/67600 (epoch 1), train_loss = 1.403, time/batch=0.104\n",
      "1549/67600 (epoch 1), train_loss = 1.393, time/batch=0.080\n",
      "1550/67600 (epoch 1), train_loss = 1.425, time/batch=0.079\n",
      "1551/67600 (epoch 1), train_loss = 1.395, time/batch=0.086\n",
      "1552/67600 (epoch 1), train_loss = 1.376, time/batch=0.080\n",
      "1553/67600 (epoch 1), train_loss = 1.380, time/batch=0.076\n",
      "1554/67600 (epoch 1), train_loss = 1.471, time/batch=0.080\n",
      "1555/67600 (epoch 1), train_loss = 1.425, time/batch=0.206\n",
      "1556/67600 (epoch 1), train_loss = 1.443, time/batch=0.135\n",
      "1557/67600 (epoch 1), train_loss = 1.353, time/batch=0.074\n",
      "1558/67600 (epoch 1), train_loss = 1.370, time/batch=0.071\n",
      "1559/67600 (epoch 1), train_loss = 1.379, time/batch=0.078\n",
      "1560/67600 (epoch 1), train_loss = 1.436, time/batch=0.072\n",
      "1561/67600 (epoch 1), train_loss = 1.471, time/batch=0.070\n",
      "1562/67600 (epoch 1), train_loss = 1.422, time/batch=0.069\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/67600 (epoch 1), train_loss = 1.502, time/batch=0.076\n",
      "1564/67600 (epoch 1), train_loss = 1.411, time/batch=0.076\n",
      "1565/67600 (epoch 1), train_loss = 1.401, time/batch=0.071\n",
      "1566/67600 (epoch 1), train_loss = 1.439, time/batch=0.202\n",
      "1567/67600 (epoch 1), train_loss = 1.459, time/batch=0.070\n",
      "1568/67600 (epoch 1), train_loss = 1.386, time/batch=0.087\n",
      "1569/67600 (epoch 1), train_loss = 1.401, time/batch=0.073\n",
      "1570/67600 (epoch 1), train_loss = 1.377, time/batch=0.077\n",
      "1571/67600 (epoch 1), train_loss = 1.398, time/batch=0.074\n",
      "1572/67600 (epoch 1), train_loss = 1.486, time/batch=0.073\n",
      "1573/67600 (epoch 1), train_loss = 1.399, time/batch=0.068\n",
      "1574/67600 (epoch 1), train_loss = 1.408, time/batch=0.069\n",
      "1575/67600 (epoch 1), train_loss = 1.424, time/batch=0.070\n",
      "1576/67600 (epoch 1), train_loss = 1.433, time/batch=0.073\n",
      "1577/67600 (epoch 1), train_loss = 1.423, time/batch=0.071\n",
      "1578/67600 (epoch 1), train_loss = 1.464, time/batch=0.213\n",
      "1579/67600 (epoch 1), train_loss = 1.384, time/batch=0.072\n",
      "1580/67600 (epoch 1), train_loss = 1.411, time/batch=0.080\n",
      "1581/67600 (epoch 1), train_loss = 1.392, time/batch=0.074\n",
      "1582/67600 (epoch 1), train_loss = 1.437, time/batch=0.068\n",
      "1583/67600 (epoch 1), train_loss = 1.436, time/batch=0.073\n",
      "1584/67600 (epoch 1), train_loss = 1.378, time/batch=0.076\n",
      "1585/67600 (epoch 1), train_loss = 1.334, time/batch=0.069\n",
      "1586/67600 (epoch 1), train_loss = 1.431, time/batch=0.072\n",
      "1587/67600 (epoch 1), train_loss = 1.406, time/batch=0.072\n",
      "1588/67600 (epoch 1), train_loss = 1.392, time/batch=0.071\n",
      "1589/67600 (epoch 1), train_loss = 1.387, time/batch=0.074\n",
      "1590/67600 (epoch 1), train_loss = 1.471, time/batch=0.222\n",
      "1591/67600 (epoch 1), train_loss = 1.444, time/batch=0.074\n",
      "1592/67600 (epoch 1), train_loss = 1.442, time/batch=0.072\n",
      "1593/67600 (epoch 1), train_loss = 1.374, time/batch=0.072\n",
      "1594/67600 (epoch 1), train_loss = 1.411, time/batch=0.070\n",
      "1595/67600 (epoch 1), train_loss = 1.422, time/batch=0.069\n",
      "1596/67600 (epoch 1), train_loss = 1.369, time/batch=0.070\n",
      "1597/67600 (epoch 1), train_loss = 1.424, time/batch=0.071\n",
      "1598/67600 (epoch 1), train_loss = 1.395, time/batch=0.119\n",
      "1599/67600 (epoch 1), train_loss = 1.397, time/batch=0.074\n",
      "1600/67600 (epoch 1), train_loss = 1.425, time/batch=0.075\n",
      "1601/67600 (epoch 1), train_loss = 1.385, time/batch=0.074\n",
      "1602/67600 (epoch 1), train_loss = 1.388, time/batch=0.071\n",
      "1603/67600 (epoch 1), train_loss = 1.462, time/batch=0.073\n",
      "1604/67600 (epoch 1), train_loss = 1.406, time/batch=0.073\n",
      "1605/67600 (epoch 1), train_loss = 1.413, time/batch=0.073\n",
      "1606/67600 (epoch 1), train_loss = 1.426, time/batch=0.072\n",
      "1607/67600 (epoch 1), train_loss = 1.459, time/batch=0.070\n",
      "1608/67600 (epoch 1), train_loss = 1.437, time/batch=0.274\n",
      "1609/67600 (epoch 1), train_loss = 1.443, time/batch=0.067\n",
      "1610/67600 (epoch 1), train_loss = 1.364, time/batch=0.091\n",
      "1611/67600 (epoch 1), train_loss = 1.377, time/batch=0.081\n",
      "1612/67600 (epoch 1), train_loss = 1.374, time/batch=0.069\n",
      "1613/67600 (epoch 1), train_loss = 1.398, time/batch=0.070\n",
      "1614/67600 (epoch 1), train_loss = 1.400, time/batch=0.070\n",
      "1615/67600 (epoch 1), train_loss = 1.414, time/batch=0.072\n",
      "1616/67600 (epoch 1), train_loss = 1.385, time/batch=0.071\n",
      "1617/67600 (epoch 1), train_loss = 1.369, time/batch=0.072\n",
      "1618/67600 (epoch 1), train_loss = 1.370, time/batch=0.071\n",
      "1619/67600 (epoch 1), train_loss = 1.417, time/batch=0.070\n",
      "1620/67600 (epoch 1), train_loss = 1.362, time/batch=0.220\n",
      "1621/67600 (epoch 1), train_loss = 1.389, time/batch=0.083\n",
      "1622/67600 (epoch 1), train_loss = 1.451, time/batch=0.071\n",
      "1623/67600 (epoch 1), train_loss = 1.382, time/batch=0.074\n",
      "1624/67600 (epoch 1), train_loss = 1.444, time/batch=0.072\n",
      "1625/67600 (epoch 1), train_loss = 1.465, time/batch=0.071\n",
      "1626/67600 (epoch 1), train_loss = 1.416, time/batch=0.073\n",
      "1627/67600 (epoch 1), train_loss = 1.412, time/batch=0.072\n",
      "1628/67600 (epoch 1), train_loss = 1.416, time/batch=0.071\n",
      "1629/67600 (epoch 1), train_loss = 1.373, time/batch=0.073\n",
      "1630/67600 (epoch 1), train_loss = 1.371, time/batch=0.068\n",
      "1631/67600 (epoch 1), train_loss = 1.444, time/batch=0.080\n",
      "1632/67600 (epoch 1), train_loss = 1.470, time/batch=0.203\n",
      "1633/67600 (epoch 1), train_loss = 1.396, time/batch=0.076\n",
      "1634/67600 (epoch 1), train_loss = 1.340, time/batch=0.069\n",
      "1635/67600 (epoch 1), train_loss = 1.435, time/batch=0.089\n",
      "1636/67600 (epoch 1), train_loss = 1.405, time/batch=0.073\n",
      "1637/67600 (epoch 1), train_loss = 1.501, time/batch=0.073\n",
      "1638/67600 (epoch 1), train_loss = 1.427, time/batch=0.068\n",
      "1639/67600 (epoch 1), train_loss = 1.425, time/batch=0.073\n",
      "1640/67600 (epoch 1), train_loss = 1.453, time/batch=0.184\n",
      "1641/67600 (epoch 1), train_loss = 1.487, time/batch=0.074\n",
      "1642/67600 (epoch 1), train_loss = 1.436, time/batch=0.111\n",
      "1643/67600 (epoch 1), train_loss = 1.410, time/batch=0.069\n",
      "1644/67600 (epoch 1), train_loss = 1.420, time/batch=0.072\n",
      "1645/67600 (epoch 1), train_loss = 1.428, time/batch=0.078\n",
      "1646/67600 (epoch 1), train_loss = 1.421, time/batch=0.075\n",
      "1647/67600 (epoch 1), train_loss = 1.464, time/batch=0.070\n",
      "1648/67600 (epoch 1), train_loss = 1.435, time/batch=0.073\n",
      "1649/67600 (epoch 1), train_loss = 1.385, time/batch=0.072\n",
      "1650/67600 (epoch 1), train_loss = 1.411, time/batch=0.067\n",
      "1651/67600 (epoch 1), train_loss = 1.458, time/batch=0.076\n",
      "1652/67600 (epoch 1), train_loss = 1.413, time/batch=0.179\n",
      "1653/67600 (epoch 1), train_loss = 1.426, time/batch=0.090\n",
      "1654/67600 (epoch 1), train_loss = 1.408, time/batch=0.081\n",
      "1655/67600 (epoch 1), train_loss = 1.423, time/batch=0.069\n",
      "1656/67600 (epoch 1), train_loss = 1.461, time/batch=0.072\n",
      "1657/67600 (epoch 1), train_loss = 1.457, time/batch=0.077\n",
      "1658/67600 (epoch 1), train_loss = 1.468, time/batch=0.072\n",
      "1659/67600 (epoch 1), train_loss = 1.440, time/batch=0.071\n",
      "1660/67600 (epoch 1), train_loss = 1.467, time/batch=0.071\n",
      "1661/67600 (epoch 1), train_loss = 1.455, time/batch=0.070\n",
      "1662/67600 (epoch 1), train_loss = 1.418, time/batch=0.070\n",
      "1663/67600 (epoch 1), train_loss = 1.403, time/batch=0.071\n",
      "1664/67600 (epoch 1), train_loss = 1.382, time/batch=0.198\n",
      "1665/67600 (epoch 1), train_loss = 1.428, time/batch=0.097\n",
      "1666/67600 (epoch 1), train_loss = 1.421, time/batch=0.075\n",
      "1667/67600 (epoch 1), train_loss = 1.490, time/batch=0.070\n",
      "1668/67600 (epoch 1), train_loss = 1.426, time/batch=0.071\n",
      "1669/67600 (epoch 1), train_loss = 1.436, time/batch=0.072\n",
      "1670/67600 (epoch 1), train_loss = 1.444, time/batch=0.073\n",
      "1671/67600 (epoch 1), train_loss = 1.440, time/batch=0.078\n",
      "1672/67600 (epoch 1), train_loss = 1.507, time/batch=0.071\n",
      "1673/67600 (epoch 1), train_loss = 1.403, time/batch=0.073\n",
      "1674/67600 (epoch 1), train_loss = 1.409, time/batch=0.068\n",
      "1675/67600 (epoch 1), train_loss = 1.399, time/batch=0.130\n",
      "1676/67600 (epoch 1), train_loss = 1.436, time/batch=0.134\n",
      "1677/67600 (epoch 1), train_loss = 1.404, time/batch=0.096\n",
      "1678/67600 (epoch 1), train_loss = 1.379, time/batch=0.070\n",
      "1679/67600 (epoch 1), train_loss = 1.433, time/batch=0.071\n",
      "1680/67600 (epoch 1), train_loss = 1.389, time/batch=0.067\n",
      "1681/67600 (epoch 1), train_loss = 1.422, time/batch=0.066\n",
      "1682/67600 (epoch 1), train_loss = 1.438, time/batch=0.066\n",
      "1683/67600 (epoch 1), train_loss = 1.362, time/batch=0.067\n",
      "1684/67600 (epoch 1), train_loss = 1.426, time/batch=0.066\n",
      "1685/67600 (epoch 1), train_loss = 1.387, time/batch=0.066\n",
      "1686/67600 (epoch 1), train_loss = 1.403, time/batch=0.064\n",
      "1687/67600 (epoch 1), train_loss = 1.445, time/batch=0.065\n",
      "1688/67600 (epoch 1), train_loss = 1.407, time/batch=0.164\n",
      "1689/67600 (epoch 1), train_loss = 1.398, time/batch=0.088\n",
      "1690/67600 (epoch 1), train_loss = 1.434, time/batch=0.070\n",
      "1691/67600 (epoch 1), train_loss = 1.434, time/batch=0.063\n",
      "1692/67600 (epoch 1), train_loss = 1.393, time/batch=0.062\n",
      "1693/67600 (epoch 1), train_loss = 1.423, time/batch=0.065\n",
      "1694/67600 (epoch 1), train_loss = 1.362, time/batch=0.066\n",
      "1695/67600 (epoch 1), train_loss = 1.378, time/batch=0.066\n",
      "1696/67600 (epoch 1), train_loss = 1.466, time/batch=0.067\n",
      "1697/67600 (epoch 1), train_loss = 1.473, time/batch=0.066\n",
      "1698/67600 (epoch 1), train_loss = 1.401, time/batch=0.154\n",
      "1699/67600 (epoch 1), train_loss = 1.408, time/batch=0.071\n",
      "1700/67600 (epoch 1), train_loss = 1.459, time/batch=0.105\n",
      "1701/67600 (epoch 1), train_loss = 1.460, time/batch=0.065\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1702/67600 (epoch 1), train_loss = 1.386, time/batch=0.066\n",
      "1703/67600 (epoch 1), train_loss = 1.349, time/batch=0.070\n",
      "1704/67600 (epoch 1), train_loss = 1.331, time/batch=0.067\n",
      "1705/67600 (epoch 1), train_loss = 1.383, time/batch=0.066\n",
      "1706/67600 (epoch 1), train_loss = 1.374, time/batch=0.086\n",
      "1707/67600 (epoch 1), train_loss = 1.454, time/batch=0.066\n",
      "1708/67600 (epoch 1), train_loss = 1.381, time/batch=0.068\n",
      "1709/67600 (epoch 1), train_loss = 1.384, time/batch=0.065\n",
      "1710/67600 (epoch 1), train_loss = 1.337, time/batch=0.087\n",
      "1711/67600 (epoch 1), train_loss = 1.495, time/batch=0.144\n",
      "1712/67600 (epoch 1), train_loss = 1.437, time/batch=0.074\n",
      "1713/67600 (epoch 1), train_loss = 1.350, time/batch=0.097\n",
      "1714/67600 (epoch 1), train_loss = 1.392, time/batch=0.073\n",
      "1715/67600 (epoch 1), train_loss = 1.458, time/batch=0.065\n",
      "1716/67600 (epoch 1), train_loss = 1.417, time/batch=0.066\n",
      "1717/67600 (epoch 1), train_loss = 1.404, time/batch=0.066\n",
      "1718/67600 (epoch 1), train_loss = 1.401, time/batch=0.068\n",
      "1719/67600 (epoch 1), train_loss = 1.352, time/batch=0.065\n",
      "1720/67600 (epoch 1), train_loss = 1.393, time/batch=0.067\n",
      "1721/67600 (epoch 1), train_loss = 1.473, time/batch=0.087\n",
      "1722/67600 (epoch 1), train_loss = 1.385, time/batch=0.065\n",
      "1723/67600 (epoch 1), train_loss = 1.420, time/batch=0.170\n",
      "1724/67600 (epoch 1), train_loss = 1.434, time/batch=0.068\n",
      "1725/67600 (epoch 1), train_loss = 1.399, time/batch=0.110\n",
      "1726/67600 (epoch 1), train_loss = 1.470, time/batch=0.067\n",
      "1727/67600 (epoch 1), train_loss = 1.504, time/batch=0.065\n",
      "1728/67600 (epoch 1), train_loss = 1.429, time/batch=0.066\n",
      "1729/67600 (epoch 1), train_loss = 1.405, time/batch=0.066\n",
      "1730/67600 (epoch 1), train_loss = 1.445, time/batch=0.066\n",
      "1731/67600 (epoch 1), train_loss = 1.485, time/batch=0.066\n",
      "1732/67600 (epoch 1), train_loss = 1.436, time/batch=0.066\n",
      "1733/67600 (epoch 1), train_loss = 1.401, time/batch=0.070\n",
      "1734/67600 (epoch 1), train_loss = 1.428, time/batch=0.066\n",
      "1735/67600 (epoch 1), train_loss = 1.424, time/batch=0.071\n",
      "1736/67600 (epoch 1), train_loss = 1.507, time/batch=0.184\n",
      "1737/67600 (epoch 1), train_loss = 1.407, time/batch=0.066\n",
      "1738/67600 (epoch 1), train_loss = 1.404, time/batch=0.082\n",
      "1739/67600 (epoch 1), train_loss = 1.404, time/batch=0.067\n",
      "1740/67600 (epoch 1), train_loss = 1.429, time/batch=0.065\n",
      "1741/67600 (epoch 1), train_loss = 1.404, time/batch=0.072\n",
      "1742/67600 (epoch 1), train_loss = 1.409, time/batch=0.071\n",
      "1743/67600 (epoch 1), train_loss = 1.389, time/batch=0.065\n",
      "1744/67600 (epoch 1), train_loss = 1.389, time/batch=0.066\n",
      "1745/67600 (epoch 1), train_loss = 1.445, time/batch=0.067\n",
      "1746/67600 (epoch 1), train_loss = 1.409, time/batch=0.065\n",
      "1747/67600 (epoch 1), train_loss = 1.390, time/batch=0.066\n",
      "1748/67600 (epoch 1), train_loss = 1.460, time/batch=0.063\n",
      "1749/67600 (epoch 1), train_loss = 1.481, time/batch=0.189\n",
      "1750/67600 (epoch 1), train_loss = 1.398, time/batch=0.067\n",
      "1751/67600 (epoch 1), train_loss = 1.398, time/batch=0.077\n",
      "1752/67600 (epoch 1), train_loss = 1.450, time/batch=0.066\n",
      "1753/67600 (epoch 1), train_loss = 1.485, time/batch=0.066\n",
      "1754/67600 (epoch 1), train_loss = 1.485, time/batch=0.067\n",
      "1755/67600 (epoch 1), train_loss = 1.427, time/batch=0.065\n",
      "1756/67600 (epoch 1), train_loss = 1.516, time/batch=0.065\n",
      "1757/67600 (epoch 1), train_loss = 1.455, time/batch=0.064\n",
      "1758/67600 (epoch 1), train_loss = 1.501, time/batch=0.066\n",
      "1759/67600 (epoch 1), train_loss = 1.404, time/batch=0.064\n",
      "1760/67600 (epoch 1), train_loss = 1.442, time/batch=0.066\n",
      "1761/67600 (epoch 1), train_loss = 1.438, time/batch=0.063\n",
      "1762/67600 (epoch 1), train_loss = 1.418, time/batch=0.158\n",
      "1763/67600 (epoch 1), train_loss = 1.389, time/batch=0.101\n",
      "1764/67600 (epoch 1), train_loss = 1.393, time/batch=0.076\n",
      "1765/67600 (epoch 1), train_loss = 1.420, time/batch=0.067\n",
      "1766/67600 (epoch 1), train_loss = 1.406, time/batch=0.065\n",
      "1767/67600 (epoch 1), train_loss = 1.462, time/batch=0.067\n",
      "1768/67600 (epoch 1), train_loss = 1.421, time/batch=0.064\n",
      "1769/67600 (epoch 1), train_loss = 1.448, time/batch=0.066\n",
      "1770/67600 (epoch 1), train_loss = 1.440, time/batch=0.064\n",
      "1771/67600 (epoch 1), train_loss = 1.406, time/batch=0.103\n",
      "1772/67600 (epoch 1), train_loss = 1.363, time/batch=0.075\n",
      "1773/67600 (epoch 1), train_loss = 1.363, time/batch=0.071\n",
      "1774/67600 (epoch 1), train_loss = 1.399, time/batch=0.066\n",
      "1775/67600 (epoch 1), train_loss = 1.373, time/batch=0.065\n",
      "1776/67600 (epoch 1), train_loss = 1.416, time/batch=0.065\n",
      "1777/67600 (epoch 1), train_loss = 1.381, time/batch=0.070\n",
      "1778/67600 (epoch 1), train_loss = 1.417, time/batch=0.064\n",
      "1779/67600 (epoch 1), train_loss = 1.401, time/batch=0.065\n",
      "1780/67600 (epoch 1), train_loss = 1.321, time/batch=0.067\n",
      "1781/67600 (epoch 1), train_loss = 1.380, time/batch=0.064\n",
      "1782/67600 (epoch 1), train_loss = 1.454, time/batch=0.206\n",
      "1783/67600 (epoch 1), train_loss = 1.371, time/batch=0.084\n",
      "1784/67600 (epoch 1), train_loss = 1.416, time/batch=0.086\n",
      "1785/67600 (epoch 1), train_loss = 1.429, time/batch=0.070\n",
      "1786/67600 (epoch 1), train_loss = 1.363, time/batch=0.063\n",
      "1787/67600 (epoch 1), train_loss = 1.486, time/batch=0.063\n",
      "1788/67600 (epoch 1), train_loss = 1.417, time/batch=0.065\n",
      "1789/67600 (epoch 1), train_loss = 1.408, time/batch=0.067\n",
      "1790/67600 (epoch 1), train_loss = 1.420, time/batch=0.064\n",
      "1791/67600 (epoch 1), train_loss = 1.415, time/batch=0.066\n",
      "1792/67600 (epoch 1), train_loss = 1.398, time/batch=0.065\n",
      "1793/67600 (epoch 1), train_loss = 1.424, time/batch=0.066\n",
      "1794/67600 (epoch 1), train_loss = 1.381, time/batch=0.064\n",
      "1795/67600 (epoch 1), train_loss = 1.379, time/batch=0.094\n",
      "1796/67600 (epoch 1), train_loss = 1.404, time/batch=0.158\n",
      "1797/67600 (epoch 1), train_loss = 1.463, time/batch=0.083\n",
      "1798/67600 (epoch 1), train_loss = 1.358, time/batch=0.067\n",
      "1799/67600 (epoch 1), train_loss = 1.362, time/batch=0.069\n",
      "1800/67600 (epoch 1), train_loss = 1.352, time/batch=0.065\n",
      "1801/67600 (epoch 1), train_loss = 1.389, time/batch=0.062\n",
      "1802/67600 (epoch 1), train_loss = 1.319, time/batch=0.063\n",
      "1803/67600 (epoch 1), train_loss = 1.457, time/batch=0.063\n",
      "1804/67600 (epoch 1), train_loss = 1.444, time/batch=0.063\n",
      "1805/67600 (epoch 1), train_loss = 1.350, time/batch=0.064\n",
      "1806/67600 (epoch 1), train_loss = 1.338, time/batch=0.062\n",
      "1807/67600 (epoch 1), train_loss = 1.369, time/batch=0.067\n",
      "1808/67600 (epoch 1), train_loss = 1.393, time/batch=0.065\n",
      "1809/67600 (epoch 1), train_loss = 1.416, time/batch=0.198\n",
      "1810/67600 (epoch 1), train_loss = 1.434, time/batch=0.078\n",
      "1811/67600 (epoch 1), train_loss = 1.413, time/batch=0.067\n",
      "1812/67600 (epoch 1), train_loss = 1.398, time/batch=0.072\n",
      "1813/67600 (epoch 1), train_loss = 1.357, time/batch=0.067\n",
      "1814/67600 (epoch 1), train_loss = 1.439, time/batch=0.076\n",
      "1815/67600 (epoch 1), train_loss = 1.419, time/batch=0.067\n",
      "1816/67600 (epoch 1), train_loss = 1.362, time/batch=0.063\n",
      "1817/67600 (epoch 1), train_loss = 1.373, time/batch=0.066\n",
      "1818/67600 (epoch 1), train_loss = 1.400, time/batch=0.162\n",
      "1819/67600 (epoch 1), train_loss = 1.455, time/batch=0.066\n",
      "1820/67600 (epoch 1), train_loss = 1.411, time/batch=0.105\n",
      "1821/67600 (epoch 1), train_loss = 1.389, time/batch=0.067\n",
      "1822/67600 (epoch 1), train_loss = 1.405, time/batch=0.064\n",
      "1823/67600 (epoch 1), train_loss = 1.385, time/batch=0.071\n",
      "1824/67600 (epoch 1), train_loss = 1.363, time/batch=0.071\n",
      "1825/67600 (epoch 1), train_loss = 1.400, time/batch=0.068\n",
      "1826/67600 (epoch 1), train_loss = 1.379, time/batch=0.070\n",
      "1827/67600 (epoch 1), train_loss = 1.346, time/batch=0.067\n",
      "1828/67600 (epoch 1), train_loss = 1.406, time/batch=0.064\n",
      "1829/67600 (epoch 1), train_loss = 1.370, time/batch=0.064\n",
      "1830/67600 (epoch 1), train_loss = 1.398, time/batch=0.065\n",
      "1831/67600 (epoch 1), train_loss = 1.412, time/batch=0.167\n",
      "1832/67600 (epoch 1), train_loss = 1.347, time/batch=0.066\n",
      "1833/67600 (epoch 1), train_loss = 1.399, time/batch=0.101\n",
      "1834/67600 (epoch 1), train_loss = 1.375, time/batch=0.066\n",
      "1835/67600 (epoch 1), train_loss = 1.344, time/batch=0.063\n",
      "1836/67600 (epoch 1), train_loss = 1.420, time/batch=0.066\n",
      "1837/67600 (epoch 1), train_loss = 1.415, time/batch=0.067\n",
      "1838/67600 (epoch 1), train_loss = 1.422, time/batch=0.065\n",
      "1839/67600 (epoch 1), train_loss = 1.393, time/batch=0.063\n",
      "1840/67600 (epoch 1), train_loss = 1.458, time/batch=0.064\n",
      "1841/67600 (epoch 1), train_loss = 1.424, time/batch=0.064\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1842/67600 (epoch 1), train_loss = 1.337, time/batch=0.065\n",
      "1843/67600 (epoch 1), train_loss = 1.388, time/batch=0.065\n",
      "1844/67600 (epoch 1), train_loss = 1.438, time/batch=0.162\n",
      "1845/67600 (epoch 1), train_loss = 1.375, time/batch=0.075\n",
      "1846/67600 (epoch 1), train_loss = 1.440, time/batch=0.093\n",
      "1847/67600 (epoch 1), train_loss = 1.398, time/batch=0.068\n",
      "1848/67600 (epoch 1), train_loss = 1.369, time/batch=0.072\n",
      "1849/67600 (epoch 1), train_loss = 1.389, time/batch=0.067\n",
      "1850/67600 (epoch 1), train_loss = 1.432, time/batch=0.067\n",
      "1851/67600 (epoch 1), train_loss = 1.373, time/batch=0.068\n",
      "1852/67600 (epoch 1), train_loss = 1.320, time/batch=0.065\n",
      "1853/67600 (epoch 1), train_loss = 1.315, time/batch=0.065\n",
      "1854/67600 (epoch 1), train_loss = 1.384, time/batch=0.073\n",
      "1855/67600 (epoch 1), train_loss = 1.407, time/batch=0.066\n",
      "1856/67600 (epoch 1), train_loss = 1.409, time/batch=0.066\n",
      "1857/67600 (epoch 1), train_loss = 1.458, time/batch=0.172\n",
      "1858/67600 (epoch 1), train_loss = 1.410, time/batch=0.076\n",
      "1859/67600 (epoch 1), train_loss = 1.412, time/batch=0.083\n",
      "1860/67600 (epoch 1), train_loss = 1.339, time/batch=0.066\n",
      "1861/67600 (epoch 1), train_loss = 1.359, time/batch=0.065\n",
      "1862/67600 (epoch 1), train_loss = 1.445, time/batch=0.066\n",
      "1863/67600 (epoch 1), train_loss = 1.387, time/batch=0.067\n",
      "1864/67600 (epoch 1), train_loss = 1.400, time/batch=0.074\n",
      "1865/67600 (epoch 1), train_loss = 1.364, time/batch=0.065\n",
      "1866/67600 (epoch 1), train_loss = 1.410, time/batch=0.066\n",
      "1867/67600 (epoch 1), train_loss = 1.438, time/batch=0.065\n",
      "1868/67600 (epoch 1), train_loss = 1.435, time/batch=0.065\n",
      "1869/67600 (epoch 1), train_loss = 1.417, time/batch=0.066\n",
      "1870/67600 (epoch 1), train_loss = 1.405, time/batch=0.155\n",
      "1871/67600 (epoch 1), train_loss = 1.328, time/batch=0.097\n",
      "1872/67600 (epoch 1), train_loss = 1.432, time/batch=0.071\n",
      "1873/67600 (epoch 1), train_loss = 1.449, time/batch=0.067\n",
      "1874/67600 (epoch 1), train_loss = 1.452, time/batch=0.063\n",
      "1875/67600 (epoch 1), train_loss = 1.379, time/batch=0.065\n",
      "1876/67600 (epoch 1), train_loss = 1.413, time/batch=0.066\n",
      "1877/67600 (epoch 1), train_loss = 1.394, time/batch=0.065\n",
      "1878/67600 (epoch 1), train_loss = 1.405, time/batch=0.065\n",
      "1879/67600 (epoch 1), train_loss = 1.379, time/batch=0.065\n",
      "1880/67600 (epoch 1), train_loss = 1.430, time/batch=0.154\n",
      "1881/67600 (epoch 1), train_loss = 1.365, time/batch=0.067\n",
      "1882/67600 (epoch 1), train_loss = 1.424, time/batch=0.098\n",
      "1883/67600 (epoch 1), train_loss = 1.445, time/batch=0.066\n",
      "1884/67600 (epoch 1), train_loss = 1.404, time/batch=0.066\n",
      "1885/67600 (epoch 1), train_loss = 1.379, time/batch=0.071\n",
      "1886/67600 (epoch 1), train_loss = 1.375, time/batch=0.069\n",
      "1887/67600 (epoch 1), train_loss = 1.345, time/batch=0.066\n",
      "1888/67600 (epoch 1), train_loss = 1.377, time/batch=0.063\n",
      "1889/67600 (epoch 1), train_loss = 1.413, time/batch=0.068\n",
      "1890/67600 (epoch 1), train_loss = 1.386, time/batch=0.073\n",
      "1891/67600 (epoch 1), train_loss = 1.402, time/batch=0.064\n",
      "1892/67600 (epoch 1), train_loss = 1.390, time/batch=0.063\n",
      "1893/67600 (epoch 1), train_loss = 1.329, time/batch=0.161\n",
      "1894/67600 (epoch 1), train_loss = 1.380, time/batch=0.066\n",
      "1895/67600 (epoch 1), train_loss = 1.335, time/batch=0.098\n",
      "1896/67600 (epoch 1), train_loss = 1.417, time/batch=0.064\n",
      "1897/67600 (epoch 1), train_loss = 1.391, time/batch=0.065\n",
      "1898/67600 (epoch 1), train_loss = 1.373, time/batch=0.066\n",
      "1899/67600 (epoch 1), train_loss = 1.390, time/batch=0.082\n",
      "1900/67600 (epoch 1), train_loss = 1.521, time/batch=0.066\n",
      "1901/67600 (epoch 1), train_loss = 1.410, time/batch=0.068\n",
      "1902/67600 (epoch 1), train_loss = 1.382, time/batch=0.065\n",
      "1903/67600 (epoch 1), train_loss = 1.446, time/batch=0.065\n",
      "1904/67600 (epoch 1), train_loss = 1.370, time/batch=0.063\n",
      "1905/67600 (epoch 1), train_loss = 1.385, time/batch=0.063\n",
      "1906/67600 (epoch 1), train_loss = 1.435, time/batch=0.170\n",
      "1907/67600 (epoch 1), train_loss = 1.368, time/batch=0.067\n",
      "1908/67600 (epoch 1), train_loss = 1.430, time/batch=0.093\n",
      "1909/67600 (epoch 1), train_loss = 1.384, time/batch=0.068\n",
      "1910/67600 (epoch 1), train_loss = 1.345, time/batch=0.076\n",
      "1911/67600 (epoch 1), train_loss = 1.342, time/batch=0.078\n",
      "1912/67600 (epoch 1), train_loss = 1.354, time/batch=0.066\n",
      "1913/67600 (epoch 1), train_loss = 1.371, time/batch=0.065\n",
      "1914/67600 (epoch 1), train_loss = 1.355, time/batch=0.067\n",
      "1915/67600 (epoch 1), train_loss = 1.387, time/batch=0.065\n",
      "1916/67600 (epoch 1), train_loss = 1.356, time/batch=0.066\n",
      "1917/67600 (epoch 1), train_loss = 1.378, time/batch=0.064\n",
      "1918/67600 (epoch 1), train_loss = 1.414, time/batch=0.067\n",
      "1919/67600 (epoch 1), train_loss = 1.443, time/batch=0.186\n",
      "1920/67600 (epoch 1), train_loss = 1.402, time/batch=0.066\n",
      "1921/67600 (epoch 1), train_loss = 1.367, time/batch=0.081\n",
      "1922/67600 (epoch 1), train_loss = 1.365, time/batch=0.068\n",
      "1923/67600 (epoch 1), train_loss = 1.352, time/batch=0.076\n",
      "1924/67600 (epoch 1), train_loss = 1.391, time/batch=0.066\n",
      "1925/67600 (epoch 1), train_loss = 1.383, time/batch=0.069\n",
      "1926/67600 (epoch 1), train_loss = 1.394, time/batch=0.063\n",
      "1927/67600 (epoch 1), train_loss = 1.373, time/batch=0.063\n",
      "1928/67600 (epoch 1), train_loss = 1.424, time/batch=0.064\n",
      "1929/67600 (epoch 1), train_loss = 1.409, time/batch=0.064\n",
      "1930/67600 (epoch 1), train_loss = 1.439, time/batch=0.064\n",
      "1931/67600 (epoch 1), train_loss = 1.380, time/batch=0.063\n",
      "1932/67600 (epoch 1), train_loss = 1.386, time/batch=0.190\n",
      "1933/67600 (epoch 1), train_loss = 1.407, time/batch=0.065\n",
      "1934/67600 (epoch 1), train_loss = 1.354, time/batch=0.084\n",
      "1935/67600 (epoch 1), train_loss = 1.356, time/batch=0.066\n",
      "1936/67600 (epoch 1), train_loss = 1.395, time/batch=0.064\n",
      "1937/67600 (epoch 1), train_loss = 1.439, time/batch=0.065\n",
      "1938/67600 (epoch 1), train_loss = 1.355, time/batch=0.063\n",
      "1939/67600 (epoch 1), train_loss = 1.458, time/batch=0.065\n",
      "1940/67600 (epoch 1), train_loss = 1.358, time/batch=0.064\n",
      "1941/67600 (epoch 1), train_loss = 1.385, time/batch=0.068\n",
      "1942/67600 (epoch 1), train_loss = 1.447, time/batch=0.066\n",
      "1943/67600 (epoch 1), train_loss = 1.364, time/batch=0.074\n",
      "1944/67600 (epoch 1), train_loss = 1.375, time/batch=0.069\n",
      "1945/67600 (epoch 1), train_loss = 1.402, time/batch=0.201\n",
      "1946/67600 (epoch 1), train_loss = 1.332, time/batch=0.066\n",
      "1947/67600 (epoch 1), train_loss = 1.396, time/batch=0.066\n",
      "1948/67600 (epoch 1), train_loss = 1.385, time/batch=0.066\n",
      "1949/67600 (epoch 1), train_loss = 1.378, time/batch=0.066\n",
      "1950/67600 (epoch 1), train_loss = 1.366, time/batch=0.067\n",
      "1951/67600 (epoch 1), train_loss = 1.362, time/batch=0.066\n",
      "1952/67600 (epoch 1), train_loss = 1.394, time/batch=0.065\n",
      "1953/67600 (epoch 1), train_loss = 1.352, time/batch=0.070\n",
      "1954/67600 (epoch 1), train_loss = 1.382, time/batch=0.114\n",
      "1955/67600 (epoch 1), train_loss = 1.381, time/batch=0.064\n",
      "1956/67600 (epoch 1), train_loss = 1.428, time/batch=0.075\n",
      "1957/67600 (epoch 1), train_loss = 1.373, time/batch=0.066\n",
      "1958/67600 (epoch 1), train_loss = 1.448, time/batch=0.067\n",
      "1959/67600 (epoch 1), train_loss = 1.353, time/batch=0.064\n",
      "1960/67600 (epoch 1), train_loss = 1.452, time/batch=0.066\n",
      "1961/67600 (epoch 1), train_loss = 1.394, time/batch=0.064\n",
      "1962/67600 (epoch 1), train_loss = 1.370, time/batch=0.062\n",
      "1963/67600 (epoch 1), train_loss = 1.469, time/batch=0.062\n",
      "1964/67600 (epoch 1), train_loss = 1.388, time/batch=0.064\n",
      "1965/67600 (epoch 1), train_loss = 1.373, time/batch=0.162\n",
      "1966/67600 (epoch 1), train_loss = 1.381, time/batch=0.122\n",
      "1967/67600 (epoch 1), train_loss = 1.442, time/batch=0.094\n",
      "1968/67600 (epoch 1), train_loss = 1.417, time/batch=0.063\n",
      "1969/67600 (epoch 1), train_loss = 1.463, time/batch=0.065\n",
      "1970/67600 (epoch 1), train_loss = 1.385, time/batch=0.065\n",
      "1971/67600 (epoch 1), train_loss = 1.353, time/batch=0.067\n",
      "1972/67600 (epoch 1), train_loss = 1.353, time/batch=0.068\n",
      "1973/67600 (epoch 1), train_loss = 1.390, time/batch=0.070\n",
      "1974/67600 (epoch 1), train_loss = 1.413, time/batch=0.068\n",
      "1975/67600 (epoch 1), train_loss = 1.355, time/batch=0.070\n",
      "1976/67600 (epoch 1), train_loss = 1.390, time/batch=0.067\n",
      "1977/67600 (epoch 1), train_loss = 1.388, time/batch=0.071\n",
      "1978/67600 (epoch 1), train_loss = 1.387, time/batch=0.238\n",
      "1979/67600 (epoch 1), train_loss = 1.441, time/batch=0.087\n",
      "1980/67600 (epoch 1), train_loss = 1.411, time/batch=0.065\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1981/67600 (epoch 1), train_loss = 1.365, time/batch=0.066\n",
      "1982/67600 (epoch 1), train_loss = 1.425, time/batch=0.065\n",
      "1983/67600 (epoch 1), train_loss = 1.458, time/batch=0.069\n",
      "1984/67600 (epoch 1), train_loss = 1.361, time/batch=0.070\n",
      "1985/67600 (epoch 1), train_loss = 1.465, time/batch=0.069\n",
      "1986/67600 (epoch 1), train_loss = 1.450, time/batch=0.070\n",
      "1987/67600 (epoch 1), train_loss = 1.327, time/batch=0.071\n",
      "1988/67600 (epoch 1), train_loss = 1.471, time/batch=0.073\n",
      "1989/67600 (epoch 1), train_loss = 1.359, time/batch=0.068\n",
      "1990/67600 (epoch 1), train_loss = 1.332, time/batch=0.209\n",
      "1991/67600 (epoch 1), train_loss = 1.318, time/batch=0.069\n",
      "1992/67600 (epoch 1), train_loss = 1.391, time/batch=0.071\n",
      "1993/67600 (epoch 1), train_loss = 1.384, time/batch=0.066\n",
      "1994/67600 (epoch 1), train_loss = 1.406, time/batch=0.067\n",
      "1995/67600 (epoch 1), train_loss = 1.456, time/batch=0.066\n",
      "1996/67600 (epoch 1), train_loss = 1.441, time/batch=0.064\n",
      "1997/67600 (epoch 1), train_loss = 1.367, time/batch=0.068\n",
      "1998/67600 (epoch 1), train_loss = 1.393, time/batch=0.064\n",
      "1999/67600 (epoch 1), train_loss = 1.396, time/batch=0.165\n",
      "2000/67600 (epoch 1), train_loss = 1.419, time/batch=0.072\n",
      "model saved to ./save/model.ckpt\n",
      "2001/67600 (epoch 1), train_loss = 1.401, time/batch=0.093\n",
      "2002/67600 (epoch 1), train_loss = 1.436, time/batch=0.064\n",
      "2003/67600 (epoch 1), train_loss = 1.439, time/batch=0.066\n",
      "2004/67600 (epoch 1), train_loss = 1.362, time/batch=0.064\n",
      "2005/67600 (epoch 1), train_loss = 1.373, time/batch=0.068\n",
      "2006/67600 (epoch 1), train_loss = 1.376, time/batch=0.065\n",
      "2007/67600 (epoch 1), train_loss = 1.361, time/batch=0.066\n",
      "2008/67600 (epoch 1), train_loss = 1.386, time/batch=0.067\n",
      "2009/67600 (epoch 1), train_loss = 1.423, time/batch=0.065\n",
      "2010/67600 (epoch 1), train_loss = 1.408, time/batch=0.065\n",
      "2011/67600 (epoch 1), train_loss = 1.342, time/batch=0.069\n",
      "2012/67600 (epoch 1), train_loss = 1.392, time/batch=0.190\n",
      "2013/67600 (epoch 1), train_loss = 1.373, time/batch=0.065\n",
      "2014/67600 (epoch 1), train_loss = 1.312, time/batch=0.079\n",
      "2015/67600 (epoch 1), train_loss = 1.323, time/batch=0.064\n",
      "2016/67600 (epoch 1), train_loss = 1.415, time/batch=0.067\n",
      "2017/67600 (epoch 1), train_loss = 1.389, time/batch=0.067\n",
      "2018/67600 (epoch 1), train_loss = 1.411, time/batch=0.065\n",
      "2019/67600 (epoch 1), train_loss = 1.381, time/batch=0.069\n",
      "2020/67600 (epoch 1), train_loss = 1.434, time/batch=0.066\n",
      "2021/67600 (epoch 1), train_loss = 1.326, time/batch=0.085\n",
      "2022/67600 (epoch 1), train_loss = 1.302, time/batch=0.075\n",
      "2023/67600 (epoch 1), train_loss = 1.372, time/batch=0.070\n",
      "2024/67600 (epoch 1), train_loss = 1.288, time/batch=0.117\n",
      "2025/67600 (epoch 1), train_loss = 1.439, time/batch=0.167\n",
      "2026/67600 (epoch 1), train_loss = 1.428, time/batch=0.078\n",
      "2027/67600 (epoch 1), train_loss = 1.348, time/batch=0.067\n",
      "2028/67600 (epoch 1), train_loss = 1.388, time/batch=0.075\n",
      "2029/67600 (epoch 1), train_loss = 1.415, time/batch=0.074\n",
      "2030/67600 (epoch 1), train_loss = 1.413, time/batch=0.071\n",
      "2031/67600 (epoch 1), train_loss = 1.378, time/batch=0.073\n",
      "2032/67600 (epoch 1), train_loss = 1.378, time/batch=0.072\n",
      "2033/67600 (epoch 1), train_loss = 1.405, time/batch=0.173\n",
      "2034/67600 (epoch 1), train_loss = 1.394, time/batch=0.068\n",
      "2035/67600 (epoch 1), train_loss = 1.370, time/batch=0.105\n",
      "2036/67600 (epoch 1), train_loss = 1.363, time/batch=0.070\n",
      "2037/67600 (epoch 1), train_loss = 1.425, time/batch=0.075\n",
      "2038/67600 (epoch 1), train_loss = 1.391, time/batch=0.078\n",
      "2039/67600 (epoch 1), train_loss = 1.352, time/batch=0.071\n",
      "2040/67600 (epoch 1), train_loss = 1.377, time/batch=0.073\n",
      "2041/67600 (epoch 1), train_loss = 1.347, time/batch=0.072\n",
      "2042/67600 (epoch 1), train_loss = 1.379, time/batch=0.074\n",
      "2043/67600 (epoch 1), train_loss = 1.384, time/batch=0.069\n",
      "2044/67600 (epoch 1), train_loss = 1.360, time/batch=0.075\n",
      "2045/67600 (epoch 1), train_loss = 1.415, time/batch=0.183\n",
      "2046/67600 (epoch 1), train_loss = 1.375, time/batch=0.068\n",
      "2047/67600 (epoch 1), train_loss = 1.322, time/batch=0.104\n",
      "2048/67600 (epoch 1), train_loss = 1.401, time/batch=0.072\n",
      "2049/67600 (epoch 1), train_loss = 1.423, time/batch=0.073\n",
      "2050/67600 (epoch 1), train_loss = 1.384, time/batch=0.071\n",
      "2051/67600 (epoch 1), train_loss = 1.344, time/batch=0.072\n",
      "2052/67600 (epoch 1), train_loss = 1.394, time/batch=0.073\n",
      "2053/67600 (epoch 1), train_loss = 1.414, time/batch=0.089\n",
      "2054/67600 (epoch 1), train_loss = 1.390, time/batch=0.073\n",
      "2055/67600 (epoch 1), train_loss = 1.332, time/batch=0.070\n",
      "2056/67600 (epoch 1), train_loss = 1.363, time/batch=0.120\n",
      "2057/67600 (epoch 1), train_loss = 1.364, time/batch=0.138\n",
      "2058/67600 (epoch 1), train_loss = 1.365, time/batch=0.100\n",
      "2059/67600 (epoch 1), train_loss = 1.416, time/batch=0.068\n",
      "2060/67600 (epoch 1), train_loss = 1.396, time/batch=0.068\n",
      "2061/67600 (epoch 1), train_loss = 1.348, time/batch=0.072\n",
      "2062/67600 (epoch 1), train_loss = 1.374, time/batch=0.079\n",
      "2063/67600 (epoch 1), train_loss = 1.306, time/batch=0.069\n",
      "2064/67600 (epoch 1), train_loss = 1.378, time/batch=0.070\n",
      "2065/67600 (epoch 1), train_loss = 1.402, time/batch=0.072\n",
      "2066/67600 (epoch 1), train_loss = 1.371, time/batch=0.070\n",
      "2067/67600 (epoch 1), train_loss = 1.386, time/batch=0.069\n",
      "2068/67600 (epoch 1), train_loss = 1.331, time/batch=0.084\n",
      "2069/67600 (epoch 1), train_loss = 1.378, time/batch=0.192\n",
      "2070/67600 (epoch 1), train_loss = 1.343, time/batch=0.093\n",
      "2071/67600 (epoch 1), train_loss = 1.349, time/batch=0.069\n",
      "2072/67600 (epoch 1), train_loss = 1.351, time/batch=0.070\n",
      "2073/67600 (epoch 1), train_loss = 1.428, time/batch=0.070\n",
      "2074/67600 (epoch 1), train_loss = 1.379, time/batch=0.071\n",
      "2075/67600 (epoch 1), train_loss = 1.382, time/batch=0.076\n",
      "2076/67600 (epoch 1), train_loss = 1.354, time/batch=0.072\n",
      "2077/67600 (epoch 1), train_loss = 1.393, time/batch=0.071\n",
      "2078/67600 (epoch 1), train_loss = 1.384, time/batch=0.073\n",
      "2079/67600 (epoch 1), train_loss = 1.397, time/batch=0.071\n",
      "2080/67600 (epoch 1), train_loss = 1.390, time/batch=0.158\n",
      "2081/67600 (epoch 1), train_loss = 1.340, time/batch=0.126\n",
      "2082/67600 (epoch 1), train_loss = 1.358, time/batch=0.086\n",
      "2083/67600 (epoch 1), train_loss = 1.401, time/batch=0.067\n",
      "2084/67600 (epoch 1), train_loss = 1.378, time/batch=0.069\n",
      "2085/67600 (epoch 1), train_loss = 1.364, time/batch=0.069\n",
      "2086/67600 (epoch 1), train_loss = 1.381, time/batch=0.067\n",
      "2087/67600 (epoch 1), train_loss = 1.334, time/batch=0.073\n",
      "2088/67600 (epoch 1), train_loss = 1.426, time/batch=0.073\n",
      "2089/67600 (epoch 1), train_loss = 1.359, time/batch=0.072\n",
      "2090/67600 (epoch 1), train_loss = 1.330, time/batch=0.071\n",
      "2091/67600 (epoch 1), train_loss = 1.413, time/batch=0.072\n",
      "2092/67600 (epoch 1), train_loss = 1.290, time/batch=0.192\n",
      "2093/67600 (epoch 1), train_loss = 1.331, time/batch=0.099\n",
      "2094/67600 (epoch 1), train_loss = 1.308, time/batch=0.076\n",
      "2095/67600 (epoch 1), train_loss = 1.363, time/batch=0.068\n",
      "2096/67600 (epoch 1), train_loss = 1.377, time/batch=0.071\n",
      "2097/67600 (epoch 1), train_loss = 1.399, time/batch=0.073\n",
      "2098/67600 (epoch 1), train_loss = 1.358, time/batch=0.071\n",
      "2099/67600 (epoch 1), train_loss = 1.367, time/batch=0.072\n",
      "2100/67600 (epoch 1), train_loss = 1.398, time/batch=0.075\n",
      "2101/67600 (epoch 1), train_loss = 1.369, time/batch=0.113\n",
      "2102/67600 (epoch 1), train_loss = 1.346, time/batch=0.072\n",
      "2103/67600 (epoch 1), train_loss = 1.329, time/batch=0.070\n",
      "2104/67600 (epoch 1), train_loss = 1.351, time/batch=0.069\n",
      "2105/67600 (epoch 1), train_loss = 1.409, time/batch=0.073\n",
      "2106/67600 (epoch 1), train_loss = 1.344, time/batch=0.069\n",
      "2107/67600 (epoch 1), train_loss = 1.355, time/batch=0.071\n",
      "2108/67600 (epoch 1), train_loss = 1.441, time/batch=0.080\n",
      "2109/67600 (epoch 1), train_loss = 1.390, time/batch=0.072\n",
      "2110/67600 (epoch 1), train_loss = 1.351, time/batch=0.086\n",
      "2111/67600 (epoch 1), train_loss = 1.320, time/batch=0.254\n",
      "2112/67600 (epoch 1), train_loss = 1.382, time/batch=0.092\n",
      "2113/67600 (epoch 1), train_loss = 1.362, time/batch=0.073\n",
      "2114/67600 (epoch 1), train_loss = 1.347, time/batch=0.071\n",
      "2115/67600 (epoch 1), train_loss = 1.420, time/batch=0.073\n",
      "2116/67600 (epoch 1), train_loss = 1.442, time/batch=0.075\n",
      "2117/67600 (epoch 1), train_loss = 1.335, time/batch=0.073\n",
      "2118/67600 (epoch 1), train_loss = 1.402, time/batch=0.072\n",
      "2119/67600 (epoch 1), train_loss = 1.378, time/batch=0.072\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2120/67600 (epoch 1), train_loss = 1.366, time/batch=0.074\n",
      "2121/67600 (epoch 1), train_loss = 1.421, time/batch=0.069\n",
      "2122/67600 (epoch 1), train_loss = 1.374, time/batch=0.221\n",
      "2123/67600 (epoch 1), train_loss = 1.424, time/batch=0.070\n",
      "2124/67600 (epoch 1), train_loss = 1.402, time/batch=0.089\n",
      "2125/67600 (epoch 1), train_loss = 1.364, time/batch=0.072\n",
      "2126/67600 (epoch 1), train_loss = 1.425, time/batch=0.070\n",
      "2127/67600 (epoch 1), train_loss = 1.448, time/batch=0.071\n",
      "2128/67600 (epoch 1), train_loss = 1.396, time/batch=0.072\n",
      "2129/67600 (epoch 1), train_loss = 1.378, time/batch=0.069\n",
      "2130/67600 (epoch 1), train_loss = 1.368, time/batch=0.068\n",
      "2131/67600 (epoch 1), train_loss = 1.425, time/batch=0.075\n",
      "2132/67600 (epoch 1), train_loss = 1.439, time/batch=0.070\n",
      "2133/67600 (epoch 1), train_loss = 1.408, time/batch=0.069\n",
      "2134/67600 (epoch 1), train_loss = 1.358, time/batch=0.221\n",
      "2135/67600 (epoch 1), train_loss = 1.389, time/batch=0.077\n",
      "2136/67600 (epoch 1), train_loss = 1.370, time/batch=0.074\n",
      "2137/67600 (epoch 1), train_loss = 1.409, time/batch=0.076\n",
      "2138/67600 (epoch 1), train_loss = 1.402, time/batch=0.072\n",
      "2139/67600 (epoch 1), train_loss = 1.390, time/batch=0.071\n",
      "2140/67600 (epoch 1), train_loss = 1.390, time/batch=0.072\n",
      "2141/67600 (epoch 1), train_loss = 1.348, time/batch=0.070\n",
      "2142/67600 (epoch 1), train_loss = 1.369, time/batch=0.184\n",
      "2143/67600 (epoch 1), train_loss = 1.364, time/batch=0.069\n",
      "2144/67600 (epoch 1), train_loss = 1.349, time/batch=0.109\n",
      "2145/67600 (epoch 1), train_loss = 1.405, time/batch=0.073\n",
      "2146/67600 (epoch 1), train_loss = 1.368, time/batch=0.072\n",
      "2147/67600 (epoch 1), train_loss = 1.381, time/batch=0.079\n",
      "2148/67600 (epoch 1), train_loss = 1.432, time/batch=0.069\n",
      "2149/67600 (epoch 1), train_loss = 1.394, time/batch=0.072\n",
      "2150/67600 (epoch 1), train_loss = 1.411, time/batch=0.073\n",
      "2151/67600 (epoch 1), train_loss = 1.379, time/batch=0.071\n",
      "2152/67600 (epoch 1), train_loss = 1.376, time/batch=0.068\n",
      "2153/67600 (epoch 1), train_loss = 1.396, time/batch=0.071\n",
      "2154/67600 (epoch 1), train_loss = 1.369, time/batch=0.190\n",
      "2155/67600 (epoch 1), train_loss = 1.386, time/batch=0.068\n",
      "2156/67600 (epoch 1), train_loss = 1.344, time/batch=0.109\n",
      "2157/67600 (epoch 1), train_loss = 1.340, time/batch=0.071\n",
      "2158/67600 (epoch 1), train_loss = 1.393, time/batch=0.071\n",
      "2159/67600 (epoch 1), train_loss = 1.342, time/batch=0.073\n",
      "2160/67600 (epoch 1), train_loss = 1.302, time/batch=0.070\n",
      "2161/67600 (epoch 1), train_loss = 1.409, time/batch=0.077\n",
      "2162/67600 (epoch 1), train_loss = 1.344, time/batch=0.076\n",
      "2163/67600 (epoch 1), train_loss = 1.417, time/batch=0.078\n",
      "2164/67600 (epoch 1), train_loss = 1.392, time/batch=0.070\n",
      "2165/67600 (epoch 1), train_loss = 1.388, time/batch=0.071\n",
      "2166/67600 (epoch 1), train_loss = 1.423, time/batch=0.189\n",
      "2167/67600 (epoch 1), train_loss = 1.327, time/batch=0.087\n",
      "2168/67600 (epoch 1), train_loss = 1.440, time/batch=0.090\n",
      "2169/67600 (epoch 1), train_loss = 1.318, time/batch=0.072\n",
      "2170/67600 (epoch 1), train_loss = 1.354, time/batch=0.073\n",
      "2171/67600 (epoch 1), train_loss = 1.379, time/batch=0.071\n",
      "2172/67600 (epoch 1), train_loss = 1.292, time/batch=0.065\n",
      "2173/67600 (epoch 1), train_loss = 1.414, time/batch=0.072\n",
      "2174/67600 (epoch 1), train_loss = 1.378, time/batch=0.078\n",
      "2175/67600 (epoch 1), train_loss = 1.438, time/batch=0.076\n",
      "2176/67600 (epoch 1), train_loss = 1.384, time/batch=0.065\n",
      "2177/67600 (epoch 1), train_loss = 1.413, time/batch=0.158\n",
      "2178/67600 (epoch 1), train_loss = 1.516, time/batch=0.129\n",
      "2179/67600 (epoch 1), train_loss = 1.361, time/batch=0.098\n",
      "2180/67600 (epoch 1), train_loss = 1.375, time/batch=0.074\n",
      "2181/67600 (epoch 1), train_loss = 1.383, time/batch=0.067\n",
      "2182/67600 (epoch 1), train_loss = 1.428, time/batch=0.074\n",
      "2183/67600 (epoch 1), train_loss = 1.387, time/batch=0.072\n",
      "2184/67600 (epoch 1), train_loss = 1.391, time/batch=0.070\n",
      "2185/67600 (epoch 1), train_loss = 1.396, time/batch=0.074\n",
      "2186/67600 (epoch 1), train_loss = 1.345, time/batch=0.079\n",
      "2187/67600 (epoch 1), train_loss = 1.411, time/batch=0.075\n",
      "2188/67600 (epoch 1), train_loss = 1.270, time/batch=0.070\n",
      "2189/67600 (epoch 1), train_loss = 1.418, time/batch=0.213\n",
      "2190/67600 (epoch 1), train_loss = 1.300, time/batch=0.071\n",
      "2191/67600 (epoch 1), train_loss = 1.380, time/batch=0.087\n",
      "2192/67600 (epoch 1), train_loss = 1.433, time/batch=0.074\n",
      "2193/67600 (epoch 1), train_loss = 1.382, time/batch=0.070\n",
      "2194/67600 (epoch 1), train_loss = 1.368, time/batch=0.070\n",
      "2195/67600 (epoch 1), train_loss = 1.392, time/batch=0.073\n",
      "2196/67600 (epoch 1), train_loss = 1.379, time/batch=0.070\n",
      "2197/67600 (epoch 1), train_loss = 1.370, time/batch=0.112\n",
      "2198/67600 (epoch 1), train_loss = 1.373, time/batch=0.130\n",
      "2199/67600 (epoch 1), train_loss = 1.352, time/batch=0.095\n",
      "2200/67600 (epoch 1), train_loss = 1.400, time/batch=0.076\n",
      "2201/67600 (epoch 1), train_loss = 1.366, time/batch=0.070\n",
      "2202/67600 (epoch 1), train_loss = 1.358, time/batch=0.067\n",
      "2203/67600 (epoch 1), train_loss = 1.460, time/batch=0.079\n",
      "2204/67600 (epoch 1), train_loss = 1.451, time/batch=0.074\n",
      "2205/67600 (epoch 1), train_loss = 1.416, time/batch=0.070\n",
      "2206/67600 (epoch 1), train_loss = 1.360, time/batch=0.073\n",
      "2207/67600 (epoch 1), train_loss = 1.430, time/batch=0.072\n",
      "2208/67600 (epoch 1), train_loss = 1.381, time/batch=0.068\n",
      "2209/67600 (epoch 1), train_loss = 1.374, time/batch=0.078\n",
      "2210/67600 (epoch 1), train_loss = 1.410, time/batch=0.184\n",
      "2211/67600 (epoch 1), train_loss = 1.410, time/batch=0.108\n",
      "2212/67600 (epoch 1), train_loss = 1.384, time/batch=0.076\n",
      "2213/67600 (epoch 1), train_loss = 1.454, time/batch=0.074\n",
      "2214/67600 (epoch 1), train_loss = 1.449, time/batch=0.073\n",
      "2215/67600 (epoch 1), train_loss = 1.436, time/batch=0.073\n",
      "2216/67600 (epoch 1), train_loss = 1.337, time/batch=0.076\n",
      "2217/67600 (epoch 1), train_loss = 1.442, time/batch=0.074\n",
      "2218/67600 (epoch 1), train_loss = 1.432, time/batch=0.068\n",
      "2219/67600 (epoch 1), train_loss = 1.349, time/batch=0.073\n",
      "2220/67600 (epoch 1), train_loss = 1.377, time/batch=0.070\n",
      "2221/67600 (epoch 1), train_loss = 1.364, time/batch=0.189\n",
      "2222/67600 (epoch 1), train_loss = 1.371, time/batch=0.073\n",
      "2223/67600 (epoch 1), train_loss = 1.367, time/batch=0.105\n",
      "2224/67600 (epoch 1), train_loss = 1.409, time/batch=0.073\n",
      "2225/67600 (epoch 1), train_loss = 1.351, time/batch=0.072\n",
      "2226/67600 (epoch 1), train_loss = 1.383, time/batch=0.069\n",
      "2227/67600 (epoch 1), train_loss = 1.430, time/batch=0.070\n",
      "2228/67600 (epoch 1), train_loss = 1.401, time/batch=0.070\n",
      "2229/67600 (epoch 1), train_loss = 1.268, time/batch=0.067\n",
      "2230/67600 (epoch 1), train_loss = 1.362, time/batch=0.075\n",
      "2231/67600 (epoch 1), train_loss = 1.290, time/batch=0.074\n",
      "2232/67600 (epoch 1), train_loss = 1.338, time/batch=0.073\n",
      "2233/67600 (epoch 1), train_loss = 1.353, time/batch=0.209\n",
      "2234/67600 (epoch 1), train_loss = 1.363, time/batch=0.069\n",
      "2235/67600 (epoch 1), train_loss = 1.364, time/batch=0.094\n",
      "2236/67600 (epoch 1), train_loss = 1.345, time/batch=0.074\n",
      "2237/67600 (epoch 1), train_loss = 1.369, time/batch=0.070\n",
      "2238/67600 (epoch 1), train_loss = 1.351, time/batch=0.070\n",
      "2239/67600 (epoch 1), train_loss = 1.281, time/batch=0.072\n",
      "2240/67600 (epoch 1), train_loss = 1.453, time/batch=0.071\n",
      "2241/67600 (epoch 1), train_loss = 1.397, time/batch=0.070\n",
      "2242/67600 (epoch 1), train_loss = 1.441, time/batch=0.074\n",
      "2243/67600 (epoch 1), train_loss = 1.412, time/batch=0.071\n",
      "2244/67600 (epoch 1), train_loss = 1.388, time/batch=0.075\n",
      "2245/67600 (epoch 1), train_loss = 1.374, time/batch=0.208\n",
      "2246/67600 (epoch 1), train_loss = 1.392, time/batch=0.085\n",
      "2247/67600 (epoch 1), train_loss = 1.357, time/batch=0.078\n",
      "2248/67600 (epoch 1), train_loss = 1.366, time/batch=0.072\n",
      "2249/67600 (epoch 1), train_loss = 1.415, time/batch=0.071\n",
      "2250/67600 (epoch 1), train_loss = 1.399, time/batch=0.069\n",
      "2251/67600 (epoch 1), train_loss = 1.404, time/batch=0.071\n",
      "2252/67600 (epoch 1), train_loss = 1.389, time/batch=0.080\n",
      "2253/67600 (epoch 1), train_loss = 1.432, time/batch=0.185\n",
      "2254/67600 (epoch 1), train_loss = 1.440, time/batch=0.071\n",
      "2255/67600 (epoch 1), train_loss = 1.327, time/batch=0.102\n",
      "2256/67600 (epoch 1), train_loss = 1.369, time/batch=0.073\n",
      "2257/67600 (epoch 1), train_loss = 1.413, time/batch=0.073\n",
      "2258/67600 (epoch 1), train_loss = 1.367, time/batch=0.092\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2259/67600 (epoch 1), train_loss = 1.349, time/batch=0.073\n",
      "2260/67600 (epoch 1), train_loss = 1.423, time/batch=0.071\n",
      "2261/67600 (epoch 1), train_loss = 1.347, time/batch=0.074\n",
      "2262/67600 (epoch 1), train_loss = 1.345, time/batch=0.075\n",
      "2263/67600 (epoch 1), train_loss = 1.414, time/batch=0.072\n",
      "2264/67600 (epoch 1), train_loss = 1.366, time/batch=0.071\n",
      "2265/67600 (epoch 1), train_loss = 1.400, time/batch=0.124\n",
      "2266/67600 (epoch 1), train_loss = 1.416, time/batch=0.075\n",
      "2267/67600 (epoch 1), train_loss = 1.338, time/batch=0.073\n",
      "2268/67600 (epoch 1), train_loss = 1.368, time/batch=0.072\n",
      "2269/67600 (epoch 1), train_loss = 1.364, time/batch=0.068\n",
      "2270/67600 (epoch 1), train_loss = 1.358, time/batch=0.071\n",
      "2271/67600 (epoch 1), train_loss = 1.379, time/batch=0.073\n",
      "2272/67600 (epoch 1), train_loss = 1.398, time/batch=0.066\n",
      "2273/67600 (epoch 1), train_loss = 1.363, time/batch=0.072\n",
      "2274/67600 (epoch 1), train_loss = 1.411, time/batch=0.113\n",
      "2275/67600 (epoch 1), train_loss = 1.354, time/batch=0.197\n",
      "2276/67600 (epoch 1), train_loss = 1.310, time/batch=0.093\n",
      "2277/67600 (epoch 1), train_loss = 1.386, time/batch=0.079\n",
      "2278/67600 (epoch 1), train_loss = 1.365, time/batch=0.072\n",
      "2279/67600 (epoch 1), train_loss = 1.384, time/batch=0.075\n",
      "2280/67600 (epoch 1), train_loss = 1.357, time/batch=0.072\n",
      "2281/67600 (epoch 1), train_loss = 1.385, time/batch=0.076\n",
      "2282/67600 (epoch 1), train_loss = 1.321, time/batch=0.070\n",
      "2283/67600 (epoch 1), train_loss = 1.392, time/batch=0.073\n",
      "2284/67600 (epoch 1), train_loss = 1.345, time/batch=0.070\n",
      "2285/67600 (epoch 1), train_loss = 1.320, time/batch=0.072\n",
      "2286/67600 (epoch 1), train_loss = 1.330, time/batch=0.144\n",
      "2287/67600 (epoch 1), train_loss = 1.348, time/batch=0.138\n",
      "2288/67600 (epoch 1), train_loss = 1.391, time/batch=0.081\n",
      "2289/67600 (epoch 1), train_loss = 1.353, time/batch=0.073\n",
      "2290/67600 (epoch 1), train_loss = 1.331, time/batch=0.069\n",
      "2291/67600 (epoch 1), train_loss = 1.357, time/batch=0.073\n",
      "2292/67600 (epoch 1), train_loss = 1.369, time/batch=0.071\n",
      "2293/67600 (epoch 1), train_loss = 1.323, time/batch=0.070\n",
      "2294/67600 (epoch 1), train_loss = 1.290, time/batch=0.069\n",
      "2295/67600 (epoch 1), train_loss = 1.412, time/batch=0.071\n",
      "2296/67600 (epoch 1), train_loss = 1.350, time/batch=0.073\n",
      "2297/67600 (epoch 1), train_loss = 1.410, time/batch=0.068\n",
      "2298/67600 (epoch 1), train_loss = 1.347, time/batch=0.161\n",
      "2299/67600 (epoch 1), train_loss = 1.325, time/batch=0.125\n",
      "2300/67600 (epoch 1), train_loss = 1.387, time/batch=0.078\n",
      "2301/67600 (epoch 1), train_loss = 1.344, time/batch=0.072\n",
      "2302/67600 (epoch 1), train_loss = 1.412, time/batch=0.075\n",
      "2303/67600 (epoch 1), train_loss = 1.341, time/batch=0.073\n",
      "2304/67600 (epoch 1), train_loss = 1.396, time/batch=0.072\n",
      "2305/67600 (epoch 1), train_loss = 1.332, time/batch=0.071\n",
      "2306/67600 (epoch 1), train_loss = 1.281, time/batch=0.074\n",
      "2307/67600 (epoch 1), train_loss = 1.389, time/batch=0.181\n",
      "2308/67600 (epoch 1), train_loss = 1.390, time/batch=0.076\n",
      "2309/67600 (epoch 1), train_loss = 1.401, time/batch=0.120\n",
      "2310/67600 (epoch 1), train_loss = 1.337, time/batch=0.072\n",
      "2311/67600 (epoch 1), train_loss = 1.357, time/batch=0.080\n",
      "2312/67600 (epoch 1), train_loss = 1.344, time/batch=0.081\n",
      "2313/67600 (epoch 1), train_loss = 1.264, time/batch=0.097\n",
      "2314/67600 (epoch 1), train_loss = 1.293, time/batch=0.091\n",
      "2315/67600 (epoch 1), train_loss = 1.307, time/batch=0.084\n",
      "2316/67600 (epoch 1), train_loss = 1.276, time/batch=0.085\n",
      "2317/67600 (epoch 1), train_loss = 1.376, time/batch=0.205\n",
      "2318/67600 (epoch 1), train_loss = 1.379, time/batch=0.073\n",
      "2319/67600 (epoch 1), train_loss = 1.322, time/batch=0.112\n",
      "2320/67600 (epoch 1), train_loss = 1.331, time/batch=0.074\n",
      "2321/67600 (epoch 1), train_loss = 1.315, time/batch=0.070\n",
      "2322/67600 (epoch 1), train_loss = 1.369, time/batch=0.073\n",
      "2323/67600 (epoch 1), train_loss = 1.371, time/batch=0.073\n",
      "2324/67600 (epoch 1), train_loss = 1.309, time/batch=0.071\n",
      "2325/67600 (epoch 1), train_loss = 1.381, time/batch=0.071\n",
      "2326/67600 (epoch 1), train_loss = 1.391, time/batch=0.075\n",
      "2327/67600 (epoch 1), train_loss = 1.286, time/batch=0.073\n",
      "2328/67600 (epoch 1), train_loss = 1.283, time/batch=0.069\n",
      "2329/67600 (epoch 1), train_loss = 1.322, time/batch=0.195\n",
      "2330/67600 (epoch 1), train_loss = 1.391, time/batch=0.103\n",
      "2331/67600 (epoch 1), train_loss = 1.359, time/batch=0.071\n",
      "2332/67600 (epoch 1), train_loss = 1.377, time/batch=0.075\n",
      "2333/67600 (epoch 1), train_loss = 1.321, time/batch=0.070\n",
      "2334/67600 (epoch 1), train_loss = 1.315, time/batch=0.070\n",
      "2335/67600 (epoch 1), train_loss = 1.374, time/batch=0.070\n",
      "2336/67600 (epoch 1), train_loss = 1.338, time/batch=0.069\n",
      "2337/67600 (epoch 1), train_loss = 1.449, time/batch=0.069\n",
      "2338/67600 (epoch 1), train_loss = 1.362, time/batch=0.072\n",
      "2339/67600 (epoch 1), train_loss = 1.438, time/batch=0.069\n",
      "2340/67600 (epoch 1), train_loss = 1.324, time/batch=0.073\n",
      "2341/67600 (epoch 1), train_loss = 1.324, time/batch=0.205\n",
      "2342/67600 (epoch 1), train_loss = 1.367, time/batch=0.100\n",
      "2343/67600 (epoch 1), train_loss = 1.321, time/batch=0.070\n",
      "2344/67600 (epoch 1), train_loss = 1.413, time/batch=0.069\n",
      "2345/67600 (epoch 1), train_loss = 1.356, time/batch=0.076\n",
      "2346/67600 (epoch 1), train_loss = 1.360, time/batch=0.070\n",
      "2347/67600 (epoch 1), train_loss = 1.359, time/batch=0.075\n",
      "2348/67600 (epoch 1), train_loss = 1.368, time/batch=0.078\n",
      "2349/67600 (epoch 1), train_loss = 1.391, time/batch=0.072\n",
      "2350/67600 (epoch 1), train_loss = 1.300, time/batch=0.072\n",
      "2351/67600 (epoch 1), train_loss = 1.328, time/batch=0.069\n",
      "2352/67600 (epoch 1), train_loss = 1.346, time/batch=0.203\n",
      "2353/67600 (epoch 1), train_loss = 1.371, time/batch=0.084\n",
      "2354/67600 (epoch 1), train_loss = 1.329, time/batch=0.075\n",
      "2355/67600 (epoch 1), train_loss = 1.365, time/batch=0.072\n",
      "2356/67600 (epoch 1), train_loss = 1.297, time/batch=0.070\n",
      "2357/67600 (epoch 1), train_loss = 1.374, time/batch=0.071\n",
      "2358/67600 (epoch 1), train_loss = 1.353, time/batch=0.075\n",
      "2359/67600 (epoch 1), train_loss = 1.309, time/batch=0.072\n",
      "2360/67600 (epoch 1), train_loss = 1.361, time/batch=0.070\n",
      "2361/67600 (epoch 1), train_loss = 1.307, time/batch=0.168\n",
      "2362/67600 (epoch 1), train_loss = 1.342, time/batch=0.071\n",
      "2363/67600 (epoch 1), train_loss = 1.344, time/batch=0.109\n",
      "2364/67600 (epoch 1), train_loss = 1.306, time/batch=0.074\n",
      "2365/67600 (epoch 1), train_loss = 1.305, time/batch=0.069\n",
      "2366/67600 (epoch 1), train_loss = 1.330, time/batch=0.075\n",
      "2367/67600 (epoch 1), train_loss = 1.332, time/batch=0.076\n",
      "2368/67600 (epoch 1), train_loss = 1.332, time/batch=0.072\n",
      "2369/67600 (epoch 1), train_loss = 1.370, time/batch=0.073\n",
      "2370/67600 (epoch 1), train_loss = 1.335, time/batch=0.077\n",
      "2371/67600 (epoch 1), train_loss = 1.356, time/batch=0.073\n",
      "2372/67600 (epoch 1), train_loss = 1.354, time/batch=0.100\n",
      "2373/67600 (epoch 1), train_loss = 1.332, time/batch=0.152\n",
      "2374/67600 (epoch 1), train_loss = 1.325, time/batch=0.093\n",
      "2375/67600 (epoch 1), train_loss = 1.347, time/batch=0.077\n",
      "2376/67600 (epoch 1), train_loss = 1.345, time/batch=0.075\n",
      "2377/67600 (epoch 1), train_loss = 1.311, time/batch=0.070\n",
      "2378/67600 (epoch 1), train_loss = 1.375, time/batch=0.080\n",
      "2379/67600 (epoch 1), train_loss = 1.305, time/batch=0.071\n",
      "2380/67600 (epoch 1), train_loss = 1.404, time/batch=0.072\n",
      "2381/67600 (epoch 1), train_loss = 1.390, time/batch=0.076\n",
      "2382/67600 (epoch 1), train_loss = 1.405, time/batch=0.070\n",
      "2383/67600 (epoch 1), train_loss = 1.391, time/batch=0.075\n",
      "2384/67600 (epoch 1), train_loss = 1.353, time/batch=0.126\n",
      "2385/67600 (epoch 1), train_loss = 1.316, time/batch=0.134\n",
      "2386/67600 (epoch 1), train_loss = 1.360, time/batch=0.102\n",
      "2387/67600 (epoch 1), train_loss = 1.324, time/batch=0.065\n",
      "2388/67600 (epoch 1), train_loss = 1.309, time/batch=0.070\n",
      "2389/67600 (epoch 1), train_loss = 1.306, time/batch=0.067\n",
      "2390/67600 (epoch 1), train_loss = 1.339, time/batch=0.065\n",
      "2391/67600 (epoch 1), train_loss = 1.335, time/batch=0.070\n",
      "2392/67600 (epoch 1), train_loss = 1.360, time/batch=0.075\n",
      "2393/67600 (epoch 1), train_loss = 1.334, time/batch=0.066\n",
      "2394/67600 (epoch 1), train_loss = 1.389, time/batch=0.067\n",
      "2395/67600 (epoch 1), train_loss = 1.259, time/batch=0.066\n",
      "2396/67600 (epoch 1), train_loss = 1.344, time/batch=0.067\n",
      "2397/67600 (epoch 1), train_loss = 1.326, time/batch=0.179\n",
      "2398/67600 (epoch 1), train_loss = 1.354, time/batch=0.064\n",
      "2399/67600 (epoch 1), train_loss = 1.416, time/batch=0.079\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2400/67600 (epoch 1), train_loss = 1.391, time/batch=0.065\n",
      "2401/67600 (epoch 1), train_loss = 1.367, time/batch=0.065\n",
      "2402/67600 (epoch 1), train_loss = 1.343, time/batch=0.069\n",
      "2403/67600 (epoch 1), train_loss = 1.319, time/batch=0.064\n",
      "2404/67600 (epoch 1), train_loss = 1.377, time/batch=0.074\n",
      "2405/67600 (epoch 1), train_loss = 1.346, time/batch=0.065\n",
      "2406/67600 (epoch 1), train_loss = 1.387, time/batch=0.066\n",
      "2407/67600 (epoch 1), train_loss = 1.365, time/batch=0.064\n",
      "2408/67600 (epoch 1), train_loss = 1.288, time/batch=0.066\n",
      "2409/67600 (epoch 1), train_loss = 1.388, time/batch=0.063\n",
      "2410/67600 (epoch 1), train_loss = 1.415, time/batch=0.170\n",
      "2411/67600 (epoch 1), train_loss = 1.347, time/batch=0.087\n",
      "2412/67600 (epoch 1), train_loss = 1.369, time/batch=0.071\n",
      "2413/67600 (epoch 1), train_loss = 1.361, time/batch=0.066\n",
      "2414/67600 (epoch 1), train_loss = 1.351, time/batch=0.065\n",
      "2415/67600 (epoch 1), train_loss = 1.309, time/batch=0.065\n",
      "2416/67600 (epoch 1), train_loss = 1.354, time/batch=0.069\n",
      "2417/67600 (epoch 1), train_loss = 1.354, time/batch=0.068\n",
      "2418/67600 (epoch 1), train_loss = 1.321, time/batch=0.066\n",
      "2419/67600 (epoch 1), train_loss = 1.399, time/batch=0.091\n",
      "2420/67600 (epoch 1), train_loss = 1.335, time/batch=0.135\n",
      "2421/67600 (epoch 1), train_loss = 1.390, time/batch=0.064\n",
      "2422/67600 (epoch 1), train_loss = 1.390, time/batch=0.093\n",
      "2423/67600 (epoch 1), train_loss = 1.405, time/batch=0.067\n",
      "2424/67600 (epoch 1), train_loss = 1.351, time/batch=0.065\n",
      "2425/67600 (epoch 1), train_loss = 1.348, time/batch=0.085\n",
      "2426/67600 (epoch 1), train_loss = 1.317, time/batch=0.068\n",
      "2427/67600 (epoch 1), train_loss = 1.333, time/batch=0.069\n",
      "2428/67600 (epoch 1), train_loss = 1.369, time/batch=0.067\n",
      "2429/67600 (epoch 1), train_loss = 1.358, time/batch=0.069\n",
      "2430/67600 (epoch 1), train_loss = 1.384, time/batch=0.067\n",
      "2431/67600 (epoch 1), train_loss = 1.413, time/batch=0.066\n",
      "2432/67600 (epoch 1), train_loss = 1.406, time/batch=0.098\n",
      "2433/67600 (epoch 1), train_loss = 1.346, time/batch=0.074\n",
      "2434/67600 (epoch 1), train_loss = 1.394, time/batch=0.066\n",
      "2435/67600 (epoch 1), train_loss = 1.325, time/batch=0.070\n",
      "2436/67600 (epoch 1), train_loss = 1.324, time/batch=0.064\n",
      "2437/67600 (epoch 1), train_loss = 1.443, time/batch=0.077\n",
      "2438/67600 (epoch 1), train_loss = 1.368, time/batch=0.067\n",
      "2439/67600 (epoch 1), train_loss = 1.288, time/batch=0.068\n",
      "2440/67600 (epoch 1), train_loss = 1.344, time/batch=0.065\n",
      "2441/67600 (epoch 1), train_loss = 1.325, time/batch=0.067\n",
      "2442/67600 (epoch 1), train_loss = 1.385, time/batch=0.067\n",
      "2443/67600 (epoch 1), train_loss = 1.366, time/batch=0.174\n",
      "2444/67600 (epoch 1), train_loss = 1.399, time/batch=0.110\n",
      "2445/67600 (epoch 1), train_loss = 1.331, time/batch=0.089\n",
      "2446/67600 (epoch 1), train_loss = 1.339, time/batch=0.070\n",
      "2447/67600 (epoch 1), train_loss = 1.342, time/batch=0.068\n",
      "2448/67600 (epoch 1), train_loss = 1.360, time/batch=0.067\n",
      "2449/67600 (epoch 1), train_loss = 1.350, time/batch=0.073\n",
      "2450/67600 (epoch 1), train_loss = 1.322, time/batch=0.087\n",
      "2451/67600 (epoch 1), train_loss = 1.276, time/batch=0.065\n",
      "2452/67600 (epoch 1), train_loss = 1.343, time/batch=0.066\n",
      "2453/67600 (epoch 1), train_loss = 1.334, time/batch=0.064\n",
      "2454/67600 (epoch 1), train_loss = 1.324, time/batch=0.073\n",
      "2455/67600 (epoch 1), train_loss = 1.290, time/batch=0.063\n",
      "2456/67600 (epoch 1), train_loss = 1.435, time/batch=0.186\n",
      "2457/67600 (epoch 1), train_loss = 1.326, time/batch=0.064\n",
      "2458/67600 (epoch 1), train_loss = 1.333, time/batch=0.081\n",
      "2459/67600 (epoch 1), train_loss = 1.364, time/batch=0.065\n",
      "2460/67600 (epoch 1), train_loss = 1.342, time/batch=0.065\n",
      "2461/67600 (epoch 1), train_loss = 1.362, time/batch=0.065\n",
      "2462/67600 (epoch 1), train_loss = 1.351, time/batch=0.065\n",
      "2463/67600 (epoch 1), train_loss = 1.354, time/batch=0.066\n",
      "2464/67600 (epoch 1), train_loss = 1.402, time/batch=0.069\n",
      "2465/67600 (epoch 1), train_loss = 1.403, time/batch=0.066\n",
      "2466/67600 (epoch 1), train_loss = 1.400, time/batch=0.066\n",
      "2467/67600 (epoch 1), train_loss = 1.459, time/batch=0.066\n",
      "2468/67600 (epoch 1), train_loss = 1.328, time/batch=0.065\n",
      "2469/67600 (epoch 1), train_loss = 1.379, time/batch=0.192\n",
      "2470/67600 (epoch 1), train_loss = 1.346, time/batch=0.073\n",
      "2471/67600 (epoch 1), train_loss = 1.451, time/batch=0.070\n",
      "2472/67600 (epoch 1), train_loss = 1.357, time/batch=0.066\n",
      "2473/67600 (epoch 1), train_loss = 1.392, time/batch=0.065\n",
      "2474/67600 (epoch 1), train_loss = 1.466, time/batch=0.066\n",
      "2475/67600 (epoch 1), train_loss = 1.364, time/batch=0.066\n",
      "2476/67600 (epoch 1), train_loss = 1.353, time/batch=0.066\n",
      "2477/67600 (epoch 1), train_loss = 1.369, time/batch=0.065\n",
      "2478/67600 (epoch 1), train_loss = 1.433, time/batch=0.125\n",
      "2479/67600 (epoch 1), train_loss = 1.340, time/batch=0.109\n",
      "2480/67600 (epoch 1), train_loss = 1.381, time/batch=0.076\n",
      "2481/67600 (epoch 1), train_loss = 1.357, time/batch=0.091\n",
      "2482/67600 (epoch 1), train_loss = 1.375, time/batch=0.065\n",
      "2483/67600 (epoch 1), train_loss = 1.392, time/batch=0.065\n",
      "2484/67600 (epoch 1), train_loss = 1.340, time/batch=0.073\n",
      "2485/67600 (epoch 1), train_loss = 1.399, time/batch=0.064\n",
      "2486/67600 (epoch 1), train_loss = 1.428, time/batch=0.065\n",
      "2487/67600 (epoch 1), train_loss = 1.422, time/batch=0.067\n",
      "2488/67600 (epoch 1), train_loss = 1.393, time/batch=0.065\n",
      "2489/67600 (epoch 1), train_loss = 1.358, time/batch=0.067\n",
      "2490/67600 (epoch 1), train_loss = 1.375, time/batch=0.066\n",
      "2491/67600 (epoch 1), train_loss = 1.402, time/batch=0.134\n",
      "2492/67600 (epoch 1), train_loss = 1.365, time/batch=0.106\n",
      "2493/67600 (epoch 1), train_loss = 1.364, time/batch=0.078\n",
      "2494/67600 (epoch 1), train_loss = 1.418, time/batch=0.085\n",
      "2495/67600 (epoch 1), train_loss = 1.411, time/batch=0.066\n",
      "2496/67600 (epoch 1), train_loss = 1.373, time/batch=0.066\n",
      "2497/67600 (epoch 1), train_loss = 1.343, time/batch=0.066\n",
      "2498/67600 (epoch 1), train_loss = 1.344, time/batch=0.068\n",
      "2499/67600 (epoch 1), train_loss = 1.328, time/batch=0.066\n",
      "2500/67600 (epoch 1), train_loss = 1.312, time/batch=0.068\n",
      "model saved to ./save/model.ckpt\n",
      "2501/67600 (epoch 1), train_loss = 1.345, time/batch=0.142\n",
      "2502/67600 (epoch 1), train_loss = 1.284, time/batch=0.074\n",
      "2503/67600 (epoch 1), train_loss = 1.381, time/batch=0.066\n",
      "2504/67600 (epoch 1), train_loss = 1.346, time/batch=0.065\n",
      "2505/67600 (epoch 1), train_loss = 1.317, time/batch=0.067\n",
      "2506/67600 (epoch 1), train_loss = 1.376, time/batch=0.067\n",
      "2507/67600 (epoch 1), train_loss = 1.343, time/batch=0.064\n",
      "2508/67600 (epoch 1), train_loss = 1.343, time/batch=0.065\n",
      "2509/67600 (epoch 1), train_loss = 1.285, time/batch=0.064\n",
      "2510/67600 (epoch 1), train_loss = 1.393, time/batch=0.159\n",
      "2511/67600 (epoch 1), train_loss = 1.381, time/batch=0.065\n",
      "2512/67600 (epoch 1), train_loss = 1.315, time/batch=0.099\n",
      "2513/67600 (epoch 1), train_loss = 1.325, time/batch=0.068\n",
      "2514/67600 (epoch 1), train_loss = 1.336, time/batch=0.066\n",
      "2515/67600 (epoch 1), train_loss = 1.316, time/batch=0.072\n",
      "2516/67600 (epoch 1), train_loss = 1.373, time/batch=0.071\n",
      "2517/67600 (epoch 1), train_loss = 1.299, time/batch=0.066\n",
      "2518/67600 (epoch 1), train_loss = 1.324, time/batch=0.071\n",
      "2519/67600 (epoch 1), train_loss = 1.336, time/batch=0.068\n",
      "2520/67600 (epoch 1), train_loss = 1.385, time/batch=0.069\n",
      "2521/67600 (epoch 1), train_loss = 1.311, time/batch=0.066\n",
      "2522/67600 (epoch 1), train_loss = 1.319, time/batch=0.065\n",
      "2523/67600 (epoch 1), train_loss = 1.313, time/batch=0.167\n",
      "2524/67600 (epoch 1), train_loss = 1.328, time/batch=0.065\n",
      "2525/67600 (epoch 1), train_loss = 1.318, time/batch=0.094\n",
      "2526/67600 (epoch 1), train_loss = 1.326, time/batch=0.069\n",
      "2527/67600 (epoch 1), train_loss = 1.350, time/batch=0.064\n",
      "2528/67600 (epoch 1), train_loss = 1.359, time/batch=0.077\n",
      "2529/67600 (epoch 1), train_loss = 1.360, time/batch=0.070\n",
      "2530/67600 (epoch 1), train_loss = 1.373, time/batch=0.065\n",
      "2531/67600 (epoch 1), train_loss = 1.468, time/batch=0.065\n",
      "2532/67600 (epoch 1), train_loss = 1.423, time/batch=0.066\n",
      "2533/67600 (epoch 1), train_loss = 1.393, time/batch=0.067\n",
      "2534/67600 (epoch 1), train_loss = 1.337, time/batch=0.065\n",
      "2535/67600 (epoch 1), train_loss = 1.346, time/batch=0.066\n",
      "2536/67600 (epoch 1), train_loss = 1.375, time/batch=0.185\n",
      "2537/67600 (epoch 1), train_loss = 1.285, time/batch=0.065\n",
      "2538/67600 (epoch 1), train_loss = 1.316, time/batch=0.093\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2539/67600 (epoch 1), train_loss = 1.416, time/batch=0.069\n",
      "2540/67600 (epoch 1), train_loss = 1.348, time/batch=0.065\n",
      "2541/67600 (epoch 1), train_loss = 1.331, time/batch=0.066\n",
      "2542/67600 (epoch 1), train_loss = 1.351, time/batch=0.063\n",
      "2543/67600 (epoch 1), train_loss = 1.337, time/batch=0.069\n",
      "2544/67600 (epoch 1), train_loss = 1.326, time/batch=0.063\n",
      "2545/67600 (epoch 1), train_loss = 1.333, time/batch=0.064\n",
      "2546/67600 (epoch 1), train_loss = 1.301, time/batch=0.063\n",
      "2547/67600 (epoch 1), train_loss = 1.317, time/batch=0.064\n",
      "2548/67600 (epoch 1), train_loss = 1.368, time/batch=0.065\n",
      "2549/67600 (epoch 1), train_loss = 1.371, time/batch=0.179\n",
      "2550/67600 (epoch 1), train_loss = 1.376, time/batch=0.072\n",
      "2551/67600 (epoch 1), train_loss = 1.336, time/batch=0.082\n",
      "2552/67600 (epoch 1), train_loss = 1.360, time/batch=0.069\n",
      "2553/67600 (epoch 1), train_loss = 1.331, time/batch=0.064\n",
      "2554/67600 (epoch 1), train_loss = 1.339, time/batch=0.071\n",
      "2555/67600 (epoch 1), train_loss = 1.321, time/batch=0.066\n",
      "2556/67600 (epoch 1), train_loss = 1.434, time/batch=0.066\n",
      "2557/67600 (epoch 1), train_loss = 1.349, time/batch=0.069\n",
      "2558/67600 (epoch 1), train_loss = 1.318, time/batch=0.066\n",
      "2559/67600 (epoch 1), train_loss = 1.372, time/batch=0.066\n",
      "2560/67600 (epoch 1), train_loss = 1.320, time/batch=0.073\n",
      "2561/67600 (epoch 1), train_loss = 1.303, time/batch=0.065\n",
      "2562/67600 (epoch 1), train_loss = 1.357, time/batch=0.194\n",
      "2563/67600 (epoch 1), train_loss = 1.320, time/batch=0.069\n",
      "2564/67600 (epoch 1), train_loss = 1.298, time/batch=0.071\n",
      "2565/67600 (epoch 1), train_loss = 1.353, time/batch=0.068\n",
      "2566/67600 (epoch 1), train_loss = 1.383, time/batch=0.065\n",
      "2567/67600 (epoch 1), train_loss = 1.338, time/batch=0.074\n",
      "2568/67600 (epoch 1), train_loss = 1.354, time/batch=0.067\n",
      "2569/67600 (epoch 1), train_loss = 1.351, time/batch=0.065\n",
      "2570/67600 (epoch 1), train_loss = 1.338, time/batch=0.065\n",
      "2571/67600 (epoch 1), train_loss = 1.351, time/batch=0.151\n",
      "2572/67600 (epoch 1), train_loss = 1.343, time/batch=0.080\n",
      "2573/67600 (epoch 1), train_loss = 1.319, time/batch=0.095\n",
      "2574/67600 (epoch 1), train_loss = 1.366, time/batch=0.067\n",
      "2575/67600 (epoch 1), train_loss = 1.323, time/batch=0.067\n",
      "2576/67600 (epoch 1), train_loss = 1.391, time/batch=0.066\n",
      "2577/67600 (epoch 1), train_loss = 1.388, time/batch=0.082\n",
      "2578/67600 (epoch 1), train_loss = 1.370, time/batch=0.066\n",
      "2579/67600 (epoch 1), train_loss = 1.357, time/batch=0.065\n",
      "2580/67600 (epoch 1), train_loss = 1.403, time/batch=0.066\n",
      "2581/67600 (epoch 1), train_loss = 1.326, time/batch=0.066\n",
      "2582/67600 (epoch 1), train_loss = 1.369, time/batch=0.071\n",
      "2583/67600 (epoch 1), train_loss = 1.379, time/batch=0.064\n",
      "2584/67600 (epoch 1), train_loss = 1.450, time/batch=0.113\n",
      "2585/67600 (epoch 1), train_loss = 1.394, time/batch=0.065\n",
      "2586/67600 (epoch 1), train_loss = 1.302, time/batch=0.065\n",
      "2587/67600 (epoch 1), train_loss = 1.341, time/batch=0.076\n",
      "2588/67600 (epoch 1), train_loss = 1.339, time/batch=0.072\n",
      "2589/67600 (epoch 1), train_loss = 1.362, time/batch=0.065\n",
      "2590/67600 (epoch 1), train_loss = 1.328, time/batch=0.072\n",
      "2591/67600 (epoch 1), train_loss = 1.321, time/batch=0.065\n",
      "2592/67600 (epoch 1), train_loss = 1.407, time/batch=0.069\n",
      "2593/67600 (epoch 1), train_loss = 1.326, time/batch=0.065\n",
      "2594/67600 (epoch 1), train_loss = 1.336, time/batch=0.097\n",
      "2595/67600 (epoch 1), train_loss = 1.367, time/batch=0.216\n",
      "2596/67600 (epoch 1), train_loss = 1.448, time/batch=0.086\n",
      "2597/67600 (epoch 1), train_loss = 1.351, time/batch=0.068\n",
      "2598/67600 (epoch 1), train_loss = 1.329, time/batch=0.067\n",
      "2599/67600 (epoch 1), train_loss = 1.352, time/batch=0.065\n",
      "2600/67600 (epoch 1), train_loss = 1.384, time/batch=0.065\n",
      "2601/67600 (epoch 1), train_loss = 1.365, time/batch=0.063\n",
      "2602/67600 (epoch 1), train_loss = 1.315, time/batch=0.065\n",
      "2603/67600 (epoch 1), train_loss = 1.414, time/batch=0.063\n",
      "2604/67600 (epoch 1), train_loss = 1.306, time/batch=0.066\n",
      "2605/67600 (epoch 1), train_loss = 1.424, time/batch=0.066\n",
      "2606/67600 (epoch 1), train_loss = 1.352, time/batch=0.066\n",
      "2607/67600 (epoch 1), train_loss = 1.391, time/batch=0.069\n",
      "2608/67600 (epoch 1), train_loss = 1.378, time/batch=0.184\n",
      "2609/67600 (epoch 1), train_loss = 1.373, time/batch=0.069\n",
      "2610/67600 (epoch 1), train_loss = 1.426, time/batch=0.068\n",
      "2611/67600 (epoch 1), train_loss = 1.353, time/batch=0.069\n",
      "2612/67600 (epoch 1), train_loss = 1.369, time/batch=0.065\n",
      "2613/67600 (epoch 1), train_loss = 1.307, time/batch=0.065\n",
      "2614/67600 (epoch 1), train_loss = 1.431, time/batch=0.065\n",
      "2615/67600 (epoch 1), train_loss = 1.419, time/batch=0.069\n",
      "2616/67600 (epoch 1), train_loss = 1.413, time/batch=0.071\n",
      "2617/67600 (epoch 1), train_loss = 1.350, time/batch=0.067\n",
      "2618/67600 (epoch 1), train_loss = 1.423, time/batch=0.063\n",
      "2619/67600 (epoch 1), train_loss = 1.344, time/batch=0.075\n",
      "2620/67600 (epoch 1), train_loss = 1.287, time/batch=0.068\n",
      "2621/67600 (epoch 1), train_loss = 1.348, time/batch=0.188\n",
      "2622/67600 (epoch 1), train_loss = 1.347, time/batch=0.077\n",
      "2623/67600 (epoch 1), train_loss = 1.317, time/batch=0.064\n",
      "2624/67600 (epoch 1), train_loss = 1.355, time/batch=0.066\n",
      "2625/67600 (epoch 1), train_loss = 1.367, time/batch=0.068\n",
      "2626/67600 (epoch 1), train_loss = 1.376, time/batch=0.065\n",
      "2627/67600 (epoch 1), train_loss = 1.395, time/batch=0.066\n",
      "2628/67600 (epoch 1), train_loss = 1.371, time/batch=0.065\n",
      "2629/67600 (epoch 1), train_loss = 1.363, time/batch=0.067\n",
      "2630/67600 (epoch 1), train_loss = 1.314, time/batch=0.166\n",
      "2631/67600 (epoch 1), train_loss = 1.287, time/batch=0.069\n",
      "2632/67600 (epoch 1), train_loss = 1.325, time/batch=0.100\n",
      "2633/67600 (epoch 1), train_loss = 1.381, time/batch=0.067\n",
      "2634/67600 (epoch 1), train_loss = 1.316, time/batch=0.065\n",
      "2635/67600 (epoch 1), train_loss = 1.374, time/batch=0.069\n",
      "2636/67600 (epoch 1), train_loss = 1.374, time/batch=0.064\n",
      "2637/67600 (epoch 1), train_loss = 1.349, time/batch=0.065\n",
      "2638/67600 (epoch 1), train_loss = 1.299, time/batch=0.063\n",
      "2639/67600 (epoch 1), train_loss = 1.394, time/batch=0.072\n",
      "2640/67600 (epoch 1), train_loss = 1.339, time/batch=0.067\n",
      "2641/67600 (epoch 1), train_loss = 1.391, time/batch=0.066\n",
      "2642/67600 (epoch 1), train_loss = 1.430, time/batch=0.067\n",
      "2643/67600 (epoch 1), train_loss = 1.388, time/batch=0.172\n",
      "2644/67600 (epoch 1), train_loss = 1.315, time/batch=0.066\n",
      "2645/67600 (epoch 1), train_loss = 1.376, time/batch=0.104\n",
      "2646/67600 (epoch 1), train_loss = 1.362, time/batch=0.066\n",
      "2647/67600 (epoch 1), train_loss = 1.325, time/batch=0.066\n",
      "2648/67600 (epoch 1), train_loss = 1.363, time/batch=0.069\n",
      "2649/67600 (epoch 1), train_loss = 1.367, time/batch=0.064\n",
      "2650/67600 (epoch 1), train_loss = 1.304, time/batch=0.066\n",
      "2651/67600 (epoch 1), train_loss = 1.371, time/batch=0.065\n",
      "2652/67600 (epoch 1), train_loss = 1.401, time/batch=0.069\n",
      "2653/67600 (epoch 1), train_loss = 1.355, time/batch=0.066\n",
      "2654/67600 (epoch 1), train_loss = 1.304, time/batch=0.066\n",
      "2655/67600 (epoch 1), train_loss = 1.340, time/batch=0.065\n",
      "2656/67600 (epoch 1), train_loss = 1.371, time/batch=0.170\n",
      "2657/67600 (epoch 1), train_loss = 1.292, time/batch=0.066\n",
      "2658/67600 (epoch 1), train_loss = 1.370, time/batch=0.097\n",
      "2659/67600 (epoch 1), train_loss = 1.351, time/batch=0.067\n",
      "2660/67600 (epoch 1), train_loss = 1.364, time/batch=0.067\n",
      "2661/67600 (epoch 1), train_loss = 1.343, time/batch=0.067\n",
      "2662/67600 (epoch 1), train_loss = 1.342, time/batch=0.064\n",
      "2663/67600 (epoch 1), train_loss = 1.378, time/batch=0.066\n",
      "2664/67600 (epoch 1), train_loss = 1.335, time/batch=0.065\n",
      "2665/67600 (epoch 1), train_loss = 1.394, time/batch=0.066\n",
      "2666/67600 (epoch 1), train_loss = 1.416, time/batch=0.068\n",
      "2667/67600 (epoch 1), train_loss = 1.348, time/batch=0.068\n",
      "2668/67600 (epoch 1), train_loss = 1.383, time/batch=0.068\n",
      "2669/67600 (epoch 1), train_loss = 1.391, time/batch=0.188\n",
      "2670/67600 (epoch 1), train_loss = 1.359, time/batch=0.065\n",
      "2671/67600 (epoch 1), train_loss = 1.347, time/batch=0.082\n",
      "2672/67600 (epoch 1), train_loss = 1.345, time/batch=0.069\n",
      "2673/67600 (epoch 1), train_loss = 1.351, time/batch=0.065\n",
      "2674/67600 (epoch 1), train_loss = 1.306, time/batch=0.067\n",
      "2675/67600 (epoch 1), train_loss = 1.357, time/batch=0.066\n",
      "2676/67600 (epoch 1), train_loss = 1.414, time/batch=0.066\n",
      "2677/67600 (epoch 1), train_loss = 1.346, time/batch=0.066\n",
      "2678/67600 (epoch 1), train_loss = 1.360, time/batch=0.066\n",
      "2679/67600 (epoch 1), train_loss = 1.352, time/batch=0.063\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2680/67600 (epoch 1), train_loss = 1.353, time/batch=0.069\n",
      "2681/67600 (epoch 1), train_loss = 1.368, time/batch=0.065\n",
      "2682/67600 (epoch 1), train_loss = 1.400, time/batch=0.191\n",
      "2683/67600 (epoch 1), train_loss = 1.420, time/batch=0.074\n",
      "2684/67600 (epoch 1), train_loss = 1.365, time/batch=0.072\n",
      "2685/67600 (epoch 1), train_loss = 1.333, time/batch=0.066\n",
      "2686/67600 (epoch 1), train_loss = 1.298, time/batch=0.066\n",
      "2687/67600 (epoch 1), train_loss = 1.365, time/batch=0.066\n",
      "2688/67600 (epoch 1), train_loss = 1.377, time/batch=0.064\n",
      "2689/67600 (epoch 1), train_loss = 1.343, time/batch=0.069\n",
      "2690/67600 (epoch 1), train_loss = 1.390, time/batch=0.065\n",
      "2691/67600 (epoch 1), train_loss = 1.336, time/batch=0.128\n",
      "2692/67600 (epoch 1), train_loss = 1.335, time/batch=0.090\n",
      "2693/67600 (epoch 1), train_loss = 1.365, time/batch=0.070\n",
      "2694/67600 (epoch 1), train_loss = 1.375, time/batch=0.114\n",
      "2695/67600 (epoch 1), train_loss = 1.336, time/batch=0.072\n",
      "2696/67600 (epoch 1), train_loss = 1.326, time/batch=0.065\n",
      "2697/67600 (epoch 1), train_loss = 1.368, time/batch=0.067\n",
      "2698/67600 (epoch 1), train_loss = 1.313, time/batch=0.063\n",
      "2699/67600 (epoch 1), train_loss = 1.360, time/batch=0.064\n",
      "2700/67600 (epoch 1), train_loss = 1.408, time/batch=0.070\n",
      "2701/67600 (epoch 1), train_loss = 1.433, time/batch=0.064\n",
      "2702/67600 (epoch 1), train_loss = 1.358, time/batch=0.066\n",
      "2703/67600 (epoch 1), train_loss = 1.366, time/batch=0.067\n",
      "2704/67600 (epoch 2), train_loss = 1.516, time/batch=0.151\n",
      "2705/67600 (epoch 2), train_loss = 1.300, time/batch=0.067\n",
      "2706/67600 (epoch 2), train_loss = 1.385, time/batch=0.096\n",
      "2707/67600 (epoch 2), train_loss = 1.332, time/batch=0.065\n",
      "2708/67600 (epoch 2), train_loss = 1.366, time/batch=0.064\n",
      "2709/67600 (epoch 2), train_loss = 1.378, time/batch=0.065\n",
      "2710/67600 (epoch 2), train_loss = 1.339, time/batch=0.065\n",
      "2711/67600 (epoch 2), train_loss = 1.373, time/batch=0.063\n",
      "2712/67600 (epoch 2), train_loss = 1.388, time/batch=0.064\n",
      "2713/67600 (epoch 2), train_loss = 1.332, time/batch=0.062\n",
      "2714/67600 (epoch 2), train_loss = 1.309, time/batch=0.067\n",
      "2715/67600 (epoch 2), train_loss = 1.324, time/batch=0.066\n",
      "2716/67600 (epoch 2), train_loss = 1.330, time/batch=0.065\n",
      "2717/67600 (epoch 2), train_loss = 1.371, time/batch=0.176\n",
      "2718/67600 (epoch 2), train_loss = 1.369, time/batch=0.067\n",
      "2719/67600 (epoch 2), train_loss = 1.331, time/batch=0.097\n",
      "2720/67600 (epoch 2), train_loss = 1.344, time/batch=0.072\n",
      "2721/67600 (epoch 2), train_loss = 1.374, time/batch=0.065\n",
      "2722/67600 (epoch 2), train_loss = 1.357, time/batch=0.079\n",
      "2723/67600 (epoch 2), train_loss = 1.366, time/batch=0.084\n",
      "2724/67600 (epoch 2), train_loss = 1.364, time/batch=0.069\n",
      "2725/67600 (epoch 2), train_loss = 1.300, time/batch=0.077\n",
      "2726/67600 (epoch 2), train_loss = 1.387, time/batch=0.077\n",
      "2727/67600 (epoch 2), train_loss = 1.395, time/batch=0.073\n",
      "2728/67600 (epoch 2), train_loss = 1.428, time/batch=0.073\n",
      "2729/67600 (epoch 2), train_loss = 1.266, time/batch=0.202\n",
      "2730/67600 (epoch 2), train_loss = 1.364, time/batch=0.093\n",
      "2731/67600 (epoch 2), train_loss = 1.400, time/batch=0.073\n",
      "2732/67600 (epoch 2), train_loss = 1.424, time/batch=0.075\n",
      "2733/67600 (epoch 2), train_loss = 1.354, time/batch=0.069\n",
      "2734/67600 (epoch 2), train_loss = 1.343, time/batch=0.073\n",
      "2735/67600 (epoch 2), train_loss = 1.418, time/batch=0.072\n",
      "2736/67600 (epoch 2), train_loss = 1.341, time/batch=0.069\n",
      "2737/67600 (epoch 2), train_loss = 1.397, time/batch=0.072\n",
      "2738/67600 (epoch 2), train_loss = 1.372, time/batch=0.074\n",
      "2739/67600 (epoch 2), train_loss = 1.355, time/batch=0.070\n",
      "2740/67600 (epoch 2), train_loss = 1.300, time/batch=0.071\n",
      "2741/67600 (epoch 2), train_loss = 1.391, time/batch=0.207\n",
      "2742/67600 (epoch 2), train_loss = 1.377, time/batch=0.079\n",
      "2743/67600 (epoch 2), train_loss = 1.361, time/batch=0.073\n",
      "2744/67600 (epoch 2), train_loss = 1.280, time/batch=0.080\n",
      "2745/67600 (epoch 2), train_loss = 1.401, time/batch=0.071\n",
      "2746/67600 (epoch 2), train_loss = 1.378, time/batch=0.072\n",
      "2747/67600 (epoch 2), train_loss = 1.378, time/batch=0.073\n",
      "2748/67600 (epoch 2), train_loss = 1.396, time/batch=0.073\n",
      "2749/67600 (epoch 2), train_loss = 1.356, time/batch=0.181\n",
      "2750/67600 (epoch 2), train_loss = 1.307, time/batch=0.077\n",
      "2751/67600 (epoch 2), train_loss = 1.339, time/batch=0.102\n",
      "2752/67600 (epoch 2), train_loss = 1.327, time/batch=0.071\n",
      "2753/67600 (epoch 2), train_loss = 1.295, time/batch=0.070\n",
      "2754/67600 (epoch 2), train_loss = 1.426, time/batch=0.093\n",
      "2755/67600 (epoch 2), train_loss = 1.321, time/batch=0.072\n",
      "2756/67600 (epoch 2), train_loss = 1.336, time/batch=0.070\n",
      "2757/67600 (epoch 2), train_loss = 1.433, time/batch=0.072\n",
      "2758/67600 (epoch 2), train_loss = 1.397, time/batch=0.072\n",
      "2759/67600 (epoch 2), train_loss = 1.355, time/batch=0.071\n",
      "2760/67600 (epoch 2), train_loss = 1.375, time/batch=0.067\n",
      "2761/67600 (epoch 2), train_loss = 1.354, time/batch=0.115\n",
      "2762/67600 (epoch 2), train_loss = 1.348, time/batch=0.067\n",
      "2763/67600 (epoch 2), train_loss = 1.374, time/batch=0.072\n",
      "2764/67600 (epoch 2), train_loss = 1.359, time/batch=0.075\n",
      "2765/67600 (epoch 2), train_loss = 1.327, time/batch=0.069\n",
      "2766/67600 (epoch 2), train_loss = 1.379, time/batch=0.070\n",
      "2767/67600 (epoch 2), train_loss = 1.385, time/batch=0.082\n",
      "2768/67600 (epoch 2), train_loss = 1.357, time/batch=0.072\n",
      "2769/67600 (epoch 2), train_loss = 1.338, time/batch=0.069\n",
      "2770/67600 (epoch 2), train_loss = 1.341, time/batch=0.072\n",
      "2771/67600 (epoch 2), train_loss = 1.378, time/batch=0.243\n",
      "2772/67600 (epoch 2), train_loss = 1.372, time/batch=0.078\n",
      "2773/67600 (epoch 2), train_loss = 1.371, time/batch=0.081\n",
      "2774/67600 (epoch 2), train_loss = 1.374, time/batch=0.075\n",
      "2775/67600 (epoch 2), train_loss = 1.375, time/batch=0.070\n",
      "2776/67600 (epoch 2), train_loss = 1.343, time/batch=0.071\n",
      "2777/67600 (epoch 2), train_loss = 1.440, time/batch=0.074\n",
      "2778/67600 (epoch 2), train_loss = 1.360, time/batch=0.073\n",
      "2779/67600 (epoch 2), train_loss = 1.411, time/batch=0.071\n",
      "2780/67600 (epoch 2), train_loss = 1.408, time/batch=0.073\n",
      "2781/67600 (epoch 2), train_loss = 1.475, time/batch=0.073\n",
      "2782/67600 (epoch 2), train_loss = 1.397, time/batch=0.070\n",
      "2783/67600 (epoch 2), train_loss = 1.338, time/batch=0.217\n",
      "2784/67600 (epoch 2), train_loss = 1.322, time/batch=0.079\n",
      "2785/67600 (epoch 2), train_loss = 1.349, time/batch=0.068\n",
      "2786/67600 (epoch 2), train_loss = 1.368, time/batch=0.072\n",
      "2787/67600 (epoch 2), train_loss = 1.360, time/batch=0.067\n",
      "2788/67600 (epoch 2), train_loss = 1.393, time/batch=0.071\n",
      "2789/67600 (epoch 2), train_loss = 1.353, time/batch=0.074\n",
      "2790/67600 (epoch 2), train_loss = 1.283, time/batch=0.072\n",
      "2791/67600 (epoch 2), train_loss = 1.413, time/batch=0.067\n",
      "2792/67600 (epoch 2), train_loss = 1.386, time/batch=0.072\n",
      "2793/67600 (epoch 2), train_loss = 1.376, time/batch=0.071\n",
      "2794/67600 (epoch 2), train_loss = 1.348, time/batch=0.070\n",
      "2795/67600 (epoch 2), train_loss = 1.377, time/batch=0.229\n",
      "2796/67600 (epoch 2), train_loss = 1.311, time/batch=0.074\n",
      "2797/67600 (epoch 2), train_loss = 1.307, time/batch=0.070\n",
      "2798/67600 (epoch 2), train_loss = 1.302, time/batch=0.070\n",
      "2799/67600 (epoch 2), train_loss = 1.267, time/batch=0.068\n",
      "2800/67600 (epoch 2), train_loss = 1.284, time/batch=0.074\n",
      "2801/67600 (epoch 2), train_loss = 1.352, time/batch=0.078\n",
      "2802/67600 (epoch 2), train_loss = 1.337, time/batch=0.074\n",
      "2803/67600 (epoch 2), train_loss = 1.404, time/batch=0.178\n",
      "2804/67600 (epoch 2), train_loss = 1.265, time/batch=0.070\n",
      "2805/67600 (epoch 2), train_loss = 1.349, time/batch=0.107\n",
      "2806/67600 (epoch 2), train_loss = 1.380, time/batch=0.075\n",
      "2807/67600 (epoch 2), train_loss = 1.299, time/batch=0.070\n",
      "2808/67600 (epoch 2), train_loss = 1.314, time/batch=0.073\n",
      "2809/67600 (epoch 2), train_loss = 1.359, time/batch=0.072\n",
      "2810/67600 (epoch 2), train_loss = 1.316, time/batch=0.072\n",
      "2811/67600 (epoch 2), train_loss = 1.349, time/batch=0.069\n",
      "2812/67600 (epoch 2), train_loss = 1.383, time/batch=0.073\n",
      "2813/67600 (epoch 2), train_loss = 1.351, time/batch=0.076\n",
      "2814/67600 (epoch 2), train_loss = 1.328, time/batch=0.076\n",
      "2815/67600 (epoch 2), train_loss = 1.373, time/batch=0.186\n",
      "2816/67600 (epoch 2), train_loss = 1.342, time/batch=0.071\n",
      "2817/67600 (epoch 2), train_loss = 1.370, time/batch=0.107\n",
      "2818/67600 (epoch 2), train_loss = 1.363, time/batch=0.070\n",
      "2819/67600 (epoch 2), train_loss = 1.307, time/batch=0.075\n",
      "2820/67600 (epoch 2), train_loss = 1.302, time/batch=0.072\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2821/67600 (epoch 2), train_loss = 1.339, time/batch=0.074\n",
      "2822/67600 (epoch 2), train_loss = 1.356, time/batch=0.073\n",
      "2823/67600 (epoch 2), train_loss = 1.384, time/batch=0.075\n",
      "2824/67600 (epoch 2), train_loss = 1.347, time/batch=0.071\n",
      "2825/67600 (epoch 2), train_loss = 1.371, time/batch=0.071\n",
      "2826/67600 (epoch 2), train_loss = 1.342, time/batch=0.109\n",
      "2827/67600 (epoch 2), train_loss = 1.333, time/batch=0.159\n",
      "2828/67600 (epoch 2), train_loss = 1.336, time/batch=0.098\n",
      "2829/67600 (epoch 2), train_loss = 1.260, time/batch=0.072\n",
      "2830/67600 (epoch 2), train_loss = 1.352, time/batch=0.073\n",
      "2831/67600 (epoch 2), train_loss = 1.395, time/batch=0.075\n",
      "2832/67600 (epoch 2), train_loss = 1.334, time/batch=0.070\n",
      "2833/67600 (epoch 2), train_loss = 1.347, time/batch=0.072\n",
      "2834/67600 (epoch 2), train_loss = 1.359, time/batch=0.074\n",
      "2835/67600 (epoch 2), train_loss = 1.333, time/batch=0.069\n",
      "2836/67600 (epoch 2), train_loss = 1.385, time/batch=0.073\n",
      "2837/67600 (epoch 2), train_loss = 1.337, time/batch=0.071\n",
      "2838/67600 (epoch 2), train_loss = 1.385, time/batch=0.137\n",
      "2839/67600 (epoch 2), train_loss = 1.362, time/batch=0.142\n",
      "2840/67600 (epoch 2), train_loss = 1.365, time/batch=0.090\n",
      "2841/67600 (epoch 2), train_loss = 1.354, time/batch=0.071\n",
      "2842/67600 (epoch 2), train_loss = 1.364, time/batch=0.079\n",
      "2843/67600 (epoch 2), train_loss = 1.329, time/batch=0.076\n",
      "2844/67600 (epoch 2), train_loss = 1.311, time/batch=0.073\n",
      "2845/67600 (epoch 2), train_loss = 1.289, time/batch=0.071\n",
      "2846/67600 (epoch 2), train_loss = 1.381, time/batch=0.075\n",
      "2847/67600 (epoch 2), train_loss = 1.302, time/batch=0.071\n",
      "2848/67600 (epoch 2), train_loss = 1.373, time/batch=0.071\n",
      "2849/67600 (epoch 2), train_loss = 1.430, time/batch=0.074\n",
      "2850/67600 (epoch 2), train_loss = 1.337, time/batch=0.207\n",
      "2851/67600 (epoch 2), train_loss = 1.359, time/batch=0.080\n",
      "2852/67600 (epoch 2), train_loss = 1.390, time/batch=0.072\n",
      "2853/67600 (epoch 2), train_loss = 1.276, time/batch=0.071\n",
      "2854/67600 (epoch 2), train_loss = 1.362, time/batch=0.071\n",
      "2855/67600 (epoch 2), train_loss = 1.314, time/batch=0.076\n",
      "2856/67600 (epoch 2), train_loss = 1.298, time/batch=0.071\n",
      "2857/67600 (epoch 2), train_loss = 1.348, time/batch=0.073\n",
      "2858/67600 (epoch 2), train_loss = 1.301, time/batch=0.096\n",
      "2859/67600 (epoch 2), train_loss = 1.364, time/batch=0.143\n",
      "2860/67600 (epoch 2), train_loss = 1.379, time/batch=0.068\n",
      "2861/67600 (epoch 2), train_loss = 1.381, time/batch=0.107\n",
      "2862/67600 (epoch 2), train_loss = 1.347, time/batch=0.076\n",
      "2863/67600 (epoch 2), train_loss = 1.331, time/batch=0.074\n",
      "2864/67600 (epoch 2), train_loss = 1.322, time/batch=0.073\n",
      "2865/67600 (epoch 2), train_loss = 1.288, time/batch=0.075\n",
      "2866/67600 (epoch 2), train_loss = 1.353, time/batch=0.073\n",
      "2867/67600 (epoch 2), train_loss = 1.351, time/batch=0.073\n",
      "2868/67600 (epoch 2), train_loss = 1.236, time/batch=0.072\n",
      "2869/67600 (epoch 2), train_loss = 1.359, time/batch=0.075\n",
      "2870/67600 (epoch 2), train_loss = 1.341, time/batch=0.157\n",
      "2871/67600 (epoch 2), train_loss = 1.319, time/batch=0.098\n",
      "2872/67600 (epoch 2), train_loss = 1.362, time/batch=0.110\n",
      "2873/67600 (epoch 2), train_loss = 1.358, time/batch=0.071\n",
      "2874/67600 (epoch 2), train_loss = 1.335, time/batch=0.070\n",
      "2875/67600 (epoch 2), train_loss = 1.294, time/batch=0.078\n",
      "2876/67600 (epoch 2), train_loss = 1.374, time/batch=0.071\n",
      "2877/67600 (epoch 2), train_loss = 1.314, time/batch=0.068\n",
      "2878/67600 (epoch 2), train_loss = 1.318, time/batch=0.072\n",
      "2879/67600 (epoch 2), train_loss = 1.341, time/batch=0.075\n",
      "2880/67600 (epoch 2), train_loss = 1.361, time/batch=0.071\n",
      "2881/67600 (epoch 2), train_loss = 1.394, time/batch=0.071\n",
      "2882/67600 (epoch 2), train_loss = 1.307, time/batch=0.189\n",
      "2883/67600 (epoch 2), train_loss = 1.319, time/batch=0.079\n",
      "2884/67600 (epoch 2), train_loss = 1.269, time/batch=0.110\n",
      "2885/67600 (epoch 2), train_loss = 1.275, time/batch=0.070\n",
      "2886/67600 (epoch 2), train_loss = 1.337, time/batch=0.073\n",
      "2887/67600 (epoch 2), train_loss = 1.436, time/batch=0.077\n",
      "2888/67600 (epoch 2), train_loss = 1.447, time/batch=0.073\n",
      "2889/67600 (epoch 2), train_loss = 1.423, time/batch=0.072\n",
      "2890/67600 (epoch 2), train_loss = 1.436, time/batch=0.072\n",
      "2891/67600 (epoch 2), train_loss = 1.353, time/batch=0.073\n",
      "2892/67600 (epoch 2), train_loss = 1.353, time/batch=0.073\n",
      "2893/67600 (epoch 2), train_loss = 1.332, time/batch=0.071\n",
      "2894/67600 (epoch 2), train_loss = 1.397, time/batch=0.207\n",
      "2895/67600 (epoch 2), train_loss = 1.379, time/batch=0.089\n",
      "2896/67600 (epoch 2), train_loss = 1.339, time/batch=0.069\n",
      "2897/67600 (epoch 2), train_loss = 1.356, time/batch=0.071\n",
      "2898/67600 (epoch 2), train_loss = 1.370, time/batch=0.068\n",
      "2899/67600 (epoch 2), train_loss = 1.350, time/batch=0.070\n",
      "2900/67600 (epoch 2), train_loss = 1.331, time/batch=0.077\n",
      "2901/67600 (epoch 2), train_loss = 1.322, time/batch=0.071\n",
      "2902/67600 (epoch 2), train_loss = 1.356, time/batch=0.071\n",
      "2903/67600 (epoch 2), train_loss = 1.312, time/batch=0.072\n",
      "2904/67600 (epoch 2), train_loss = 1.305, time/batch=0.069\n",
      "2905/67600 (epoch 2), train_loss = 1.296, time/batch=0.068\n",
      "2906/67600 (epoch 2), train_loss = 1.398, time/batch=0.213\n",
      "2907/67600 (epoch 2), train_loss = 1.353, time/batch=0.079\n",
      "2908/67600 (epoch 2), train_loss = 1.365, time/batch=0.070\n",
      "2909/67600 (epoch 2), train_loss = 1.266, time/batch=0.073\n",
      "2910/67600 (epoch 2), train_loss = 1.287, time/batch=0.071\n",
      "2911/67600 (epoch 2), train_loss = 1.304, time/batch=0.072\n",
      "2912/67600 (epoch 2), train_loss = 1.366, time/batch=0.077\n",
      "2913/67600 (epoch 2), train_loss = 1.389, time/batch=0.071\n",
      "2914/67600 (epoch 2), train_loss = 1.352, time/batch=0.167\n",
      "2915/67600 (epoch 2), train_loss = 1.421, time/batch=0.080\n",
      "2916/67600 (epoch 2), train_loss = 1.322, time/batch=0.102\n",
      "2917/67600 (epoch 2), train_loss = 1.321, time/batch=0.076\n",
      "2918/67600 (epoch 2), train_loss = 1.347, time/batch=0.079\n",
      "2919/67600 (epoch 2), train_loss = 1.382, time/batch=0.094\n",
      "2920/67600 (epoch 2), train_loss = 1.307, time/batch=0.071\n",
      "2921/67600 (epoch 2), train_loss = 1.320, time/batch=0.070\n",
      "2922/67600 (epoch 2), train_loss = 1.301, time/batch=0.074\n",
      "2923/67600 (epoch 2), train_loss = 1.319, time/batch=0.074\n",
      "2924/67600 (epoch 2), train_loss = 1.410, time/batch=0.070\n",
      "2925/67600 (epoch 2), train_loss = 1.312, time/batch=0.073\n",
      "2926/67600 (epoch 2), train_loss = 1.329, time/batch=0.117\n",
      "2927/67600 (epoch 2), train_loss = 1.343, time/batch=0.069\n",
      "2928/67600 (epoch 2), train_loss = 1.350, time/batch=0.072\n",
      "2929/67600 (epoch 2), train_loss = 1.349, time/batch=0.073\n",
      "2930/67600 (epoch 2), train_loss = 1.385, time/batch=0.072\n",
      "2931/67600 (epoch 2), train_loss = 1.304, time/batch=0.072\n",
      "2932/67600 (epoch 2), train_loss = 1.325, time/batch=0.074\n",
      "2933/67600 (epoch 2), train_loss = 1.311, time/batch=0.071\n",
      "2934/67600 (epoch 2), train_loss = 1.345, time/batch=0.071\n",
      "2935/67600 (epoch 2), train_loss = 1.355, time/batch=0.082\n",
      "2936/67600 (epoch 2), train_loss = 1.291, time/batch=0.235\n",
      "2937/67600 (epoch 2), train_loss = 1.266, time/batch=0.091\n",
      "2938/67600 (epoch 2), train_loss = 1.362, time/batch=0.070\n",
      "2939/67600 (epoch 2), train_loss = 1.339, time/batch=0.072\n",
      "2940/67600 (epoch 2), train_loss = 1.316, time/batch=0.073\n",
      "2941/67600 (epoch 2), train_loss = 1.318, time/batch=0.075\n",
      "2942/67600 (epoch 2), train_loss = 1.384, time/batch=0.073\n",
      "2943/67600 (epoch 2), train_loss = 1.366, time/batch=0.074\n",
      "2944/67600 (epoch 2), train_loss = 1.365, time/batch=0.073\n",
      "2945/67600 (epoch 2), train_loss = 1.293, time/batch=0.073\n",
      "2946/67600 (epoch 2), train_loss = 1.337, time/batch=0.069\n",
      "2947/67600 (epoch 2), train_loss = 1.342, time/batch=0.068\n",
      "2948/67600 (epoch 2), train_loss = 1.287, time/batch=0.208\n",
      "2949/67600 (epoch 2), train_loss = 1.346, time/batch=0.084\n",
      "2950/67600 (epoch 2), train_loss = 1.327, time/batch=0.069\n",
      "2951/67600 (epoch 2), train_loss = 1.333, time/batch=0.069\n",
      "2952/67600 (epoch 2), train_loss = 1.358, time/batch=0.068\n",
      "2953/67600 (epoch 2), train_loss = 1.298, time/batch=0.071\n",
      "2954/67600 (epoch 2), train_loss = 1.305, time/batch=0.089\n",
      "2955/67600 (epoch 2), train_loss = 1.390, time/batch=0.078\n",
      "2956/67600 (epoch 2), train_loss = 1.329, time/batch=0.182\n",
      "2957/67600 (epoch 2), train_loss = 1.330, time/batch=0.072\n",
      "2958/67600 (epoch 2), train_loss = 1.354, time/batch=0.102\n",
      "2959/67600 (epoch 2), train_loss = 1.392, time/batch=0.070\n",
      "2960/67600 (epoch 2), train_loss = 1.361, time/batch=0.072\n",
      "2961/67600 (epoch 2), train_loss = 1.370, time/batch=0.094\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2962/67600 (epoch 2), train_loss = 1.286, time/batch=0.073\n",
      "2963/67600 (epoch 2), train_loss = 1.292, time/batch=0.070\n",
      "2964/67600 (epoch 2), train_loss = 1.297, time/batch=0.073\n",
      "2965/67600 (epoch 2), train_loss = 1.318, time/batch=0.078\n",
      "2966/67600 (epoch 2), train_loss = 1.321, time/batch=0.072\n",
      "2967/67600 (epoch 2), train_loss = 1.356, time/batch=0.075\n",
      "2968/67600 (epoch 2), train_loss = 1.313, time/batch=0.176\n",
      "2969/67600 (epoch 2), train_loss = 1.303, time/batch=0.103\n",
      "2970/67600 (epoch 2), train_loss = 1.297, time/batch=0.076\n",
      "2971/67600 (epoch 2), train_loss = 1.341, time/batch=0.071\n",
      "2972/67600 (epoch 2), train_loss = 1.287, time/batch=0.075\n",
      "2973/67600 (epoch 2), train_loss = 1.310, time/batch=0.075\n",
      "2974/67600 (epoch 2), train_loss = 1.375, time/batch=0.076\n",
      "2975/67600 (epoch 2), train_loss = 1.316, time/batch=0.070\n",
      "2976/67600 (epoch 2), train_loss = 1.363, time/batch=0.069\n",
      "2977/67600 (epoch 2), train_loss = 1.388, time/batch=0.070\n",
      "2978/67600 (epoch 2), train_loss = 1.341, time/batch=0.072\n",
      "2979/67600 (epoch 2), train_loss = 1.344, time/batch=0.119\n",
      "2980/67600 (epoch 2), train_loss = 1.357, time/batch=0.141\n",
      "2981/67600 (epoch 2), train_loss = 1.306, time/batch=0.112\n",
      "2982/67600 (epoch 2), train_loss = 1.295, time/batch=0.072\n",
      "2983/67600 (epoch 2), train_loss = 1.370, time/batch=0.073\n",
      "2984/67600 (epoch 2), train_loss = 1.398, time/batch=0.072\n",
      "2985/67600 (epoch 2), train_loss = 1.321, time/batch=0.070\n",
      "2986/67600 (epoch 2), train_loss = 1.274, time/batch=0.074\n",
      "2987/67600 (epoch 2), train_loss = 1.366, time/batch=0.077\n",
      "2988/67600 (epoch 2), train_loss = 1.325, time/batch=0.074\n",
      "2989/67600 (epoch 2), train_loss = 1.426, time/batch=0.070\n",
      "2990/67600 (epoch 2), train_loss = 1.357, time/batch=0.070\n",
      "2991/67600 (epoch 2), train_loss = 1.345, time/batch=0.179\n",
      "2992/67600 (epoch 2), train_loss = 1.380, time/batch=0.075\n",
      "2993/67600 (epoch 2), train_loss = 1.389, time/batch=0.101\n",
      "2994/67600 (epoch 2), train_loss = 1.364, time/batch=0.073\n",
      "2995/67600 (epoch 2), train_loss = 1.340, time/batch=0.070\n",
      "2996/67600 (epoch 2), train_loss = 1.349, time/batch=0.074\n",
      "2997/67600 (epoch 2), train_loss = 1.351, time/batch=0.069\n",
      "2998/67600 (epoch 2), train_loss = 1.350, time/batch=0.069\n",
      "2999/67600 (epoch 2), train_loss = 1.377, time/batch=0.074\n",
      "3000/67600 (epoch 2), train_loss = 1.362, time/batch=0.073\n",
      "model saved to ./save/model.ckpt\n",
      "3001/67600 (epoch 2), train_loss = 1.307, time/batch=0.108\n",
      "3002/67600 (epoch 2), train_loss = 1.336, time/batch=0.071\n",
      "3003/67600 (epoch 2), train_loss = 1.373, time/batch=0.071\n",
      "3004/67600 (epoch 2), train_loss = 1.345, time/batch=0.075\n",
      "3005/67600 (epoch 2), train_loss = 1.362, time/batch=0.073\n",
      "3006/67600 (epoch 2), train_loss = 1.330, time/batch=0.072\n",
      "3007/67600 (epoch 2), train_loss = 1.350, time/batch=0.070\n",
      "3008/67600 (epoch 2), train_loss = 1.370, time/batch=0.072\n",
      "3009/67600 (epoch 2), train_loss = 1.380, time/batch=0.075\n",
      "3010/67600 (epoch 2), train_loss = 1.387, time/batch=0.070\n",
      "3011/67600 (epoch 2), train_loss = 1.370, time/batch=0.189\n",
      "3012/67600 (epoch 2), train_loss = 1.394, time/batch=0.077\n",
      "3013/67600 (epoch 2), train_loss = 1.375, time/batch=0.096\n",
      "3014/67600 (epoch 2), train_loss = 1.346, time/batch=0.074\n",
      "3015/67600 (epoch 2), train_loss = 1.315, time/batch=0.070\n",
      "3016/67600 (epoch 2), train_loss = 1.310, time/batch=0.072\n",
      "3017/67600 (epoch 2), train_loss = 1.353, time/batch=0.072\n",
      "3018/67600 (epoch 2), train_loss = 1.333, time/batch=0.076\n",
      "3019/67600 (epoch 2), train_loss = 1.424, time/batch=0.070\n",
      "3020/67600 (epoch 2), train_loss = 1.332, time/batch=0.073\n",
      "3021/67600 (epoch 2), train_loss = 1.353, time/batch=0.069\n",
      "3022/67600 (epoch 2), train_loss = 1.363, time/batch=0.074\n",
      "3023/67600 (epoch 2), train_loss = 1.369, time/batch=0.189\n",
      "3024/67600 (epoch 2), train_loss = 1.411, time/batch=0.105\n",
      "3025/67600 (epoch 2), train_loss = 1.330, time/batch=0.070\n",
      "3026/67600 (epoch 2), train_loss = 1.336, time/batch=0.072\n",
      "3027/67600 (epoch 2), train_loss = 1.316, time/batch=0.077\n",
      "3028/67600 (epoch 2), train_loss = 1.354, time/batch=0.072\n",
      "3029/67600 (epoch 2), train_loss = 1.324, time/batch=0.073\n",
      "3030/67600 (epoch 2), train_loss = 1.307, time/batch=0.073\n",
      "3031/67600 (epoch 2), train_loss = 1.355, time/batch=0.069\n",
      "3032/67600 (epoch 2), train_loss = 1.318, time/batch=0.071\n",
      "3033/67600 (epoch 2), train_loss = 1.350, time/batch=0.069\n",
      "3034/67600 (epoch 2), train_loss = 1.377, time/batch=0.148\n",
      "3035/67600 (epoch 2), train_loss = 1.281, time/batch=0.127\n",
      "3036/67600 (epoch 2), train_loss = 1.351, time/batch=0.095\n",
      "3037/67600 (epoch 2), train_loss = 1.315, time/batch=0.073\n",
      "3038/67600 (epoch 2), train_loss = 1.335, time/batch=0.069\n",
      "3039/67600 (epoch 2), train_loss = 1.380, time/batch=0.072\n",
      "3040/67600 (epoch 2), train_loss = 1.337, time/batch=0.070\n",
      "3041/67600 (epoch 2), train_loss = 1.322, time/batch=0.070\n",
      "3042/67600 (epoch 2), train_loss = 1.352, time/batch=0.070\n",
      "3043/67600 (epoch 2), train_loss = 1.367, time/batch=0.073\n",
      "3044/67600 (epoch 2), train_loss = 1.321, time/batch=0.068\n",
      "3045/67600 (epoch 2), train_loss = 1.345, time/batch=0.073\n",
      "3046/67600 (epoch 2), train_loss = 1.300, time/batch=0.176\n",
      "3047/67600 (epoch 2), train_loss = 1.303, time/batch=0.113\n",
      "3048/67600 (epoch 2), train_loss = 1.394, time/batch=0.084\n",
      "3049/67600 (epoch 2), train_loss = 1.402, time/batch=0.074\n",
      "3050/67600 (epoch 2), train_loss = 1.331, time/batch=0.073\n",
      "3051/67600 (epoch 2), train_loss = 1.339, time/batch=0.071\n",
      "3052/67600 (epoch 2), train_loss = 1.392, time/batch=0.072\n",
      "3053/67600 (epoch 2), train_loss = 1.388, time/batch=0.074\n",
      "3054/67600 (epoch 2), train_loss = 1.309, time/batch=0.101\n",
      "3055/67600 (epoch 2), train_loss = 1.277, time/batch=0.151\n",
      "3056/67600 (epoch 2), train_loss = 1.267, time/batch=0.099\n",
      "3057/67600 (epoch 2), train_loss = 1.319, time/batch=0.074\n",
      "3058/67600 (epoch 2), train_loss = 1.310, time/batch=0.074\n",
      "3059/67600 (epoch 2), train_loss = 1.392, time/batch=0.094\n",
      "3060/67600 (epoch 2), train_loss = 1.306, time/batch=0.069\n",
      "3061/67600 (epoch 2), train_loss = 1.320, time/batch=0.074\n",
      "3062/67600 (epoch 2), train_loss = 1.284, time/batch=0.069\n",
      "3063/67600 (epoch 2), train_loss = 1.438, time/batch=0.070\n",
      "3064/67600 (epoch 2), train_loss = 1.348, time/batch=0.075\n",
      "3065/67600 (epoch 2), train_loss = 1.286, time/batch=0.070\n",
      "3066/67600 (epoch 2), train_loss = 1.303, time/batch=0.116\n",
      "3067/67600 (epoch 2), train_loss = 1.395, time/batch=0.072\n",
      "3068/67600 (epoch 2), train_loss = 1.337, time/batch=0.069\n",
      "3069/67600 (epoch 2), train_loss = 1.323, time/batch=0.066\n",
      "3070/67600 (epoch 2), train_loss = 1.332, time/batch=0.074\n",
      "3071/67600 (epoch 2), train_loss = 1.290, time/batch=0.063\n",
      "3072/67600 (epoch 2), train_loss = 1.323, time/batch=0.062\n",
      "3073/67600 (epoch 2), train_loss = 1.399, time/batch=0.063\n",
      "3074/67600 (epoch 2), train_loss = 1.322, time/batch=0.066\n",
      "3075/67600 (epoch 2), train_loss = 1.348, time/batch=0.069\n",
      "3076/67600 (epoch 2), train_loss = 1.361, time/batch=0.067\n",
      "3077/67600 (epoch 2), train_loss = 1.333, time/batch=0.245\n",
      "3078/67600 (epoch 2), train_loss = 1.404, time/batch=0.067\n",
      "3079/67600 (epoch 2), train_loss = 1.422, time/batch=0.083\n",
      "3080/67600 (epoch 2), train_loss = 1.356, time/batch=0.073\n",
      "3081/67600 (epoch 2), train_loss = 1.340, time/batch=0.065\n",
      "3082/67600 (epoch 2), train_loss = 1.392, time/batch=0.066\n",
      "3083/67600 (epoch 2), train_loss = 1.423, time/batch=0.065\n",
      "3084/67600 (epoch 2), train_loss = 1.366, time/batch=0.066\n",
      "3085/67600 (epoch 2), train_loss = 1.335, time/batch=0.065\n",
      "3086/67600 (epoch 2), train_loss = 1.344, time/batch=0.066\n",
      "3087/67600 (epoch 2), train_loss = 1.373, time/batch=0.066\n",
      "3088/67600 (epoch 2), train_loss = 1.443, time/batch=0.069\n",
      "3089/67600 (epoch 2), train_loss = 1.345, time/batch=0.066\n",
      "3090/67600 (epoch 2), train_loss = 1.329, time/batch=0.192\n",
      "3091/67600 (epoch 2), train_loss = 1.328, time/batch=0.065\n",
      "3092/67600 (epoch 2), train_loss = 1.364, time/batch=0.075\n",
      "3093/67600 (epoch 2), train_loss = 1.347, time/batch=0.065\n",
      "3094/67600 (epoch 2), train_loss = 1.330, time/batch=0.068\n",
      "3095/67600 (epoch 2), train_loss = 1.322, time/batch=0.069\n",
      "3096/67600 (epoch 2), train_loss = 1.322, time/batch=0.066\n",
      "3097/67600 (epoch 2), train_loss = 1.361, time/batch=0.066\n",
      "3098/67600 (epoch 2), train_loss = 1.335, time/batch=0.065\n",
      "3099/67600 (epoch 2), train_loss = 1.323, time/batch=0.069\n",
      "3100/67600 (epoch 2), train_loss = 1.388, time/batch=0.067\n",
      "3101/67600 (epoch 2), train_loss = 1.399, time/batch=0.065\n",
      "3102/67600 (epoch 2), train_loss = 1.333, time/batch=0.067\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3103/67600 (epoch 2), train_loss = 1.329, time/batch=0.196\n",
      "3104/67600 (epoch 2), train_loss = 1.377, time/batch=0.071\n",
      "3105/67600 (epoch 2), train_loss = 1.417, time/batch=0.068\n",
      "3106/67600 (epoch 2), train_loss = 1.415, time/batch=0.064\n",
      "3107/67600 (epoch 2), train_loss = 1.364, time/batch=0.064\n",
      "3108/67600 (epoch 2), train_loss = 1.446, time/batch=0.076\n",
      "3109/67600 (epoch 2), train_loss = 1.386, time/batch=0.066\n",
      "3110/67600 (epoch 2), train_loss = 1.414, time/batch=0.069\n",
      "3111/67600 (epoch 2), train_loss = 1.336, time/batch=0.067\n",
      "3112/67600 (epoch 2), train_loss = 1.378, time/batch=0.200\n",
      "3113/67600 (epoch 2), train_loss = 1.375, time/batch=0.079\n",
      "3114/67600 (epoch 2), train_loss = 1.359, time/batch=0.097\n",
      "3115/67600 (epoch 2), train_loss = 1.329, time/batch=0.066\n",
      "3116/67600 (epoch 2), train_loss = 1.330, time/batch=0.064\n",
      "3117/67600 (epoch 2), train_loss = 1.351, time/batch=0.070\n",
      "3118/67600 (epoch 2), train_loss = 1.339, time/batch=0.066\n",
      "3119/67600 (epoch 2), train_loss = 1.389, time/batch=0.066\n",
      "3120/67600 (epoch 2), train_loss = 1.347, time/batch=0.064\n",
      "3121/67600 (epoch 2), train_loss = 1.387, time/batch=0.066\n",
      "3122/67600 (epoch 2), train_loss = 1.376, time/batch=0.064\n",
      "3123/67600 (epoch 2), train_loss = 1.339, time/batch=0.064\n",
      "3124/67600 (epoch 2), train_loss = 1.286, time/batch=0.066\n",
      "3125/67600 (epoch 2), train_loss = 1.295, time/batch=0.163\n",
      "3126/67600 (epoch 2), train_loss = 1.335, time/batch=0.067\n",
      "3127/67600 (epoch 2), train_loss = 1.303, time/batch=0.103\n",
      "3128/67600 (epoch 2), train_loss = 1.345, time/batch=0.068\n",
      "3129/67600 (epoch 2), train_loss = 1.309, time/batch=0.071\n",
      "3130/67600 (epoch 2), train_loss = 1.344, time/batch=0.068\n",
      "3131/67600 (epoch 2), train_loss = 1.326, time/batch=0.071\n",
      "3132/67600 (epoch 2), train_loss = 1.251, time/batch=0.066\n",
      "3133/67600 (epoch 2), train_loss = 1.318, time/batch=0.067\n",
      "3134/67600 (epoch 2), train_loss = 1.387, time/batch=0.073\n",
      "3135/67600 (epoch 2), train_loss = 1.300, time/batch=0.068\n",
      "3136/67600 (epoch 2), train_loss = 1.356, time/batch=0.064\n",
      "3137/67600 (epoch 2), train_loss = 1.372, time/batch=0.117\n",
      "3138/67600 (epoch 2), train_loss = 1.298, time/batch=0.112\n",
      "3139/67600 (epoch 2), train_loss = 1.407, time/batch=0.066\n",
      "3140/67600 (epoch 2), train_loss = 1.343, time/batch=0.088\n",
      "3141/67600 (epoch 2), train_loss = 1.343, time/batch=0.066\n",
      "3142/67600 (epoch 2), train_loss = 1.348, time/batch=0.062\n",
      "3143/67600 (epoch 2), train_loss = 1.338, time/batch=0.063\n",
      "3144/67600 (epoch 2), train_loss = 1.325, time/batch=0.065\n",
      "3145/67600 (epoch 2), train_loss = 1.362, time/batch=0.066\n",
      "3146/67600 (epoch 2), train_loss = 1.314, time/batch=0.069\n",
      "3147/67600 (epoch 2), train_loss = 1.305, time/batch=0.066\n",
      "3148/67600 (epoch 2), train_loss = 1.326, time/batch=0.065\n",
      "3149/67600 (epoch 2), train_loss = 1.384, time/batch=0.067\n",
      "3150/67600 (epoch 2), train_loss = 1.285, time/batch=0.066\n",
      "3151/67600 (epoch 2), train_loss = 1.305, time/batch=0.186\n",
      "3152/67600 (epoch 2), train_loss = 1.287, time/batch=0.065\n",
      "3153/67600 (epoch 2), train_loss = 1.322, time/batch=0.082\n",
      "3154/67600 (epoch 2), train_loss = 1.257, time/batch=0.066\n",
      "3155/67600 (epoch 2), train_loss = 1.377, time/batch=0.068\n",
      "3156/67600 (epoch 2), train_loss = 1.374, time/batch=0.067\n",
      "3157/67600 (epoch 2), train_loss = 1.273, time/batch=0.064\n",
      "3158/67600 (epoch 2), train_loss = 1.260, time/batch=0.066\n",
      "3159/67600 (epoch 2), train_loss = 1.297, time/batch=0.067\n",
      "3160/67600 (epoch 2), train_loss = 1.320, time/batch=0.066\n",
      "3161/67600 (epoch 2), train_loss = 1.353, time/batch=0.065\n",
      "3162/67600 (epoch 2), train_loss = 1.364, time/batch=0.066\n",
      "3163/67600 (epoch 2), train_loss = 1.344, time/batch=0.068\n",
      "3164/67600 (epoch 2), train_loss = 1.339, time/batch=0.191\n",
      "3165/67600 (epoch 2), train_loss = 1.291, time/batch=0.067\n",
      "3166/67600 (epoch 2), train_loss = 1.373, time/batch=0.072\n",
      "3167/67600 (epoch 2), train_loss = 1.345, time/batch=0.066\n",
      "3168/67600 (epoch 2), train_loss = 1.299, time/batch=0.067\n",
      "3169/67600 (epoch 2), train_loss = 1.308, time/batch=0.069\n",
      "3170/67600 (epoch 2), train_loss = 1.330, time/batch=0.068\n",
      "3171/67600 (epoch 2), train_loss = 1.398, time/batch=0.066\n",
      "3172/67600 (epoch 2), train_loss = 1.333, time/batch=0.068\n",
      "3173/67600 (epoch 2), train_loss = 1.312, time/batch=0.153\n",
      "3174/67600 (epoch 2), train_loss = 1.332, time/batch=0.068\n",
      "3175/67600 (epoch 2), train_loss = 1.319, time/batch=0.105\n",
      "3176/67600 (epoch 2), train_loss = 1.298, time/batch=0.067\n",
      "3177/67600 (epoch 2), train_loss = 1.338, time/batch=0.065\n",
      "3178/67600 (epoch 2), train_loss = 1.307, time/batch=0.065\n",
      "3179/67600 (epoch 2), train_loss = 1.283, time/batch=0.071\n",
      "3180/67600 (epoch 2), train_loss = 1.348, time/batch=0.067\n",
      "3181/67600 (epoch 2), train_loss = 1.300, time/batch=0.066\n",
      "3182/67600 (epoch 2), train_loss = 1.330, time/batch=0.066\n",
      "3183/67600 (epoch 2), train_loss = 1.335, time/batch=0.069\n",
      "3184/67600 (epoch 2), train_loss = 1.272, time/batch=0.066\n",
      "3185/67600 (epoch 2), train_loss = 1.331, time/batch=0.064\n",
      "3186/67600 (epoch 2), train_loss = 1.316, time/batch=0.173\n",
      "3187/67600 (epoch 2), train_loss = 1.286, time/batch=0.066\n",
      "3188/67600 (epoch 2), train_loss = 1.357, time/batch=0.100\n",
      "3189/67600 (epoch 2), train_loss = 1.342, time/batch=0.069\n",
      "3190/67600 (epoch 2), train_loss = 1.364, time/batch=0.064\n",
      "3191/67600 (epoch 2), train_loss = 1.334, time/batch=0.064\n",
      "3192/67600 (epoch 2), train_loss = 1.406, time/batch=0.063\n",
      "3193/67600 (epoch 2), train_loss = 1.361, time/batch=0.064\n",
      "3194/67600 (epoch 2), train_loss = 1.279, time/batch=0.065\n",
      "3195/67600 (epoch 2), train_loss = 1.326, time/batch=0.066\n",
      "3196/67600 (epoch 2), train_loss = 1.360, time/batch=0.065\n",
      "3197/67600 (epoch 2), train_loss = 1.317, time/batch=0.076\n",
      "3198/67600 (epoch 2), train_loss = 1.378, time/batch=0.074\n",
      "3199/67600 (epoch 2), train_loss = 1.348, time/batch=0.180\n",
      "3200/67600 (epoch 2), train_loss = 1.311, time/batch=0.065\n",
      "3201/67600 (epoch 2), train_loss = 1.335, time/batch=0.095\n",
      "3202/67600 (epoch 2), train_loss = 1.377, time/batch=0.066\n",
      "3203/67600 (epoch 2), train_loss = 1.323, time/batch=0.066\n",
      "3204/67600 (epoch 2), train_loss = 1.269, time/batch=0.064\n",
      "3205/67600 (epoch 2), train_loss = 1.266, time/batch=0.062\n",
      "3206/67600 (epoch 2), train_loss = 1.316, time/batch=0.063\n",
      "3207/67600 (epoch 2), train_loss = 1.350, time/batch=0.062\n",
      "3208/67600 (epoch 2), train_loss = 1.347, time/batch=0.063\n",
      "3209/67600 (epoch 2), train_loss = 1.386, time/batch=0.063\n",
      "3210/67600 (epoch 2), train_loss = 1.346, time/batch=0.067\n",
      "3211/67600 (epoch 2), train_loss = 1.347, time/batch=0.070\n",
      "3212/67600 (epoch 2), train_loss = 1.274, time/batch=0.112\n",
      "3213/67600 (epoch 2), train_loss = 1.306, time/batch=0.141\n",
      "3214/67600 (epoch 2), train_loss = 1.374, time/batch=0.081\n",
      "3215/67600 (epoch 2), train_loss = 1.329, time/batch=0.063\n",
      "3216/67600 (epoch 2), train_loss = 1.343, time/batch=0.070\n",
      "3217/67600 (epoch 2), train_loss = 1.302, time/batch=0.070\n",
      "3218/67600 (epoch 2), train_loss = 1.341, time/batch=0.065\n",
      "3219/67600 (epoch 2), train_loss = 1.378, time/batch=0.064\n",
      "3220/67600 (epoch 2), train_loss = 1.374, time/batch=0.065\n",
      "3221/67600 (epoch 2), train_loss = 1.358, time/batch=0.065\n",
      "3222/67600 (epoch 2), train_loss = 1.340, time/batch=0.063\n",
      "3223/67600 (epoch 2), train_loss = 1.263, time/batch=0.064\n",
      "3224/67600 (epoch 2), train_loss = 1.368, time/batch=0.067\n",
      "3225/67600 (epoch 2), train_loss = 1.372, time/batch=0.106\n",
      "3226/67600 (epoch 2), train_loss = 1.389, time/batch=0.147\n",
      "3227/67600 (epoch 2), train_loss = 1.332, time/batch=0.077\n",
      "3228/67600 (epoch 2), train_loss = 1.342, time/batch=0.064\n",
      "3229/67600 (epoch 2), train_loss = 1.334, time/batch=0.073\n",
      "3230/67600 (epoch 2), train_loss = 1.354, time/batch=0.066\n",
      "3231/67600 (epoch 2), train_loss = 1.309, time/batch=0.069\n",
      "3232/67600 (epoch 2), train_loss = 1.369, time/batch=0.065\n",
      "3233/67600 (epoch 2), train_loss = 1.320, time/batch=0.066\n",
      "3234/67600 (epoch 2), train_loss = 1.370, time/batch=0.078\n",
      "3235/67600 (epoch 2), train_loss = 1.389, time/batch=0.066\n",
      "3236/67600 (epoch 2), train_loss = 1.348, time/batch=0.068\n",
      "3237/67600 (epoch 2), train_loss = 1.313, time/batch=0.067\n",
      "3238/67600 (epoch 2), train_loss = 1.308, time/batch=0.181\n",
      "3239/67600 (epoch 2), train_loss = 1.288, time/batch=0.088\n",
      "3240/67600 (epoch 2), train_loss = 1.313, time/batch=0.072\n",
      "3241/67600 (epoch 2), train_loss = 1.345, time/batch=0.068\n",
      "3242/67600 (epoch 2), train_loss = 1.332, time/batch=0.065\n",
      "3243/67600 (epoch 2), train_loss = 1.345, time/batch=0.081\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3244/67600 (epoch 2), train_loss = 1.339, time/batch=0.073\n",
      "3245/67600 (epoch 2), train_loss = 1.266, time/batch=0.063\n",
      "3246/67600 (epoch 2), train_loss = 1.321, time/batch=0.063\n",
      "3247/67600 (epoch 2), train_loss = 1.285, time/batch=0.108\n",
      "3248/67600 (epoch 2), train_loss = 1.362, time/batch=0.067\n",
      "3249/67600 (epoch 2), train_loss = 1.328, time/batch=0.068\n",
      "3250/67600 (epoch 2), train_loss = 1.308, time/batch=0.067\n",
      "3251/67600 (epoch 2), train_loss = 1.332, time/batch=0.074\n",
      "3252/67600 (epoch 2), train_loss = 1.459, time/batch=0.066\n",
      "3253/67600 (epoch 2), train_loss = 1.351, time/batch=0.064\n",
      "3254/67600 (epoch 2), train_loss = 1.314, time/batch=0.064\n",
      "3255/67600 (epoch 2), train_loss = 1.376, time/batch=0.064\n",
      "3256/67600 (epoch 2), train_loss = 1.301, time/batch=0.066\n",
      "3257/67600 (epoch 2), train_loss = 1.326, time/batch=0.067\n",
      "3258/67600 (epoch 2), train_loss = 1.374, time/batch=0.201\n",
      "3259/67600 (epoch 2), train_loss = 1.311, time/batch=0.081\n",
      "3260/67600 (epoch 2), train_loss = 1.369, time/batch=0.083\n",
      "3261/67600 (epoch 2), train_loss = 1.318, time/batch=0.067\n",
      "3262/67600 (epoch 2), train_loss = 1.289, time/batch=0.068\n",
      "3263/67600 (epoch 2), train_loss = 1.275, time/batch=0.065\n",
      "3264/67600 (epoch 2), train_loss = 1.287, time/batch=0.067\n",
      "3265/67600 (epoch 2), train_loss = 1.315, time/batch=0.069\n",
      "3266/67600 (epoch 2), train_loss = 1.287, time/batch=0.067\n",
      "3267/67600 (epoch 2), train_loss = 1.325, time/batch=0.065\n",
      "3268/67600 (epoch 2), train_loss = 1.292, time/batch=0.065\n",
      "3269/67600 (epoch 2), train_loss = 1.312, time/batch=0.066\n",
      "3270/67600 (epoch 2), train_loss = 1.349, time/batch=0.076\n",
      "3271/67600 (epoch 2), train_loss = 1.371, time/batch=0.192\n",
      "3272/67600 (epoch 2), train_loss = 1.352, time/batch=0.071\n",
      "3273/67600 (epoch 2), train_loss = 1.313, time/batch=0.075\n",
      "3274/67600 (epoch 2), train_loss = 1.299, time/batch=0.067\n",
      "3275/67600 (epoch 2), train_loss = 1.281, time/batch=0.070\n",
      "3276/67600 (epoch 2), train_loss = 1.325, time/batch=0.067\n",
      "3277/67600 (epoch 2), train_loss = 1.325, time/batch=0.065\n",
      "3278/67600 (epoch 2), train_loss = 1.330, time/batch=0.066\n",
      "3279/67600 (epoch 2), train_loss = 1.311, time/batch=0.068\n",
      "3280/67600 (epoch 2), train_loss = 1.358, time/batch=0.066\n",
      "3281/67600 (epoch 2), train_loss = 1.340, time/batch=0.067\n",
      "3282/67600 (epoch 2), train_loss = 1.369, time/batch=0.069\n",
      "3283/67600 (epoch 2), train_loss = 1.323, time/batch=0.065\n",
      "3284/67600 (epoch 2), train_loss = 1.339, time/batch=0.190\n",
      "3285/67600 (epoch 2), train_loss = 1.340, time/batch=0.074\n",
      "3286/67600 (epoch 2), train_loss = 1.295, time/batch=0.071\n",
      "3287/67600 (epoch 2), train_loss = 1.295, time/batch=0.068\n",
      "3288/67600 (epoch 2), train_loss = 1.327, time/batch=0.066\n",
      "3289/67600 (epoch 2), train_loss = 1.385, time/batch=0.066\n",
      "3290/67600 (epoch 2), train_loss = 1.295, time/batch=0.065\n",
      "3291/67600 (epoch 2), train_loss = 1.384, time/batch=0.065\n",
      "3292/67600 (epoch 2), train_loss = 1.296, time/batch=0.065\n",
      "3293/67600 (epoch 2), train_loss = 1.326, time/batch=0.124\n",
      "3294/67600 (epoch 2), train_loss = 1.392, time/batch=0.106\n",
      "3295/67600 (epoch 2), train_loss = 1.295, time/batch=0.068\n",
      "3296/67600 (epoch 2), train_loss = 1.309, time/batch=0.111\n",
      "3297/67600 (epoch 2), train_loss = 1.328, time/batch=0.080\n",
      "3298/67600 (epoch 2), train_loss = 1.274, time/batch=0.074\n",
      "3299/67600 (epoch 2), train_loss = 1.322, time/batch=0.066\n",
      "3300/67600 (epoch 2), train_loss = 1.330, time/batch=0.066\n",
      "3301/67600 (epoch 2), train_loss = 1.308, time/batch=0.067\n",
      "3302/67600 (epoch 2), train_loss = 1.301, time/batch=0.066\n",
      "3303/67600 (epoch 2), train_loss = 1.296, time/batch=0.065\n",
      "3304/67600 (epoch 2), train_loss = 1.348, time/batch=0.066\n",
      "3305/67600 (epoch 2), train_loss = 1.277, time/batch=0.065\n",
      "3306/67600 (epoch 2), train_loss = 1.321, time/batch=0.175\n",
      "3307/67600 (epoch 2), train_loss = 1.315, time/batch=0.065\n",
      "3308/67600 (epoch 2), train_loss = 1.364, time/batch=0.094\n",
      "3309/67600 (epoch 2), train_loss = 1.308, time/batch=0.069\n",
      "3310/67600 (epoch 2), train_loss = 1.378, time/batch=0.066\n",
      "3311/67600 (epoch 2), train_loss = 1.292, time/batch=0.065\n",
      "3312/67600 (epoch 2), train_loss = 1.399, time/batch=0.070\n",
      "3313/67600 (epoch 2), train_loss = 1.332, time/batch=0.068\n",
      "3314/67600 (epoch 2), train_loss = 1.320, time/batch=0.079\n",
      "3315/67600 (epoch 2), train_loss = 1.416, time/batch=0.069\n",
      "3316/67600 (epoch 2), train_loss = 1.327, time/batch=0.067\n",
      "3317/67600 (epoch 2), train_loss = 1.311, time/batch=0.072\n",
      "3318/67600 (epoch 2), train_loss = 1.335, time/batch=0.090\n",
      "3319/67600 (epoch 2), train_loss = 1.380, time/batch=0.161\n",
      "3320/67600 (epoch 2), train_loss = 1.353, time/batch=0.077\n",
      "3321/67600 (epoch 2), train_loss = 1.407, time/batch=0.083\n",
      "3322/67600 (epoch 2), train_loss = 1.328, time/batch=0.067\n",
      "3323/67600 (epoch 2), train_loss = 1.288, time/batch=0.066\n",
      "3324/67600 (epoch 2), train_loss = 1.293, time/batch=0.067\n",
      "3325/67600 (epoch 2), train_loss = 1.329, time/batch=0.073\n",
      "3326/67600 (epoch 2), train_loss = 1.353, time/batch=0.075\n",
      "3327/67600 (epoch 2), train_loss = 1.288, time/batch=0.065\n",
      "3328/67600 (epoch 2), train_loss = 1.327, time/batch=0.065\n",
      "3329/67600 (epoch 2), train_loss = 1.319, time/batch=0.065\n",
      "3330/67600 (epoch 2), train_loss = 1.343, time/batch=0.068\n",
      "3331/67600 (epoch 2), train_loss = 1.379, time/batch=0.138\n",
      "3332/67600 (epoch 2), train_loss = 1.358, time/batch=0.110\n",
      "3333/67600 (epoch 2), train_loss = 1.307, time/batch=0.089\n",
      "3334/67600 (epoch 2), train_loss = 1.364, time/batch=0.064\n",
      "3335/67600 (epoch 2), train_loss = 1.397, time/batch=0.067\n",
      "3336/67600 (epoch 2), train_loss = 1.300, time/batch=0.067\n",
      "3337/67600 (epoch 2), train_loss = 1.398, time/batch=0.066\n",
      "3338/67600 (epoch 2), train_loss = 1.389, time/batch=0.066\n",
      "3339/67600 (epoch 2), train_loss = 1.263, time/batch=0.070\n",
      "3340/67600 (epoch 2), train_loss = 1.408, time/batch=0.079\n",
      "3341/67600 (epoch 2), train_loss = 1.303, time/batch=0.064\n",
      "3342/67600 (epoch 2), train_loss = 1.276, time/batch=0.066\n",
      "3343/67600 (epoch 2), train_loss = 1.261, time/batch=0.072\n",
      "3344/67600 (epoch 2), train_loss = 1.333, time/batch=0.188\n",
      "3345/67600 (epoch 2), train_loss = 1.314, time/batch=0.070\n",
      "3346/67600 (epoch 2), train_loss = 1.351, time/batch=0.070\n",
      "3347/67600 (epoch 2), train_loss = 1.403, time/batch=0.065\n",
      "3348/67600 (epoch 2), train_loss = 1.376, time/batch=0.064\n",
      "3349/67600 (epoch 2), train_loss = 1.307, time/batch=0.066\n",
      "3350/67600 (epoch 2), train_loss = 1.345, time/batch=0.068\n",
      "3351/67600 (epoch 2), train_loss = 1.342, time/batch=0.068\n",
      "3352/67600 (epoch 2), train_loss = 1.356, time/batch=0.065\n",
      "3353/67600 (epoch 2), train_loss = 1.330, time/batch=0.117\n",
      "3354/67600 (epoch 2), train_loss = 1.375, time/batch=0.109\n",
      "3355/67600 (epoch 2), train_loss = 1.391, time/batch=0.066\n",
      "3356/67600 (epoch 2), train_loss = 1.316, time/batch=0.097\n",
      "3357/67600 (epoch 2), train_loss = 1.326, time/batch=0.066\n",
      "3358/67600 (epoch 2), train_loss = 1.324, time/batch=0.065\n",
      "3359/67600 (epoch 2), train_loss = 1.317, time/batch=0.073\n",
      "3360/67600 (epoch 2), train_loss = 1.326, time/batch=0.065\n",
      "3361/67600 (epoch 2), train_loss = 1.379, time/batch=0.071\n",
      "3362/67600 (epoch 2), train_loss = 1.354, time/batch=0.064\n",
      "3363/67600 (epoch 2), train_loss = 1.282, time/batch=0.068\n",
      "3364/67600 (epoch 2), train_loss = 1.331, time/batch=0.067\n",
      "3365/67600 (epoch 2), train_loss = 1.322, time/batch=0.071\n",
      "3366/67600 (epoch 2), train_loss = 1.254, time/batch=0.124\n",
      "3367/67600 (epoch 2), train_loss = 1.264, time/batch=0.106\n",
      "3368/67600 (epoch 2), train_loss = 1.359, time/batch=0.065\n",
      "3369/67600 (epoch 2), train_loss = 1.336, time/batch=0.101\n",
      "3370/67600 (epoch 2), train_loss = 1.363, time/batch=0.067\n",
      "3371/67600 (epoch 2), train_loss = 1.326, time/batch=0.065\n",
      "3372/67600 (epoch 2), train_loss = 1.382, time/batch=0.066\n",
      "3373/67600 (epoch 2), train_loss = 1.271, time/batch=0.069\n",
      "3374/67600 (epoch 2), train_loss = 1.242, time/batch=0.064\n",
      "3375/67600 (epoch 2), train_loss = 1.324, time/batch=0.065\n",
      "3376/67600 (epoch 2), train_loss = 1.232, time/batch=0.066\n",
      "3377/67600 (epoch 2), train_loss = 1.389, time/batch=0.067\n",
      "3378/67600 (epoch 2), train_loss = 1.372, time/batch=0.064\n",
      "3379/67600 (epoch 2), train_loss = 1.292, time/batch=0.072\n",
      "3380/67600 (epoch 2), train_loss = 1.332, time/batch=0.166\n",
      "3381/67600 (epoch 2), train_loss = 1.373, time/batch=0.065\n",
      "3382/67600 (epoch 2), train_loss = 1.366, time/batch=0.092\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3383/67600 (epoch 2), train_loss = 1.316, time/batch=0.067\n",
      "3384/67600 (epoch 2), train_loss = 1.326, time/batch=0.070\n",
      "3385/67600 (epoch 2), train_loss = 1.358, time/batch=0.071\n",
      "3386/67600 (epoch 2), train_loss = 1.347, time/batch=0.064\n",
      "3387/67600 (epoch 2), train_loss = 1.308, time/batch=0.068\n",
      "3388/67600 (epoch 2), train_loss = 1.293, time/batch=0.064\n",
      "3389/67600 (epoch 2), train_loss = 1.371, time/batch=0.066\n",
      "3390/67600 (epoch 2), train_loss = 1.340, time/batch=0.070\n",
      "3391/67600 (epoch 2), train_loss = 1.297, time/batch=0.064\n",
      "3392/67600 (epoch 2), train_loss = 1.322, time/batch=0.096\n",
      "3393/67600 (epoch 2), train_loss = 1.296, time/batch=0.163\n",
      "3394/67600 (epoch 2), train_loss = 1.325, time/batch=0.088\n",
      "3395/67600 (epoch 2), train_loss = 1.321, time/batch=0.065\n",
      "3396/67600 (epoch 2), train_loss = 1.305, time/batch=0.070\n",
      "3397/67600 (epoch 2), train_loss = 1.359, time/batch=0.066\n",
      "3398/67600 (epoch 2), train_loss = 1.325, time/batch=0.070\n",
      "3399/67600 (epoch 2), train_loss = 1.268, time/batch=0.065\n",
      "3400/67600 (epoch 2), train_loss = 1.349, time/batch=0.071\n",
      "3401/67600 (epoch 2), train_loss = 1.373, time/batch=0.067\n",
      "3402/67600 (epoch 2), train_loss = 1.342, time/batch=0.067\n",
      "3403/67600 (epoch 2), train_loss = 1.294, time/batch=0.066\n",
      "3404/67600 (epoch 2), train_loss = 1.335, time/batch=0.064\n",
      "3405/67600 (epoch 2), train_loss = 1.363, time/batch=0.118\n",
      "3406/67600 (epoch 2), train_loss = 1.335, time/batch=0.140\n",
      "3407/67600 (epoch 2), train_loss = 1.282, time/batch=0.080\n",
      "3408/67600 (epoch 2), train_loss = 1.325, time/batch=0.066\n",
      "3409/67600 (epoch 2), train_loss = 1.311, time/batch=0.076\n",
      "3410/67600 (epoch 2), train_loss = 1.310, time/batch=0.067\n",
      "3411/67600 (epoch 2), train_loss = 1.357, time/batch=0.065\n",
      "3412/67600 (epoch 2), train_loss = 1.344, time/batch=0.070\n",
      "3413/67600 (epoch 2), train_loss = 1.294, time/batch=0.066\n",
      "3414/67600 (epoch 2), train_loss = 1.324, time/batch=0.070\n",
      "3415/67600 (epoch 2), train_loss = 1.243, time/batch=0.065\n",
      "3416/67600 (epoch 2), train_loss = 1.322, time/batch=0.067\n",
      "3417/67600 (epoch 2), train_loss = 1.342, time/batch=0.064\n",
      "3418/67600 (epoch 2), train_loss = 1.323, time/batch=0.124\n",
      "3419/67600 (epoch 2), train_loss = 1.320, time/batch=0.155\n",
      "3420/67600 (epoch 2), train_loss = 1.273, time/batch=0.100\n",
      "3421/67600 (epoch 2), train_loss = 1.326, time/batch=0.091\n",
      "3422/67600 (epoch 2), train_loss = 1.281, time/batch=0.119\n",
      "3423/67600 (epoch 2), train_loss = 1.303, time/batch=0.092\n",
      "3424/67600 (epoch 2), train_loss = 1.303, time/batch=0.149\n",
      "3425/67600 (epoch 2), train_loss = 1.362, time/batch=0.108\n",
      "3426/67600 (epoch 2), train_loss = 1.329, time/batch=0.081\n",
      "3427/67600 (epoch 2), train_loss = 1.329, time/batch=0.087\n",
      "3428/67600 (epoch 2), train_loss = 1.305, time/batch=0.065\n",
      "3429/67600 (epoch 2), train_loss = 1.346, time/batch=0.067\n",
      "3430/67600 (epoch 2), train_loss = 1.325, time/batch=0.066\n",
      "3431/67600 (epoch 2), train_loss = 1.347, time/batch=0.069\n",
      "3432/67600 (epoch 2), train_loss = 1.340, time/batch=0.067\n",
      "3433/67600 (epoch 2), train_loss = 1.298, time/batch=0.065\n",
      "3434/67600 (epoch 2), train_loss = 1.305, time/batch=0.173\n",
      "3435/67600 (epoch 2), train_loss = 1.353, time/batch=0.110\n",
      "3436/67600 (epoch 2), train_loss = 1.325, time/batch=0.090\n",
      "3437/67600 (epoch 2), train_loss = 1.309, time/batch=0.067\n",
      "3438/67600 (epoch 2), train_loss = 1.330, time/batch=0.065\n",
      "3439/67600 (epoch 2), train_loss = 1.277, time/batch=0.066\n",
      "3440/67600 (epoch 2), train_loss = 1.378, time/batch=0.068\n",
      "3441/67600 (epoch 2), train_loss = 1.305, time/batch=0.067\n",
      "3442/67600 (epoch 2), train_loss = 1.270, time/batch=0.066\n",
      "3443/67600 (epoch 2), train_loss = 1.348, time/batch=0.071\n",
      "3444/67600 (epoch 2), train_loss = 1.239, time/batch=0.069\n",
      "3445/67600 (epoch 2), train_loss = 1.282, time/batch=0.065\n",
      "3446/67600 (epoch 2), train_loss = 1.251, time/batch=0.067\n",
      "3447/67600 (epoch 2), train_loss = 1.313, time/batch=0.142\n",
      "3448/67600 (epoch 2), train_loss = 1.325, time/batch=0.118\n",
      "3449/67600 (epoch 2), train_loss = 1.341, time/batch=0.080\n",
      "3450/67600 (epoch 2), train_loss = 1.305, time/batch=0.073\n",
      "3451/67600 (epoch 2), train_loss = 1.326, time/batch=0.070\n",
      "3452/67600 (epoch 2), train_loss = 1.343, time/batch=0.066\n",
      "3453/67600 (epoch 2), train_loss = 1.306, time/batch=0.067\n",
      "3454/67600 (epoch 2), train_loss = 1.291, time/batch=0.066\n",
      "3455/67600 (epoch 2), train_loss = 1.276, time/batch=0.066\n",
      "3456/67600 (epoch 2), train_loss = 1.304, time/batch=0.065\n",
      "3457/67600 (epoch 2), train_loss = 1.364, time/batch=0.067\n",
      "3458/67600 (epoch 2), train_loss = 1.298, time/batch=0.068\n",
      "3459/67600 (epoch 2), train_loss = 1.311, time/batch=0.065\n",
      "3460/67600 (epoch 2), train_loss = 1.390, time/batch=0.181\n",
      "3461/67600 (epoch 2), train_loss = 1.328, time/batch=0.081\n",
      "3462/67600 (epoch 2), train_loss = 1.298, time/batch=0.071\n",
      "3463/67600 (epoch 2), train_loss = 1.271, time/batch=0.068\n",
      "3464/67600 (epoch 2), train_loss = 1.309, time/batch=0.068\n",
      "3465/67600 (epoch 2), train_loss = 1.306, time/batch=0.067\n",
      "3466/67600 (epoch 2), train_loss = 1.300, time/batch=0.066\n",
      "3467/67600 (epoch 2), train_loss = 1.381, time/batch=0.071\n",
      "3468/67600 (epoch 2), train_loss = 1.379, time/batch=0.066\n",
      "3469/67600 (epoch 2), train_loss = 1.287, time/batch=0.117\n",
      "3470/67600 (epoch 2), train_loss = 1.344, time/batch=0.113\n",
      "3471/67600 (epoch 2), train_loss = 1.323, time/batch=0.075\n",
      "3472/67600 (epoch 2), train_loss = 1.322, time/batch=0.088\n",
      "3473/67600 (epoch 2), train_loss = 1.354, time/batch=0.065\n",
      "3474/67600 (epoch 2), train_loss = 1.314, time/batch=0.066\n",
      "3475/67600 (epoch 2), train_loss = 1.377, time/batch=0.073\n",
      "3476/67600 (epoch 2), train_loss = 1.348, time/batch=0.066\n",
      "3477/67600 (epoch 2), train_loss = 1.312, time/batch=0.073\n",
      "3478/67600 (epoch 2), train_loss = 1.368, time/batch=0.070\n",
      "3479/67600 (epoch 2), train_loss = 1.400, time/batch=0.064\n",
      "3480/67600 (epoch 2), train_loss = 1.356, time/batch=0.064\n",
      "3481/67600 (epoch 2), train_loss = 1.333, time/batch=0.064\n",
      "3482/67600 (epoch 2), train_loss = 1.328, time/batch=0.129\n",
      "3483/67600 (epoch 2), train_loss = 1.372, time/batch=0.105\n",
      "3484/67600 (epoch 2), train_loss = 1.383, time/batch=0.096\n",
      "3485/67600 (epoch 2), train_loss = 1.346, time/batch=0.074\n",
      "3486/67600 (epoch 2), train_loss = 1.302, time/batch=0.064\n",
      "3487/67600 (epoch 2), train_loss = 1.339, time/batch=0.067\n",
      "3488/67600 (epoch 2), train_loss = 1.314, time/batch=0.067\n",
      "3489/67600 (epoch 2), train_loss = 1.352, time/batch=0.072\n",
      "3490/67600 (epoch 2), train_loss = 1.344, time/batch=0.066\n",
      "3491/67600 (epoch 2), train_loss = 1.329, time/batch=0.068\n",
      "3492/67600 (epoch 2), train_loss = 1.341, time/batch=0.067\n",
      "3493/67600 (epoch 2), train_loss = 1.290, time/batch=0.067\n",
      "3494/67600 (epoch 2), train_loss = 1.316, time/batch=0.067\n",
      "3495/67600 (epoch 2), train_loss = 1.316, time/batch=0.149\n",
      "3496/67600 (epoch 2), train_loss = 1.301, time/batch=0.085\n",
      "3497/67600 (epoch 2), train_loss = 1.351, time/batch=0.087\n",
      "3498/67600 (epoch 2), train_loss = 1.312, time/batch=0.073\n",
      "3499/67600 (epoch 2), train_loss = 1.330, time/batch=0.064\n",
      "3500/67600 (epoch 2), train_loss = 1.382, time/batch=0.068\n",
      "model saved to ./save/model.ckpt\n",
      "3501/67600 (epoch 2), train_loss = 1.350, time/batch=0.066\n",
      "3502/67600 (epoch 2), train_loss = 1.359, time/batch=0.155\n",
      "3503/67600 (epoch 2), train_loss = 1.334, time/batch=0.067\n",
      "3504/67600 (epoch 2), train_loss = 1.324, time/batch=0.096\n",
      "3505/67600 (epoch 2), train_loss = 1.343, time/batch=0.066\n",
      "3506/67600 (epoch 2), train_loss = 1.322, time/batch=0.064\n",
      "3507/67600 (epoch 2), train_loss = 1.338, time/batch=0.065\n",
      "3508/67600 (epoch 2), train_loss = 1.302, time/batch=0.073\n",
      "3509/67600 (epoch 2), train_loss = 1.291, time/batch=0.069\n",
      "3510/67600 (epoch 2), train_loss = 1.338, time/batch=0.067\n",
      "3511/67600 (epoch 2), train_loss = 1.293, time/batch=0.069\n",
      "3512/67600 (epoch 2), train_loss = 1.250, time/batch=0.067\n",
      "3513/67600 (epoch 2), train_loss = 1.355, time/batch=0.068\n",
      "3514/67600 (epoch 2), train_loss = 1.281, time/batch=0.078\n",
      "3515/67600 (epoch 2), train_loss = 1.355, time/batch=0.173\n",
      "3516/67600 (epoch 2), train_loss = 1.345, time/batch=0.068\n",
      "3517/67600 (epoch 2), train_loss = 1.343, time/batch=0.099\n",
      "3518/67600 (epoch 2), train_loss = 1.366, time/batch=0.065\n",
      "3519/67600 (epoch 2), train_loss = 1.276, time/batch=0.066\n",
      "3520/67600 (epoch 2), train_loss = 1.386, time/batch=0.080\n",
      "3521/67600 (epoch 2), train_loss = 1.277, time/batch=0.065\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3522/67600 (epoch 2), train_loss = 1.300, time/batch=0.065\n",
      "3523/67600 (epoch 2), train_loss = 1.332, time/batch=0.066\n",
      "3524/67600 (epoch 2), train_loss = 1.239, time/batch=0.069\n",
      "3525/67600 (epoch 2), train_loss = 1.359, time/batch=0.065\n",
      "3526/67600 (epoch 2), train_loss = 1.328, time/batch=0.072\n",
      "3527/67600 (epoch 2), train_loss = 1.403, time/batch=0.079\n",
      "3528/67600 (epoch 2), train_loss = 1.341, time/batch=0.153\n",
      "3529/67600 (epoch 2), train_loss = 1.374, time/batch=0.066\n",
      "3530/67600 (epoch 2), train_loss = 1.472, time/batch=0.096\n",
      "3531/67600 (epoch 2), train_loss = 1.309, time/batch=0.068\n",
      "3532/67600 (epoch 2), train_loss = 1.326, time/batch=0.066\n",
      "3533/67600 (epoch 2), train_loss = 1.351, time/batch=0.067\n",
      "3534/67600 (epoch 2), train_loss = 1.388, time/batch=0.065\n",
      "3535/67600 (epoch 2), train_loss = 1.327, time/batch=0.065\n",
      "3536/67600 (epoch 2), train_loss = 1.332, time/batch=0.067\n",
      "3537/67600 (epoch 2), train_loss = 1.337, time/batch=0.066\n",
      "3538/67600 (epoch 2), train_loss = 1.281, time/batch=0.071\n",
      "3539/67600 (epoch 2), train_loss = 1.368, time/batch=0.065\n",
      "3540/67600 (epoch 2), train_loss = 1.220, time/batch=0.079\n",
      "3541/67600 (epoch 2), train_loss = 1.365, time/batch=0.173\n",
      "3542/67600 (epoch 2), train_loss = 1.244, time/batch=0.067\n",
      "3543/67600 (epoch 2), train_loss = 1.317, time/batch=0.079\n",
      "3544/67600 (epoch 2), train_loss = 1.376, time/batch=0.069\n",
      "3545/67600 (epoch 2), train_loss = 1.335, time/batch=0.066\n",
      "3546/67600 (epoch 2), train_loss = 1.329, time/batch=0.066\n",
      "3547/67600 (epoch 2), train_loss = 1.341, time/batch=0.069\n",
      "3548/67600 (epoch 2), train_loss = 1.334, time/batch=0.067\n",
      "3549/67600 (epoch 2), train_loss = 1.318, time/batch=0.066\n",
      "3550/67600 (epoch 2), train_loss = 1.313, time/batch=0.066\n",
      "3551/67600 (epoch 2), train_loss = 1.312, time/batch=0.066\n",
      "3552/67600 (epoch 2), train_loss = 1.356, time/batch=0.076\n",
      "3553/67600 (epoch 2), train_loss = 1.311, time/batch=0.089\n",
      "3554/67600 (epoch 2), train_loss = 1.310, time/batch=0.166\n",
      "3555/67600 (epoch 2), train_loss = 1.413, time/batch=0.073\n",
      "3556/67600 (epoch 2), train_loss = 1.403, time/batch=0.067\n",
      "3557/67600 (epoch 2), train_loss = 1.376, time/batch=0.066\n",
      "3558/67600 (epoch 2), train_loss = 1.310, time/batch=0.068\n",
      "3559/67600 (epoch 2), train_loss = 1.373, time/batch=0.066\n",
      "3560/67600 (epoch 2), train_loss = 1.324, time/batch=0.065\n",
      "3561/67600 (epoch 2), train_loss = 1.319, time/batch=0.071\n",
      "3562/67600 (epoch 2), train_loss = 1.362, time/batch=0.066\n",
      "3563/67600 (epoch 2), train_loss = 1.357, time/batch=0.068\n",
      "3564/67600 (epoch 2), train_loss = 1.337, time/batch=0.065\n",
      "3565/67600 (epoch 2), train_loss = 1.391, time/batch=0.065\n",
      "3566/67600 (epoch 2), train_loss = 1.395, time/batch=0.065\n",
      "3567/67600 (epoch 2), train_loss = 1.372, time/batch=0.198\n",
      "3568/67600 (epoch 2), train_loss = 1.293, time/batch=0.068\n",
      "3569/67600 (epoch 2), train_loss = 1.382, time/batch=0.067\n",
      "3570/67600 (epoch 2), train_loss = 1.371, time/batch=0.065\n",
      "3571/67600 (epoch 2), train_loss = 1.295, time/batch=0.070\n",
      "3572/67600 (epoch 2), train_loss = 1.320, time/batch=0.066\n",
      "3573/67600 (epoch 2), train_loss = 1.322, time/batch=0.064\n",
      "3574/67600 (epoch 2), train_loss = 1.323, time/batch=0.066\n",
      "3575/67600 (epoch 2), train_loss = 1.310, time/batch=0.066\n",
      "3576/67600 (epoch 2), train_loss = 1.356, time/batch=0.106\n",
      "3577/67600 (epoch 2), train_loss = 1.299, time/batch=0.066\n",
      "3578/67600 (epoch 2), train_loss = 1.331, time/batch=0.066\n",
      "3579/67600 (epoch 2), train_loss = 1.390, time/batch=0.069\n",
      "3580/67600 (epoch 2), train_loss = 1.361, time/batch=0.066\n",
      "3581/67600 (epoch 2), train_loss = 1.228, time/batch=0.069\n",
      "3582/67600 (epoch 2), train_loss = 1.315, time/batch=0.072\n",
      "3583/67600 (epoch 2), train_loss = 1.233, time/batch=0.065\n",
      "3584/67600 (epoch 2), train_loss = 1.291, time/batch=0.067\n",
      "3585/67600 (epoch 2), train_loss = 1.300, time/batch=0.073\n",
      "3586/67600 (epoch 2), train_loss = 1.315, time/batch=0.100\n",
      "3587/67600 (epoch 2), train_loss = 1.318, time/batch=0.216\n",
      "3588/67600 (epoch 2), train_loss = 1.290, time/batch=0.082\n",
      "3589/67600 (epoch 2), train_loss = 1.318, time/batch=0.065\n",
      "3590/67600 (epoch 2), train_loss = 1.304, time/batch=0.078\n",
      "3591/67600 (epoch 2), train_loss = 1.245, time/batch=0.067\n",
      "3592/67600 (epoch 2), train_loss = 1.393, time/batch=0.069\n",
      "3593/67600 (epoch 2), train_loss = 1.346, time/batch=0.076\n",
      "3594/67600 (epoch 2), train_loss = 1.387, time/batch=0.065\n",
      "3595/67600 (epoch 2), train_loss = 1.370, time/batch=0.066\n",
      "3596/67600 (epoch 2), train_loss = 1.355, time/batch=0.065\n",
      "3597/67600 (epoch 2), train_loss = 1.330, time/batch=0.066\n",
      "3598/67600 (epoch 2), train_loss = 1.362, time/batch=0.065\n",
      "3599/67600 (epoch 2), train_loss = 1.314, time/batch=0.179\n",
      "3600/67600 (epoch 2), train_loss = 1.313, time/batch=0.086\n",
      "3601/67600 (epoch 2), train_loss = 1.367, time/batch=0.083\n",
      "3602/67600 (epoch 2), train_loss = 1.349, time/batch=0.067\n",
      "3603/67600 (epoch 2), train_loss = 1.350, time/batch=0.065\n",
      "3604/67600 (epoch 2), train_loss = 1.334, time/batch=0.064\n",
      "3605/67600 (epoch 2), train_loss = 1.389, time/batch=0.067\n",
      "3606/67600 (epoch 2), train_loss = 1.380, time/batch=0.068\n",
      "3607/67600 (epoch 2), train_loss = 1.271, time/batch=0.066\n",
      "3608/67600 (epoch 2), train_loss = 1.318, time/batch=0.067\n",
      "3609/67600 (epoch 2), train_loss = 1.369, time/batch=0.065\n",
      "3610/67600 (epoch 2), train_loss = 1.312, time/batch=0.068\n",
      "3611/67600 (epoch 2), train_loss = 1.295, time/batch=0.065\n",
      "3612/67600 (epoch 2), train_loss = 1.371, time/batch=0.178\n",
      "3613/67600 (epoch 2), train_loss = 1.305, time/batch=0.088\n",
      "3614/67600 (epoch 2), train_loss = 1.303, time/batch=0.071\n",
      "3615/67600 (epoch 2), train_loss = 1.366, time/batch=0.065\n",
      "3616/67600 (epoch 2), train_loss = 1.314, time/batch=0.063\n",
      "3617/67600 (epoch 2), train_loss = 1.348, time/batch=0.065\n",
      "3618/67600 (epoch 2), train_loss = 1.379, time/batch=0.067\n",
      "3619/67600 (epoch 2), train_loss = 1.295, time/batch=0.071\n",
      "3620/67600 (epoch 2), train_loss = 1.323, time/batch=0.065\n",
      "3621/67600 (epoch 2), train_loss = 1.310, time/batch=0.098\n",
      "3622/67600 (epoch 2), train_loss = 1.317, time/batch=0.129\n",
      "3623/67600 (epoch 2), train_loss = 1.332, time/batch=0.113\n",
      "3624/67600 (epoch 2), train_loss = 1.345, time/batch=0.070\n",
      "3625/67600 (epoch 2), train_loss = 1.314, time/batch=0.073\n",
      "3626/67600 (epoch 2), train_loss = 1.361, time/batch=0.065\n",
      "3627/67600 (epoch 2), train_loss = 1.312, time/batch=0.070\n",
      "3628/67600 (epoch 2), train_loss = 1.265, time/batch=0.064\n",
      "3629/67600 (epoch 2), train_loss = 1.326, time/batch=0.067\n",
      "3630/67600 (epoch 2), train_loss = 1.313, time/batch=0.066\n",
      "3631/67600 (epoch 2), train_loss = 1.327, time/batch=0.084\n",
      "3632/67600 (epoch 2), train_loss = 1.308, time/batch=0.072\n",
      "3633/67600 (epoch 2), train_loss = 1.330, time/batch=0.066\n",
      "3634/67600 (epoch 2), train_loss = 1.270, time/batch=0.167\n",
      "3635/67600 (epoch 2), train_loss = 1.335, time/batch=0.065\n",
      "3636/67600 (epoch 2), train_loss = 1.297, time/batch=0.101\n",
      "3637/67600 (epoch 2), train_loss = 1.276, time/batch=0.069\n",
      "3638/67600 (epoch 2), train_loss = 1.286, time/batch=0.070\n",
      "3639/67600 (epoch 2), train_loss = 1.301, time/batch=0.066\n",
      "3640/67600 (epoch 2), train_loss = 1.351, time/batch=0.066\n",
      "3641/67600 (epoch 2), train_loss = 1.311, time/batch=0.065\n",
      "3642/67600 (epoch 2), train_loss = 1.289, time/batch=0.066\n",
      "3643/67600 (epoch 2), train_loss = 1.306, time/batch=0.067\n",
      "3644/67600 (epoch 2), train_loss = 1.318, time/batch=0.067\n",
      "3645/67600 (epoch 2), train_loss = 1.278, time/batch=0.066\n",
      "3646/67600 (epoch 2), train_loss = 1.253, time/batch=0.068\n",
      "3647/67600 (epoch 2), train_loss = 1.371, time/batch=0.170\n",
      "3648/67600 (epoch 2), train_loss = 1.310, time/batch=0.078\n",
      "3649/67600 (epoch 2), train_loss = 1.344, time/batch=0.090\n",
      "3650/67600 (epoch 2), train_loss = 1.299, time/batch=0.072\n",
      "3651/67600 (epoch 2), train_loss = 1.278, time/batch=0.067\n",
      "3652/67600 (epoch 2), train_loss = 1.331, time/batch=0.076\n",
      "3653/67600 (epoch 2), train_loss = 1.302, time/batch=0.066\n",
      "3654/67600 (epoch 2), train_loss = 1.360, time/batch=0.076\n",
      "3655/67600 (epoch 2), train_loss = 1.294, time/batch=0.063\n",
      "3656/67600 (epoch 2), train_loss = 1.348, time/batch=0.071\n",
      "3657/67600 (epoch 2), train_loss = 1.279, time/batch=0.065\n",
      "3658/67600 (epoch 2), train_loss = 1.238, time/batch=0.070\n",
      "3659/67600 (epoch 2), train_loss = 1.361, time/batch=0.168\n",
      "3660/67600 (epoch 2), train_loss = 1.334, time/batch=0.097\n",
      "3661/67600 (epoch 2), train_loss = 1.341, time/batch=0.082\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3662/67600 (epoch 2), train_loss = 1.287, time/batch=0.067\n",
      "3663/67600 (epoch 2), train_loss = 1.299, time/batch=0.068\n",
      "3664/67600 (epoch 2), train_loss = 1.293, time/batch=0.064\n",
      "3665/67600 (epoch 2), train_loss = 1.214, time/batch=0.068\n",
      "3666/67600 (epoch 2), train_loss = 1.244, time/batch=0.076\n",
      "3667/67600 (epoch 2), train_loss = 1.257, time/batch=0.066\n",
      "3668/67600 (epoch 2), train_loss = 1.238, time/batch=0.065\n",
      "3669/67600 (epoch 2), train_loss = 1.321, time/batch=0.066\n",
      "3670/67600 (epoch 2), train_loss = 1.331, time/batch=0.065\n",
      "3671/67600 (epoch 2), train_loss = 1.268, time/batch=0.065\n",
      "3672/67600 (epoch 2), train_loss = 1.285, time/batch=0.168\n",
      "3673/67600 (epoch 2), train_loss = 1.278, time/batch=0.090\n",
      "3674/67600 (epoch 2), train_loss = 1.316, time/batch=0.074\n",
      "3675/67600 (epoch 2), train_loss = 1.322, time/batch=0.066\n",
      "3676/67600 (epoch 2), train_loss = 1.259, time/batch=0.067\n",
      "3677/67600 (epoch 2), train_loss = 1.329, time/batch=0.074\n",
      "3678/67600 (epoch 2), train_loss = 1.336, time/batch=0.064\n",
      "3679/67600 (epoch 2), train_loss = 1.246, time/batch=0.067\n",
      "3680/67600 (epoch 2), train_loss = 1.234, time/batch=0.066\n",
      "3681/67600 (epoch 2), train_loss = 1.271, time/batch=0.109\n",
      "3682/67600 (epoch 2), train_loss = 1.339, time/batch=0.117\n",
      "3683/67600 (epoch 2), train_loss = 1.302, time/batch=0.069\n",
      "3684/67600 (epoch 2), train_loss = 1.319, time/batch=0.099\n",
      "3685/67600 (epoch 2), train_loss = 1.276, time/batch=0.077\n",
      "3686/67600 (epoch 2), train_loss = 1.270, time/batch=0.065\n",
      "3687/67600 (epoch 2), train_loss = 1.327, time/batch=0.071\n",
      "3688/67600 (epoch 2), train_loss = 1.276, time/batch=0.064\n",
      "3689/67600 (epoch 2), train_loss = 1.390, time/batch=0.065\n",
      "3690/67600 (epoch 2), train_loss = 1.314, time/batch=0.064\n",
      "3691/67600 (epoch 2), train_loss = 1.388, time/batch=0.064\n",
      "3692/67600 (epoch 2), train_loss = 1.280, time/batch=0.063\n",
      "3693/67600 (epoch 2), train_loss = 1.284, time/batch=0.065\n",
      "3694/67600 (epoch 2), train_loss = 1.320, time/batch=0.095\n",
      "3695/67600 (epoch 2), train_loss = 1.280, time/batch=0.133\n",
      "3696/67600 (epoch 2), train_loss = 1.363, time/batch=0.065\n",
      "3697/67600 (epoch 2), train_loss = 1.313, time/batch=0.090\n",
      "3698/67600 (epoch 2), train_loss = 1.310, time/batch=0.064\n",
      "3699/67600 (epoch 2), train_loss = 1.314, time/batch=0.067\n",
      "3700/67600 (epoch 2), train_loss = 1.316, time/batch=0.068\n",
      "3701/67600 (epoch 2), train_loss = 1.342, time/batch=0.067\n",
      "3702/67600 (epoch 2), train_loss = 1.254, time/batch=0.068\n",
      "3703/67600 (epoch 2), train_loss = 1.282, time/batch=0.066\n",
      "3704/67600 (epoch 2), train_loss = 1.296, time/batch=0.080\n",
      "3705/67600 (epoch 2), train_loss = 1.310, time/batch=0.066\n",
      "3706/67600 (epoch 2), train_loss = 1.284, time/batch=0.065\n",
      "3707/67600 (epoch 2), train_loss = 1.311, time/batch=0.083\n",
      "3708/67600 (epoch 2), train_loss = 1.246, time/batch=0.158\n",
      "3709/67600 (epoch 2), train_loss = 1.319, time/batch=0.086\n",
      "3710/67600 (epoch 2), train_loss = 1.310, time/batch=0.081\n",
      "3711/67600 (epoch 2), train_loss = 1.273, time/batch=0.065\n",
      "3712/67600 (epoch 2), train_loss = 1.311, time/batch=0.066\n",
      "3713/67600 (epoch 2), train_loss = 1.263, time/batch=0.069\n",
      "3714/67600 (epoch 2), train_loss = 1.293, time/batch=0.065\n",
      "3715/67600 (epoch 2), train_loss = 1.295, time/batch=0.067\n",
      "3716/67600 (epoch 2), train_loss = 1.253, time/batch=0.066\n",
      "3717/67600 (epoch 2), train_loss = 1.266, time/batch=0.065\n",
      "3718/67600 (epoch 2), train_loss = 1.276, time/batch=0.078\n",
      "3719/67600 (epoch 2), train_loss = 1.286, time/batch=0.079\n",
      "3720/67600 (epoch 2), train_loss = 1.285, time/batch=0.176\n",
      "3721/67600 (epoch 2), train_loss = 1.318, time/batch=0.093\n",
      "3722/67600 (epoch 2), train_loss = 1.295, time/batch=0.088\n",
      "3723/67600 (epoch 2), train_loss = 1.309, time/batch=0.077\n",
      "3724/67600 (epoch 2), train_loss = 1.307, time/batch=0.071\n",
      "3725/67600 (epoch 2), train_loss = 1.292, time/batch=0.077\n",
      "3726/67600 (epoch 2), train_loss = 1.283, time/batch=0.077\n",
      "3727/67600 (epoch 2), train_loss = 1.296, time/batch=0.071\n",
      "3728/67600 (epoch 2), train_loss = 1.306, time/batch=0.073\n",
      "3729/67600 (epoch 2), train_loss = 1.268, time/batch=0.073\n",
      "3730/67600 (epoch 2), train_loss = 1.331, time/batch=0.070\n",
      "3731/67600 (epoch 2), train_loss = 1.259, time/batch=0.075\n",
      "3732/67600 (epoch 2), train_loss = 1.356, time/batch=0.204\n",
      "3733/67600 (epoch 2), train_loss = 1.340, time/batch=0.077\n",
      "3734/67600 (epoch 2), train_loss = 1.354, time/batch=0.071\n",
      "3735/67600 (epoch 2), train_loss = 1.341, time/batch=0.072\n",
      "3736/67600 (epoch 2), train_loss = 1.305, time/batch=0.069\n",
      "3737/67600 (epoch 2), train_loss = 1.274, time/batch=0.068\n",
      "3738/67600 (epoch 2), train_loss = 1.315, time/batch=0.065\n",
      "3739/67600 (epoch 2), train_loss = 1.276, time/batch=0.068\n",
      "3740/67600 (epoch 2), train_loss = 1.263, time/batch=0.077\n",
      "3741/67600 (epoch 2), train_loss = 1.263, time/batch=0.079\n",
      "3742/67600 (epoch 2), train_loss = 1.297, time/batch=0.067\n",
      "3743/67600 (epoch 2), train_loss = 1.288, time/batch=0.073\n",
      "3744/67600 (epoch 2), train_loss = 1.307, time/batch=0.207\n",
      "3745/67600 (epoch 2), train_loss = 1.294, time/batch=0.083\n",
      "3746/67600 (epoch 2), train_loss = 1.343, time/batch=0.085\n",
      "3747/67600 (epoch 2), train_loss = 1.207, time/batch=0.081\n",
      "3748/67600 (epoch 2), train_loss = 1.300, time/batch=0.078\n",
      "3749/67600 (epoch 2), train_loss = 1.291, time/batch=0.079\n",
      "3750/67600 (epoch 2), train_loss = 1.309, time/batch=0.089\n",
      "3751/67600 (epoch 2), train_loss = 1.368, time/batch=0.106\n",
      "3752/67600 (epoch 2), train_loss = 1.347, time/batch=0.092\n",
      "3753/67600 (epoch 2), train_loss = 1.319, time/batch=0.082\n",
      "3754/67600 (epoch 2), train_loss = 1.297, time/batch=0.081\n",
      "3755/67600 (epoch 2), train_loss = 1.265, time/batch=0.080\n",
      "3756/67600 (epoch 2), train_loss = 1.328, time/batch=0.083\n",
      "3757/67600 (epoch 2), train_loss = 1.301, time/batch=0.082\n",
      "3758/67600 (epoch 2), train_loss = 1.340, time/batch=0.079\n",
      "3759/67600 (epoch 2), train_loss = 1.318, time/batch=0.075\n",
      "3760/67600 (epoch 2), train_loss = 1.245, time/batch=0.116\n",
      "3761/67600 (epoch 2), train_loss = 1.353, time/batch=0.187\n",
      "3762/67600 (epoch 2), train_loss = 1.377, time/batch=0.074\n",
      "3763/67600 (epoch 2), train_loss = 1.305, time/batch=0.089\n",
      "3764/67600 (epoch 2), train_loss = 1.321, time/batch=0.069\n",
      "3765/67600 (epoch 2), train_loss = 1.325, time/batch=0.067\n",
      "3766/67600 (epoch 2), train_loss = 1.301, time/batch=0.069\n",
      "3767/67600 (epoch 2), train_loss = 1.265, time/batch=0.070\n",
      "3768/67600 (epoch 2), train_loss = 1.314, time/batch=0.067\n",
      "3769/67600 (epoch 2), train_loss = 1.309, time/batch=0.071\n",
      "3770/67600 (epoch 2), train_loss = 1.292, time/batch=0.066\n",
      "3771/67600 (epoch 2), train_loss = 1.346, time/batch=0.078\n",
      "3772/67600 (epoch 2), train_loss = 1.291, time/batch=0.083\n",
      "3773/67600 (epoch 2), train_loss = 1.340, time/batch=0.205\n",
      "3774/67600 (epoch 2), train_loss = 1.342, time/batch=0.072\n",
      "3775/67600 (epoch 2), train_loss = 1.355, time/batch=0.067\n",
      "3776/67600 (epoch 2), train_loss = 1.311, time/batch=0.065\n",
      "3777/67600 (epoch 2), train_loss = 1.298, time/batch=0.065\n",
      "3778/67600 (epoch 2), train_loss = 1.276, time/batch=0.066\n",
      "3779/67600 (epoch 2), train_loss = 1.298, time/batch=0.065\n",
      "3780/67600 (epoch 2), train_loss = 1.335, time/batch=0.066\n",
      "3781/67600 (epoch 2), train_loss = 1.319, time/batch=0.064\n",
      "3782/67600 (epoch 2), train_loss = 1.335, time/batch=0.170\n",
      "3783/67600 (epoch 2), train_loss = 1.361, time/batch=0.069\n",
      "3784/67600 (epoch 2), train_loss = 1.358, time/batch=0.094\n",
      "3785/67600 (epoch 2), train_loss = 1.292, time/batch=0.071\n",
      "3786/67600 (epoch 2), train_loss = 1.349, time/batch=0.063\n",
      "3787/67600 (epoch 2), train_loss = 1.276, time/batch=0.063\n",
      "3788/67600 (epoch 2), train_loss = 1.273, time/batch=0.086\n",
      "3789/67600 (epoch 2), train_loss = 1.391, time/batch=0.064\n",
      "3790/67600 (epoch 2), train_loss = 1.339, time/batch=0.075\n",
      "3791/67600 (epoch 2), train_loss = 1.246, time/batch=0.067\n",
      "3792/67600 (epoch 2), train_loss = 1.300, time/batch=0.073\n",
      "3793/67600 (epoch 2), train_loss = 1.273, time/batch=0.065\n",
      "3794/67600 (epoch 2), train_loss = 1.342, time/batch=0.062\n",
      "3795/67600 (epoch 2), train_loss = 1.308, time/batch=0.167\n",
      "3796/67600 (epoch 2), train_loss = 1.347, time/batch=0.068\n",
      "3797/67600 (epoch 2), train_loss = 1.288, time/batch=0.104\n",
      "3798/67600 (epoch 2), train_loss = 1.300, time/batch=0.064\n",
      "3799/67600 (epoch 2), train_loss = 1.292, time/batch=0.067\n",
      "3800/67600 (epoch 2), train_loss = 1.314, time/batch=0.072\n",
      "3801/67600 (epoch 2), train_loss = 1.306, time/batch=0.072\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3802/67600 (epoch 2), train_loss = 1.275, time/batch=0.068\n",
      "3803/67600 (epoch 2), train_loss = 1.230, time/batch=0.067\n",
      "3804/67600 (epoch 2), train_loss = 1.296, time/batch=0.067\n",
      "3805/67600 (epoch 2), train_loss = 1.286, time/batch=0.065\n",
      "3806/67600 (epoch 2), train_loss = 1.288, time/batch=0.075\n",
      "3807/67600 (epoch 2), train_loss = 1.255, time/batch=0.074\n",
      "3808/67600 (epoch 2), train_loss = 1.390, time/batch=0.160\n",
      "3809/67600 (epoch 2), train_loss = 1.286, time/batch=0.066\n",
      "3810/67600 (epoch 2), train_loss = 1.288, time/batch=0.101\n",
      "3811/67600 (epoch 2), train_loss = 1.319, time/batch=0.073\n",
      "3812/67600 (epoch 2), train_loss = 1.301, time/batch=0.064\n",
      "3813/67600 (epoch 2), train_loss = 1.315, time/batch=0.066\n",
      "3814/67600 (epoch 2), train_loss = 1.314, time/batch=0.067\n",
      "3815/67600 (epoch 2), train_loss = 1.301, time/batch=0.070\n",
      "3816/67600 (epoch 2), train_loss = 1.352, time/batch=0.062\n",
      "3817/67600 (epoch 2), train_loss = 1.357, time/batch=0.064\n",
      "3818/67600 (epoch 2), train_loss = 1.355, time/batch=0.064\n",
      "3819/67600 (epoch 2), train_loss = 1.403, time/batch=0.067\n",
      "3820/67600 (epoch 2), train_loss = 1.297, time/batch=0.069\n",
      "3821/67600 (epoch 2), train_loss = 1.330, time/batch=0.163\n",
      "3822/67600 (epoch 2), train_loss = 1.295, time/batch=0.069\n",
      "3823/67600 (epoch 2), train_loss = 1.406, time/batch=0.093\n",
      "3824/67600 (epoch 2), train_loss = 1.307, time/batch=0.067\n",
      "3825/67600 (epoch 2), train_loss = 1.343, time/batch=0.067\n",
      "3826/67600 (epoch 2), train_loss = 1.422, time/batch=0.065\n",
      "3827/67600 (epoch 2), train_loss = 1.326, time/batch=0.065\n",
      "3828/67600 (epoch 2), train_loss = 1.311, time/batch=0.066\n",
      "3829/67600 (epoch 2), train_loss = 1.312, time/batch=0.066\n",
      "3830/67600 (epoch 2), train_loss = 1.386, time/batch=0.064\n",
      "3831/67600 (epoch 2), train_loss = 1.295, time/batch=0.062\n",
      "3832/67600 (epoch 2), train_loss = 1.335, time/batch=0.064\n",
      "3833/67600 (epoch 2), train_loss = 1.317, time/batch=0.062\n",
      "3834/67600 (epoch 2), train_loss = 1.325, time/batch=0.171\n",
      "3835/67600 (epoch 2), train_loss = 1.351, time/batch=0.086\n",
      "3836/67600 (epoch 2), train_loss = 1.292, time/batch=0.083\n",
      "3837/67600 (epoch 2), train_loss = 1.357, time/batch=0.065\n",
      "3838/67600 (epoch 2), train_loss = 1.380, time/batch=0.065\n",
      "3839/67600 (epoch 2), train_loss = 1.390, time/batch=0.076\n",
      "3840/67600 (epoch 2), train_loss = 1.349, time/batch=0.064\n",
      "3841/67600 (epoch 2), train_loss = 1.315, time/batch=0.064\n",
      "3842/67600 (epoch 2), train_loss = 1.327, time/batch=0.068\n",
      "3843/67600 (epoch 2), train_loss = 1.365, time/batch=0.070\n",
      "3844/67600 (epoch 2), train_loss = 1.319, time/batch=0.068\n",
      "3845/67600 (epoch 2), train_loss = 1.314, time/batch=0.064\n",
      "3846/67600 (epoch 2), train_loss = 1.361, time/batch=0.063\n",
      "3847/67600 (epoch 2), train_loss = 1.370, time/batch=0.188\n",
      "3848/67600 (epoch 2), train_loss = 1.327, time/batch=0.067\n",
      "3849/67600 (epoch 2), train_loss = 1.285, time/batch=0.075\n",
      "3850/67600 (epoch 2), train_loss = 1.296, time/batch=0.065\n",
      "3851/67600 (epoch 2), train_loss = 1.286, time/batch=0.066\n",
      "3852/67600 (epoch 2), train_loss = 1.273, time/batch=0.067\n",
      "3853/67600 (epoch 2), train_loss = 1.302, time/batch=0.065\n",
      "3854/67600 (epoch 2), train_loss = 1.243, time/batch=0.067\n",
      "3855/67600 (epoch 2), train_loss = 1.342, time/batch=0.065\n",
      "3856/67600 (epoch 2), train_loss = 1.304, time/batch=0.146\n",
      "3857/67600 (epoch 2), train_loss = 1.290, time/batch=0.077\n",
      "3858/67600 (epoch 2), train_loss = 1.334, time/batch=0.070\n",
      "3859/67600 (epoch 2), train_loss = 1.296, time/batch=0.105\n",
      "3860/67600 (epoch 2), train_loss = 1.299, time/batch=0.069\n",
      "3861/67600 (epoch 2), train_loss = 1.247, time/batch=0.072\n",
      "3862/67600 (epoch 2), train_loss = 1.350, time/batch=0.075\n",
      "3863/67600 (epoch 2), train_loss = 1.334, time/batch=0.069\n",
      "3864/67600 (epoch 2), train_loss = 1.263, time/batch=0.071\n",
      "3865/67600 (epoch 2), train_loss = 1.284, time/batch=0.075\n",
      "3866/67600 (epoch 2), train_loss = 1.298, time/batch=0.072\n",
      "3867/67600 (epoch 2), train_loss = 1.267, time/batch=0.075\n",
      "3868/67600 (epoch 2), train_loss = 1.326, time/batch=0.098\n",
      "3869/67600 (epoch 2), train_loss = 1.254, time/batch=0.148\n",
      "3870/67600 (epoch 2), train_loss = 1.280, time/batch=0.075\n",
      "3871/67600 (epoch 2), train_loss = 1.298, time/batch=0.097\n",
      "3872/67600 (epoch 2), train_loss = 1.337, time/batch=0.068\n",
      "3873/67600 (epoch 2), train_loss = 1.253, time/batch=0.068\n",
      "3874/67600 (epoch 2), train_loss = 1.275, time/batch=0.064\n",
      "3875/67600 (epoch 2), train_loss = 1.264, time/batch=0.076\n",
      "3876/67600 (epoch 2), train_loss = 1.291, time/batch=0.080\n",
      "3877/67600 (epoch 2), train_loss = 1.282, time/batch=0.076\n",
      "3878/67600 (epoch 2), train_loss = 1.281, time/batch=0.068\n",
      "3879/67600 (epoch 2), train_loss = 1.307, time/batch=0.070\n",
      "3880/67600 (epoch 2), train_loss = 1.309, time/batch=0.065\n",
      "3881/67600 (epoch 2), train_loss = 1.320, time/batch=0.196\n",
      "3882/67600 (epoch 2), train_loss = 1.335, time/batch=0.066\n",
      "3883/67600 (epoch 2), train_loss = 1.412, time/batch=0.091\n",
      "3884/67600 (epoch 2), train_loss = 1.378, time/batch=0.066\n",
      "3885/67600 (epoch 2), train_loss = 1.341, time/batch=0.066\n",
      "3886/67600 (epoch 2), train_loss = 1.303, time/batch=0.067\n",
      "3887/67600 (epoch 2), train_loss = 1.302, time/batch=0.063\n",
      "3888/67600 (epoch 2), train_loss = 1.324, time/batch=0.065\n",
      "3889/67600 (epoch 2), train_loss = 1.237, time/batch=0.085\n",
      "3890/67600 (epoch 2), train_loss = 1.271, time/batch=0.067\n",
      "3891/67600 (epoch 2), train_loss = 1.367, time/batch=0.085\n",
      "3892/67600 (epoch 2), train_loss = 1.317, time/batch=0.074\n",
      "3893/67600 (epoch 2), train_loss = 1.278, time/batch=0.193\n",
      "3894/67600 (epoch 2), train_loss = 1.304, time/batch=0.065\n",
      "3895/67600 (epoch 2), train_loss = 1.294, time/batch=0.078\n",
      "3896/67600 (epoch 2), train_loss = 1.298, time/batch=0.067\n",
      "3897/67600 (epoch 2), train_loss = 1.294, time/batch=0.066\n",
      "3898/67600 (epoch 2), train_loss = 1.253, time/batch=0.076\n",
      "3899/67600 (epoch 2), train_loss = 1.281, time/batch=0.068\n",
      "3900/67600 (epoch 2), train_loss = 1.325, time/batch=0.065\n",
      "3901/67600 (epoch 2), train_loss = 1.335, time/batch=0.110\n",
      "3902/67600 (epoch 2), train_loss = 1.333, time/batch=0.080\n",
      "3903/67600 (epoch 2), train_loss = 1.294, time/batch=0.085\n",
      "3904/67600 (epoch 2), train_loss = 1.315, time/batch=0.072\n",
      "3905/67600 (epoch 2), train_loss = 1.293, time/batch=0.186\n",
      "3906/67600 (epoch 2), train_loss = 1.295, time/batch=0.074\n",
      "3907/67600 (epoch 2), train_loss = 1.275, time/batch=0.068\n",
      "3908/67600 (epoch 2), train_loss = 1.393, time/batch=0.065\n",
      "3909/67600 (epoch 2), train_loss = 1.307, time/batch=0.069\n",
      "3910/67600 (epoch 2), train_loss = 1.273, time/batch=0.076\n",
      "3911/67600 (epoch 2), train_loss = 1.327, time/batch=0.069\n",
      "3912/67600 (epoch 2), train_loss = 1.270, time/batch=0.066\n",
      "3913/67600 (epoch 2), train_loss = 1.260, time/batch=0.065\n",
      "3914/67600 (epoch 2), train_loss = 1.312, time/batch=0.092\n",
      "3915/67600 (epoch 2), train_loss = 1.276, time/batch=0.071\n",
      "3916/67600 (epoch 2), train_loss = 1.259, time/batch=0.083\n",
      "3917/67600 (epoch 2), train_loss = 1.306, time/batch=0.196\n",
      "3918/67600 (epoch 2), train_loss = 1.339, time/batch=0.065\n",
      "3919/67600 (epoch 2), train_loss = 1.290, time/batch=0.073\n",
      "3920/67600 (epoch 2), train_loss = 1.312, time/batch=0.066\n",
      "3921/67600 (epoch 2), train_loss = 1.301, time/batch=0.066\n",
      "3922/67600 (epoch 2), train_loss = 1.294, time/batch=0.070\n",
      "3923/67600 (epoch 2), train_loss = 1.303, time/batch=0.088\n",
      "3924/67600 (epoch 2), train_loss = 1.296, time/batch=0.065\n",
      "3925/67600 (epoch 2), train_loss = 1.274, time/batch=0.063\n",
      "3926/67600 (epoch 2), train_loss = 1.326, time/batch=0.112\n",
      "3927/67600 (epoch 2), train_loss = 1.286, time/batch=0.093\n",
      "3928/67600 (epoch 2), train_loss = 1.338, time/batch=0.070\n",
      "3929/67600 (epoch 2), train_loss = 1.346, time/batch=0.089\n",
      "3930/67600 (epoch 2), train_loss = 1.330, time/batch=0.069\n",
      "3931/67600 (epoch 2), train_loss = 1.315, time/batch=0.067\n",
      "3932/67600 (epoch 2), train_loss = 1.364, time/batch=0.088\n",
      "3933/67600 (epoch 2), train_loss = 1.285, time/batch=0.088\n",
      "3934/67600 (epoch 2), train_loss = 1.321, time/batch=0.083\n",
      "3935/67600 (epoch 2), train_loss = 1.331, time/batch=0.242\n",
      "3936/67600 (epoch 2), train_loss = 1.406, time/batch=0.075\n",
      "3937/67600 (epoch 2), train_loss = 1.364, time/batch=0.105\n",
      "3938/67600 (epoch 2), train_loss = 1.259, time/batch=0.070\n",
      "3939/67600 (epoch 2), train_loss = 1.299, time/batch=0.066\n",
      "3940/67600 (epoch 2), train_loss = 1.296, time/batch=0.072\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3941/67600 (epoch 2), train_loss = 1.318, time/batch=0.073\n",
      "3942/67600 (epoch 2), train_loss = 1.286, time/batch=0.075\n",
      "3943/67600 (epoch 2), train_loss = 1.279, time/batch=0.076\n",
      "3944/67600 (epoch 2), train_loss = 1.363, time/batch=0.069\n",
      "3945/67600 (epoch 2), train_loss = 1.282, time/batch=0.073\n",
      "3946/67600 (epoch 2), train_loss = 1.295, time/batch=0.081\n",
      "3947/67600 (epoch 2), train_loss = 1.327, time/batch=0.199\n",
      "3948/67600 (epoch 2), train_loss = 1.404, time/batch=0.076\n",
      "3949/67600 (epoch 2), train_loss = 1.317, time/batch=0.069\n",
      "3950/67600 (epoch 2), train_loss = 1.300, time/batch=0.067\n",
      "3951/67600 (epoch 2), train_loss = 1.304, time/batch=0.065\n",
      "3952/67600 (epoch 2), train_loss = 1.344, time/batch=0.068\n",
      "3953/67600 (epoch 2), train_loss = 1.323, time/batch=0.069\n",
      "3954/67600 (epoch 2), train_loss = 1.280, time/batch=0.067\n",
      "3955/67600 (epoch 2), train_loss = 1.371, time/batch=0.066\n",
      "3956/67600 (epoch 2), train_loss = 1.265, time/batch=0.065\n",
      "3957/67600 (epoch 2), train_loss = 1.382, time/batch=0.077\n",
      "3958/67600 (epoch 2), train_loss = 1.314, time/batch=0.085\n",
      "3959/67600 (epoch 2), train_loss = 1.355, time/batch=0.228\n",
      "3960/67600 (epoch 2), train_loss = 1.344, time/batch=0.097\n",
      "3961/67600 (epoch 2), train_loss = 1.329, time/batch=0.068\n",
      "3962/67600 (epoch 2), train_loss = 1.384, time/batch=0.089\n",
      "3963/67600 (epoch 2), train_loss = 1.319, time/batch=0.083\n",
      "3964/67600 (epoch 2), train_loss = 1.334, time/batch=0.072\n",
      "3965/67600 (epoch 2), train_loss = 1.284, time/batch=0.087\n",
      "3966/67600 (epoch 2), train_loss = 1.389, time/batch=0.211\n",
      "3967/67600 (epoch 2), train_loss = 1.376, time/batch=0.069\n",
      "3968/67600 (epoch 2), train_loss = 1.372, time/batch=0.099\n",
      "3969/67600 (epoch 2), train_loss = 1.305, time/batch=0.067\n",
      "3970/67600 (epoch 2), train_loss = 1.381, time/batch=0.094\n",
      "3971/67600 (epoch 2), train_loss = 1.287, time/batch=0.070\n",
      "3972/67600 (epoch 2), train_loss = 1.244, time/batch=0.073\n",
      "3973/67600 (epoch 2), train_loss = 1.300, time/batch=0.110\n",
      "3974/67600 (epoch 2), train_loss = 1.305, time/batch=0.069\n",
      "3975/67600 (epoch 2), train_loss = 1.266, time/batch=0.090\n",
      "3976/67600 (epoch 2), train_loss = 1.314, time/batch=0.066\n",
      "3977/67600 (epoch 2), train_loss = 1.318, time/batch=0.211\n",
      "3978/67600 (epoch 2), train_loss = 1.313, time/batch=0.135\n",
      "3979/67600 (epoch 2), train_loss = 1.357, time/batch=0.102\n",
      "3980/67600 (epoch 2), train_loss = 1.331, time/batch=0.075\n",
      "3981/67600 (epoch 2), train_loss = 1.326, time/batch=0.071\n",
      "3982/67600 (epoch 2), train_loss = 1.265, time/batch=0.070\n",
      "3983/67600 (epoch 2), train_loss = 1.240, time/batch=0.065\n",
      "3984/67600 (epoch 2), train_loss = 1.282, time/batch=0.069\n",
      "3985/67600 (epoch 2), train_loss = 1.326, time/batch=0.096\n",
      "3986/67600 (epoch 2), train_loss = 1.274, time/batch=0.076\n",
      "3987/67600 (epoch 2), train_loss = 1.326, time/batch=0.183\n",
      "3988/67600 (epoch 2), train_loss = 1.332, time/batch=0.088\n",
      "3989/67600 (epoch 2), train_loss = 1.309, time/batch=0.114\n",
      "3990/67600 (epoch 2), train_loss = 1.265, time/batch=0.102\n",
      "3991/67600 (epoch 2), train_loss = 1.352, time/batch=0.066\n",
      "3992/67600 (epoch 2), train_loss = 1.295, time/batch=0.068\n",
      "3993/67600 (epoch 2), train_loss = 1.346, time/batch=0.065\n",
      "3994/67600 (epoch 2), train_loss = 1.388, time/batch=0.074\n",
      "3995/67600 (epoch 2), train_loss = 1.346, time/batch=0.071\n",
      "3996/67600 (epoch 2), train_loss = 1.278, time/batch=0.077\n",
      "3997/67600 (epoch 2), train_loss = 1.330, time/batch=0.071\n",
      "3998/67600 (epoch 2), train_loss = 1.320, time/batch=0.065\n",
      "3999/67600 (epoch 2), train_loss = 1.287, time/batch=0.187\n",
      "4000/67600 (epoch 2), train_loss = 1.330, time/batch=0.088\n",
      "model saved to ./save/model.ckpt\n",
      "4001/67600 (epoch 2), train_loss = 1.331, time/batch=0.065\n",
      "4002/67600 (epoch 2), train_loss = 1.263, time/batch=0.068\n",
      "4003/67600 (epoch 2), train_loss = 1.330, time/batch=0.078\n",
      "4004/67600 (epoch 2), train_loss = 1.365, time/batch=0.073\n",
      "4005/67600 (epoch 2), train_loss = 1.307, time/batch=0.063\n",
      "4006/67600 (epoch 2), train_loss = 1.264, time/batch=0.168\n",
      "4007/67600 (epoch 2), train_loss = 1.302, time/batch=0.065\n",
      "4008/67600 (epoch 2), train_loss = 1.339, time/batch=0.090\n",
      "4009/67600 (epoch 2), train_loss = 1.252, time/batch=0.067\n",
      "4010/67600 (epoch 2), train_loss = 1.328, time/batch=0.065\n",
      "4011/67600 (epoch 2), train_loss = 1.307, time/batch=0.067\n",
      "4012/67600 (epoch 2), train_loss = 1.322, time/batch=0.066\n",
      "4013/67600 (epoch 2), train_loss = 1.310, time/batch=0.066\n",
      "4014/67600 (epoch 2), train_loss = 1.296, time/batch=0.068\n",
      "4015/67600 (epoch 2), train_loss = 1.327, time/batch=0.064\n",
      "4016/67600 (epoch 2), train_loss = 1.297, time/batch=0.064\n",
      "4017/67600 (epoch 2), train_loss = 1.358, time/batch=0.064\n",
      "4018/67600 (epoch 2), train_loss = 1.377, time/batch=0.064\n",
      "4019/67600 (epoch 2), train_loss = 1.302, time/batch=0.199\n",
      "4020/67600 (epoch 2), train_loss = 1.337, time/batch=0.068\n",
      "4021/67600 (epoch 2), train_loss = 1.353, time/batch=0.092\n",
      "4022/67600 (epoch 2), train_loss = 1.329, time/batch=0.067\n",
      "4023/67600 (epoch 2), train_loss = 1.299, time/batch=0.067\n",
      "4024/67600 (epoch 2), train_loss = 1.306, time/batch=0.067\n",
      "4025/67600 (epoch 2), train_loss = 1.309, time/batch=0.063\n",
      "4026/67600 (epoch 2), train_loss = 1.272, time/batch=0.069\n",
      "4027/67600 (epoch 2), train_loss = 1.312, time/batch=0.084\n",
      "4028/67600 (epoch 2), train_loss = 1.372, time/batch=0.071\n",
      "4029/67600 (epoch 2), train_loss = 1.312, time/batch=0.067\n",
      "4030/67600 (epoch 2), train_loss = 1.322, time/batch=0.065\n",
      "4031/67600 (epoch 2), train_loss = 1.306, time/batch=0.159\n",
      "4032/67600 (epoch 2), train_loss = 1.309, time/batch=0.110\n",
      "4033/67600 (epoch 2), train_loss = 1.336, time/batch=0.086\n",
      "4034/67600 (epoch 2), train_loss = 1.357, time/batch=0.074\n",
      "4035/67600 (epoch 2), train_loss = 1.364, time/batch=0.067\n",
      "4036/67600 (epoch 2), train_loss = 1.318, time/batch=0.067\n",
      "4037/67600 (epoch 2), train_loss = 1.298, time/batch=0.067\n",
      "4038/67600 (epoch 2), train_loss = 1.266, time/batch=0.068\n",
      "4039/67600 (epoch 2), train_loss = 1.328, time/batch=0.065\n",
      "4040/67600 (epoch 2), train_loss = 1.332, time/batch=0.066\n",
      "4041/67600 (epoch 2), train_loss = 1.306, time/batch=0.095\n",
      "4042/67600 (epoch 2), train_loss = 1.348, time/batch=0.065\n",
      "4043/67600 (epoch 2), train_loss = 1.300, time/batch=0.065\n",
      "4044/67600 (epoch 2), train_loss = 1.290, time/batch=0.189\n",
      "4045/67600 (epoch 2), train_loss = 1.315, time/batch=0.071\n",
      "4046/67600 (epoch 2), train_loss = 1.335, time/batch=0.073\n",
      "4047/67600 (epoch 2), train_loss = 1.304, time/batch=0.076\n",
      "4048/67600 (epoch 2), train_loss = 1.283, time/batch=0.066\n",
      "4049/67600 (epoch 2), train_loss = 1.326, time/batch=0.065\n",
      "4050/67600 (epoch 2), train_loss = 1.277, time/batch=0.064\n",
      "4051/67600 (epoch 2), train_loss = 1.324, time/batch=0.063\n",
      "4052/67600 (epoch 2), train_loss = 1.367, time/batch=0.063\n",
      "4053/67600 (epoch 2), train_loss = 1.400, time/batch=0.073\n",
      "4054/67600 (epoch 2), train_loss = 1.323, time/batch=0.081\n",
      "4055/67600 (epoch 2), train_loss = 1.321, time/batch=0.070\n",
      "4056/67600 (epoch 3), train_loss = 1.484, time/batch=0.192\n",
      "4057/67600 (epoch 3), train_loss = 1.265, time/batch=0.069\n",
      "4058/67600 (epoch 3), train_loss = 1.355, time/batch=0.067\n",
      "4059/67600 (epoch 3), train_loss = 1.293, time/batch=0.066\n",
      "4060/67600 (epoch 3), train_loss = 1.320, time/batch=0.078\n",
      "4061/67600 (epoch 3), train_loss = 1.353, time/batch=0.066\n",
      "4062/67600 (epoch 3), train_loss = 1.299, time/batch=0.065\n",
      "4063/67600 (epoch 3), train_loss = 1.337, time/batch=0.091\n",
      "4064/67600 (epoch 3), train_loss = 1.345, time/batch=0.099\n",
      "4065/67600 (epoch 3), train_loss = 1.305, time/batch=0.086\n",
      "4066/67600 (epoch 3), train_loss = 1.273, time/batch=0.067\n",
      "4067/67600 (epoch 3), train_loss = 1.286, time/batch=0.069\n",
      "4068/67600 (epoch 3), train_loss = 1.287, time/batch=0.065\n",
      "4069/67600 (epoch 3), train_loss = 1.346, time/batch=0.066\n",
      "4070/67600 (epoch 3), train_loss = 1.330, time/batch=0.068\n",
      "4071/67600 (epoch 3), train_loss = 1.293, time/batch=0.066\n",
      "4072/67600 (epoch 3), train_loss = 1.307, time/batch=0.066\n",
      "4073/67600 (epoch 3), train_loss = 1.341, time/batch=0.065\n",
      "4074/67600 (epoch 3), train_loss = 1.314, time/batch=0.066\n",
      "4075/67600 (epoch 3), train_loss = 1.328, time/batch=0.246\n",
      "4076/67600 (epoch 3), train_loss = 1.321, time/batch=0.079\n",
      "4077/67600 (epoch 3), train_loss = 1.261, time/batch=0.083\n",
      "4078/67600 (epoch 3), train_loss = 1.352, time/batch=0.068\n",
      "4079/67600 (epoch 3), train_loss = 1.353, time/batch=0.070\n",
      "4080/67600 (epoch 3), train_loss = 1.393, time/batch=0.066\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4081/67600 (epoch 3), train_loss = 1.235, time/batch=0.067\n",
      "4082/67600 (epoch 3), train_loss = 1.323, time/batch=0.067\n",
      "4083/67600 (epoch 3), train_loss = 1.360, time/batch=0.063\n",
      "4084/67600 (epoch 3), train_loss = 1.386, time/batch=0.082\n",
      "4085/67600 (epoch 3), train_loss = 1.313, time/batch=0.071\n",
      "4086/67600 (epoch 3), train_loss = 1.307, time/batch=0.064\n",
      "4087/67600 (epoch 3), train_loss = 1.378, time/batch=0.084\n",
      "4088/67600 (epoch 3), train_loss = 1.302, time/batch=0.174\n",
      "4089/67600 (epoch 3), train_loss = 1.359, time/batch=0.080\n",
      "4090/67600 (epoch 3), train_loss = 1.334, time/batch=0.067\n",
      "4091/67600 (epoch 3), train_loss = 1.316, time/batch=0.065\n",
      "4092/67600 (epoch 3), train_loss = 1.263, time/batch=0.062\n",
      "4093/67600 (epoch 3), train_loss = 1.342, time/batch=0.069\n",
      "4094/67600 (epoch 3), train_loss = 1.336, time/batch=0.063\n",
      "4095/67600 (epoch 3), train_loss = 1.326, time/batch=0.078\n",
      "4096/67600 (epoch 3), train_loss = 1.243, time/batch=0.088\n",
      "4097/67600 (epoch 3), train_loss = 1.353, time/batch=0.068\n",
      "4098/67600 (epoch 3), train_loss = 1.345, time/batch=0.066\n",
      "4099/67600 (epoch 3), train_loss = 1.339, time/batch=0.065\n",
      "4100/67600 (epoch 3), train_loss = 1.350, time/batch=0.162\n",
      "4101/67600 (epoch 3), train_loss = 1.313, time/batch=0.102\n",
      "4102/67600 (epoch 3), train_loss = 1.276, time/batch=0.069\n",
      "4103/67600 (epoch 3), train_loss = 1.314, time/batch=0.086\n",
      "4104/67600 (epoch 3), train_loss = 1.286, time/batch=0.069\n",
      "4105/67600 (epoch 3), train_loss = 1.271, time/batch=0.067\n",
      "4106/67600 (epoch 3), train_loss = 1.390, time/batch=0.063\n",
      "4107/67600 (epoch 3), train_loss = 1.283, time/batch=0.065\n",
      "4108/67600 (epoch 3), train_loss = 1.294, time/batch=0.064\n",
      "4109/67600 (epoch 3), train_loss = 1.390, time/batch=0.125\n",
      "4110/67600 (epoch 3), train_loss = 1.366, time/batch=0.114\n",
      "4111/67600 (epoch 3), train_loss = 1.319, time/batch=0.117\n",
      "4112/67600 (epoch 3), train_loss = 1.328, time/batch=0.066\n",
      "4113/67600 (epoch 3), train_loss = 1.322, time/batch=0.069\n",
      "4114/67600 (epoch 3), train_loss = 1.317, time/batch=0.072\n",
      "4115/67600 (epoch 3), train_loss = 1.337, time/batch=0.065\n",
      "4116/67600 (epoch 3), train_loss = 1.316, time/batch=0.069\n",
      "4117/67600 (epoch 3), train_loss = 1.294, time/batch=0.068\n",
      "4118/67600 (epoch 3), train_loss = 1.348, time/batch=0.065\n",
      "4119/67600 (epoch 3), train_loss = 1.347, time/batch=0.068\n",
      "4120/67600 (epoch 3), train_loss = 1.316, time/batch=0.070\n",
      "4121/67600 (epoch 3), train_loss = 1.304, time/batch=0.069\n",
      "4122/67600 (epoch 3), train_loss = 1.306, time/batch=0.215\n",
      "4123/67600 (epoch 3), train_loss = 1.338, time/batch=0.131\n",
      "4124/67600 (epoch 3), train_loss = 1.335, time/batch=0.066\n",
      "4125/67600 (epoch 3), train_loss = 1.332, time/batch=0.067\n",
      "4126/67600 (epoch 3), train_loss = 1.335, time/batch=0.070\n",
      "4127/67600 (epoch 3), train_loss = 1.338, time/batch=0.066\n",
      "4128/67600 (epoch 3), train_loss = 1.299, time/batch=0.066\n",
      "4129/67600 (epoch 3), train_loss = 1.393, time/batch=0.071\n",
      "4130/67600 (epoch 3), train_loss = 1.319, time/batch=0.066\n",
      "4131/67600 (epoch 3), train_loss = 1.367, time/batch=0.065\n",
      "4132/67600 (epoch 3), train_loss = 1.369, time/batch=0.065\n",
      "4133/67600 (epoch 3), train_loss = 1.443, time/batch=0.282\n",
      "4134/67600 (epoch 3), train_loss = 1.357, time/batch=0.163\n",
      "4135/67600 (epoch 3), train_loss = 1.301, time/batch=0.078\n",
      "4136/67600 (epoch 3), train_loss = 1.285, time/batch=0.075\n",
      "4137/67600 (epoch 3), train_loss = 1.314, time/batch=0.080\n",
      "4138/67600 (epoch 3), train_loss = 1.334, time/batch=0.072\n",
      "4139/67600 (epoch 3), train_loss = 1.320, time/batch=0.077\n",
      "4140/67600 (epoch 3), train_loss = 1.340, time/batch=0.073\n",
      "4141/67600 (epoch 3), train_loss = 1.317, time/batch=0.077\n",
      "4142/67600 (epoch 3), train_loss = 1.246, time/batch=0.071\n",
      "4143/67600 (epoch 3), train_loss = 1.374, time/batch=0.216\n",
      "4144/67600 (epoch 3), train_loss = 1.348, time/batch=0.121\n",
      "4145/67600 (epoch 3), train_loss = 1.337, time/batch=0.076\n",
      "4146/67600 (epoch 3), train_loss = 1.320, time/batch=0.077\n",
      "4147/67600 (epoch 3), train_loss = 1.332, time/batch=0.079\n",
      "4148/67600 (epoch 3), train_loss = 1.272, time/batch=0.076\n",
      "4149/67600 (epoch 3), train_loss = 1.280, time/batch=0.082\n",
      "4150/67600 (epoch 3), train_loss = 1.276, time/batch=0.087\n",
      "4151/67600 (epoch 3), train_loss = 1.223, time/batch=0.072\n",
      "4152/67600 (epoch 3), train_loss = 1.240, time/batch=0.070\n",
      "4153/67600 (epoch 3), train_loss = 1.316, time/batch=0.208\n",
      "4154/67600 (epoch 3), train_loss = 1.296, time/batch=0.141\n",
      "4155/67600 (epoch 3), train_loss = 1.353, time/batch=0.080\n",
      "4156/67600 (epoch 3), train_loss = 1.223, time/batch=0.087\n",
      "4157/67600 (epoch 3), train_loss = 1.303, time/batch=0.066\n",
      "4158/67600 (epoch 3), train_loss = 1.344, time/batch=0.077\n",
      "4159/67600 (epoch 3), train_loss = 1.263, time/batch=0.070\n",
      "4160/67600 (epoch 3), train_loss = 1.280, time/batch=0.177\n",
      "4161/67600 (epoch 3), train_loss = 1.326, time/batch=0.117\n",
      "4162/67600 (epoch 3), train_loss = 1.280, time/batch=0.108\n",
      "4163/67600 (epoch 3), train_loss = 1.313, time/batch=0.074\n",
      "4164/67600 (epoch 3), train_loss = 1.350, time/batch=0.072\n",
      "4165/67600 (epoch 3), train_loss = 1.313, time/batch=0.100\n",
      "4166/67600 (epoch 3), train_loss = 1.274, time/batch=0.071\n",
      "4167/67600 (epoch 3), train_loss = 1.322, time/batch=0.072\n",
      "4168/67600 (epoch 3), train_loss = 1.306, time/batch=0.078\n",
      "4169/67600 (epoch 3), train_loss = 1.335, time/batch=0.081\n",
      "4170/67600 (epoch 3), train_loss = 1.331, time/batch=0.074\n",
      "4171/67600 (epoch 3), train_loss = 1.265, time/batch=0.188\n",
      "4172/67600 (epoch 3), train_loss = 1.267, time/batch=0.086\n",
      "4173/67600 (epoch 3), train_loss = 1.301, time/batch=0.134\n",
      "4174/67600 (epoch 3), train_loss = 1.317, time/batch=0.098\n",
      "4175/67600 (epoch 3), train_loss = 1.346, time/batch=0.095\n",
      "4176/67600 (epoch 3), train_loss = 1.311, time/batch=0.072\n",
      "4177/67600 (epoch 3), train_loss = 1.326, time/batch=0.096\n",
      "4178/67600 (epoch 3), train_loss = 1.303, time/batch=0.094\n",
      "4179/67600 (epoch 3), train_loss = 1.299, time/batch=0.073\n",
      "4180/67600 (epoch 3), train_loss = 1.302, time/batch=0.088\n",
      "4181/67600 (epoch 3), train_loss = 1.221, time/batch=0.188\n",
      "4182/67600 (epoch 3), train_loss = 1.319, time/batch=0.065\n",
      "4183/67600 (epoch 3), train_loss = 1.348, time/batch=0.133\n",
      "4184/67600 (epoch 3), train_loss = 1.295, time/batch=0.102\n",
      "4185/67600 (epoch 3), train_loss = 1.296, time/batch=0.095\n",
      "4186/67600 (epoch 3), train_loss = 1.325, time/batch=0.079\n",
      "4187/67600 (epoch 3), train_loss = 1.301, time/batch=0.101\n",
      "4188/67600 (epoch 3), train_loss = 1.364, time/batch=0.096\n",
      "4189/67600 (epoch 3), train_loss = 1.300, time/batch=0.094\n",
      "4190/67600 (epoch 3), train_loss = 1.342, time/batch=0.136\n",
      "4191/67600 (epoch 3), train_loss = 1.319, time/batch=0.190\n",
      "4192/67600 (epoch 3), train_loss = 1.331, time/batch=0.115\n",
      "4193/67600 (epoch 3), train_loss = 1.318, time/batch=0.074\n",
      "4194/67600 (epoch 3), train_loss = 1.323, time/batch=0.082\n",
      "4195/67600 (epoch 3), train_loss = 1.295, time/batch=0.096\n",
      "4196/67600 (epoch 3), train_loss = 1.279, time/batch=0.089\n",
      "4197/67600 (epoch 3), train_loss = 1.257, time/batch=0.069\n",
      "4198/67600 (epoch 3), train_loss = 1.343, time/batch=0.097\n",
      "4199/67600 (epoch 3), train_loss = 1.262, time/batch=0.085\n",
      "4200/67600 (epoch 3), train_loss = 1.337, time/batch=0.243\n",
      "4201/67600 (epoch 3), train_loss = 1.389, time/batch=0.089\n",
      "4202/67600 (epoch 3), train_loss = 1.312, time/batch=0.085\n",
      "4203/67600 (epoch 3), train_loss = 1.316, time/batch=0.071\n",
      "4204/67600 (epoch 3), train_loss = 1.353, time/batch=0.064\n",
      "4205/67600 (epoch 3), train_loss = 1.238, time/batch=0.080\n",
      "4206/67600 (epoch 3), train_loss = 1.320, time/batch=0.069\n",
      "4207/67600 (epoch 3), train_loss = 1.264, time/batch=0.064\n",
      "4208/67600 (epoch 3), train_loss = 1.257, time/batch=0.092\n",
      "4209/67600 (epoch 3), train_loss = 1.306, time/batch=0.091\n",
      "4210/67600 (epoch 3), train_loss = 1.272, time/batch=0.086\n",
      "4211/67600 (epoch 3), train_loss = 1.325, time/batch=0.276\n",
      "4212/67600 (epoch 3), train_loss = 1.342, time/batch=0.080\n",
      "4213/67600 (epoch 3), train_loss = 1.338, time/batch=0.073\n",
      "4214/67600 (epoch 3), train_loss = 1.315, time/batch=0.082\n",
      "4215/67600 (epoch 3), train_loss = 1.289, time/batch=0.079\n",
      "4216/67600 (epoch 3), train_loss = 1.280, time/batch=0.081\n",
      "4217/67600 (epoch 3), train_loss = 1.253, time/batch=0.086\n",
      "4218/67600 (epoch 3), train_loss = 1.319, time/batch=0.148\n",
      "4219/67600 (epoch 3), train_loss = 1.311, time/batch=0.081\n",
      "4220/67600 (epoch 3), train_loss = 1.200, time/batch=0.076\n",
      "4221/67600 (epoch 3), train_loss = 1.312, time/batch=0.067\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4222/67600 (epoch 3), train_loss = 1.300, time/batch=0.074\n",
      "4223/67600 (epoch 3), train_loss = 1.278, time/batch=0.079\n",
      "4224/67600 (epoch 3), train_loss = 1.326, time/batch=0.072\n",
      "4225/67600 (epoch 3), train_loss = 1.329, time/batch=0.071\n",
      "4226/67600 (epoch 3), train_loss = 1.306, time/batch=0.089\n",
      "4227/67600 (epoch 3), train_loss = 1.252, time/batch=0.245\n",
      "4228/67600 (epoch 3), train_loss = 1.338, time/batch=0.079\n",
      "4229/67600 (epoch 3), train_loss = 1.282, time/batch=0.087\n",
      "4230/67600 (epoch 3), train_loss = 1.278, time/batch=0.080\n",
      "4231/67600 (epoch 3), train_loss = 1.294, time/batch=0.075\n",
      "4232/67600 (epoch 3), train_loss = 1.325, time/batch=0.089\n",
      "4233/67600 (epoch 3), train_loss = 1.360, time/batch=0.079\n",
      "4234/67600 (epoch 3), train_loss = 1.277, time/batch=0.074\n",
      "4235/67600 (epoch 3), train_loss = 1.282, time/batch=0.075\n",
      "4236/67600 (epoch 3), train_loss = 1.243, time/batch=0.080\n",
      "4237/67600 (epoch 3), train_loss = 1.244, time/batch=0.069\n",
      "4238/67600 (epoch 3), train_loss = 1.296, time/batch=0.216\n",
      "4239/67600 (epoch 3), train_loss = 1.402, time/batch=0.074\n",
      "4240/67600 (epoch 3), train_loss = 1.410, time/batch=0.080\n",
      "4241/67600 (epoch 3), train_loss = 1.387, time/batch=0.075\n",
      "4242/67600 (epoch 3), train_loss = 1.394, time/batch=0.070\n",
      "4243/67600 (epoch 3), train_loss = 1.317, time/batch=0.076\n",
      "4244/67600 (epoch 3), train_loss = 1.314, time/batch=0.082\n",
      "4245/67600 (epoch 3), train_loss = 1.302, time/batch=0.074\n",
      "4246/67600 (epoch 3), train_loss = 1.370, time/batch=0.073\n",
      "4247/67600 (epoch 3), train_loss = 1.346, time/batch=0.072\n",
      "4248/67600 (epoch 3), train_loss = 1.301, time/batch=0.074\n",
      "4249/67600 (epoch 3), train_loss = 1.323, time/batch=0.082\n",
      "4250/67600 (epoch 3), train_loss = 1.336, time/batch=0.214\n",
      "4251/67600 (epoch 3), train_loss = 1.318, time/batch=0.075\n",
      "4252/67600 (epoch 3), train_loss = 1.298, time/batch=0.071\n",
      "4253/67600 (epoch 3), train_loss = 1.291, time/batch=0.075\n",
      "4254/67600 (epoch 3), train_loss = 1.318, time/batch=0.072\n",
      "4255/67600 (epoch 3), train_loss = 1.273, time/batch=0.074\n",
      "4256/67600 (epoch 3), train_loss = 1.263, time/batch=0.077\n",
      "4257/67600 (epoch 3), train_loss = 1.255, time/batch=0.072\n",
      "4258/67600 (epoch 3), train_loss = 1.356, time/batch=0.195\n",
      "4259/67600 (epoch 3), train_loss = 1.320, time/batch=0.110\n",
      "4260/67600 (epoch 3), train_loss = 1.328, time/batch=0.077\n",
      "4261/67600 (epoch 3), train_loss = 1.234, time/batch=0.072\n",
      "4262/67600 (epoch 3), train_loss = 1.248, time/batch=0.085\n",
      "4263/67600 (epoch 3), train_loss = 1.276, time/batch=0.074\n",
      "4264/67600 (epoch 3), train_loss = 1.333, time/batch=0.075\n",
      "4265/67600 (epoch 3), train_loss = 1.355, time/batch=0.074\n",
      "4266/67600 (epoch 3), train_loss = 1.324, time/batch=0.070\n",
      "4267/67600 (epoch 3), train_loss = 1.386, time/batch=0.074\n",
      "4268/67600 (epoch 3), train_loss = 1.284, time/batch=0.070\n",
      "4269/67600 (epoch 3), train_loss = 1.287, time/batch=0.196\n",
      "4270/67600 (epoch 3), train_loss = 1.315, time/batch=0.083\n",
      "4271/67600 (epoch 3), train_loss = 1.341, time/batch=0.118\n",
      "4272/67600 (epoch 3), train_loss = 1.284, time/batch=0.077\n",
      "4273/67600 (epoch 3), train_loss = 1.289, time/batch=0.093\n",
      "4274/67600 (epoch 3), train_loss = 1.267, time/batch=0.076\n",
      "4275/67600 (epoch 3), train_loss = 1.279, time/batch=0.079\n",
      "4276/67600 (epoch 3), train_loss = 1.371, time/batch=0.077\n",
      "4277/67600 (epoch 3), train_loss = 1.279, time/batch=0.073\n",
      "4278/67600 (epoch 3), train_loss = 1.294, time/batch=0.075\n",
      "4279/67600 (epoch 3), train_loss = 1.297, time/batch=0.077\n",
      "4280/67600 (epoch 3), train_loss = 1.312, time/batch=0.212\n",
      "4281/67600 (epoch 3), train_loss = 1.302, time/batch=0.110\n",
      "4282/67600 (epoch 3), train_loss = 1.344, time/batch=0.071\n",
      "4283/67600 (epoch 3), train_loss = 1.270, time/batch=0.066\n",
      "4284/67600 (epoch 3), train_loss = 1.292, time/batch=0.066\n",
      "4285/67600 (epoch 3), train_loss = 1.274, time/batch=0.066\n",
      "4286/67600 (epoch 3), train_loss = 1.303, time/batch=0.064\n",
      "4287/67600 (epoch 3), train_loss = 1.317, time/batch=0.078\n",
      "4288/67600 (epoch 3), train_loss = 1.249, time/batch=0.104\n",
      "4289/67600 (epoch 3), train_loss = 1.238, time/batch=0.106\n",
      "4290/67600 (epoch 3), train_loss = 1.327, time/batch=0.236\n",
      "4291/67600 (epoch 3), train_loss = 1.304, time/batch=0.077\n",
      "4292/67600 (epoch 3), train_loss = 1.286, time/batch=0.094\n",
      "4293/67600 (epoch 3), train_loss = 1.281, time/batch=0.081\n",
      "4294/67600 (epoch 3), train_loss = 1.348, time/batch=0.075\n",
      "4295/67600 (epoch 3), train_loss = 1.322, time/batch=0.075\n",
      "4296/67600 (epoch 3), train_loss = 1.325, time/batch=0.080\n",
      "4297/67600 (epoch 3), train_loss = 1.255, time/batch=0.076\n",
      "4298/67600 (epoch 3), train_loss = 1.305, time/batch=0.077\n",
      "4299/67600 (epoch 3), train_loss = 1.310, time/batch=0.078\n",
      "4300/67600 (epoch 3), train_loss = 1.254, time/batch=0.077\n",
      "4301/67600 (epoch 3), train_loss = 1.307, time/batch=0.238\n",
      "4302/67600 (epoch 3), train_loss = 1.292, time/batch=0.082\n",
      "4303/67600 (epoch 3), train_loss = 1.306, time/batch=0.075\n",
      "4304/67600 (epoch 3), train_loss = 1.325, time/batch=0.076\n",
      "4305/67600 (epoch 3), train_loss = 1.269, time/batch=0.075\n",
      "4306/67600 (epoch 3), train_loss = 1.267, time/batch=0.080\n",
      "4307/67600 (epoch 3), train_loss = 1.356, time/batch=0.079\n",
      "4308/67600 (epoch 3), train_loss = 1.287, time/batch=0.070\n",
      "4309/67600 (epoch 3), train_loss = 1.300, time/batch=0.175\n",
      "4310/67600 (epoch 3), train_loss = 1.324, time/batch=0.076\n",
      "4311/67600 (epoch 3), train_loss = 1.363, time/batch=0.114\n",
      "4312/67600 (epoch 3), train_loss = 1.331, time/batch=0.078\n",
      "4313/67600 (epoch 3), train_loss = 1.338, time/batch=0.078\n",
      "4314/67600 (epoch 3), train_loss = 1.252, time/batch=0.078\n",
      "4315/67600 (epoch 3), train_loss = 1.257, time/batch=0.079\n",
      "4316/67600 (epoch 3), train_loss = 1.272, time/batch=0.079\n",
      "4317/67600 (epoch 3), train_loss = 1.283, time/batch=0.075\n",
      "4318/67600 (epoch 3), train_loss = 1.286, time/batch=0.072\n",
      "4319/67600 (epoch 3), train_loss = 1.321, time/batch=0.093\n",
      "4320/67600 (epoch 3), train_loss = 1.279, time/batch=0.193\n",
      "4321/67600 (epoch 3), train_loss = 1.280, time/batch=0.077\n",
      "4322/67600 (epoch 3), train_loss = 1.260, time/batch=0.112\n",
      "4323/67600 (epoch 3), train_loss = 1.314, time/batch=0.079\n",
      "4324/67600 (epoch 3), train_loss = 1.257, time/batch=0.077\n",
      "4325/67600 (epoch 3), train_loss = 1.281, time/batch=0.069\n",
      "4326/67600 (epoch 3), train_loss = 1.343, time/batch=0.095\n",
      "4327/67600 (epoch 3), train_loss = 1.294, time/batch=0.080\n",
      "4328/67600 (epoch 3), train_loss = 1.320, time/batch=0.073\n",
      "4329/67600 (epoch 3), train_loss = 1.352, time/batch=0.094\n",
      "4330/67600 (epoch 3), train_loss = 1.310, time/batch=0.237\n",
      "4331/67600 (epoch 3), train_loss = 1.311, time/batch=0.136\n",
      "4332/67600 (epoch 3), train_loss = 1.322, time/batch=0.085\n",
      "4333/67600 (epoch 3), train_loss = 1.269, time/batch=0.070\n",
      "4334/67600 (epoch 3), train_loss = 1.261, time/batch=0.070\n",
      "4335/67600 (epoch 3), train_loss = 1.338, time/batch=0.073\n",
      "4336/67600 (epoch 3), train_loss = 1.358, time/batch=0.070\n",
      "4337/67600 (epoch 3), train_loss = 1.295, time/batch=0.069\n",
      "4338/67600 (epoch 3), train_loss = 1.242, time/batch=0.077\n",
      "4339/67600 (epoch 3), train_loss = 1.323, time/batch=0.072\n",
      "4340/67600 (epoch 3), train_loss = 1.286, time/batch=0.068\n",
      "4341/67600 (epoch 3), train_loss = 1.387, time/batch=0.154\n",
      "4342/67600 (epoch 3), train_loss = 1.324, time/batch=0.112\n",
      "4343/67600 (epoch 3), train_loss = 1.312, time/batch=0.091\n",
      "4344/67600 (epoch 3), train_loss = 1.340, time/batch=0.074\n",
      "4345/67600 (epoch 3), train_loss = 1.338, time/batch=0.090\n",
      "4346/67600 (epoch 3), train_loss = 1.326, time/batch=0.073\n",
      "4347/67600 (epoch 3), train_loss = 1.315, time/batch=0.072\n",
      "4348/67600 (epoch 3), train_loss = 1.317, time/batch=0.074\n",
      "4349/67600 (epoch 3), train_loss = 1.308, time/batch=0.073\n",
      "4350/67600 (epoch 3), train_loss = 1.315, time/batch=0.070\n",
      "4351/67600 (epoch 3), train_loss = 1.340, time/batch=0.072\n",
      "4352/67600 (epoch 3), train_loss = 1.329, time/batch=0.076\n",
      "4353/67600 (epoch 3), train_loss = 1.278, time/batch=0.212\n",
      "4354/67600 (epoch 3), train_loss = 1.298, time/batch=0.087\n",
      "4355/67600 (epoch 3), train_loss = 1.338, time/batch=0.070\n",
      "4356/67600 (epoch 3), train_loss = 1.319, time/batch=0.073\n",
      "4357/67600 (epoch 3), train_loss = 1.334, time/batch=0.072\n",
      "4358/67600 (epoch 3), train_loss = 1.298, time/batch=0.069\n",
      "4359/67600 (epoch 3), train_loss = 1.317, time/batch=0.074\n",
      "4360/67600 (epoch 3), train_loss = 1.333, time/batch=0.071\n",
      "4361/67600 (epoch 3), train_loss = 1.338, time/batch=0.070\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4362/67600 (epoch 3), train_loss = 1.355, time/batch=0.071\n",
      "4363/67600 (epoch 3), train_loss = 1.333, time/batch=0.070\n",
      "4364/67600 (epoch 3), train_loss = 1.351, time/batch=0.074\n",
      "4365/67600 (epoch 3), train_loss = 1.337, time/batch=0.214\n",
      "4366/67600 (epoch 3), train_loss = 1.314, time/batch=0.084\n",
      "4367/67600 (epoch 3), train_loss = 1.271, time/batch=0.071\n",
      "4368/67600 (epoch 3), train_loss = 1.281, time/batch=0.076\n",
      "4369/67600 (epoch 3), train_loss = 1.327, time/batch=0.073\n",
      "4370/67600 (epoch 3), train_loss = 1.292, time/batch=0.070\n",
      "4371/67600 (epoch 3), train_loss = 1.388, time/batch=0.074\n",
      "4372/67600 (epoch 3), train_loss = 1.303, time/batch=0.071\n",
      "4373/67600 (epoch 3), train_loss = 1.309, time/batch=0.116\n",
      "4374/67600 (epoch 3), train_loss = 1.326, time/batch=0.073\n",
      "4375/67600 (epoch 3), train_loss = 1.337, time/batch=0.070\n",
      "4376/67600 (epoch 3), train_loss = 1.360, time/batch=0.071\n",
      "4377/67600 (epoch 3), train_loss = 1.300, time/batch=0.073\n",
      "4378/67600 (epoch 3), train_loss = 1.306, time/batch=0.070\n",
      "4379/67600 (epoch 3), train_loss = 1.282, time/batch=0.071\n",
      "4380/67600 (epoch 3), train_loss = 1.308, time/batch=0.071\n",
      "4381/67600 (epoch 3), train_loss = 1.283, time/batch=0.070\n",
      "4382/67600 (epoch 3), train_loss = 1.271, time/batch=0.075\n",
      "4383/67600 (epoch 3), train_loss = 1.319, time/batch=0.234\n",
      "4384/67600 (epoch 3), train_loss = 1.293, time/batch=0.069\n",
      "4385/67600 (epoch 3), train_loss = 1.315, time/batch=0.086\n",
      "4386/67600 (epoch 3), train_loss = 1.339, time/batch=0.074\n",
      "4387/67600 (epoch 3), train_loss = 1.246, time/batch=0.074\n",
      "4388/67600 (epoch 3), train_loss = 1.316, time/batch=0.069\n",
      "4389/67600 (epoch 3), train_loss = 1.287, time/batch=0.071\n",
      "4390/67600 (epoch 3), train_loss = 1.305, time/batch=0.073\n",
      "4391/67600 (epoch 3), train_loss = 1.350, time/batch=0.070\n",
      "4392/67600 (epoch 3), train_loss = 1.298, time/batch=0.073\n",
      "4393/67600 (epoch 3), train_loss = 1.283, time/batch=0.072\n",
      "4394/67600 (epoch 3), train_loss = 1.318, time/batch=0.072\n",
      "4395/67600 (epoch 3), train_loss = 1.330, time/batch=0.232\n",
      "4396/67600 (epoch 3), train_loss = 1.287, time/batch=0.082\n",
      "4397/67600 (epoch 3), train_loss = 1.299, time/batch=0.070\n",
      "4398/67600 (epoch 3), train_loss = 1.279, time/batch=0.075\n",
      "4399/67600 (epoch 3), train_loss = 1.270, time/batch=0.074\n",
      "4400/67600 (epoch 3), train_loss = 1.362, time/batch=0.073\n",
      "4401/67600 (epoch 3), train_loss = 1.378, time/batch=0.070\n",
      "4402/67600 (epoch 3), train_loss = 1.297, time/batch=0.073\n",
      "4403/67600 (epoch 3), train_loss = 1.312, time/batch=0.171\n",
      "4404/67600 (epoch 3), train_loss = 1.357, time/batch=0.078\n",
      "4405/67600 (epoch 3), train_loss = 1.360, time/batch=0.101\n",
      "4406/67600 (epoch 3), train_loss = 1.272, time/batch=0.070\n",
      "4407/67600 (epoch 3), train_loss = 1.248, time/batch=0.072\n",
      "4408/67600 (epoch 3), train_loss = 1.235, time/batch=0.090\n",
      "4409/67600 (epoch 3), train_loss = 1.284, time/batch=0.067\n",
      "4410/67600 (epoch 3), train_loss = 1.279, time/batch=0.068\n",
      "4411/67600 (epoch 3), train_loss = 1.355, time/batch=0.070\n",
      "4412/67600 (epoch 3), train_loss = 1.270, time/batch=0.070\n",
      "4413/67600 (epoch 3), train_loss = 1.287, time/batch=0.070\n",
      "4414/67600 (epoch 3), train_loss = 1.252, time/batch=0.073\n",
      "4415/67600 (epoch 3), train_loss = 1.397, time/batch=0.176\n",
      "4416/67600 (epoch 3), train_loss = 1.307, time/batch=0.077\n",
      "4417/67600 (epoch 3), train_loss = 1.255, time/batch=0.111\n",
      "4418/67600 (epoch 3), train_loss = 1.265, time/batch=0.073\n",
      "4419/67600 (epoch 3), train_loss = 1.359, time/batch=0.080\n",
      "4420/67600 (epoch 3), train_loss = 1.304, time/batch=0.078\n",
      "4421/67600 (epoch 3), train_loss = 1.288, time/batch=0.072\n",
      "4422/67600 (epoch 3), train_loss = 1.306, time/batch=0.070\n",
      "4423/67600 (epoch 3), train_loss = 1.254, time/batch=0.071\n",
      "4424/67600 (epoch 3), train_loss = 1.288, time/batch=0.072\n",
      "4425/67600 (epoch 3), train_loss = 1.366, time/batch=0.068\n",
      "4426/67600 (epoch 3), train_loss = 1.291, time/batch=0.076\n",
      "4427/67600 (epoch 3), train_loss = 1.311, time/batch=0.183\n",
      "4428/67600 (epoch 3), train_loss = 1.328, time/batch=0.071\n",
      "4429/67600 (epoch 3), train_loss = 1.302, time/batch=0.114\n",
      "4430/67600 (epoch 3), train_loss = 1.377, time/batch=0.071\n",
      "4431/67600 (epoch 3), train_loss = 1.386, time/batch=0.070\n",
      "4432/67600 (epoch 3), train_loss = 1.321, time/batch=0.071\n",
      "4433/67600 (epoch 3), train_loss = 1.311, time/batch=0.070\n",
      "4434/67600 (epoch 3), train_loss = 1.360, time/batch=0.069\n",
      "4435/67600 (epoch 3), train_loss = 1.390, time/batch=0.073\n",
      "4436/67600 (epoch 3), train_loss = 1.333, time/batch=0.071\n",
      "4437/67600 (epoch 3), train_loss = 1.307, time/batch=0.069\n",
      "4438/67600 (epoch 3), train_loss = 1.309, time/batch=0.071\n",
      "4439/67600 (epoch 3), train_loss = 1.346, time/batch=0.189\n",
      "4440/67600 (epoch 3), train_loss = 1.401, time/batch=0.071\n",
      "4441/67600 (epoch 3), train_loss = 1.313, time/batch=0.100\n",
      "4442/67600 (epoch 3), train_loss = 1.293, time/batch=0.069\n",
      "4443/67600 (epoch 3), train_loss = 1.295, time/batch=0.074\n",
      "4444/67600 (epoch 3), train_loss = 1.346, time/batch=0.075\n",
      "4445/67600 (epoch 3), train_loss = 1.318, time/batch=0.072\n",
      "4446/67600 (epoch 3), train_loss = 1.296, time/batch=0.075\n",
      "4447/67600 (epoch 3), train_loss = 1.299, time/batch=0.075\n",
      "4448/67600 (epoch 3), train_loss = 1.294, time/batch=0.072\n",
      "4449/67600 (epoch 3), train_loss = 1.323, time/batch=0.071\n",
      "4450/67600 (epoch 3), train_loss = 1.300, time/batch=0.071\n",
      "4451/67600 (epoch 3), train_loss = 1.293, time/batch=0.214\n",
      "4452/67600 (epoch 3), train_loss = 1.356, time/batch=0.093\n",
      "4453/67600 (epoch 3), train_loss = 1.357, time/batch=0.072\n",
      "4454/67600 (epoch 3), train_loss = 1.303, time/batch=0.067\n",
      "4455/67600 (epoch 3), train_loss = 1.296, time/batch=0.070\n",
      "4456/67600 (epoch 3), train_loss = 1.340, time/batch=0.070\n",
      "4457/67600 (epoch 3), train_loss = 1.383, time/batch=0.067\n",
      "4458/67600 (epoch 3), train_loss = 1.374, time/batch=0.071\n",
      "4459/67600 (epoch 3), train_loss = 1.326, time/batch=0.070\n",
      "4460/67600 (epoch 3), train_loss = 1.413, time/batch=0.068\n",
      "4461/67600 (epoch 3), train_loss = 1.357, time/batch=0.076\n",
      "4462/67600 (epoch 3), train_loss = 1.371, time/batch=0.086\n",
      "4463/67600 (epoch 3), train_loss = 1.300, time/batch=0.197\n",
      "4464/67600 (epoch 3), train_loss = 1.342, time/batch=0.083\n",
      "4465/67600 (epoch 3), train_loss = 1.345, time/batch=0.071\n",
      "4466/67600 (epoch 3), train_loss = 1.335, time/batch=0.071\n",
      "4467/67600 (epoch 3), train_loss = 1.290, time/batch=0.072\n",
      "4468/67600 (epoch 3), train_loss = 1.297, time/batch=0.073\n",
      "4469/67600 (epoch 3), train_loss = 1.318, time/batch=0.069\n",
      "4470/67600 (epoch 3), train_loss = 1.308, time/batch=0.071\n",
      "4471/67600 (epoch 3), train_loss = 1.351, time/batch=0.171\n",
      "4472/67600 (epoch 3), train_loss = 1.316, time/batch=0.070\n",
      "4473/67600 (epoch 3), train_loss = 1.353, time/batch=0.112\n",
      "4474/67600 (epoch 3), train_loss = 1.350, time/batch=0.070\n",
      "4475/67600 (epoch 3), train_loss = 1.307, time/batch=0.071\n",
      "4476/67600 (epoch 3), train_loss = 1.245, time/batch=0.078\n",
      "4477/67600 (epoch 3), train_loss = 1.258, time/batch=0.070\n",
      "4478/67600 (epoch 3), train_loss = 1.300, time/batch=0.068\n",
      "4479/67600 (epoch 3), train_loss = 1.271, time/batch=0.070\n",
      "4480/67600 (epoch 3), train_loss = 1.314, time/batch=0.071\n",
      "4481/67600 (epoch 3), train_loss = 1.280, time/batch=0.069\n",
      "4482/67600 (epoch 3), train_loss = 1.308, time/batch=0.071\n",
      "4483/67600 (epoch 3), train_loss = 1.296, time/batch=0.184\n",
      "4484/67600 (epoch 3), train_loss = 1.220, time/batch=0.078\n",
      "4485/67600 (epoch 3), train_loss = 1.285, time/batch=0.106\n",
      "4486/67600 (epoch 3), train_loss = 1.360, time/batch=0.072\n",
      "4487/67600 (epoch 3), train_loss = 1.265, time/batch=0.072\n",
      "4488/67600 (epoch 3), train_loss = 1.328, time/batch=0.074\n",
      "4489/67600 (epoch 3), train_loss = 1.335, time/batch=0.071\n",
      "4490/67600 (epoch 3), train_loss = 1.274, time/batch=0.075\n",
      "4491/67600 (epoch 3), train_loss = 1.368, time/batch=0.070\n",
      "4492/67600 (epoch 3), train_loss = 1.299, time/batch=0.073\n",
      "4493/67600 (epoch 3), train_loss = 1.312, time/batch=0.068\n",
      "4494/67600 (epoch 3), train_loss = 1.324, time/batch=0.070\n",
      "4495/67600 (epoch 3), train_loss = 1.299, time/batch=0.197\n",
      "4496/67600 (epoch 3), train_loss = 1.291, time/batch=0.076\n",
      "4497/67600 (epoch 3), train_loss = 1.326, time/batch=0.113\n",
      "4498/67600 (epoch 3), train_loss = 1.286, time/batch=0.077\n",
      "4499/67600 (epoch 3), train_loss = 1.277, time/batch=0.070\n",
      "4500/67600 (epoch 3), train_loss = 1.300, time/batch=0.070\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saved to ./save/model.ckpt\n",
      "4501/67600 (epoch 3), train_loss = 1.346, time/batch=0.070\n",
      "4502/67600 (epoch 3), train_loss = 1.260, time/batch=0.071\n",
      "4503/67600 (epoch 3), train_loss = 1.277, time/batch=0.070\n",
      "4504/67600 (epoch 3), train_loss = 1.251, time/batch=0.071\n",
      "4505/67600 (epoch 3), train_loss = 1.287, time/batch=0.078\n",
      "4506/67600 (epoch 3), train_loss = 1.231, time/batch=0.214\n",
      "4507/67600 (epoch 3), train_loss = 1.340, time/batch=0.072\n",
      "4508/67600 (epoch 3), train_loss = 1.342, time/batch=0.068\n",
      "4509/67600 (epoch 3), train_loss = 1.241, time/batch=0.070\n",
      "4510/67600 (epoch 3), train_loss = 1.225, time/batch=0.078\n",
      "4511/67600 (epoch 3), train_loss = 1.266, time/batch=0.071\n",
      "4512/67600 (epoch 3), train_loss = 1.283, time/batch=0.070\n",
      "4513/67600 (epoch 3), train_loss = 1.311, time/batch=0.070\n",
      "4514/67600 (epoch 3), train_loss = 1.328, time/batch=0.114\n",
      "4515/67600 (epoch 3), train_loss = 1.307, time/batch=0.074\n",
      "4516/67600 (epoch 3), train_loss = 1.307, time/batch=0.069\n",
      "4517/67600 (epoch 3), train_loss = 1.265, time/batch=0.070\n",
      "4518/67600 (epoch 3), train_loss = 1.338, time/batch=0.076\n",
      "4519/67600 (epoch 3), train_loss = 1.309, time/batch=0.075\n",
      "4520/67600 (epoch 3), train_loss = 1.261, time/batch=0.070\n",
      "4521/67600 (epoch 3), train_loss = 1.276, time/batch=0.073\n",
      "4522/67600 (epoch 3), train_loss = 1.294, time/batch=0.071\n",
      "4523/67600 (epoch 3), train_loss = 1.362, time/batch=0.069\n",
      "4524/67600 (epoch 3), train_loss = 1.304, time/batch=0.267\n",
      "4525/67600 (epoch 3), train_loss = 1.275, time/batch=0.099\n",
      "4526/67600 (epoch 3), train_loss = 1.295, time/batch=0.077\n",
      "4527/67600 (epoch 3), train_loss = 1.292, time/batch=0.073\n",
      "4528/67600 (epoch 3), train_loss = 1.263, time/batch=0.070\n",
      "4529/67600 (epoch 3), train_loss = 1.306, time/batch=0.072\n",
      "4530/67600 (epoch 3), train_loss = 1.279, time/batch=0.082\n",
      "4531/67600 (epoch 3), train_loss = 1.252, time/batch=0.073\n",
      "4532/67600 (epoch 3), train_loss = 1.319, time/batch=0.068\n",
      "4533/67600 (epoch 3), train_loss = 1.263, time/batch=0.074\n",
      "4534/67600 (epoch 3), train_loss = 1.291, time/batch=0.072\n",
      "4535/67600 (epoch 3), train_loss = 1.300, time/batch=0.146\n",
      "4536/67600 (epoch 3), train_loss = 1.244, time/batch=0.140\n",
      "4537/67600 (epoch 3), train_loss = 1.298, time/batch=0.082\n",
      "4538/67600 (epoch 3), train_loss = 1.289, time/batch=0.072\n",
      "4539/67600 (epoch 3), train_loss = 1.252, time/batch=0.073\n",
      "4540/67600 (epoch 3), train_loss = 1.323, time/batch=0.073\n",
      "4541/67600 (epoch 3), train_loss = 1.311, time/batch=0.071\n",
      "4542/67600 (epoch 3), train_loss = 1.336, time/batch=0.069\n",
      "4543/67600 (epoch 3), train_loss = 1.306, time/batch=0.080\n",
      "4544/67600 (epoch 3), train_loss = 1.371, time/batch=0.068\n",
      "4545/67600 (epoch 3), train_loss = 1.327, time/batch=0.068\n",
      "4546/67600 (epoch 3), train_loss = 1.249, time/batch=0.071\n",
      "4547/67600 (epoch 3), train_loss = 1.294, time/batch=0.168\n",
      "4548/67600 (epoch 3), train_loss = 1.320, time/batch=0.113\n",
      "4549/67600 (epoch 3), train_loss = 1.279, time/batch=0.075\n",
      "4550/67600 (epoch 3), train_loss = 1.351, time/batch=0.071\n",
      "4551/67600 (epoch 3), train_loss = 1.325, time/batch=0.073\n",
      "4552/67600 (epoch 3), train_loss = 1.283, time/batch=0.070\n",
      "4553/67600 (epoch 3), train_loss = 1.312, time/batch=0.071\n",
      "4554/67600 (epoch 3), train_loss = 1.349, time/batch=0.073\n",
      "4555/67600 (epoch 3), train_loss = 1.291, time/batch=0.072\n",
      "4556/67600 (epoch 3), train_loss = 1.239, time/batch=0.181\n",
      "4557/67600 (epoch 3), train_loss = 1.243, time/batch=0.072\n",
      "4558/67600 (epoch 3), train_loss = 1.283, time/batch=0.109\n",
      "4559/67600 (epoch 3), train_loss = 1.325, time/batch=0.076\n",
      "4560/67600 (epoch 3), train_loss = 1.321, time/batch=0.070\n",
      "4561/67600 (epoch 3), train_loss = 1.352, time/batch=0.075\n",
      "4562/67600 (epoch 3), train_loss = 1.324, time/batch=0.075\n",
      "4563/67600 (epoch 3), train_loss = 1.318, time/batch=0.072\n",
      "4564/67600 (epoch 3), train_loss = 1.242, time/batch=0.069\n",
      "4565/67600 (epoch 3), train_loss = 1.275, time/batch=0.077\n",
      "4566/67600 (epoch 3), train_loss = 1.339, time/batch=0.072\n",
      "4567/67600 (epoch 3), train_loss = 1.297, time/batch=0.097\n",
      "4568/67600 (epoch 3), train_loss = 1.314, time/batch=0.154\n",
      "4569/67600 (epoch 3), train_loss = 1.279, time/batch=0.109\n",
      "4570/67600 (epoch 3), train_loss = 1.308, time/batch=0.074\n",
      "4571/67600 (epoch 3), train_loss = 1.349, time/batch=0.073\n",
      "4572/67600 (epoch 3), train_loss = 1.349, time/batch=0.079\n",
      "4573/67600 (epoch 3), train_loss = 1.332, time/batch=0.069\n",
      "4574/67600 (epoch 3), train_loss = 1.305, time/batch=0.072\n",
      "4575/67600 (epoch 3), train_loss = 1.231, time/batch=0.072\n",
      "4576/67600 (epoch 3), train_loss = 1.343, time/batch=0.074\n",
      "4577/67600 (epoch 3), train_loss = 1.343, time/batch=0.071\n",
      "4578/67600 (epoch 3), train_loss = 1.360, time/batch=0.073\n",
      "4579/67600 (epoch 3), train_loss = 1.300, time/batch=0.192\n",
      "4580/67600 (epoch 3), train_loss = 1.306, time/batch=0.075\n",
      "4581/67600 (epoch 3), train_loss = 1.301, time/batch=0.100\n",
      "4582/67600 (epoch 3), train_loss = 1.326, time/batch=0.077\n",
      "4583/67600 (epoch 3), train_loss = 1.273, time/batch=0.071\n",
      "4584/67600 (epoch 3), train_loss = 1.329, time/batch=0.074\n",
      "4585/67600 (epoch 3), train_loss = 1.293, time/batch=0.072\n",
      "4586/67600 (epoch 3), train_loss = 1.352, time/batch=0.070\n",
      "4587/67600 (epoch 3), train_loss = 1.361, time/batch=0.075\n",
      "4588/67600 (epoch 3), train_loss = 1.317, time/batch=0.077\n",
      "4589/67600 (epoch 3), train_loss = 1.278, time/batch=0.069\n",
      "4590/67600 (epoch 3), train_loss = 1.279, time/batch=0.069\n",
      "4591/67600 (epoch 3), train_loss = 1.262, time/batch=0.199\n",
      "4592/67600 (epoch 3), train_loss = 1.277, time/batch=0.072\n",
      "4593/67600 (epoch 3), train_loss = 1.311, time/batch=0.088\n",
      "4594/67600 (epoch 3), train_loss = 1.295, time/batch=0.071\n",
      "4595/67600 (epoch 3), train_loss = 1.307, time/batch=0.069\n",
      "4596/67600 (epoch 3), train_loss = 1.312, time/batch=0.072\n",
      "4597/67600 (epoch 3), train_loss = 1.242, time/batch=0.069\n",
      "4598/67600 (epoch 3), train_loss = 1.283, time/batch=0.070\n",
      "4599/67600 (epoch 3), train_loss = 1.256, time/batch=0.073\n",
      "4600/67600 (epoch 3), train_loss = 1.336, time/batch=0.083\n",
      "4601/67600 (epoch 3), train_loss = 1.301, time/batch=0.069\n",
      "4602/67600 (epoch 3), train_loss = 1.277, time/batch=0.070\n",
      "4603/67600 (epoch 3), train_loss = 1.297, time/batch=0.209\n",
      "4604/67600 (epoch 3), train_loss = 1.430, time/batch=0.076\n",
      "4605/67600 (epoch 3), train_loss = 1.326, time/batch=0.074\n",
      "4606/67600 (epoch 3), train_loss = 1.284, time/batch=0.072\n",
      "4607/67600 (epoch 3), train_loss = 1.340, time/batch=0.070\n",
      "4608/67600 (epoch 3), train_loss = 1.272, time/batch=0.072\n",
      "4609/67600 (epoch 3), train_loss = 1.291, time/batch=0.069\n",
      "4610/67600 (epoch 3), train_loss = 1.342, time/batch=0.068\n",
      "4611/67600 (epoch 3), train_loss = 1.280, time/batch=0.107\n",
      "4612/67600 (epoch 3), train_loss = 1.346, time/batch=0.137\n",
      "4613/67600 (epoch 3), train_loss = 1.290, time/batch=0.091\n",
      "4614/67600 (epoch 3), train_loss = 1.262, time/batch=0.084\n",
      "4615/67600 (epoch 3), train_loss = 1.241, time/batch=0.074\n",
      "4616/67600 (epoch 3), train_loss = 1.258, time/batch=0.074\n",
      "4617/67600 (epoch 3), train_loss = 1.286, time/batch=0.073\n",
      "4618/67600 (epoch 3), train_loss = 1.256, time/batch=0.072\n",
      "4619/67600 (epoch 3), train_loss = 1.299, time/batch=0.073\n",
      "4620/67600 (epoch 3), train_loss = 1.259, time/batch=0.070\n",
      "4621/67600 (epoch 3), train_loss = 1.274, time/batch=0.072\n",
      "4622/67600 (epoch 3), train_loss = 1.318, time/batch=0.072\n",
      "4623/67600 (epoch 3), train_loss = 1.334, time/batch=0.091\n",
      "4624/67600 (epoch 3), train_loss = 1.321, time/batch=0.160\n",
      "4625/67600 (epoch 3), train_loss = 1.279, time/batch=0.101\n",
      "4626/67600 (epoch 3), train_loss = 1.270, time/batch=0.075\n",
      "4627/67600 (epoch 3), train_loss = 1.254, time/batch=0.074\n",
      "4628/67600 (epoch 3), train_loss = 1.290, time/batch=0.072\n",
      "4629/67600 (epoch 3), train_loss = 1.289, time/batch=0.077\n",
      "4630/67600 (epoch 3), train_loss = 1.299, time/batch=0.072\n",
      "4631/67600 (epoch 3), train_loss = 1.277, time/batch=0.074\n",
      "4632/67600 (epoch 3), train_loss = 1.324, time/batch=0.071\n",
      "4633/67600 (epoch 3), train_loss = 1.309, time/batch=0.071\n",
      "4634/67600 (epoch 3), train_loss = 1.330, time/batch=0.071\n",
      "4635/67600 (epoch 3), train_loss = 1.296, time/batch=0.175\n",
      "4636/67600 (epoch 3), train_loss = 1.310, time/batch=0.086\n",
      "4637/67600 (epoch 3), train_loss = 1.307, time/batch=0.103\n",
      "4638/67600 (epoch 3), train_loss = 1.268, time/batch=0.070\n",
      "4639/67600 (epoch 3), train_loss = 1.265, time/batch=0.070\n",
      "4640/67600 (epoch 3), train_loss = 1.295, time/batch=0.074\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4641/67600 (epoch 3), train_loss = 1.358, time/batch=0.071\n",
      "4642/67600 (epoch 3), train_loss = 1.268, time/batch=0.068\n",
      "4643/67600 (epoch 3), train_loss = 1.351, time/batch=0.086\n",
      "4644/67600 (epoch 3), train_loss = 1.266, time/batch=0.075\n",
      "4645/67600 (epoch 3), train_loss = 1.304, time/batch=0.069\n",
      "4646/67600 (epoch 3), train_loss = 1.364, time/batch=0.071\n",
      "4647/67600 (epoch 3), train_loss = 1.268, time/batch=0.199\n",
      "4648/67600 (epoch 3), train_loss = 1.275, time/batch=0.074\n",
      "4649/67600 (epoch 3), train_loss = 1.299, time/batch=0.085\n",
      "4650/67600 (epoch 3), train_loss = 1.242, time/batch=0.076\n",
      "4651/67600 (epoch 3), train_loss = 1.294, time/batch=0.072\n",
      "4652/67600 (epoch 3), train_loss = 1.303, time/batch=0.071\n",
      "4653/67600 (epoch 3), train_loss = 1.270, time/batch=0.071\n",
      "4654/67600 (epoch 3), train_loss = 1.275, time/batch=0.070\n",
      "4655/67600 (epoch 3), train_loss = 1.267, time/batch=0.073\n",
      "4656/67600 (epoch 3), train_loss = 1.323, time/batch=0.070\n",
      "4657/67600 (epoch 3), train_loss = 1.245, time/batch=0.069\n",
      "4658/67600 (epoch 3), train_loss = 1.291, time/batch=0.072\n",
      "4659/67600 (epoch 3), train_loss = 1.284, time/batch=0.232\n",
      "4660/67600 (epoch 3), train_loss = 1.339, time/batch=0.083\n",
      "4661/67600 (epoch 3), train_loss = 1.271, time/batch=0.074\n",
      "4662/67600 (epoch 3), train_loss = 1.345, time/batch=0.069\n",
      "4663/67600 (epoch 3), train_loss = 1.267, time/batch=0.071\n",
      "4664/67600 (epoch 3), train_loss = 1.363, time/batch=0.070\n",
      "4665/67600 (epoch 3), train_loss = 1.302, time/batch=0.070\n",
      "4666/67600 (epoch 3), train_loss = 1.301, time/batch=0.069\n",
      "4667/67600 (epoch 3), train_loss = 1.388, time/batch=0.069\n",
      "4668/67600 (epoch 3), train_loss = 1.292, time/batch=0.070\n",
      "4669/67600 (epoch 3), train_loss = 1.285, time/batch=0.070\n",
      "4670/67600 (epoch 3), train_loss = 1.308, time/batch=0.070\n",
      "4671/67600 (epoch 3), train_loss = 1.354, time/batch=0.227\n",
      "4672/67600 (epoch 3), train_loss = 1.321, time/batch=0.070\n",
      "4673/67600 (epoch 3), train_loss = 1.385, time/batch=0.069\n",
      "4674/67600 (epoch 3), train_loss = 1.295, time/batch=0.073\n",
      "4675/67600 (epoch 3), train_loss = 1.256, time/batch=0.068\n",
      "4676/67600 (epoch 3), train_loss = 1.259, time/batch=0.072\n",
      "4677/67600 (epoch 3), train_loss = 1.303, time/batch=0.075\n",
      "4678/67600 (epoch 3), train_loss = 1.315, time/batch=0.072\n",
      "4679/67600 (epoch 3), train_loss = 1.260, time/batch=0.117\n",
      "4680/67600 (epoch 3), train_loss = 1.299, time/batch=0.071\n",
      "4681/67600 (epoch 3), train_loss = 1.290, time/batch=0.073\n",
      "4682/67600 (epoch 3), train_loss = 1.325, time/batch=0.074\n",
      "4683/67600 (epoch 3), train_loss = 1.351, time/batch=0.071\n",
      "4684/67600 (epoch 3), train_loss = 1.331, time/batch=0.070\n",
      "4685/67600 (epoch 3), train_loss = 1.286, time/batch=0.070\n",
      "4686/67600 (epoch 3), train_loss = 1.333, time/batch=0.072\n",
      "4687/67600 (epoch 3), train_loss = 1.367, time/batch=0.070\n",
      "4688/67600 (epoch 3), train_loss = 1.275, time/batch=0.070\n",
      "4689/67600 (epoch 3), train_loss = 1.369, time/batch=0.184\n",
      "4690/67600 (epoch 3), train_loss = 1.362, time/batch=0.119\n",
      "4691/67600 (epoch 3), train_loss = 1.237, time/batch=0.091\n",
      "4692/67600 (epoch 3), train_loss = 1.384, time/batch=0.069\n",
      "4693/67600 (epoch 3), train_loss = 1.265, time/batch=0.071\n",
      "4694/67600 (epoch 3), train_loss = 1.241, time/batch=0.077\n",
      "4695/67600 (epoch 3), train_loss = 1.228, time/batch=0.071\n",
      "4696/67600 (epoch 3), train_loss = 1.306, time/batch=0.071\n",
      "4697/67600 (epoch 3), train_loss = 1.276, time/batch=0.074\n",
      "4698/67600 (epoch 3), train_loss = 1.324, time/batch=0.070\n",
      "4699/67600 (epoch 3), train_loss = 1.365, time/batch=0.072\n",
      "4700/67600 (epoch 3), train_loss = 1.346, time/batch=0.078\n",
      "4701/67600 (epoch 3), train_loss = 1.276, time/batch=0.088\n",
      "4702/67600 (epoch 3), train_loss = 1.319, time/batch=0.202\n",
      "4703/67600 (epoch 3), train_loss = 1.312, time/batch=0.103\n",
      "4704/67600 (epoch 3), train_loss = 1.331, time/batch=0.072\n",
      "4705/67600 (epoch 3), train_loss = 1.301, time/batch=0.076\n",
      "4706/67600 (epoch 3), train_loss = 1.350, time/batch=0.074\n",
      "4707/67600 (epoch 3), train_loss = 1.368, time/batch=0.066\n",
      "4708/67600 (epoch 3), train_loss = 1.287, time/batch=0.074\n",
      "4709/67600 (epoch 3), train_loss = 1.290, time/batch=0.079\n",
      "4710/67600 (epoch 3), train_loss = 1.299, time/batch=0.074\n",
      "4711/67600 (epoch 3), train_loss = 1.294, time/batch=0.069\n",
      "4712/67600 (epoch 3), train_loss = 1.300, time/batch=0.072\n",
      "4713/67600 (epoch 3), train_loss = 1.355, time/batch=0.214\n",
      "4714/67600 (epoch 3), train_loss = 1.327, time/batch=0.081\n",
      "4715/67600 (epoch 3), train_loss = 1.249, time/batch=0.074\n",
      "4716/67600 (epoch 3), train_loss = 1.310, time/batch=0.070\n",
      "4717/67600 (epoch 3), train_loss = 1.294, time/batch=0.072\n",
      "4718/67600 (epoch 3), train_loss = 1.225, time/batch=0.081\n",
      "4719/67600 (epoch 3), train_loss = 1.235, time/batch=0.077\n",
      "4720/67600 (epoch 3), train_loss = 1.329, time/batch=0.069\n",
      "4721/67600 (epoch 3), train_loss = 1.304, time/batch=0.186\n",
      "4722/67600 (epoch 3), train_loss = 1.332, time/batch=0.075\n",
      "4723/67600 (epoch 3), train_loss = 1.297, time/batch=0.108\n",
      "4724/67600 (epoch 3), train_loss = 1.352, time/batch=0.075\n",
      "4725/67600 (epoch 3), train_loss = 1.251, time/batch=0.067\n",
      "4726/67600 (epoch 3), train_loss = 1.209, time/batch=0.078\n",
      "4727/67600 (epoch 3), train_loss = 1.302, time/batch=0.079\n",
      "4728/67600 (epoch 3), train_loss = 1.213, time/batch=0.079\n",
      "4729/67600 (epoch 3), train_loss = 1.356, time/batch=0.068\n",
      "4730/67600 (epoch 3), train_loss = 1.346, time/batch=0.066\n",
      "4731/67600 (epoch 3), train_loss = 1.265, time/batch=0.064\n",
      "4732/67600 (epoch 3), train_loss = 1.306, time/batch=0.080\n",
      "4733/67600 (epoch 3), train_loss = 1.344, time/batch=0.186\n",
      "4734/67600 (epoch 3), train_loss = 1.337, time/batch=0.103\n",
      "4735/67600 (epoch 3), train_loss = 1.291, time/batch=0.093\n",
      "4736/67600 (epoch 3), train_loss = 1.299, time/batch=0.085\n",
      "4737/67600 (epoch 3), train_loss = 1.326, time/batch=0.072\n",
      "4738/67600 (epoch 3), train_loss = 1.319, time/batch=0.073\n",
      "4739/67600 (epoch 3), train_loss = 1.283, time/batch=0.073\n",
      "4740/67600 (epoch 3), train_loss = 1.261, time/batch=0.070\n",
      "4741/67600 (epoch 3), train_loss = 1.347, time/batch=0.072\n",
      "4742/67600 (epoch 3), train_loss = 1.312, time/batch=0.076\n",
      "4743/67600 (epoch 3), train_loss = 1.273, time/batch=0.070\n",
      "4744/67600 (epoch 3), train_loss = 1.296, time/batch=0.196\n",
      "4745/67600 (epoch 3), train_loss = 1.265, time/batch=0.068\n",
      "4746/67600 (epoch 3), train_loss = 1.297, time/batch=0.100\n",
      "4747/67600 (epoch 3), train_loss = 1.286, time/batch=0.079\n",
      "4748/67600 (epoch 3), train_loss = 1.274, time/batch=0.071\n",
      "4749/67600 (epoch 3), train_loss = 1.329, time/batch=0.083\n",
      "4750/67600 (epoch 3), train_loss = 1.311, time/batch=0.080\n",
      "4751/67600 (epoch 3), train_loss = 1.239, time/batch=0.074\n",
      "4752/67600 (epoch 3), train_loss = 1.323, time/batch=0.080\n",
      "4753/67600 (epoch 3), train_loss = 1.346, time/batch=0.072\n",
      "4754/67600 (epoch 3), train_loss = 1.320, time/batch=0.068\n",
      "4755/67600 (epoch 3), train_loss = 1.272, time/batch=0.156\n",
      "4756/67600 (epoch 3), train_loss = 1.308, time/batch=0.111\n",
      "4757/67600 (epoch 3), train_loss = 1.335, time/batch=0.100\n",
      "4758/67600 (epoch 3), train_loss = 1.305, time/batch=0.071\n",
      "4759/67600 (epoch 3), train_loss = 1.261, time/batch=0.068\n",
      "4760/67600 (epoch 3), train_loss = 1.296, time/batch=0.074\n",
      "4761/67600 (epoch 3), train_loss = 1.286, time/batch=0.071\n",
      "4762/67600 (epoch 3), train_loss = 1.280, time/batch=0.068\n",
      "4763/67600 (epoch 3), train_loss = 1.333, time/batch=0.075\n",
      "4764/67600 (epoch 3), train_loss = 1.314, time/batch=0.074\n",
      "4765/67600 (epoch 3), train_loss = 1.265, time/batch=0.067\n",
      "4766/67600 (epoch 3), train_loss = 1.297, time/batch=0.072\n",
      "4767/67600 (epoch 3), train_loss = 1.211, time/batch=0.158\n",
      "4768/67600 (epoch 3), train_loss = 1.298, time/batch=0.121\n",
      "4769/67600 (epoch 3), train_loss = 1.312, time/batch=0.077\n",
      "4770/67600 (epoch 3), train_loss = 1.295, time/batch=0.070\n",
      "4771/67600 (epoch 3), train_loss = 1.287, time/batch=0.072\n",
      "4772/67600 (epoch 3), train_loss = 1.239, time/batch=0.073\n",
      "4773/67600 (epoch 3), train_loss = 1.289, time/batch=0.070\n",
      "4774/67600 (epoch 3), train_loss = 1.254, time/batch=0.072\n",
      "4775/67600 (epoch 3), train_loss = 1.275, time/batch=0.073\n",
      "4776/67600 (epoch 3), train_loss = 1.280, time/batch=0.181\n",
      "4777/67600 (epoch 3), train_loss = 1.321, time/batch=0.070\n",
      "4778/67600 (epoch 3), train_loss = 1.296, time/batch=0.103\n",
      "4779/67600 (epoch 3), train_loss = 1.305, time/batch=0.079\n",
      "4780/67600 (epoch 3), train_loss = 1.283, time/batch=0.071\n",
      "4781/67600 (epoch 3), train_loss = 1.319, time/batch=0.076\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4782/67600 (epoch 3), train_loss = 1.298, time/batch=0.070\n",
      "4783/67600 (epoch 3), train_loss = 1.321, time/batch=0.069\n",
      "4784/67600 (epoch 3), train_loss = 1.310, time/batch=0.072\n",
      "4785/67600 (epoch 3), train_loss = 1.276, time/batch=0.067\n",
      "4786/67600 (epoch 3), train_loss = 1.285, time/batch=0.064\n",
      "4787/67600 (epoch 3), train_loss = 1.321, time/batch=0.064\n",
      "4788/67600 (epoch 3), train_loss = 1.298, time/batch=0.153\n",
      "4789/67600 (epoch 3), train_loss = 1.283, time/batch=0.073\n",
      "4790/67600 (epoch 3), train_loss = 1.311, time/batch=0.079\n",
      "4791/67600 (epoch 3), train_loss = 1.257, time/batch=0.083\n",
      "4792/67600 (epoch 3), train_loss = 1.353, time/batch=0.065\n",
      "4793/67600 (epoch 3), train_loss = 1.278, time/batch=0.065\n",
      "4794/67600 (epoch 3), train_loss = 1.245, time/batch=0.066\n",
      "4795/67600 (epoch 3), train_loss = 1.315, time/batch=0.065\n",
      "4796/67600 (epoch 3), train_loss = 1.214, time/batch=0.064\n",
      "4797/67600 (epoch 3), train_loss = 1.260, time/batch=0.067\n",
      "4798/67600 (epoch 3), train_loss = 1.228, time/batch=0.065\n",
      "4799/67600 (epoch 3), train_loss = 1.287, time/batch=0.066\n",
      "4800/67600 (epoch 3), train_loss = 1.297, time/batch=0.067\n",
      "4801/67600 (epoch 3), train_loss = 1.309, time/batch=0.084\n",
      "4802/67600 (epoch 3), train_loss = 1.282, time/batch=0.148\n",
      "4803/67600 (epoch 3), train_loss = 1.294, time/batch=0.066\n",
      "4804/67600 (epoch 3), train_loss = 1.317, time/batch=0.092\n",
      "4805/67600 (epoch 3), train_loss = 1.277, time/batch=0.066\n",
      "4806/67600 (epoch 3), train_loss = 1.257, time/batch=0.065\n",
      "4807/67600 (epoch 3), train_loss = 1.251, time/batch=0.066\n",
      "4808/67600 (epoch 3), train_loss = 1.283, time/batch=0.064\n",
      "4809/67600 (epoch 3), train_loss = 1.337, time/batch=0.064\n",
      "4810/67600 (epoch 3), train_loss = 1.267, time/batch=0.064\n",
      "4811/67600 (epoch 3), train_loss = 1.282, time/batch=0.065\n",
      "4812/67600 (epoch 3), train_loss = 1.363, time/batch=0.068\n",
      "4813/67600 (epoch 3), train_loss = 1.292, time/batch=0.085\n",
      "4814/67600 (epoch 3), train_loss = 1.281, time/batch=0.108\n",
      "4815/67600 (epoch 3), train_loss = 1.254, time/batch=0.151\n",
      "4816/67600 (epoch 3), train_loss = 1.279, time/batch=0.083\n",
      "4817/67600 (epoch 3), train_loss = 1.280, time/batch=0.065\n",
      "4818/67600 (epoch 3), train_loss = 1.275, time/batch=0.073\n",
      "4819/67600 (epoch 3), train_loss = 1.354, time/batch=0.062\n",
      "4820/67600 (epoch 3), train_loss = 1.344, time/batch=0.064\n",
      "4821/67600 (epoch 3), train_loss = 1.261, time/batch=0.062\n",
      "4822/67600 (epoch 3), train_loss = 1.312, time/batch=0.064\n",
      "4823/67600 (epoch 3), train_loss = 1.295, time/batch=0.065\n",
      "4824/67600 (epoch 3), train_loss = 1.304, time/batch=0.066\n",
      "4825/67600 (epoch 3), train_loss = 1.323, time/batch=0.066\n",
      "4826/67600 (epoch 3), train_loss = 1.272, time/batch=0.077\n",
      "4827/67600 (epoch 3), train_loss = 1.349, time/batch=0.091\n",
      "4828/67600 (epoch 3), train_loss = 1.318, time/batch=0.162\n",
      "4829/67600 (epoch 3), train_loss = 1.286, time/batch=0.077\n",
      "4830/67600 (epoch 3), train_loss = 1.338, time/batch=0.067\n",
      "4831/67600 (epoch 3), train_loss = 1.373, time/batch=0.067\n",
      "4832/67600 (epoch 3), train_loss = 1.337, time/batch=0.062\n",
      "4833/67600 (epoch 3), train_loss = 1.307, time/batch=0.066\n",
      "4834/67600 (epoch 3), train_loss = 1.296, time/batch=0.063\n",
      "4835/67600 (epoch 3), train_loss = 1.337, time/batch=0.064\n",
      "4836/67600 (epoch 3), train_loss = 1.352, time/batch=0.064\n",
      "4837/67600 (epoch 3), train_loss = 1.301, time/batch=0.077\n",
      "4838/67600 (epoch 3), train_loss = 1.271, time/batch=0.066\n",
      "4839/67600 (epoch 3), train_loss = 1.315, time/batch=0.067\n",
      "4840/67600 (epoch 3), train_loss = 1.287, time/batch=0.119\n",
      "4841/67600 (epoch 3), train_loss = 1.323, time/batch=0.149\n",
      "4842/67600 (epoch 3), train_loss = 1.318, time/batch=0.072\n",
      "4843/67600 (epoch 3), train_loss = 1.299, time/batch=0.070\n",
      "4844/67600 (epoch 3), train_loss = 1.318, time/batch=0.067\n",
      "4845/67600 (epoch 3), train_loss = 1.267, time/batch=0.065\n",
      "4846/67600 (epoch 3), train_loss = 1.289, time/batch=0.065\n",
      "4847/67600 (epoch 3), train_loss = 1.288, time/batch=0.065\n",
      "4848/67600 (epoch 3), train_loss = 1.270, time/batch=0.066\n",
      "4849/67600 (epoch 3), train_loss = 1.329, time/batch=0.064\n",
      "4850/67600 (epoch 3), train_loss = 1.283, time/batch=0.104\n",
      "4851/67600 (epoch 3), train_loss = 1.305, time/batch=0.068\n",
      "4852/67600 (epoch 3), train_loss = 1.356, time/batch=0.072\n",
      "4853/67600 (epoch 3), train_loss = 1.321, time/batch=0.067\n",
      "4854/67600 (epoch 3), train_loss = 1.331, time/batch=0.065\n",
      "4855/67600 (epoch 3), train_loss = 1.304, time/batch=0.066\n",
      "4856/67600 (epoch 3), train_loss = 1.300, time/batch=0.067\n",
      "4857/67600 (epoch 3), train_loss = 1.309, time/batch=0.072\n",
      "4858/67600 (epoch 3), train_loss = 1.291, time/batch=0.065\n",
      "4859/67600 (epoch 3), train_loss = 1.306, time/batch=0.065\n",
      "4860/67600 (epoch 3), train_loss = 1.274, time/batch=0.100\n",
      "4861/67600 (epoch 3), train_loss = 1.261, time/batch=0.178\n",
      "4862/67600 (epoch 3), train_loss = 1.312, time/batch=0.067\n",
      "4863/67600 (epoch 3), train_loss = 1.263, time/batch=0.082\n",
      "4864/67600 (epoch 3), train_loss = 1.222, time/batch=0.067\n",
      "4865/67600 (epoch 3), train_loss = 1.321, time/batch=0.068\n",
      "4866/67600 (epoch 3), train_loss = 1.247, time/batch=0.066\n",
      "4867/67600 (epoch 3), train_loss = 1.329, time/batch=0.065\n",
      "4868/67600 (epoch 3), train_loss = 1.316, time/batch=0.066\n",
      "4869/67600 (epoch 3), train_loss = 1.315, time/batch=0.066\n",
      "4870/67600 (epoch 3), train_loss = 1.343, time/batch=0.065\n",
      "4871/67600 (epoch 3), train_loss = 1.248, time/batch=0.063\n",
      "4872/67600 (epoch 3), train_loss = 1.356, time/batch=0.064\n",
      "4873/67600 (epoch 3), train_loss = 1.256, time/batch=0.065\n",
      "4874/67600 (epoch 3), train_loss = 1.275, time/batch=0.179\n",
      "4875/67600 (epoch 3), train_loss = 1.302, time/batch=0.075\n",
      "4876/67600 (epoch 3), train_loss = 1.209, time/batch=0.074\n",
      "4877/67600 (epoch 3), train_loss = 1.336, time/batch=0.064\n",
      "4878/67600 (epoch 3), train_loss = 1.294, time/batch=0.062\n",
      "4879/67600 (epoch 3), train_loss = 1.376, time/batch=0.064\n",
      "4880/67600 (epoch 3), train_loss = 1.320, time/batch=0.067\n",
      "4881/67600 (epoch 3), train_loss = 1.340, time/batch=0.067\n",
      "4882/67600 (epoch 3), train_loss = 1.445, time/batch=0.066\n",
      "4883/67600 (epoch 3), train_loss = 1.281, time/batch=0.067\n",
      "4884/67600 (epoch 3), train_loss = 1.301, time/batch=0.066\n",
      "4885/67600 (epoch 3), train_loss = 1.335, time/batch=0.064\n",
      "4886/67600 (epoch 3), train_loss = 1.366, time/batch=0.065\n",
      "4887/67600 (epoch 3), train_loss = 1.294, time/batch=0.112\n",
      "4888/67600 (epoch 3), train_loss = 1.299, time/batch=0.146\n",
      "4889/67600 (epoch 3), train_loss = 1.304, time/batch=0.073\n",
      "4890/67600 (epoch 3), train_loss = 1.249, time/batch=0.065\n",
      "4891/67600 (epoch 3), train_loss = 1.338, time/batch=0.064\n",
      "4892/67600 (epoch 3), train_loss = 1.194, time/batch=0.064\n",
      "4893/67600 (epoch 3), train_loss = 1.339, time/batch=0.066\n",
      "4894/67600 (epoch 3), train_loss = 1.227, time/batch=0.063\n",
      "4895/67600 (epoch 3), train_loss = 1.284, time/batch=0.065\n",
      "4896/67600 (epoch 3), train_loss = 1.347, time/batch=0.080\n",
      "4897/67600 (epoch 3), train_loss = 1.309, time/batch=0.163\n",
      "4898/67600 (epoch 3), train_loss = 1.303, time/batch=0.068\n",
      "4899/67600 (epoch 3), train_loss = 1.316, time/batch=0.099\n",
      "4900/67600 (epoch 3), train_loss = 1.308, time/batch=0.065\n",
      "4901/67600 (epoch 3), train_loss = 1.287, time/batch=0.064\n",
      "4902/67600 (epoch 3), train_loss = 1.278, time/batch=0.068\n",
      "4903/67600 (epoch 3), train_loss = 1.281, time/batch=0.063\n",
      "4904/67600 (epoch 3), train_loss = 1.327, time/batch=0.064\n",
      "4905/67600 (epoch 3), train_loss = 1.286, time/batch=0.064\n",
      "4906/67600 (epoch 3), train_loss = 1.285, time/batch=0.064\n",
      "4907/67600 (epoch 3), train_loss = 1.384, time/batch=0.064\n",
      "4908/67600 (epoch 3), train_loss = 1.377, time/batch=0.062\n",
      "4909/67600 (epoch 3), train_loss = 1.351, time/batch=0.066\n",
      "4910/67600 (epoch 3), train_loss = 1.278, time/batch=0.157\n",
      "4911/67600 (epoch 3), train_loss = 1.348, time/batch=0.077\n",
      "4912/67600 (epoch 3), train_loss = 1.304, time/batch=0.100\n",
      "4913/67600 (epoch 3), train_loss = 1.295, time/batch=0.063\n",
      "4914/67600 (epoch 3), train_loss = 1.341, time/batch=0.067\n",
      "4915/67600 (epoch 3), train_loss = 1.330, time/batch=0.079\n",
      "4916/67600 (epoch 3), train_loss = 1.310, time/batch=0.068\n",
      "4917/67600 (epoch 3), train_loss = 1.359, time/batch=0.068\n",
      "4918/67600 (epoch 3), train_loss = 1.374, time/batch=0.066\n",
      "4919/67600 (epoch 3), train_loss = 1.337, time/batch=0.066\n",
      "4920/67600 (epoch 3), train_loss = 1.268, time/batch=0.063\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4921/67600 (epoch 3), train_loss = 1.356, time/batch=0.064\n",
      "4922/67600 (epoch 3), train_loss = 1.347, time/batch=0.064\n",
      "4923/67600 (epoch 3), train_loss = 1.268, time/batch=0.163\n",
      "4924/67600 (epoch 3), train_loss = 1.296, time/batch=0.071\n",
      "4925/67600 (epoch 3), train_loss = 1.295, time/batch=0.093\n",
      "4926/67600 (epoch 3), train_loss = 1.301, time/batch=0.065\n",
      "4927/67600 (epoch 3), train_loss = 1.283, time/batch=0.065\n",
      "4928/67600 (epoch 3), train_loss = 1.329, time/batch=0.066\n",
      "4929/67600 (epoch 3), train_loss = 1.271, time/batch=0.065\n",
      "4930/67600 (epoch 3), train_loss = 1.302, time/batch=0.074\n",
      "4931/67600 (epoch 3), train_loss = 1.365, time/batch=0.066\n",
      "4932/67600 (epoch 3), train_loss = 1.332, time/batch=0.075\n",
      "4933/67600 (epoch 3), train_loss = 1.206, time/batch=0.067\n",
      "4934/67600 (epoch 3), train_loss = 1.283, time/batch=0.084\n",
      "4935/67600 (epoch 3), train_loss = 1.204, time/batch=0.069\n",
      "4936/67600 (epoch 3), train_loss = 1.261, time/batch=0.188\n",
      "4937/67600 (epoch 3), train_loss = 1.278, time/batch=0.064\n",
      "4938/67600 (epoch 3), train_loss = 1.286, time/batch=0.083\n",
      "4939/67600 (epoch 3), train_loss = 1.295, time/batch=0.066\n",
      "4940/67600 (epoch 3), train_loss = 1.270, time/batch=0.065\n",
      "4941/67600 (epoch 3), train_loss = 1.290, time/batch=0.066\n",
      "4942/67600 (epoch 3), train_loss = 1.272, time/batch=0.063\n",
      "4943/67600 (epoch 3), train_loss = 1.227, time/batch=0.066\n",
      "4944/67600 (epoch 3), train_loss = 1.366, time/batch=0.064\n",
      "4945/67600 (epoch 3), train_loss = 1.321, time/batch=0.063\n",
      "4946/67600 (epoch 3), train_loss = 1.359, time/batch=0.063\n",
      "4947/67600 (epoch 3), train_loss = 1.345, time/batch=0.065\n",
      "4948/67600 (epoch 3), train_loss = 1.330, time/batch=0.066\n",
      "4949/67600 (epoch 3), train_loss = 1.298, time/batch=0.150\n",
      "4950/67600 (epoch 3), train_loss = 1.336, time/batch=0.107\n",
      "4951/67600 (epoch 3), train_loss = 1.285, time/batch=0.071\n",
      "4952/67600 (epoch 3), train_loss = 1.288, time/batch=0.064\n",
      "4953/67600 (epoch 3), train_loss = 1.347, time/batch=0.064\n",
      "4954/67600 (epoch 3), train_loss = 1.326, time/batch=0.063\n",
      "4955/67600 (epoch 3), train_loss = 1.329, time/batch=0.072\n",
      "4956/67600 (epoch 3), train_loss = 1.301, time/batch=0.067\n",
      "4957/67600 (epoch 3), train_loss = 1.360, time/batch=0.065\n",
      "4958/67600 (epoch 3), train_loss = 1.352, time/batch=0.087\n",
      "4959/67600 (epoch 3), train_loss = 1.241, time/batch=0.131\n",
      "4960/67600 (epoch 3), train_loss = 1.288, time/batch=0.066\n",
      "4961/67600 (epoch 3), train_loss = 1.340, time/batch=0.096\n",
      "4962/67600 (epoch 3), train_loss = 1.282, time/batch=0.067\n",
      "4963/67600 (epoch 3), train_loss = 1.272, time/batch=0.065\n",
      "4964/67600 (epoch 3), train_loss = 1.341, time/batch=0.070\n",
      "4965/67600 (epoch 3), train_loss = 1.284, time/batch=0.065\n",
      "4966/67600 (epoch 3), train_loss = 1.285, time/batch=0.065\n",
      "4967/67600 (epoch 3), train_loss = 1.338, time/batch=0.062\n",
      "4968/67600 (epoch 3), train_loss = 1.284, time/batch=0.064\n",
      "4969/67600 (epoch 3), train_loss = 1.319, time/batch=0.069\n",
      "4970/67600 (epoch 3), train_loss = 1.357, time/batch=0.064\n",
      "4971/67600 (epoch 3), train_loss = 1.272, time/batch=0.065\n",
      "4972/67600 (epoch 3), train_loss = 1.300, time/batch=0.162\n",
      "4973/67600 (epoch 3), train_loss = 1.281, time/batch=0.066\n",
      "4974/67600 (epoch 3), train_loss = 1.303, time/batch=0.100\n",
      "4975/67600 (epoch 3), train_loss = 1.305, time/batch=0.067\n",
      "4976/67600 (epoch 3), train_loss = 1.319, time/batch=0.064\n",
      "4977/67600 (epoch 3), train_loss = 1.291, time/batch=0.074\n",
      "4978/67600 (epoch 3), train_loss = 1.332, time/batch=0.069\n",
      "4979/67600 (epoch 3), train_loss = 1.291, time/batch=0.064\n",
      "4980/67600 (epoch 3), train_loss = 1.250, time/batch=0.065\n",
      "4981/67600 (epoch 3), train_loss = 1.294, time/batch=0.066\n",
      "4982/67600 (epoch 3), train_loss = 1.280, time/batch=0.066\n",
      "4983/67600 (epoch 3), train_loss = 1.301, time/batch=0.064\n",
      "4984/67600 (epoch 3), train_loss = 1.282, time/batch=0.061\n",
      "4985/67600 (epoch 3), train_loss = 1.291, time/batch=0.179\n",
      "4986/67600 (epoch 3), train_loss = 1.245, time/batch=0.064\n",
      "4987/67600 (epoch 3), train_loss = 1.309, time/batch=0.090\n",
      "4988/67600 (epoch 3), train_loss = 1.273, time/batch=0.063\n",
      "4989/67600 (epoch 3), train_loss = 1.250, time/batch=0.066\n",
      "4990/67600 (epoch 3), train_loss = 1.269, time/batch=0.076\n",
      "4991/67600 (epoch 3), train_loss = 1.266, time/batch=0.065\n",
      "4992/67600 (epoch 3), train_loss = 1.324, time/batch=0.063\n",
      "4993/67600 (epoch 3), train_loss = 1.285, time/batch=0.081\n",
      "4994/67600 (epoch 3), train_loss = 1.266, time/batch=0.085\n",
      "4995/67600 (epoch 3), train_loss = 1.274, time/batch=0.068\n",
      "4996/67600 (epoch 3), train_loss = 1.290, time/batch=0.064\n",
      "4997/67600 (epoch 3), train_loss = 1.256, time/batch=0.065\n",
      "4998/67600 (epoch 3), train_loss = 1.232, time/batch=0.184\n",
      "4999/67600 (epoch 3), train_loss = 1.341, time/batch=0.065\n",
      "5000/67600 (epoch 3), train_loss = 1.288, time/batch=0.083\n",
      "model saved to ./save/model.ckpt\n",
      "5001/67600 (epoch 3), train_loss = 1.316, time/batch=0.064\n",
      "5002/67600 (epoch 3), train_loss = 1.275, time/batch=0.061\n",
      "5003/67600 (epoch 3), train_loss = 1.249, time/batch=0.065\n",
      "5004/67600 (epoch 3), train_loss = 1.302, time/batch=0.066\n",
      "5005/67600 (epoch 3), train_loss = 1.271, time/batch=0.064\n",
      "5006/67600 (epoch 3), train_loss = 1.328, time/batch=0.062\n",
      "5007/67600 (epoch 3), train_loss = 1.266, time/batch=0.107\n",
      "5008/67600 (epoch 3), train_loss = 1.322, time/batch=0.065\n",
      "5009/67600 (epoch 3), train_loss = 1.245, time/batch=0.065\n",
      "5010/67600 (epoch 3), train_loss = 1.221, time/batch=0.072\n",
      "5011/67600 (epoch 3), train_loss = 1.351, time/batch=0.065\n",
      "5012/67600 (epoch 3), train_loss = 1.308, time/batch=0.064\n",
      "5013/67600 (epoch 3), train_loss = 1.313, time/batch=0.063\n",
      "5014/67600 (epoch 3), train_loss = 1.256, time/batch=0.065\n",
      "5015/67600 (epoch 3), train_loss = 1.274, time/batch=0.063\n",
      "5016/67600 (epoch 3), train_loss = 1.267, time/batch=0.063\n",
      "5017/67600 (epoch 3), train_loss = 1.194, time/batch=0.062\n",
      "5018/67600 (epoch 3), train_loss = 1.223, time/batch=0.232\n",
      "5019/67600 (epoch 3), train_loss = 1.229, time/batch=0.081\n",
      "5020/67600 (epoch 3), train_loss = 1.218, time/batch=0.090\n",
      "5021/67600 (epoch 3), train_loss = 1.296, time/batch=0.067\n",
      "5022/67600 (epoch 3), train_loss = 1.299, time/batch=0.071\n",
      "5023/67600 (epoch 3), train_loss = 1.233, time/batch=0.066\n",
      "5024/67600 (epoch 3), train_loss = 1.260, time/batch=0.066\n",
      "5025/67600 (epoch 3), train_loss = 1.255, time/batch=0.066\n",
      "5026/67600 (epoch 3), train_loss = 1.293, time/batch=0.064\n",
      "5027/67600 (epoch 3), train_loss = 1.294, time/batch=0.076\n",
      "5028/67600 (epoch 3), train_loss = 1.239, time/batch=0.065\n",
      "5029/67600 (epoch 3), train_loss = 1.304, time/batch=0.064\n",
      "5030/67600 (epoch 3), train_loss = 1.316, time/batch=0.065\n",
      "5031/67600 (epoch 3), train_loss = 1.226, time/batch=0.194\n",
      "5032/67600 (epoch 3), train_loss = 1.209, time/batch=0.075\n",
      "5033/67600 (epoch 3), train_loss = 1.246, time/batch=0.068\n",
      "5034/67600 (epoch 3), train_loss = 1.311, time/batch=0.066\n",
      "5035/67600 (epoch 3), train_loss = 1.277, time/batch=0.065\n",
      "5036/67600 (epoch 3), train_loss = 1.288, time/batch=0.066\n",
      "5037/67600 (epoch 3), train_loss = 1.250, time/batch=0.067\n",
      "5038/67600 (epoch 3), train_loss = 1.246, time/batch=0.066\n",
      "5039/67600 (epoch 3), train_loss = 1.304, time/batch=0.066\n",
      "5040/67600 (epoch 3), train_loss = 1.247, time/batch=0.064\n",
      "5041/67600 (epoch 3), train_loss = 1.357, time/batch=0.064\n",
      "5042/67600 (epoch 3), train_loss = 1.291, time/batch=0.065\n",
      "5043/67600 (epoch 3), train_loss = 1.361, time/batch=0.065\n",
      "5044/67600 (epoch 3), train_loss = 1.251, time/batch=0.194\n",
      "5045/67600 (epoch 3), train_loss = 1.262, time/batch=0.066\n",
      "5046/67600 (epoch 3), train_loss = 1.297, time/batch=0.076\n",
      "5047/67600 (epoch 3), train_loss = 1.260, time/batch=0.063\n",
      "5048/67600 (epoch 3), train_loss = 1.332, time/batch=0.064\n",
      "5049/67600 (epoch 3), train_loss = 1.285, time/batch=0.068\n",
      "5050/67600 (epoch 3), train_loss = 1.280, time/batch=0.064\n",
      "5051/67600 (epoch 3), train_loss = 1.287, time/batch=0.066\n",
      "5052/67600 (epoch 3), train_loss = 1.288, time/batch=0.065\n",
      "5053/67600 (epoch 3), train_loss = 1.309, time/batch=0.145\n",
      "5054/67600 (epoch 3), train_loss = 1.227, time/batch=0.082\n",
      "5055/67600 (epoch 3), train_loss = 1.255, time/batch=0.090\n",
      "5056/67600 (epoch 3), train_loss = 1.266, time/batch=0.073\n",
      "5057/67600 (epoch 3), train_loss = 1.280, time/batch=0.076\n",
      "5058/67600 (epoch 3), train_loss = 1.265, time/batch=0.066\n",
      "5059/67600 (epoch 3), train_loss = 1.285, time/batch=0.072\n",
      "5060/67600 (epoch 3), train_loss = 1.226, time/batch=0.063\n",
      "5061/67600 (epoch 3), train_loss = 1.298, time/batch=0.063\n",
      "5062/67600 (epoch 3), train_loss = 1.287, time/batch=0.064\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5063/67600 (epoch 3), train_loss = 1.247, time/batch=0.065\n",
      "5064/67600 (epoch 3), train_loss = 1.284, time/batch=0.063\n",
      "5065/67600 (epoch 3), train_loss = 1.243, time/batch=0.064\n",
      "5066/67600 (epoch 3), train_loss = 1.266, time/batch=0.108\n",
      "5067/67600 (epoch 3), train_loss = 1.264, time/batch=0.124\n",
      "5068/67600 (epoch 3), train_loss = 1.228, time/batch=0.064\n",
      "5069/67600 (epoch 3), train_loss = 1.245, time/batch=0.100\n",
      "5070/67600 (epoch 3), train_loss = 1.258, time/batch=0.065\n",
      "5071/67600 (epoch 3), train_loss = 1.261, time/batch=0.064\n",
      "5072/67600 (epoch 3), train_loss = 1.257, time/batch=0.066\n",
      "5073/67600 (epoch 3), train_loss = 1.300, time/batch=0.066\n",
      "5074/67600 (epoch 3), train_loss = 1.272, time/batch=0.064\n",
      "5075/67600 (epoch 3), train_loss = 1.284, time/batch=0.064\n",
      "5076/67600 (epoch 3), train_loss = 1.281, time/batch=0.064\n",
      "5077/67600 (epoch 3), train_loss = 1.263, time/batch=0.064\n",
      "5078/67600 (epoch 3), train_loss = 1.261, time/batch=0.062\n",
      "5079/67600 (epoch 3), train_loss = 1.270, time/batch=0.064\n",
      "5080/67600 (epoch 3), train_loss = 1.284, time/batch=0.166\n",
      "5081/67600 (epoch 3), train_loss = 1.239, time/batch=0.065\n",
      "5082/67600 (epoch 3), train_loss = 1.312, time/batch=0.092\n",
      "5083/67600 (epoch 3), train_loss = 1.236, time/batch=0.066\n",
      "5084/67600 (epoch 3), train_loss = 1.336, time/batch=0.065\n",
      "5085/67600 (epoch 3), train_loss = 1.311, time/batch=0.067\n",
      "5086/67600 (epoch 3), train_loss = 1.322, time/batch=0.064\n",
      "5087/67600 (epoch 3), train_loss = 1.316, time/batch=0.064\n",
      "5088/67600 (epoch 3), train_loss = 1.282, time/batch=0.063\n",
      "5089/67600 (epoch 3), train_loss = 1.250, time/batch=0.063\n",
      "5090/67600 (epoch 3), train_loss = 1.290, time/batch=0.063\n",
      "5091/67600 (epoch 3), train_loss = 1.253, time/batch=0.064\n",
      "5092/67600 (epoch 3), train_loss = 1.237, time/batch=0.062\n",
      "5093/67600 (epoch 3), train_loss = 1.239, time/batch=0.105\n",
      "5094/67600 (epoch 3), train_loss = 1.272, time/batch=0.140\n",
      "5095/67600 (epoch 3), train_loss = 1.259, time/batch=0.080\n",
      "5096/67600 (epoch 3), train_loss = 1.279, time/batch=0.063\n",
      "5097/67600 (epoch 3), train_loss = 1.274, time/batch=0.067\n",
      "5098/67600 (epoch 3), train_loss = 1.323, time/batch=0.066\n",
      "5099/67600 (epoch 3), train_loss = 1.180, time/batch=0.067\n",
      "5100/67600 (epoch 3), train_loss = 1.274, time/batch=0.065\n",
      "5101/67600 (epoch 3), train_loss = 1.269, time/batch=0.066\n",
      "5102/67600 (epoch 3), train_loss = 1.280, time/batch=0.066\n",
      "5103/67600 (epoch 3), train_loss = 1.340, time/batch=0.065\n",
      "5104/67600 (epoch 3), train_loss = 1.324, time/batch=0.064\n",
      "5105/67600 (epoch 3), train_loss = 1.299, time/batch=0.064\n",
      "5106/67600 (epoch 3), train_loss = 1.274, time/batch=0.063\n",
      "5107/67600 (epoch 3), train_loss = 1.243, time/batch=0.185\n",
      "5108/67600 (epoch 3), train_loss = 1.301, time/batch=0.065\n",
      "5109/67600 (epoch 3), train_loss = 1.281, time/batch=0.068\n",
      "5110/67600 (epoch 3), train_loss = 1.315, time/batch=0.063\n",
      "5111/67600 (epoch 3), train_loss = 1.290, time/batch=0.064\n",
      "5112/67600 (epoch 3), train_loss = 1.217, time/batch=0.065\n",
      "5113/67600 (epoch 3), train_loss = 1.328, time/batch=0.070\n",
      "5114/67600 (epoch 3), train_loss = 1.356, time/batch=0.063\n",
      "5115/67600 (epoch 3), train_loss = 1.272, time/batch=0.065\n",
      "5116/67600 (epoch 3), train_loss = 1.293, time/batch=0.131\n",
      "5117/67600 (epoch 3), train_loss = 1.298, time/batch=0.104\n",
      "5118/67600 (epoch 3), train_loss = 1.275, time/batch=0.070\n",
      "5119/67600 (epoch 3), train_loss = 1.238, time/batch=0.088\n",
      "5120/67600 (epoch 3), train_loss = 1.285, time/batch=0.063\n",
      "5121/67600 (epoch 3), train_loss = 1.282, time/batch=0.061\n",
      "5122/67600 (epoch 3), train_loss = 1.273, time/batch=0.069\n",
      "5123/67600 (epoch 3), train_loss = 1.318, time/batch=0.062\n",
      "5124/67600 (epoch 3), train_loss = 1.268, time/batch=0.068\n",
      "5125/67600 (epoch 3), train_loss = 1.313, time/batch=0.066\n",
      "5126/67600 (epoch 3), train_loss = 1.317, time/batch=0.067\n",
      "5127/67600 (epoch 3), train_loss = 1.332, time/batch=0.065\n",
      "5128/67600 (epoch 3), train_loss = 1.285, time/batch=0.065\n",
      "5129/67600 (epoch 3), train_loss = 1.267, time/batch=0.064\n",
      "5130/67600 (epoch 3), train_loss = 1.249, time/batch=0.162\n",
      "5131/67600 (epoch 3), train_loss = 1.274, time/batch=0.065\n",
      "5132/67600 (epoch 3), train_loss = 1.315, time/batch=0.097\n",
      "5133/67600 (epoch 3), train_loss = 1.304, time/batch=0.064\n",
      "5134/67600 (epoch 3), train_loss = 1.310, time/batch=0.063\n",
      "5135/67600 (epoch 3), train_loss = 1.324, time/batch=0.066\n",
      "5136/67600 (epoch 3), train_loss = 1.332, time/batch=0.065\n",
      "5137/67600 (epoch 3), train_loss = 1.262, time/batch=0.066\n",
      "5138/67600 (epoch 3), train_loss = 1.327, time/batch=0.065\n",
      "5139/67600 (epoch 3), train_loss = 1.252, time/batch=0.077\n",
      "5140/67600 (epoch 3), train_loss = 1.243, time/batch=0.067\n",
      "5141/67600 (epoch 3), train_loss = 1.366, time/batch=0.065\n",
      "5142/67600 (epoch 3), train_loss = 1.319, time/batch=0.067\n",
      "5143/67600 (epoch 3), train_loss = 1.224, time/batch=0.175\n",
      "5144/67600 (epoch 3), train_loss = 1.267, time/batch=0.065\n",
      "5145/67600 (epoch 3), train_loss = 1.246, time/batch=0.110\n",
      "5146/67600 (epoch 3), train_loss = 1.315, time/batch=0.067\n",
      "5147/67600 (epoch 3), train_loss = 1.276, time/batch=0.065\n",
      "5148/67600 (epoch 3), train_loss = 1.328, time/batch=0.067\n",
      "5149/67600 (epoch 3), train_loss = 1.271, time/batch=0.065\n",
      "5150/67600 (epoch 3), train_loss = 1.274, time/batch=0.067\n",
      "5151/67600 (epoch 3), train_loss = 1.267, time/batch=0.067\n",
      "5152/67600 (epoch 3), train_loss = 1.284, time/batch=0.067\n",
      "5153/67600 (epoch 3), train_loss = 1.282, time/batch=0.065\n",
      "5154/67600 (epoch 3), train_loss = 1.246, time/batch=0.074\n",
      "5155/67600 (epoch 3), train_loss = 1.206, time/batch=0.091\n",
      "5156/67600 (epoch 3), train_loss = 1.276, time/batch=0.171\n",
      "5157/67600 (epoch 3), train_loss = 1.267, time/batch=0.082\n",
      "5158/67600 (epoch 3), train_loss = 1.263, time/batch=0.064\n",
      "5159/67600 (epoch 3), train_loss = 1.243, time/batch=0.068\n",
      "5160/67600 (epoch 3), train_loss = 1.368, time/batch=0.067\n",
      "5161/67600 (epoch 3), train_loss = 1.257, time/batch=0.065\n",
      "5162/67600 (epoch 3), train_loss = 1.265, time/batch=0.065\n",
      "5163/67600 (epoch 3), train_loss = 1.302, time/batch=0.066\n",
      "5164/67600 (epoch 3), train_loss = 1.274, time/batch=0.065\n",
      "5165/67600 (epoch 3), train_loss = 1.290, time/batch=0.065\n",
      "5166/67600 (epoch 3), train_loss = 1.296, time/batch=0.066\n",
      "5167/67600 (epoch 3), train_loss = 1.274, time/batch=0.066\n",
      "5168/67600 (epoch 3), train_loss = 1.326, time/batch=0.070\n",
      "5169/67600 (epoch 3), train_loss = 1.338, time/batch=0.183\n",
      "5170/67600 (epoch 3), train_loss = 1.328, time/batch=0.070\n",
      "5171/67600 (epoch 3), train_loss = 1.375, time/batch=0.069\n",
      "5172/67600 (epoch 3), train_loss = 1.273, time/batch=0.065\n",
      "5173/67600 (epoch 3), train_loss = 1.303, time/batch=0.063\n",
      "5174/67600 (epoch 3), train_loss = 1.274, time/batch=0.067\n",
      "5175/67600 (epoch 3), train_loss = 1.384, time/batch=0.069\n",
      "5176/67600 (epoch 3), train_loss = 1.282, time/batch=0.066\n",
      "5177/67600 (epoch 3), train_loss = 1.324, time/batch=0.067\n",
      "5178/67600 (epoch 3), train_loss = 1.396, time/batch=0.065\n",
      "5179/67600 (epoch 3), train_loss = 1.305, time/batch=0.073\n",
      "5180/67600 (epoch 3), train_loss = 1.287, time/batch=0.065\n",
      "5181/67600 (epoch 3), train_loss = 1.281, time/batch=0.065\n",
      "5182/67600 (epoch 3), train_loss = 1.356, time/batch=0.207\n",
      "5183/67600 (epoch 3), train_loss = 1.279, time/batch=0.072\n",
      "5184/67600 (epoch 3), train_loss = 1.307, time/batch=0.071\n",
      "5185/67600 (epoch 3), train_loss = 1.296, time/batch=0.066\n",
      "5186/67600 (epoch 3), train_loss = 1.300, time/batch=0.065\n",
      "5187/67600 (epoch 3), train_loss = 1.323, time/batch=0.065\n",
      "5188/67600 (epoch 3), train_loss = 1.272, time/batch=0.067\n",
      "5189/67600 (epoch 3), train_loss = 1.332, time/batch=0.066\n",
      "5190/67600 (epoch 3), train_loss = 1.353, time/batch=0.066\n",
      "5191/67600 (epoch 3), train_loss = 1.365, time/batch=0.117\n",
      "5192/67600 (epoch 3), train_loss = 1.321, time/batch=0.067\n",
      "5193/67600 (epoch 3), train_loss = 1.298, time/batch=0.074\n",
      "5194/67600 (epoch 3), train_loss = 1.310, time/batch=0.065\n",
      "5195/67600 (epoch 3), train_loss = 1.340, time/batch=0.081\n",
      "5196/67600 (epoch 3), train_loss = 1.296, time/batch=0.064\n",
      "5197/67600 (epoch 3), train_loss = 1.286, time/batch=0.065\n",
      "5198/67600 (epoch 3), train_loss = 1.330, time/batch=0.066\n",
      "5199/67600 (epoch 3), train_loss = 1.340, time/batch=0.067\n",
      "5200/67600 (epoch 3), train_loss = 1.308, time/batch=0.065\n",
      "5201/67600 (epoch 3), train_loss = 1.260, time/batch=0.169\n",
      "5202/67600 (epoch 3), train_loss = 1.270, time/batch=0.113\n",
      "5203/67600 (epoch 3), train_loss = 1.259, time/batch=0.083\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5204/67600 (epoch 3), train_loss = 1.256, time/batch=0.066\n",
      "5205/67600 (epoch 3), train_loss = 1.281, time/batch=0.066\n",
      "5206/67600 (epoch 3), train_loss = 1.222, time/batch=0.063\n",
      "5207/67600 (epoch 3), train_loss = 1.324, time/batch=0.064\n",
      "5208/67600 (epoch 3), train_loss = 1.280, time/batch=0.068\n",
      "5209/67600 (epoch 3), train_loss = 1.272, time/batch=0.065\n",
      "5210/67600 (epoch 3), train_loss = 1.304, time/batch=0.064\n",
      "5211/67600 (epoch 3), train_loss = 1.270, time/batch=0.066\n",
      "5212/67600 (epoch 3), train_loss = 1.274, time/batch=0.066\n",
      "5213/67600 (epoch 3), train_loss = 1.225, time/batch=0.065\n",
      "5214/67600 (epoch 3), train_loss = 1.323, time/batch=0.064\n",
      "5215/67600 (epoch 3), train_loss = 1.313, time/batch=0.193\n",
      "5216/67600 (epoch 3), train_loss = 1.239, time/batch=0.067\n",
      "5217/67600 (epoch 3), train_loss = 1.258, time/batch=0.072\n",
      "5218/67600 (epoch 3), train_loss = 1.275, time/batch=0.068\n",
      "5219/67600 (epoch 3), train_loss = 1.243, time/batch=0.064\n",
      "5220/67600 (epoch 3), train_loss = 1.304, time/batch=0.064\n",
      "5221/67600 (epoch 3), train_loss = 1.235, time/batch=0.065\n",
      "5222/67600 (epoch 3), train_loss = 1.253, time/batch=0.065\n",
      "5223/67600 (epoch 3), train_loss = 1.274, time/batch=0.064\n",
      "5224/67600 (epoch 3), train_loss = 1.311, time/batch=0.064\n",
      "5225/67600 (epoch 3), train_loss = 1.223, time/batch=0.064\n",
      "5226/67600 (epoch 3), train_loss = 1.249, time/batch=0.065\n",
      "5227/67600 (epoch 3), train_loss = 1.241, time/batch=0.066\n",
      "5228/67600 (epoch 3), train_loss = 1.269, time/batch=0.171\n",
      "5229/67600 (epoch 3), train_loss = 1.266, time/batch=0.089\n",
      "5230/67600 (epoch 3), train_loss = 1.257, time/batch=0.071\n",
      "5231/67600 (epoch 3), train_loss = 1.285, time/batch=0.071\n",
      "5232/67600 (epoch 3), train_loss = 1.282, time/batch=0.065\n",
      "5233/67600 (epoch 3), train_loss = 1.298, time/batch=0.069\n",
      "5234/67600 (epoch 3), train_loss = 1.311, time/batch=0.065\n",
      "5235/67600 (epoch 3), train_loss = 1.388, time/batch=0.064\n",
      "5236/67600 (epoch 3), train_loss = 1.360, time/batch=0.063\n",
      "5237/67600 (epoch 3), train_loss = 1.311, time/batch=0.093\n",
      "5238/67600 (epoch 3), train_loss = 1.282, time/batch=0.132\n",
      "5239/67600 (epoch 3), train_loss = 1.274, time/batch=0.065\n",
      "5240/67600 (epoch 3), train_loss = 1.295, time/batch=0.121\n",
      "5241/67600 (epoch 3), train_loss = 1.217, time/batch=0.079\n",
      "5242/67600 (epoch 3), train_loss = 1.247, time/batch=0.089\n",
      "5243/67600 (epoch 3), train_loss = 1.338, time/batch=0.081\n",
      "5244/67600 (epoch 3), train_loss = 1.294, time/batch=0.075\n",
      "5245/67600 (epoch 3), train_loss = 1.249, time/batch=0.075\n",
      "5246/67600 (epoch 3), train_loss = 1.283, time/batch=0.081\n",
      "5247/67600 (epoch 3), train_loss = 1.269, time/batch=0.077\n",
      "5248/67600 (epoch 3), train_loss = 1.280, time/batch=0.068\n",
      "5249/67600 (epoch 3), train_loss = 1.275, time/batch=0.187\n",
      "5250/67600 (epoch 3), train_loss = 1.229, time/batch=0.079\n",
      "5251/67600 (epoch 3), train_loss = 1.261, time/batch=0.110\n",
      "5252/67600 (epoch 3), train_loss = 1.303, time/batch=0.078\n",
      "5253/67600 (epoch 3), train_loss = 1.316, time/batch=0.070\n",
      "5254/67600 (epoch 3), train_loss = 1.308, time/batch=0.073\n",
      "5255/67600 (epoch 3), train_loss = 1.275, time/batch=0.076\n",
      "5256/67600 (epoch 3), train_loss = 1.288, time/batch=0.081\n",
      "5257/67600 (epoch 3), train_loss = 1.271, time/batch=0.149\n",
      "5258/67600 (epoch 3), train_loss = 1.267, time/batch=0.121\n",
      "5259/67600 (epoch 3), train_loss = 1.253, time/batch=0.193\n",
      "5260/67600 (epoch 3), train_loss = 1.371, time/batch=0.123\n",
      "5261/67600 (epoch 3), train_loss = 1.280, time/batch=0.081\n",
      "5262/67600 (epoch 3), train_loss = 1.249, time/batch=0.078\n",
      "5263/67600 (epoch 3), train_loss = 1.300, time/batch=0.078\n",
      "5264/67600 (epoch 3), train_loss = 1.247, time/batch=0.075\n",
      "5265/67600 (epoch 3), train_loss = 1.236, time/batch=0.075\n",
      "5266/67600 (epoch 3), train_loss = 1.285, time/batch=0.079\n",
      "5267/67600 (epoch 3), train_loss = 1.254, time/batch=0.080\n",
      "5268/67600 (epoch 3), train_loss = 1.236, time/batch=0.072\n",
      "5269/67600 (epoch 3), train_loss = 1.276, time/batch=0.161\n",
      "5270/67600 (epoch 3), train_loss = 1.315, time/batch=0.121\n",
      "5271/67600 (epoch 3), train_loss = 1.267, time/batch=0.100\n",
      "5272/67600 (epoch 3), train_loss = 1.288, time/batch=0.076\n",
      "5273/67600 (epoch 3), train_loss = 1.276, time/batch=0.077\n",
      "5274/67600 (epoch 3), train_loss = 1.268, time/batch=0.084\n",
      "5275/67600 (epoch 3), train_loss = 1.279, time/batch=0.084\n",
      "5276/67600 (epoch 3), train_loss = 1.271, time/batch=0.075\n",
      "5277/67600 (epoch 3), train_loss = 1.256, time/batch=0.074\n",
      "5278/67600 (epoch 3), train_loss = 1.307, time/batch=0.073\n",
      "5279/67600 (epoch 3), train_loss = 1.267, time/batch=0.069\n",
      "5280/67600 (epoch 3), train_loss = 1.312, time/batch=0.091\n",
      "5281/67600 (epoch 3), train_loss = 1.309, time/batch=0.189\n",
      "5282/67600 (epoch 3), train_loss = 1.311, time/batch=0.080\n",
      "5283/67600 (epoch 3), train_loss = 1.286, time/batch=0.071\n",
      "5284/67600 (epoch 3), train_loss = 1.339, time/batch=0.070\n",
      "5285/67600 (epoch 3), train_loss = 1.258, time/batch=0.072\n",
      "5286/67600 (epoch 3), train_loss = 1.296, time/batch=0.077\n",
      "5287/67600 (epoch 3), train_loss = 1.304, time/batch=0.073\n",
      "5288/67600 (epoch 3), train_loss = 1.380, time/batch=0.075\n",
      "5289/67600 (epoch 3), train_loss = 1.344, time/batch=0.171\n",
      "5290/67600 (epoch 3), train_loss = 1.245, time/batch=0.072\n",
      "5291/67600 (epoch 3), train_loss = 1.279, time/batch=0.107\n",
      "5292/67600 (epoch 3), train_loss = 1.278, time/batch=0.071\n",
      "5293/67600 (epoch 3), train_loss = 1.297, time/batch=0.070\n",
      "5294/67600 (epoch 3), train_loss = 1.264, time/batch=0.083\n",
      "5295/67600 (epoch 3), train_loss = 1.258, time/batch=0.072\n",
      "5296/67600 (epoch 3), train_loss = 1.340, time/batch=0.071\n",
      "5297/67600 (epoch 3), train_loss = 1.257, time/batch=0.071\n",
      "5298/67600 (epoch 3), train_loss = 1.275, time/batch=0.072\n",
      "5299/67600 (epoch 3), train_loss = 1.305, time/batch=0.072\n",
      "5300/67600 (epoch 3), train_loss = 1.388, time/batch=0.070\n",
      "5301/67600 (epoch 3), train_loss = 1.292, time/batch=0.186\n",
      "5302/67600 (epoch 3), train_loss = 1.283, time/batch=0.072\n",
      "5303/67600 (epoch 3), train_loss = 1.281, time/batch=0.104\n",
      "5304/67600 (epoch 3), train_loss = 1.317, time/batch=0.079\n",
      "5305/67600 (epoch 3), train_loss = 1.296, time/batch=0.079\n",
      "5306/67600 (epoch 3), train_loss = 1.257, time/batch=0.075\n",
      "5307/67600 (epoch 3), train_loss = 1.341, time/batch=0.074\n",
      "5308/67600 (epoch 3), train_loss = 1.239, time/batch=0.072\n",
      "5309/67600 (epoch 3), train_loss = 1.358, time/batch=0.074\n",
      "5310/67600 (epoch 3), train_loss = 1.295, time/batch=0.073\n",
      "5311/67600 (epoch 3), train_loss = 1.336, time/batch=0.078\n",
      "5312/67600 (epoch 3), train_loss = 1.325, time/batch=0.175\n",
      "5313/67600 (epoch 3), train_loss = 1.312, time/batch=0.081\n",
      "5314/67600 (epoch 3), train_loss = 1.353, time/batch=0.099\n",
      "5315/67600 (epoch 3), train_loss = 1.297, time/batch=0.072\n",
      "5316/67600 (epoch 3), train_loss = 1.313, time/batch=0.069\n",
      "5317/67600 (epoch 3), train_loss = 1.264, time/batch=0.072\n",
      "5318/67600 (epoch 3), train_loss = 1.367, time/batch=0.074\n",
      "5319/67600 (epoch 3), train_loss = 1.356, time/batch=0.080\n",
      "5320/67600 (epoch 3), train_loss = 1.347, time/batch=0.068\n",
      "5321/67600 (epoch 3), train_loss = 1.277, time/batch=0.072\n",
      "5322/67600 (epoch 3), train_loss = 1.362, time/batch=0.071\n",
      "5323/67600 (epoch 3), train_loss = 1.261, time/batch=0.068\n",
      "5324/67600 (epoch 3), train_loss = 1.224, time/batch=0.166\n",
      "5325/67600 (epoch 3), train_loss = 1.280, time/batch=0.105\n",
      "5326/67600 (epoch 3), train_loss = 1.277, time/batch=0.090\n",
      "5327/67600 (epoch 3), train_loss = 1.236, time/batch=0.073\n",
      "5328/67600 (epoch 3), train_loss = 1.285, time/batch=0.069\n",
      "5329/67600 (epoch 3), train_loss = 1.292, time/batch=0.079\n",
      "5330/67600 (epoch 3), train_loss = 1.280, time/batch=0.075\n",
      "5331/67600 (epoch 3), train_loss = 1.330, time/batch=0.076\n",
      "5332/67600 (epoch 3), train_loss = 1.310, time/batch=0.071\n",
      "5333/67600 (epoch 3), train_loss = 1.303, time/batch=0.072\n",
      "5334/67600 (epoch 3), train_loss = 1.238, time/batch=0.077\n",
      "5335/67600 (epoch 3), train_loss = 1.223, time/batch=0.073\n",
      "5336/67600 (epoch 3), train_loss = 1.261, time/batch=0.216\n",
      "5337/67600 (epoch 3), train_loss = 1.291, time/batch=0.075\n",
      "5338/67600 (epoch 3), train_loss = 1.245, time/batch=0.069\n",
      "5339/67600 (epoch 3), train_loss = 1.302, time/batch=0.073\n",
      "5340/67600 (epoch 3), train_loss = 1.309, time/batch=0.069\n",
      "5341/67600 (epoch 3), train_loss = 1.283, time/batch=0.070\n",
      "5342/67600 (epoch 3), train_loss = 1.245, time/batch=0.076\n",
      "5343/67600 (epoch 3), train_loss = 1.329, time/batch=0.071\n",
      "5344/67600 (epoch 3), train_loss = 1.270, time/batch=0.127\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5345/67600 (epoch 3), train_loss = 1.319, time/batch=0.113\n",
      "5346/67600 (epoch 3), train_loss = 1.366, time/batch=0.101\n",
      "5347/67600 (epoch 3), train_loss = 1.320, time/batch=0.078\n",
      "5348/67600 (epoch 3), train_loss = 1.260, time/batch=0.071\n",
      "5349/67600 (epoch 3), train_loss = 1.304, time/batch=0.104\n",
      "5350/67600 (epoch 3), train_loss = 1.300, time/batch=0.077\n",
      "5351/67600 (epoch 3), train_loss = 1.271, time/batch=0.071\n",
      "5352/67600 (epoch 3), train_loss = 1.301, time/batch=0.074\n",
      "5353/67600 (epoch 3), train_loss = 1.304, time/batch=0.069\n",
      "5354/67600 (epoch 3), train_loss = 1.245, time/batch=0.078\n",
      "5355/67600 (epoch 3), train_loss = 1.308, time/batch=0.074\n",
      "5356/67600 (epoch 3), train_loss = 1.342, time/batch=0.113\n",
      "5357/67600 (epoch 3), train_loss = 1.281, time/batch=0.075\n",
      "5358/67600 (epoch 3), train_loss = 1.241, time/batch=0.069\n",
      "5359/67600 (epoch 3), train_loss = 1.280, time/batch=0.074\n",
      "5360/67600 (epoch 3), train_loss = 1.312, time/batch=0.071\n",
      "5361/67600 (epoch 3), train_loss = 1.237, time/batch=0.069\n",
      "5362/67600 (epoch 3), train_loss = 1.306, time/batch=0.067\n",
      "5363/67600 (epoch 3), train_loss = 1.285, time/batch=0.088\n",
      "5364/67600 (epoch 3), train_loss = 1.298, time/batch=0.068\n",
      "5365/67600 (epoch 3), train_loss = 1.294, time/batch=0.069\n",
      "5366/67600 (epoch 3), train_loss = 1.267, time/batch=0.238\n",
      "5367/67600 (epoch 3), train_loss = 1.290, time/batch=0.068\n",
      "5368/67600 (epoch 3), train_loss = 1.282, time/batch=0.089\n",
      "5369/67600 (epoch 3), train_loss = 1.335, time/batch=0.070\n",
      "5370/67600 (epoch 3), train_loss = 1.357, time/batch=0.076\n",
      "5371/67600 (epoch 3), train_loss = 1.288, time/batch=0.068\n",
      "5372/67600 (epoch 3), train_loss = 1.311, time/batch=0.074\n",
      "5373/67600 (epoch 3), train_loss = 1.329, time/batch=0.074\n",
      "5374/67600 (epoch 3), train_loss = 1.311, time/batch=0.072\n",
      "5375/67600 (epoch 3), train_loss = 1.274, time/batch=0.071\n",
      "5376/67600 (epoch 3), train_loss = 1.284, time/batch=0.076\n",
      "5377/67600 (epoch 3), train_loss = 1.281, time/batch=0.073\n",
      "5378/67600 (epoch 3), train_loss = 1.250, time/batch=0.229\n",
      "5379/67600 (epoch 3), train_loss = 1.290, time/batch=0.086\n",
      "5380/67600 (epoch 3), train_loss = 1.346, time/batch=0.074\n",
      "5381/67600 (epoch 3), train_loss = 1.287, time/batch=0.073\n",
      "5382/67600 (epoch 3), train_loss = 1.296, time/batch=0.074\n",
      "5383/67600 (epoch 3), train_loss = 1.282, time/batch=0.070\n",
      "5384/67600 (epoch 3), train_loss = 1.283, time/batch=0.077\n",
      "5385/67600 (epoch 3), train_loss = 1.314, time/batch=0.074\n",
      "5386/67600 (epoch 3), train_loss = 1.330, time/batch=0.070\n",
      "5387/67600 (epoch 3), train_loss = 1.340, time/batch=0.074\n",
      "5388/67600 (epoch 3), train_loss = 1.292, time/batch=0.069\n",
      "5389/67600 (epoch 3), train_loss = 1.276, time/batch=0.200\n",
      "5390/67600 (epoch 3), train_loss = 1.242, time/batch=0.092\n",
      "5391/67600 (epoch 3), train_loss = 1.314, time/batch=0.083\n",
      "5392/67600 (epoch 3), train_loss = 1.313, time/batch=0.073\n",
      "5393/67600 (epoch 3), train_loss = 1.287, time/batch=0.074\n",
      "5394/67600 (epoch 3), train_loss = 1.321, time/batch=0.071\n",
      "5395/67600 (epoch 3), train_loss = 1.281, time/batch=0.072\n",
      "5396/67600 (epoch 3), train_loss = 1.261, time/batch=0.072\n",
      "5397/67600 (epoch 3), train_loss = 1.295, time/batch=0.118\n",
      "5398/67600 (epoch 3), train_loss = 1.318, time/batch=0.136\n",
      "5399/67600 (epoch 3), train_loss = 1.284, time/batch=0.114\n",
      "5400/67600 (epoch 3), train_loss = 1.260, time/batch=0.068\n",
      "5401/67600 (epoch 3), train_loss = 1.300, time/batch=0.072\n",
      "5402/67600 (epoch 3), train_loss = 1.255, time/batch=0.072\n",
      "5403/67600 (epoch 3), train_loss = 1.298, time/batch=0.070\n",
      "5404/67600 (epoch 3), train_loss = 1.345, time/batch=0.074\n",
      "5405/67600 (epoch 3), train_loss = 1.388, time/batch=0.073\n",
      "5406/67600 (epoch 3), train_loss = 1.293, time/batch=0.069\n",
      "5407/67600 (epoch 3), train_loss = 1.294, time/batch=0.070\n",
      "5408/67600 (epoch 4), train_loss = 1.468, time/batch=0.069\n",
      "5409/67600 (epoch 4), train_loss = 1.248, time/batch=0.188\n",
      "5410/67600 (epoch 4), train_loss = 1.335, time/batch=0.074\n",
      "5411/67600 (epoch 4), train_loss = 1.272, time/batch=0.104\n",
      "5412/67600 (epoch 4), train_loss = 1.299, time/batch=0.069\n",
      "5413/67600 (epoch 4), train_loss = 1.334, time/batch=0.072\n",
      "5414/67600 (epoch 4), train_loss = 1.275, time/batch=0.068\n",
      "5415/67600 (epoch 4), train_loss = 1.309, time/batch=0.075\n",
      "5416/67600 (epoch 4), train_loss = 1.325, time/batch=0.072\n",
      "5417/67600 (epoch 4), train_loss = 1.284, time/batch=0.071\n",
      "5418/67600 (epoch 4), train_loss = 1.250, time/batch=0.073\n",
      "5419/67600 (epoch 4), train_loss = 1.261, time/batch=0.069\n",
      "5420/67600 (epoch 4), train_loss = 1.265, time/batch=0.069\n",
      "5421/67600 (epoch 4), train_loss = 1.335, time/batch=0.188\n",
      "5422/67600 (epoch 4), train_loss = 1.304, time/batch=0.094\n",
      "5423/67600 (epoch 4), train_loss = 1.275, time/batch=0.078\n",
      "5424/67600 (epoch 4), train_loss = 1.286, time/batch=0.070\n",
      "5425/67600 (epoch 4), train_loss = 1.319, time/batch=0.070\n",
      "5426/67600 (epoch 4), train_loss = 1.286, time/batch=0.073\n",
      "5427/67600 (epoch 4), train_loss = 1.305, time/batch=0.072\n",
      "5428/67600 (epoch 4), train_loss = 1.294, time/batch=0.075\n",
      "5429/67600 (epoch 4), train_loss = 1.233, time/batch=0.071\n",
      "5430/67600 (epoch 4), train_loss = 1.330, time/batch=0.074\n",
      "5431/67600 (epoch 4), train_loss = 1.330, time/batch=0.070\n",
      "5432/67600 (epoch 4), train_loss = 1.369, time/batch=0.083\n",
      "5433/67600 (epoch 4), train_loss = 1.216, time/batch=0.186\n",
      "5434/67600 (epoch 4), train_loss = 1.294, time/batch=0.093\n",
      "5435/67600 (epoch 4), train_loss = 1.336, time/batch=0.071\n",
      "5436/67600 (epoch 4), train_loss = 1.358, time/batch=0.069\n",
      "5437/67600 (epoch 4), train_loss = 1.291, time/batch=0.069\n",
      "5438/67600 (epoch 4), train_loss = 1.281, time/batch=0.079\n",
      "5439/67600 (epoch 4), train_loss = 1.355, time/batch=0.097\n",
      "5440/67600 (epoch 4), train_loss = 1.290, time/batch=0.069\n",
      "5441/67600 (epoch 4), train_loss = 1.335, time/batch=0.075\n",
      "5442/67600 (epoch 4), train_loss = 1.309, time/batch=0.072\n",
      "5443/67600 (epoch 4), train_loss = 1.294, time/batch=0.071\n",
      "5444/67600 (epoch 4), train_loss = 1.245, time/batch=0.242\n",
      "5445/67600 (epoch 4), train_loss = 1.317, time/batch=0.100\n",
      "5446/67600 (epoch 4), train_loss = 1.311, time/batch=0.078\n",
      "5447/67600 (epoch 4), train_loss = 1.306, time/batch=0.068\n",
      "5448/67600 (epoch 4), train_loss = 1.220, time/batch=0.069\n",
      "5449/67600 (epoch 4), train_loss = 1.323, time/batch=0.075\n",
      "5450/67600 (epoch 4), train_loss = 1.326, time/batch=0.071\n",
      "5451/67600 (epoch 4), train_loss = 1.318, time/batch=0.071\n",
      "5452/67600 (epoch 4), train_loss = 1.335, time/batch=0.197\n",
      "5453/67600 (epoch 4), train_loss = 1.287, time/batch=0.102\n",
      "5454/67600 (epoch 4), train_loss = 1.250, time/batch=0.084\n",
      "5455/67600 (epoch 4), train_loss = 1.300, time/batch=0.086\n",
      "5456/67600 (epoch 4), train_loss = 1.265, time/batch=0.080\n",
      "5457/67600 (epoch 4), train_loss = 1.258, time/batch=0.068\n",
      "5458/67600 (epoch 4), train_loss = 1.366, time/batch=0.082\n",
      "5459/67600 (epoch 4), train_loss = 1.264, time/batch=0.072\n",
      "5460/67600 (epoch 4), train_loss = 1.276, time/batch=0.074\n",
      "5461/67600 (epoch 4), train_loss = 1.369, time/batch=0.076\n",
      "5462/67600 (epoch 4), train_loss = 1.341, time/batch=0.071\n",
      "5463/67600 (epoch 4), train_loss = 1.294, time/batch=0.210\n",
      "5464/67600 (epoch 4), train_loss = 1.306, time/batch=0.106\n",
      "5465/67600 (epoch 4), train_loss = 1.305, time/batch=0.074\n",
      "5466/67600 (epoch 4), train_loss = 1.294, time/batch=0.084\n",
      "5467/67600 (epoch 4), train_loss = 1.314, time/batch=0.108\n",
      "5468/67600 (epoch 4), train_loss = 1.296, time/batch=0.071\n",
      "5469/67600 (epoch 4), train_loss = 1.276, time/batch=0.099\n",
      "5470/67600 (epoch 4), train_loss = 1.330, time/batch=0.077\n",
      "5471/67600 (epoch 4), train_loss = 1.327, time/batch=0.100\n",
      "5472/67600 (epoch 4), train_loss = 1.297, time/batch=0.234\n",
      "5473/67600 (epoch 4), train_loss = 1.280, time/batch=0.078\n",
      "5474/67600 (epoch 4), train_loss = 1.286, time/batch=0.100\n",
      "5475/67600 (epoch 4), train_loss = 1.310, time/batch=0.073\n",
      "5476/67600 (epoch 4), train_loss = 1.325, time/batch=0.073\n",
      "5477/67600 (epoch 4), train_loss = 1.312, time/batch=0.101\n",
      "5478/67600 (epoch 4), train_loss = 1.315, time/batch=0.083\n",
      "5479/67600 (epoch 4), train_loss = 1.319, time/batch=0.071\n",
      "5480/67600 (epoch 4), train_loss = 1.280, time/batch=0.085\n",
      "5481/67600 (epoch 4), train_loss = 1.362, time/batch=0.086\n",
      "5482/67600 (epoch 4), train_loss = 1.290, time/batch=0.071\n",
      "5483/67600 (epoch 4), train_loss = 1.338, time/batch=0.206\n",
      "5484/67600 (epoch 4), train_loss = 1.351, time/batch=0.072\n",
      "5485/67600 (epoch 4), train_loss = 1.420, time/batch=0.090\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5486/67600 (epoch 4), train_loss = 1.342, time/batch=0.077\n",
      "5487/67600 (epoch 4), train_loss = 1.279, time/batch=0.070\n",
      "5488/67600 (epoch 4), train_loss = 1.262, time/batch=0.078\n",
      "5489/67600 (epoch 4), train_loss = 1.297, time/batch=0.073\n",
      "5490/67600 (epoch 4), train_loss = 1.305, time/batch=0.091\n",
      "5491/67600 (epoch 4), train_loss = 1.297, time/batch=0.073\n",
      "5492/67600 (epoch 4), train_loss = 1.308, time/batch=0.081\n",
      "5493/67600 (epoch 4), train_loss = 1.292, time/batch=0.074\n",
      "5494/67600 (epoch 4), train_loss = 1.230, time/batch=0.188\n",
      "5495/67600 (epoch 4), train_loss = 1.352, time/batch=0.098\n",
      "5496/67600 (epoch 4), train_loss = 1.324, time/batch=0.075\n",
      "5497/67600 (epoch 4), train_loss = 1.324, time/batch=0.073\n",
      "5498/67600 (epoch 4), train_loss = 1.305, time/batch=0.067\n",
      "5499/67600 (epoch 4), train_loss = 1.311, time/batch=0.087\n",
      "5500/67600 (epoch 4), train_loss = 1.248, time/batch=0.072\n",
      "model saved to ./save/model.ckpt\n",
      "5501/67600 (epoch 4), train_loss = 1.258, time/batch=0.095\n",
      "5502/67600 (epoch 4), train_loss = 1.260, time/batch=0.073\n",
      "5503/67600 (epoch 4), train_loss = 1.201, time/batch=0.212\n",
      "5504/67600 (epoch 4), train_loss = 1.217, time/batch=0.080\n",
      "5505/67600 (epoch 4), train_loss = 1.300, time/batch=0.077\n",
      "5506/67600 (epoch 4), train_loss = 1.277, time/batch=0.076\n",
      "5507/67600 (epoch 4), train_loss = 1.333, time/batch=0.070\n",
      "5508/67600 (epoch 4), train_loss = 1.193, time/batch=0.074\n",
      "5509/67600 (epoch 4), train_loss = 1.277, time/batch=0.100\n",
      "5510/67600 (epoch 4), train_loss = 1.320, time/batch=0.070\n",
      "5511/67600 (epoch 4), train_loss = 1.235, time/batch=0.103\n",
      "5512/67600 (epoch 4), train_loss = 1.261, time/batch=0.071\n",
      "5513/67600 (epoch 4), train_loss = 1.308, time/batch=0.155\n",
      "5514/67600 (epoch 4), train_loss = 1.262, time/batch=0.266\n",
      "5515/67600 (epoch 4), train_loss = 1.296, time/batch=0.090\n",
      "5516/67600 (epoch 4), train_loss = 1.333, time/batch=0.070\n",
      "5517/67600 (epoch 4), train_loss = 1.292, time/batch=0.075\n",
      "5518/67600 (epoch 4), train_loss = 1.250, time/batch=0.072\n",
      "5519/67600 (epoch 4), train_loss = 1.295, time/batch=0.070\n",
      "5520/67600 (epoch 4), train_loss = 1.280, time/batch=0.167\n",
      "5521/67600 (epoch 4), train_loss = 1.313, time/batch=0.104\n",
      "5522/67600 (epoch 4), train_loss = 1.314, time/batch=0.130\n",
      "5523/67600 (epoch 4), train_loss = 1.248, time/batch=0.069\n",
      "5524/67600 (epoch 4), train_loss = 1.247, time/batch=0.071\n",
      "5525/67600 (epoch 4), train_loss = 1.281, time/batch=0.077\n",
      "5526/67600 (epoch 4), train_loss = 1.299, time/batch=0.074\n",
      "5527/67600 (epoch 4), train_loss = 1.319, time/batch=0.070\n",
      "5528/67600 (epoch 4), train_loss = 1.297, time/batch=0.080\n",
      "5529/67600 (epoch 4), train_loss = 1.308, time/batch=0.075\n",
      "5530/67600 (epoch 4), train_loss = 1.281, time/batch=0.115\n",
      "5531/67600 (epoch 4), train_loss = 1.274, time/batch=0.237\n",
      "5532/67600 (epoch 4), train_loss = 1.278, time/batch=0.109\n",
      "5533/67600 (epoch 4), train_loss = 1.205, time/batch=0.072\n",
      "5534/67600 (epoch 4), train_loss = 1.298, time/batch=0.072\n",
      "5535/67600 (epoch 4), train_loss = 1.321, time/batch=0.097\n",
      "5536/67600 (epoch 4), train_loss = 1.268, time/batch=0.076\n",
      "5537/67600 (epoch 4), train_loss = 1.276, time/batch=0.086\n",
      "5538/67600 (epoch 4), train_loss = 1.304, time/batch=0.072\n",
      "5539/67600 (epoch 4), train_loss = 1.284, time/batch=0.080\n",
      "5540/67600 (epoch 4), train_loss = 1.343, time/batch=0.103\n",
      "5541/67600 (epoch 4), train_loss = 1.274, time/batch=0.242\n",
      "5542/67600 (epoch 4), train_loss = 1.312, time/batch=0.101\n",
      "5543/67600 (epoch 4), train_loss = 1.297, time/batch=0.071\n",
      "5544/67600 (epoch 4), train_loss = 1.310, time/batch=0.079\n",
      "5545/67600 (epoch 4), train_loss = 1.295, time/batch=0.096\n",
      "5546/67600 (epoch 4), train_loss = 1.301, time/batch=0.070\n",
      "5547/67600 (epoch 4), train_loss = 1.266, time/batch=0.101\n",
      "5548/67600 (epoch 4), train_loss = 1.256, time/batch=0.109\n",
      "5549/67600 (epoch 4), train_loss = 1.239, time/batch=0.093\n",
      "5550/67600 (epoch 4), train_loss = 1.324, time/batch=0.252\n",
      "5551/67600 (epoch 4), train_loss = 1.240, time/batch=0.128\n",
      "5552/67600 (epoch 4), train_loss = 1.326, time/batch=0.071\n",
      "5553/67600 (epoch 4), train_loss = 1.372, time/batch=0.105\n",
      "5554/67600 (epoch 4), train_loss = 1.293, time/batch=0.073\n",
      "5555/67600 (epoch 4), train_loss = 1.295, time/batch=0.070\n",
      "5556/67600 (epoch 4), train_loss = 1.329, time/batch=0.071\n",
      "5557/67600 (epoch 4), train_loss = 1.222, time/batch=0.099\n",
      "5558/67600 (epoch 4), train_loss = 1.296, time/batch=0.101\n",
      "5559/67600 (epoch 4), train_loss = 1.250, time/batch=0.072\n",
      "5560/67600 (epoch 4), train_loss = 1.234, time/batch=0.285\n",
      "5561/67600 (epoch 4), train_loss = 1.282, time/batch=0.101\n",
      "5562/67600 (epoch 4), train_loss = 1.255, time/batch=0.090\n",
      "5563/67600 (epoch 4), train_loss = 1.309, time/batch=0.094\n",
      "5564/67600 (epoch 4), train_loss = 1.325, time/batch=0.071\n",
      "5565/67600 (epoch 4), train_loss = 1.320, time/batch=0.075\n",
      "5566/67600 (epoch 4), train_loss = 1.300, time/batch=0.235\n",
      "5567/67600 (epoch 4), train_loss = 1.274, time/batch=0.112\n",
      "5568/67600 (epoch 4), train_loss = 1.260, time/batch=0.108\n",
      "5569/67600 (epoch 4), train_loss = 1.234, time/batch=0.118\n",
      "5570/67600 (epoch 4), train_loss = 1.294, time/batch=0.071\n",
      "5571/67600 (epoch 4), train_loss = 1.285, time/batch=0.106\n",
      "5572/67600 (epoch 4), train_loss = 1.185, time/batch=0.099\n",
      "5573/67600 (epoch 4), train_loss = 1.287, time/batch=0.096\n",
      "5574/67600 (epoch 4), train_loss = 1.277, time/batch=0.077\n",
      "5575/67600 (epoch 4), train_loss = 1.252, time/batch=0.180\n",
      "5576/67600 (epoch 4), train_loss = 1.307, time/batch=0.071\n",
      "5577/67600 (epoch 4), train_loss = 1.317, time/batch=0.109\n",
      "5578/67600 (epoch 4), train_loss = 1.294, time/batch=0.072\n",
      "5579/67600 (epoch 4), train_loss = 1.230, time/batch=0.080\n",
      "5580/67600 (epoch 4), train_loss = 1.312, time/batch=0.104\n",
      "5581/67600 (epoch 4), train_loss = 1.263, time/batch=0.083\n",
      "5582/67600 (epoch 4), train_loss = 1.254, time/batch=0.090\n",
      "5583/67600 (epoch 4), train_loss = 1.260, time/batch=0.070\n",
      "5584/67600 (epoch 4), train_loss = 1.301, time/batch=0.075\n",
      "5585/67600 (epoch 4), train_loss = 1.337, time/batch=0.074\n",
      "5586/67600 (epoch 4), train_loss = 1.257, time/batch=0.220\n",
      "5587/67600 (epoch 4), train_loss = 1.260, time/batch=0.134\n",
      "5588/67600 (epoch 4), train_loss = 1.223, time/batch=0.073\n",
      "5589/67600 (epoch 4), train_loss = 1.222, time/batch=0.075\n",
      "5590/67600 (epoch 4), train_loss = 1.270, time/batch=0.105\n",
      "5591/67600 (epoch 4), train_loss = 1.372, time/batch=0.100\n",
      "5592/67600 (epoch 4), train_loss = 1.390, time/batch=0.102\n",
      "5593/67600 (epoch 4), train_loss = 1.363, time/batch=0.101\n",
      "5594/67600 (epoch 4), train_loss = 1.374, time/batch=0.098\n",
      "5595/67600 (epoch 4), train_loss = 1.293, time/batch=0.197\n",
      "5596/67600 (epoch 4), train_loss = 1.293, time/batch=0.088\n",
      "5597/67600 (epoch 4), train_loss = 1.282, time/batch=0.070\n",
      "5598/67600 (epoch 4), train_loss = 1.352, time/batch=0.073\n",
      "5599/67600 (epoch 4), train_loss = 1.319, time/batch=0.078\n",
      "5600/67600 (epoch 4), train_loss = 1.275, time/batch=0.068\n",
      "5601/67600 (epoch 4), train_loss = 1.302, time/batch=0.077\n",
      "5602/67600 (epoch 4), train_loss = 1.314, time/batch=0.102\n",
      "5603/67600 (epoch 4), train_loss = 1.297, time/batch=0.089\n",
      "5604/67600 (epoch 4), train_loss = 1.277, time/batch=0.069\n",
      "5605/67600 (epoch 4), train_loss = 1.274, time/batch=0.069\n",
      "5606/67600 (epoch 4), train_loss = 1.294, time/batch=0.221\n",
      "5607/67600 (epoch 4), train_loss = 1.257, time/batch=0.089\n",
      "5608/67600 (epoch 4), train_loss = 1.242, time/batch=0.074\n",
      "5609/67600 (epoch 4), train_loss = 1.227, time/batch=0.081\n",
      "5610/67600 (epoch 4), train_loss = 1.329, time/batch=0.086\n",
      "5611/67600 (epoch 4), train_loss = 1.304, time/batch=0.099\n",
      "5612/67600 (epoch 4), train_loss = 1.309, time/batch=0.084\n",
      "5613/67600 (epoch 4), train_loss = 1.221, time/batch=0.081\n",
      "5614/67600 (epoch 4), train_loss = 1.226, time/batch=0.076\n",
      "5615/67600 (epoch 4), train_loss = 1.255, time/batch=0.080\n",
      "5616/67600 (epoch 4), train_loss = 1.315, time/batch=0.201\n",
      "5617/67600 (epoch 4), train_loss = 1.339, time/batch=0.092\n",
      "5618/67600 (epoch 4), train_loss = 1.304, time/batch=0.078\n",
      "5619/67600 (epoch 4), train_loss = 1.369, time/batch=0.074\n",
      "5620/67600 (epoch 4), train_loss = 1.261, time/batch=0.096\n",
      "5621/67600 (epoch 4), train_loss = 1.270, time/batch=0.082\n",
      "5622/67600 (epoch 4), train_loss = 1.293, time/batch=0.078\n",
      "5623/67600 (epoch 4), train_loss = 1.324, time/batch=0.071\n",
      "5624/67600 (epoch 4), train_loss = 1.266, time/batch=0.145\n",
      "5625/67600 (epoch 4), train_loss = 1.271, time/batch=0.070\n",
      "5626/67600 (epoch 4), train_loss = 1.250, time/batch=0.068\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5627/67600 (epoch 4), train_loss = 1.255, time/batch=0.069\n",
      "5628/67600 (epoch 4), train_loss = 1.346, time/batch=0.074\n",
      "5629/67600 (epoch 4), train_loss = 1.259, time/batch=0.070\n",
      "5630/67600 (epoch 4), train_loss = 1.280, time/batch=0.071\n",
      "5631/67600 (epoch 4), train_loss = 1.280, time/batch=0.071\n",
      "5632/67600 (epoch 4), train_loss = 1.290, time/batch=0.076\n",
      "5633/67600 (epoch 4), train_loss = 1.273, time/batch=0.076\n",
      "5634/67600 (epoch 4), train_loss = 1.323, time/batch=0.286\n",
      "5635/67600 (epoch 4), train_loss = 1.244, time/batch=0.075\n",
      "5636/67600 (epoch 4), train_loss = 1.267, time/batch=0.094\n",
      "5637/67600 (epoch 4), train_loss = 1.257, time/batch=0.090\n",
      "5638/67600 (epoch 4), train_loss = 1.280, time/batch=0.071\n",
      "5639/67600 (epoch 4), train_loss = 1.294, time/batch=0.074\n",
      "5640/67600 (epoch 4), train_loss = 1.226, time/batch=0.070\n",
      "5641/67600 (epoch 4), train_loss = 1.224, time/batch=0.198\n",
      "5642/67600 (epoch 4), train_loss = 1.308, time/batch=0.087\n",
      "5643/67600 (epoch 4), train_loss = 1.280, time/batch=0.114\n",
      "5644/67600 (epoch 4), train_loss = 1.266, time/batch=0.093\n",
      "5645/67600 (epoch 4), train_loss = 1.264, time/batch=0.098\n",
      "5646/67600 (epoch 4), train_loss = 1.333, time/batch=0.074\n",
      "5647/67600 (epoch 4), train_loss = 1.294, time/batch=0.071\n",
      "5648/67600 (epoch 4), train_loss = 1.296, time/batch=0.069\n",
      "5649/67600 (epoch 4), train_loss = 1.232, time/batch=0.069\n",
      "5650/67600 (epoch 4), train_loss = 1.282, time/batch=0.093\n",
      "5651/67600 (epoch 4), train_loss = 1.292, time/batch=0.072\n",
      "5652/67600 (epoch 4), train_loss = 1.230, time/batch=0.071\n",
      "5653/67600 (epoch 4), train_loss = 1.285, time/batch=0.083\n",
      "5654/67600 (epoch 4), train_loss = 1.269, time/batch=0.070\n",
      "5655/67600 (epoch 4), train_loss = 1.289, time/batch=0.210\n",
      "5656/67600 (epoch 4), train_loss = 1.302, time/batch=0.098\n",
      "5657/67600 (epoch 4), train_loss = 1.248, time/batch=0.072\n",
      "5658/67600 (epoch 4), train_loss = 1.248, time/batch=0.080\n",
      "5659/67600 (epoch 4), train_loss = 1.329, time/batch=0.071\n",
      "5660/67600 (epoch 4), train_loss = 1.261, time/batch=0.077\n",
      "5661/67600 (epoch 4), train_loss = 1.284, time/batch=0.078\n",
      "5662/67600 (epoch 4), train_loss = 1.301, time/batch=0.077\n",
      "5663/67600 (epoch 4), train_loss = 1.343, time/batch=0.192\n",
      "5664/67600 (epoch 4), train_loss = 1.317, time/batch=0.076\n",
      "5665/67600 (epoch 4), train_loss = 1.326, time/batch=0.117\n",
      "5666/67600 (epoch 4), train_loss = 1.235, time/batch=0.075\n",
      "5667/67600 (epoch 4), train_loss = 1.244, time/batch=0.085\n",
      "5668/67600 (epoch 4), train_loss = 1.259, time/batch=0.075\n",
      "5669/67600 (epoch 4), train_loss = 1.264, time/batch=0.070\n",
      "5670/67600 (epoch 4), train_loss = 1.268, time/batch=0.070\n",
      "5671/67600 (epoch 4), train_loss = 1.303, time/batch=0.074\n",
      "5672/67600 (epoch 4), train_loss = 1.259, time/batch=0.071\n",
      "5673/67600 (epoch 4), train_loss = 1.260, time/batch=0.073\n",
      "5674/67600 (epoch 4), train_loss = 1.245, time/batch=0.197\n",
      "5675/67600 (epoch 4), train_loss = 1.294, time/batch=0.070\n",
      "5676/67600 (epoch 4), train_loss = 1.246, time/batch=0.108\n",
      "5677/67600 (epoch 4), train_loss = 1.260, time/batch=0.072\n",
      "5678/67600 (epoch 4), train_loss = 1.320, time/batch=0.070\n",
      "5679/67600 (epoch 4), train_loss = 1.276, time/batch=0.069\n",
      "5680/67600 (epoch 4), train_loss = 1.292, time/batch=0.076\n",
      "5681/67600 (epoch 4), train_loss = 1.332, time/batch=0.080\n",
      "5682/67600 (epoch 4), train_loss = 1.292, time/batch=0.079\n",
      "5683/67600 (epoch 4), train_loss = 1.291, time/batch=0.082\n",
      "5684/67600 (epoch 4), train_loss = 1.292, time/batch=0.074\n",
      "5685/67600 (epoch 4), train_loss = 1.247, time/batch=0.081\n",
      "5686/67600 (epoch 4), train_loss = 1.242, time/batch=0.182\n",
      "5687/67600 (epoch 4), train_loss = 1.320, time/batch=0.105\n",
      "5688/67600 (epoch 4), train_loss = 1.332, time/batch=0.071\n",
      "5689/67600 (epoch 4), train_loss = 1.272, time/batch=0.074\n",
      "5690/67600 (epoch 4), train_loss = 1.216, time/batch=0.077\n",
      "5691/67600 (epoch 4), train_loss = 1.294, time/batch=0.085\n",
      "5692/67600 (epoch 4), train_loss = 1.258, time/batch=0.078\n",
      "5693/67600 (epoch 4), train_loss = 1.366, time/batch=0.076\n",
      "5694/67600 (epoch 4), train_loss = 1.304, time/batch=0.074\n",
      "5695/67600 (epoch 4), train_loss = 1.292, time/batch=0.075\n",
      "5696/67600 (epoch 4), train_loss = 1.318, time/batch=0.070\n",
      "5697/67600 (epoch 4), train_loss = 1.308, time/batch=0.206\n",
      "5698/67600 (epoch 4), train_loss = 1.304, time/batch=0.069\n",
      "5699/67600 (epoch 4), train_loss = 1.300, time/batch=0.090\n",
      "5700/67600 (epoch 4), train_loss = 1.297, time/batch=0.071\n",
      "5701/67600 (epoch 4), train_loss = 1.287, time/batch=0.076\n",
      "5702/67600 (epoch 4), train_loss = 1.290, time/batch=0.073\n",
      "5703/67600 (epoch 4), train_loss = 1.313, time/batch=0.081\n",
      "5704/67600 (epoch 4), train_loss = 1.302, time/batch=0.073\n",
      "5705/67600 (epoch 4), train_loss = 1.264, time/batch=0.072\n",
      "5706/67600 (epoch 4), train_loss = 1.270, time/batch=0.076\n",
      "5707/67600 (epoch 4), train_loss = 1.315, time/batch=0.071\n",
      "5708/67600 (epoch 4), train_loss = 1.296, time/batch=0.082\n",
      "5709/67600 (epoch 4), train_loss = 1.316, time/batch=0.233\n",
      "5710/67600 (epoch 4), train_loss = 1.276, time/batch=0.083\n",
      "5711/67600 (epoch 4), train_loss = 1.298, time/batch=0.101\n",
      "5712/67600 (epoch 4), train_loss = 1.311, time/batch=0.094\n",
      "5713/67600 (epoch 4), train_loss = 1.315, time/batch=0.072\n",
      "5714/67600 (epoch 4), train_loss = 1.341, time/batch=0.066\n",
      "5715/67600 (epoch 4), train_loss = 1.312, time/batch=0.071\n",
      "5716/67600 (epoch 4), train_loss = 1.329, time/batch=0.200\n",
      "5717/67600 (epoch 4), train_loss = 1.316, time/batch=0.093\n",
      "5718/67600 (epoch 4), train_loss = 1.294, time/batch=0.114\n",
      "5719/67600 (epoch 4), train_loss = 1.245, time/batch=0.071\n",
      "5720/67600 (epoch 4), train_loss = 1.263, time/batch=0.108\n",
      "5721/67600 (epoch 4), train_loss = 1.313, time/batch=0.073\n",
      "5722/67600 (epoch 4), train_loss = 1.273, time/batch=0.106\n",
      "5723/67600 (epoch 4), train_loss = 1.370, time/batch=0.101\n",
      "5724/67600 (epoch 4), train_loss = 1.284, time/batch=0.070\n",
      "5725/67600 (epoch 4), train_loss = 1.290, time/batch=0.070\n",
      "5726/67600 (epoch 4), train_loss = 1.307, time/batch=0.182\n",
      "5727/67600 (epoch 4), train_loss = 1.318, time/batch=0.072\n",
      "5728/67600 (epoch 4), train_loss = 1.338, time/batch=0.150\n",
      "5729/67600 (epoch 4), train_loss = 1.282, time/batch=0.073\n",
      "5730/67600 (epoch 4), train_loss = 1.287, time/batch=0.098\n",
      "5731/67600 (epoch 4), train_loss = 1.263, time/batch=0.075\n",
      "5732/67600 (epoch 4), train_loss = 1.281, time/batch=0.080\n",
      "5733/67600 (epoch 4), train_loss = 1.261, time/batch=0.087\n",
      "5734/67600 (epoch 4), train_loss = 1.249, time/batch=0.071\n",
      "5735/67600 (epoch 4), train_loss = 1.300, time/batch=0.071\n",
      "5736/67600 (epoch 4), train_loss = 1.278, time/batch=0.251\n",
      "5737/67600 (epoch 4), train_loss = 1.290, time/batch=0.099\n",
      "5738/67600 (epoch 4), train_loss = 1.321, time/batch=0.073\n",
      "5739/67600 (epoch 4), train_loss = 1.224, time/batch=0.076\n",
      "5740/67600 (epoch 4), train_loss = 1.298, time/batch=0.087\n",
      "5741/67600 (epoch 4), train_loss = 1.275, time/batch=0.072\n",
      "5742/67600 (epoch 4), train_loss = 1.287, time/batch=0.111\n",
      "5743/67600 (epoch 4), train_loss = 1.331, time/batch=0.098\n",
      "5744/67600 (epoch 4), train_loss = 1.271, time/batch=0.094\n",
      "5745/67600 (epoch 4), train_loss = 1.266, time/batch=0.074\n",
      "5746/67600 (epoch 4), train_loss = 1.298, time/batch=0.223\n",
      "5747/67600 (epoch 4), train_loss = 1.313, time/batch=0.103\n",
      "5748/67600 (epoch 4), train_loss = 1.270, time/batch=0.084\n",
      "5749/67600 (epoch 4), train_loss = 1.274, time/batch=0.071\n",
      "5750/67600 (epoch 4), train_loss = 1.260, time/batch=0.078\n",
      "5751/67600 (epoch 4), train_loss = 1.248, time/batch=0.086\n",
      "5752/67600 (epoch 4), train_loss = 1.341, time/batch=0.077\n",
      "5753/67600 (epoch 4), train_loss = 1.357, time/batch=0.090\n",
      "5754/67600 (epoch 4), train_loss = 1.287, time/batch=0.072\n",
      "5755/67600 (epoch 4), train_loss = 1.296, time/batch=0.072\n",
      "5756/67600 (epoch 4), train_loss = 1.334, time/batch=0.086\n",
      "5757/67600 (epoch 4), train_loss = 1.341, time/batch=0.201\n",
      "5758/67600 (epoch 4), train_loss = 1.245, time/batch=0.099\n",
      "5759/67600 (epoch 4), train_loss = 1.232, time/batch=0.072\n",
      "5760/67600 (epoch 4), train_loss = 1.222, time/batch=0.080\n",
      "5761/67600 (epoch 4), train_loss = 1.262, time/batch=0.073\n",
      "5762/67600 (epoch 4), train_loss = 1.261, time/batch=0.092\n",
      "5763/67600 (epoch 4), train_loss = 1.331, time/batch=0.081\n",
      "5764/67600 (epoch 4), train_loss = 1.250, time/batch=0.073\n",
      "5765/67600 (epoch 4), train_loss = 1.271, time/batch=0.084\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5766/67600 (epoch 4), train_loss = 1.231, time/batch=0.072\n",
      "5767/67600 (epoch 4), train_loss = 1.376, time/batch=0.183\n",
      "5768/67600 (epoch 4), train_loss = 1.283, time/batch=0.111\n",
      "5769/67600 (epoch 4), train_loss = 1.236, time/batch=0.109\n",
      "5770/67600 (epoch 4), train_loss = 1.249, time/batch=0.078\n",
      "5771/67600 (epoch 4), train_loss = 1.343, time/batch=0.072\n",
      "5772/67600 (epoch 4), train_loss = 1.281, time/batch=0.086\n",
      "5773/67600 (epoch 4), train_loss = 1.269, time/batch=0.080\n",
      "5774/67600 (epoch 4), train_loss = 1.287, time/batch=0.078\n",
      "5775/67600 (epoch 4), train_loss = 1.225, time/batch=0.169\n",
      "5776/67600 (epoch 4), train_loss = 1.271, time/batch=0.096\n",
      "5777/67600 (epoch 4), train_loss = 1.346, time/batch=0.070\n",
      "5778/67600 (epoch 4), train_loss = 1.275, time/batch=0.069\n",
      "5779/67600 (epoch 4), train_loss = 1.285, time/batch=0.071\n",
      "5780/67600 (epoch 4), train_loss = 1.305, time/batch=0.067\n",
      "5781/67600 (epoch 4), train_loss = 1.287, time/batch=0.074\n",
      "5782/67600 (epoch 4), train_loss = 1.353, time/batch=0.071\n",
      "5783/67600 (epoch 4), train_loss = 1.363, time/batch=0.110\n",
      "5784/67600 (epoch 4), train_loss = 1.306, time/batch=0.223\n",
      "5785/67600 (epoch 4), train_loss = 1.291, time/batch=0.103\n",
      "5786/67600 (epoch 4), train_loss = 1.349, time/batch=0.072\n",
      "5787/67600 (epoch 4), train_loss = 1.367, time/batch=0.073\n",
      "5788/67600 (epoch 4), train_loss = 1.318, time/batch=0.073\n",
      "5789/67600 (epoch 4), train_loss = 1.289, time/batch=0.069\n",
      "5790/67600 (epoch 4), train_loss = 1.289, time/batch=0.076\n",
      "5791/67600 (epoch 4), train_loss = 1.328, time/batch=0.075\n",
      "5792/67600 (epoch 4), train_loss = 1.380, time/batch=0.080\n",
      "5793/67600 (epoch 4), train_loss = 1.297, time/batch=0.085\n",
      "5794/67600 (epoch 4), train_loss = 1.275, time/batch=0.077\n",
      "5795/67600 (epoch 4), train_loss = 1.273, time/batch=0.260\n",
      "5796/67600 (epoch 4), train_loss = 1.330, time/batch=0.090\n",
      "5797/67600 (epoch 4), train_loss = 1.301, time/batch=0.071\n",
      "5798/67600 (epoch 4), train_loss = 1.277, time/batch=0.081\n",
      "5799/67600 (epoch 4), train_loss = 1.279, time/batch=0.072\n",
      "5800/67600 (epoch 4), train_loss = 1.274, time/batch=0.085\n",
      "5801/67600 (epoch 4), train_loss = 1.304, time/batch=0.075\n",
      "5802/67600 (epoch 4), train_loss = 1.279, time/batch=0.089\n",
      "5803/67600 (epoch 4), train_loss = 1.271, time/batch=0.074\n",
      "5804/67600 (epoch 4), train_loss = 1.337, time/batch=0.076\n",
      "5805/67600 (epoch 4), train_loss = 1.339, time/batch=0.225\n",
      "5806/67600 (epoch 4), train_loss = 1.283, time/batch=0.094\n",
      "5807/67600 (epoch 4), train_loss = 1.270, time/batch=0.071\n",
      "5808/67600 (epoch 4), train_loss = 1.325, time/batch=0.073\n",
      "5809/67600 (epoch 4), train_loss = 1.367, time/batch=0.083\n",
      "5810/67600 (epoch 4), train_loss = 1.355, time/batch=0.075\n",
      "5811/67600 (epoch 4), train_loss = 1.307, time/batch=0.078\n",
      "5812/67600 (epoch 4), train_loss = 1.392, time/batch=0.074\n",
      "5813/67600 (epoch 4), train_loss = 1.336, time/batch=0.245\n",
      "5814/67600 (epoch 4), train_loss = 1.351, time/batch=0.137\n",
      "5815/67600 (epoch 4), train_loss = 1.282, time/batch=0.078\n",
      "5816/67600 (epoch 4), train_loss = 1.317, time/batch=0.082\n",
      "5817/67600 (epoch 4), train_loss = 1.325, time/batch=0.082\n",
      "5818/67600 (epoch 4), train_loss = 1.317, time/batch=0.104\n",
      "5819/67600 (epoch 4), train_loss = 1.266, time/batch=0.078\n",
      "5820/67600 (epoch 4), train_loss = 1.276, time/batch=0.090\n",
      "5821/67600 (epoch 4), train_loss = 1.299, time/batch=0.072\n",
      "5822/67600 (epoch 4), train_loss = 1.288, time/batch=0.277\n",
      "5823/67600 (epoch 4), train_loss = 1.332, time/batch=0.111\n",
      "5824/67600 (epoch 4), train_loss = 1.299, time/batch=0.070\n",
      "5825/67600 (epoch 4), train_loss = 1.330, time/batch=0.070\n",
      "5826/67600 (epoch 4), train_loss = 1.336, time/batch=0.076\n",
      "5827/67600 (epoch 4), train_loss = 1.284, time/batch=0.072\n",
      "5828/67600 (epoch 4), train_loss = 1.221, time/batch=0.079\n",
      "5829/67600 (epoch 4), train_loss = 1.239, time/batch=0.085\n",
      "5830/67600 (epoch 4), train_loss = 1.279, time/batch=0.076\n",
      "5831/67600 (epoch 4), train_loss = 1.252, time/batch=0.108\n",
      "5832/67600 (epoch 4), train_loss = 1.294, time/batch=0.224\n",
      "5833/67600 (epoch 4), train_loss = 1.261, time/batch=0.133\n",
      "5834/67600 (epoch 4), train_loss = 1.287, time/batch=0.079\n",
      "5835/67600 (epoch 4), train_loss = 1.279, time/batch=0.081\n",
      "5836/67600 (epoch 4), train_loss = 1.199, time/batch=0.111\n",
      "5837/67600 (epoch 4), train_loss = 1.263, time/batch=0.104\n",
      "5838/67600 (epoch 4), train_loss = 1.337, time/batch=0.070\n",
      "5839/67600 (epoch 4), train_loss = 1.247, time/batch=0.074\n",
      "5840/67600 (epoch 4), train_loss = 1.307, time/batch=0.075\n",
      "5841/67600 (epoch 4), train_loss = 1.310, time/batch=0.076\n",
      "5842/67600 (epoch 4), train_loss = 1.251, time/batch=0.220\n",
      "5843/67600 (epoch 4), train_loss = 1.352, time/batch=0.108\n",
      "5844/67600 (epoch 4), train_loss = 1.274, time/batch=0.077\n",
      "5845/67600 (epoch 4), train_loss = 1.294, time/batch=0.084\n",
      "5846/67600 (epoch 4), train_loss = 1.309, time/batch=0.084\n",
      "5847/67600 (epoch 4), train_loss = 1.275, time/batch=0.073\n",
      "5848/67600 (epoch 4), train_loss = 1.266, time/batch=0.079\n",
      "5849/67600 (epoch 4), train_loss = 1.304, time/batch=0.069\n",
      "5850/67600 (epoch 4), train_loss = 1.265, time/batch=0.081\n",
      "5851/67600 (epoch 4), train_loss = 1.259, time/batch=0.086\n",
      "5852/67600 (epoch 4), train_loss = 1.287, time/batch=0.224\n",
      "5853/67600 (epoch 4), train_loss = 1.329, time/batch=0.071\n",
      "5854/67600 (epoch 4), train_loss = 1.245, time/batch=0.076\n",
      "5855/67600 (epoch 4), train_loss = 1.259, time/batch=0.070\n",
      "5856/67600 (epoch 4), train_loss = 1.229, time/batch=0.071\n",
      "5857/67600 (epoch 4), train_loss = 1.260, time/batch=0.069\n",
      "5858/67600 (epoch 4), train_loss = 1.212, time/batch=0.075\n",
      "5859/67600 (epoch 4), train_loss = 1.323, time/batch=0.071\n",
      "5860/67600 (epoch 4), train_loss = 1.327, time/batch=0.174\n",
      "5861/67600 (epoch 4), train_loss = 1.226, time/batch=0.099\n",
      "5862/67600 (epoch 4), train_loss = 1.204, time/batch=0.113\n",
      "5863/67600 (epoch 4), train_loss = 1.248, time/batch=0.064\n",
      "5864/67600 (epoch 4), train_loss = 1.263, time/batch=0.075\n",
      "5865/67600 (epoch 4), train_loss = 1.288, time/batch=0.075\n",
      "5866/67600 (epoch 4), train_loss = 1.306, time/batch=0.065\n",
      "5867/67600 (epoch 4), train_loss = 1.286, time/batch=0.064\n",
      "5868/67600 (epoch 4), train_loss = 1.291, time/batch=0.064\n",
      "5869/67600 (epoch 4), train_loss = 1.246, time/batch=0.066\n",
      "5870/67600 (epoch 4), train_loss = 1.316, time/batch=0.067\n",
      "5871/67600 (epoch 4), train_loss = 1.287, time/batch=0.065\n",
      "5872/67600 (epoch 4), train_loss = 1.241, time/batch=0.074\n",
      "5873/67600 (epoch 4), train_loss = 1.261, time/batch=0.189\n",
      "5874/67600 (epoch 4), train_loss = 1.273, time/batch=0.130\n",
      "5875/67600 (epoch 4), train_loss = 1.338, time/batch=0.079\n",
      "5876/67600 (epoch 4), train_loss = 1.283, time/batch=0.081\n",
      "5877/67600 (epoch 4), train_loss = 1.256, time/batch=0.088\n",
      "5878/67600 (epoch 4), train_loss = 1.271, time/batch=0.078\n",
      "5879/67600 (epoch 4), train_loss = 1.280, time/batch=0.071\n",
      "5880/67600 (epoch 4), train_loss = 1.242, time/batch=0.079\n",
      "5881/67600 (epoch 4), train_loss = 1.286, time/batch=0.077\n",
      "5882/67600 (epoch 4), train_loss = 1.257, time/batch=0.075\n",
      "5883/67600 (epoch 4), train_loss = 1.227, time/batch=0.215\n",
      "5884/67600 (epoch 4), train_loss = 1.300, time/batch=0.158\n",
      "5885/67600 (epoch 4), train_loss = 1.237, time/batch=0.081\n",
      "5886/67600 (epoch 4), train_loss = 1.270, time/batch=0.079\n",
      "5887/67600 (epoch 4), train_loss = 1.288, time/batch=0.077\n",
      "5888/67600 (epoch 4), train_loss = 1.230, time/batch=0.074\n",
      "5889/67600 (epoch 4), train_loss = 1.277, time/batch=0.087\n",
      "5890/67600 (epoch 4), train_loss = 1.269, time/batch=0.076\n",
      "5891/67600 (epoch 4), train_loss = 1.232, time/batch=0.073\n",
      "5892/67600 (epoch 4), train_loss = 1.297, time/batch=0.067\n",
      "5893/67600 (epoch 4), train_loss = 1.297, time/batch=0.072\n",
      "5894/67600 (epoch 4), train_loss = 1.321, time/batch=0.244\n",
      "5895/67600 (epoch 4), train_loss = 1.286, time/batch=0.087\n",
      "5896/67600 (epoch 4), train_loss = 1.351, time/batch=0.077\n",
      "5897/67600 (epoch 4), train_loss = 1.310, time/batch=0.078\n",
      "5898/67600 (epoch 4), train_loss = 1.233, time/batch=0.083\n",
      "5899/67600 (epoch 4), train_loss = 1.279, time/batch=0.078\n",
      "5900/67600 (epoch 4), train_loss = 1.296, time/batch=0.086\n",
      "5901/67600 (epoch 4), train_loss = 1.256, time/batch=0.077\n",
      "5902/67600 (epoch 4), train_loss = 1.334, time/batch=0.076\n",
      "5903/67600 (epoch 4), train_loss = 1.299, time/batch=0.078\n",
      "5904/67600 (epoch 4), train_loss = 1.261, time/batch=0.233\n",
      "5905/67600 (epoch 4), train_loss = 1.294, time/batch=0.092\n",
      "5906/67600 (epoch 4), train_loss = 1.336, time/batch=0.090\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5907/67600 (epoch 4), train_loss = 1.272, time/batch=0.072\n",
      "5908/67600 (epoch 4), train_loss = 1.220, time/batch=0.073\n",
      "5909/67600 (epoch 4), train_loss = 1.232, time/batch=0.079\n",
      "5910/67600 (epoch 4), train_loss = 1.265, time/batch=0.073\n",
      "5911/67600 (epoch 4), train_loss = 1.306, time/batch=0.065\n",
      "5912/67600 (epoch 4), train_loss = 1.306, time/batch=0.087\n",
      "5913/67600 (epoch 4), train_loss = 1.329, time/batch=0.077\n",
      "5914/67600 (epoch 4), train_loss = 1.308, time/batch=0.073\n",
      "5915/67600 (epoch 4), train_loss = 1.297, time/batch=0.223\n",
      "5916/67600 (epoch 4), train_loss = 1.233, time/batch=0.081\n",
      "5917/67600 (epoch 4), train_loss = 1.261, time/batch=0.073\n",
      "5918/67600 (epoch 4), train_loss = 1.318, time/batch=0.120\n",
      "5919/67600 (epoch 4), train_loss = 1.277, time/batch=0.097\n",
      "5920/67600 (epoch 4), train_loss = 1.297, time/batch=0.079\n",
      "5921/67600 (epoch 4), train_loss = 1.264, time/batch=0.131\n",
      "5922/67600 (epoch 4), train_loss = 1.292, time/batch=0.108\n",
      "5923/67600 (epoch 4), train_loss = 1.330, time/batch=0.068\n",
      "5924/67600 (epoch 4), train_loss = 1.327, time/batch=0.073\n",
      "5925/67600 (epoch 4), train_loss = 1.320, time/batch=0.075\n",
      "5926/67600 (epoch 4), train_loss = 1.292, time/batch=0.096\n",
      "5927/67600 (epoch 4), train_loss = 1.210, time/batch=0.095\n",
      "5928/67600 (epoch 4), train_loss = 1.328, time/batch=0.083\n",
      "5929/67600 (epoch 4), train_loss = 1.329, time/batch=0.069\n",
      "5930/67600 (epoch 4), train_loss = 1.347, time/batch=0.251\n",
      "5931/67600 (epoch 4), train_loss = 1.282, time/batch=0.118\n",
      "5932/67600 (epoch 4), train_loss = 1.286, time/batch=0.103\n",
      "5933/67600 (epoch 4), train_loss = 1.284, time/batch=0.084\n",
      "5934/67600 (epoch 4), train_loss = 1.301, time/batch=0.072\n",
      "5935/67600 (epoch 4), train_loss = 1.250, time/batch=0.070\n",
      "5936/67600 (epoch 4), train_loss = 1.308, time/batch=0.075\n",
      "5937/67600 (epoch 4), train_loss = 1.270, time/batch=0.083\n",
      "5938/67600 (epoch 4), train_loss = 1.336, time/batch=0.100\n",
      "5939/67600 (epoch 4), train_loss = 1.343, time/batch=0.084\n",
      "5940/67600 (epoch 4), train_loss = 1.305, time/batch=0.074\n",
      "5941/67600 (epoch 4), train_loss = 1.260, time/batch=0.251\n",
      "5942/67600 (epoch 4), train_loss = 1.265, time/batch=0.092\n",
      "5943/67600 (epoch 4), train_loss = 1.237, time/batch=0.072\n",
      "5944/67600 (epoch 4), train_loss = 1.259, time/batch=0.076\n",
      "5945/67600 (epoch 4), train_loss = 1.288, time/batch=0.077\n",
      "5946/67600 (epoch 4), train_loss = 1.270, time/batch=0.074\n",
      "5947/67600 (epoch 4), train_loss = 1.284, time/batch=0.077\n",
      "5948/67600 (epoch 4), train_loss = 1.294, time/batch=0.080\n",
      "5949/67600 (epoch 4), train_loss = 1.228, time/batch=0.074\n",
      "5950/67600 (epoch 4), train_loss = 1.268, time/batch=0.074\n",
      "5951/67600 (epoch 4), train_loss = 1.245, time/batch=0.141\n",
      "5952/67600 (epoch 4), train_loss = 1.317, time/batch=0.163\n",
      "5953/67600 (epoch 4), train_loss = 1.282, time/batch=0.082\n",
      "5954/67600 (epoch 4), train_loss = 1.264, time/batch=0.083\n",
      "5955/67600 (epoch 4), train_loss = 1.278, time/batch=0.098\n",
      "5956/67600 (epoch 4), train_loss = 1.413, time/batch=0.091\n",
      "5957/67600 (epoch 4), train_loss = 1.309, time/batch=0.080\n",
      "5958/67600 (epoch 4), train_loss = 1.264, time/batch=0.075\n",
      "5959/67600 (epoch 4), train_loss = 1.319, time/batch=0.222\n",
      "5960/67600 (epoch 4), train_loss = 1.256, time/batch=0.115\n",
      "5961/67600 (epoch 4), train_loss = 1.274, time/batch=0.073\n",
      "5962/67600 (epoch 4), train_loss = 1.318, time/batch=0.078\n",
      "5963/67600 (epoch 4), train_loss = 1.263, time/batch=0.120\n",
      "5964/67600 (epoch 4), train_loss = 1.331, time/batch=0.099\n",
      "5965/67600 (epoch 4), train_loss = 1.276, time/batch=0.075\n",
      "5966/67600 (epoch 4), train_loss = 1.251, time/batch=0.068\n",
      "5967/67600 (epoch 4), train_loss = 1.221, time/batch=0.075\n",
      "5968/67600 (epoch 4), train_loss = 1.245, time/batch=0.070\n",
      "5969/67600 (epoch 4), train_loss = 1.270, time/batch=0.187\n",
      "5970/67600 (epoch 4), train_loss = 1.238, time/batch=0.076\n",
      "5971/67600 (epoch 4), train_loss = 1.280, time/batch=0.106\n",
      "5972/67600 (epoch 4), train_loss = 1.243, time/batch=0.083\n",
      "5973/67600 (epoch 4), train_loss = 1.261, time/batch=0.082\n",
      "5974/67600 (epoch 4), train_loss = 1.299, time/batch=0.067\n",
      "5975/67600 (epoch 4), train_loss = 1.311, time/batch=0.074\n",
      "5976/67600 (epoch 4), train_loss = 1.301, time/batch=0.086\n",
      "5977/67600 (epoch 4), train_loss = 1.261, time/batch=0.089\n",
      "5978/67600 (epoch 4), train_loss = 1.249, time/batch=0.077\n",
      "5979/67600 (epoch 4), train_loss = 1.232, time/batch=0.110\n",
      "5980/67600 (epoch 4), train_loss = 1.268, time/batch=0.216\n",
      "5981/67600 (epoch 4), train_loss = 1.272, time/batch=0.102\n",
      "5982/67600 (epoch 4), train_loss = 1.286, time/batch=0.072\n",
      "5983/67600 (epoch 4), train_loss = 1.251, time/batch=0.103\n",
      "5984/67600 (epoch 4), train_loss = 1.304, time/batch=0.069\n",
      "5985/67600 (epoch 4), train_loss = 1.289, time/batch=0.065\n",
      "5986/67600 (epoch 4), train_loss = 1.310, time/batch=0.067\n",
      "5987/67600 (epoch 4), train_loss = 1.278, time/batch=0.067\n",
      "5988/67600 (epoch 4), train_loss = 1.293, time/batch=0.067\n",
      "5989/67600 (epoch 4), train_loss = 1.285, time/batch=0.085\n",
      "5990/67600 (epoch 4), train_loss = 1.242, time/batch=0.162\n",
      "5991/67600 (epoch 4), train_loss = 1.251, time/batch=0.130\n",
      "5992/67600 (epoch 4), train_loss = 1.271, time/batch=0.088\n",
      "5993/67600 (epoch 4), train_loss = 1.343, time/batch=0.080\n",
      "5994/67600 (epoch 4), train_loss = 1.254, time/batch=0.077\n",
      "5995/67600 (epoch 4), train_loss = 1.338, time/batch=0.072\n",
      "5996/67600 (epoch 4), train_loss = 1.247, time/batch=0.071\n",
      "5997/67600 (epoch 4), train_loss = 1.287, time/batch=0.079\n",
      "5998/67600 (epoch 4), train_loss = 1.349, time/batch=0.070\n",
      "5999/67600 (epoch 4), train_loss = 1.248, time/batch=0.074\n",
      "6000/67600 (epoch 4), train_loss = 1.257, time/batch=0.076\n",
      "model saved to ./save/model.ckpt\n",
      "6001/67600 (epoch 4), train_loss = 1.282, time/batch=0.100\n",
      "6002/67600 (epoch 4), train_loss = 1.225, time/batch=0.121\n",
      "6003/67600 (epoch 4), train_loss = 1.278, time/batch=0.086\n",
      "6004/67600 (epoch 4), train_loss = 1.289, time/batch=0.069\n",
      "6005/67600 (epoch 4), train_loss = 1.246, time/batch=0.202\n",
      "6006/67600 (epoch 4), train_loss = 1.261, time/batch=0.095\n",
      "6007/67600 (epoch 4), train_loss = 1.252, time/batch=0.104\n",
      "6008/67600 (epoch 4), train_loss = 1.305, time/batch=0.071\n",
      "6009/67600 (epoch 4), train_loss = 1.223, time/batch=0.086\n",
      "6010/67600 (epoch 4), train_loss = 1.273, time/batch=0.097\n",
      "6011/67600 (epoch 4), train_loss = 1.267, time/batch=0.090\n",
      "6012/67600 (epoch 4), train_loss = 1.314, time/batch=0.096\n",
      "6013/67600 (epoch 4), train_loss = 1.252, time/batch=0.091\n",
      "6014/67600 (epoch 4), train_loss = 1.326, time/batch=0.077\n",
      "6015/67600 (epoch 4), train_loss = 1.253, time/batch=0.125\n",
      "6016/67600 (epoch 4), train_loss = 1.345, time/batch=0.162\n",
      "6017/67600 (epoch 4), train_loss = 1.281, time/batch=0.105\n",
      "6018/67600 (epoch 4), train_loss = 1.288, time/batch=0.074\n",
      "6019/67600 (epoch 4), train_loss = 1.370, time/batch=0.084\n",
      "6020/67600 (epoch 4), train_loss = 1.272, time/batch=0.094\n",
      "6021/67600 (epoch 4), train_loss = 1.268, time/batch=0.072\n",
      "6022/67600 (epoch 4), train_loss = 1.295, time/batch=0.068\n",
      "6023/67600 (epoch 4), train_loss = 1.339, time/batch=0.083\n",
      "6024/67600 (epoch 4), train_loss = 1.302, time/batch=0.080\n",
      "6025/67600 (epoch 4), train_loss = 1.363, time/batch=0.072\n",
      "6026/67600 (epoch 4), train_loss = 1.276, time/batch=0.223\n",
      "6027/67600 (epoch 4), train_loss = 1.240, time/batch=0.092\n",
      "6028/67600 (epoch 4), train_loss = 1.234, time/batch=0.073\n",
      "6029/67600 (epoch 4), train_loss = 1.279, time/batch=0.078\n",
      "6030/67600 (epoch 4), train_loss = 1.294, time/batch=0.133\n",
      "6031/67600 (epoch 4), train_loss = 1.246, time/batch=0.077\n",
      "6032/67600 (epoch 4), train_loss = 1.281, time/batch=0.071\n",
      "6033/67600 (epoch 4), train_loss = 1.269, time/batch=0.074\n",
      "6034/67600 (epoch 4), train_loss = 1.308, time/batch=0.070\n",
      "6035/67600 (epoch 4), train_loss = 1.332, time/batch=0.075\n",
      "6036/67600 (epoch 4), train_loss = 1.312, time/batch=0.083\n",
      "6037/67600 (epoch 4), train_loss = 1.277, time/batch=0.248\n",
      "6038/67600 (epoch 4), train_loss = 1.318, time/batch=0.078\n",
      "6039/67600 (epoch 4), train_loss = 1.350, time/batch=0.077\n",
      "6040/67600 (epoch 4), train_loss = 1.258, time/batch=0.091\n",
      "6041/67600 (epoch 4), train_loss = 1.349, time/batch=0.108\n",
      "6042/67600 (epoch 4), train_loss = 1.345, time/batch=0.079\n",
      "6043/67600 (epoch 4), train_loss = 1.217, time/batch=0.126\n",
      "6044/67600 (epoch 4), train_loss = 1.366, time/batch=0.077\n",
      "6045/67600 (epoch 4), train_loss = 1.248, time/batch=0.073\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6046/67600 (epoch 4), train_loss = 1.224, time/batch=0.079\n",
      "6047/67600 (epoch 4), train_loss = 1.208, time/batch=0.077\n",
      "6048/67600 (epoch 4), train_loss = 1.281, time/batch=0.079\n",
      "6049/67600 (epoch 4), train_loss = 1.257, time/batch=0.075\n",
      "6050/67600 (epoch 4), train_loss = 1.316, time/batch=0.082\n",
      "6051/67600 (epoch 4), train_loss = 1.349, time/batch=0.080\n",
      "6052/67600 (epoch 4), train_loss = 1.328, time/batch=0.331\n",
      "6053/67600 (epoch 4), train_loss = 1.263, time/batch=0.128\n",
      "6054/67600 (epoch 4), train_loss = 1.303, time/batch=0.072\n",
      "6055/67600 (epoch 4), train_loss = 1.298, time/batch=0.074\n",
      "6056/67600 (epoch 4), train_loss = 1.318, time/batch=0.072\n",
      "6057/67600 (epoch 4), train_loss = 1.287, time/batch=0.073\n",
      "6058/67600 (epoch 4), train_loss = 1.334, time/batch=0.099\n",
      "6059/67600 (epoch 4), train_loss = 1.355, time/batch=0.070\n",
      "6060/67600 (epoch 4), train_loss = 1.269, time/batch=0.071\n",
      "6061/67600 (epoch 4), train_loss = 1.270, time/batch=0.073\n",
      "6062/67600 (epoch 4), train_loss = 1.283, time/batch=0.267\n",
      "6063/67600 (epoch 4), train_loss = 1.278, time/batch=0.077\n",
      "6064/67600 (epoch 4), train_loss = 1.282, time/batch=0.076\n",
      "6065/67600 (epoch 4), train_loss = 1.338, time/batch=0.082\n",
      "6066/67600 (epoch 4), train_loss = 1.304, time/batch=0.087\n",
      "6067/67600 (epoch 4), train_loss = 1.232, time/batch=0.072\n",
      "6068/67600 (epoch 4), train_loss = 1.290, time/batch=0.078\n",
      "6069/67600 (epoch 4), train_loss = 1.275, time/batch=0.079\n",
      "6070/67600 (epoch 4), train_loss = 1.204, time/batch=0.188\n",
      "6071/67600 (epoch 4), train_loss = 1.224, time/batch=0.106\n",
      "6072/67600 (epoch 4), train_loss = 1.309, time/batch=0.076\n",
      "6073/67600 (epoch 4), train_loss = 1.288, time/batch=0.073\n",
      "6074/67600 (epoch 4), train_loss = 1.312, time/batch=0.094\n",
      "6075/67600 (epoch 4), train_loss = 1.276, time/batch=0.073\n",
      "6076/67600 (epoch 4), train_loss = 1.336, time/batch=0.074\n",
      "6077/67600 (epoch 4), train_loss = 1.243, time/batch=0.071\n",
      "6078/67600 (epoch 4), train_loss = 1.189, time/batch=0.075\n",
      "6079/67600 (epoch 4), train_loss = 1.277, time/batch=0.081\n",
      "6080/67600 (epoch 4), train_loss = 1.196, time/batch=0.072\n",
      "6081/67600 (epoch 4), train_loss = 1.340, time/batch=0.199\n",
      "6082/67600 (epoch 4), train_loss = 1.328, time/batch=0.124\n",
      "6083/67600 (epoch 4), train_loss = 1.252, time/batch=0.070\n",
      "6084/67600 (epoch 4), train_loss = 1.293, time/batch=0.079\n",
      "6085/67600 (epoch 4), train_loss = 1.324, time/batch=0.078\n",
      "6086/67600 (epoch 4), train_loss = 1.324, time/batch=0.072\n",
      "6087/67600 (epoch 4), train_loss = 1.276, time/batch=0.076\n",
      "6088/67600 (epoch 4), train_loss = 1.278, time/batch=0.077\n",
      "6089/67600 (epoch 4), train_loss = 1.307, time/batch=0.086\n",
      "6090/67600 (epoch 4), train_loss = 1.301, time/batch=0.079\n",
      "6091/67600 (epoch 4), train_loss = 1.263, time/batch=0.105\n",
      "6092/67600 (epoch 4), train_loss = 1.251, time/batch=0.198\n",
      "6093/67600 (epoch 4), train_loss = 1.332, time/batch=0.244\n",
      "6094/67600 (epoch 4), train_loss = 1.296, time/batch=0.077\n",
      "6095/67600 (epoch 4), train_loss = 1.251, time/batch=0.082\n",
      "6096/67600 (epoch 4), train_loss = 1.281, time/batch=0.074\n",
      "6097/67600 (epoch 4), train_loss = 1.245, time/batch=0.076\n",
      "6098/67600 (epoch 4), train_loss = 1.277, time/batch=0.076\n",
      "6099/67600 (epoch 4), train_loss = 1.272, time/batch=0.077\n",
      "6100/67600 (epoch 4), train_loss = 1.254, time/batch=0.170\n",
      "6101/67600 (epoch 4), train_loss = 1.305, time/batch=0.219\n",
      "6102/67600 (epoch 4), train_loss = 1.295, time/batch=0.078\n",
      "6103/67600 (epoch 4), train_loss = 1.218, time/batch=0.087\n",
      "6104/67600 (epoch 4), train_loss = 1.307, time/batch=0.089\n",
      "6105/67600 (epoch 4), train_loss = 1.328, time/batch=0.080\n",
      "6106/67600 (epoch 4), train_loss = 1.304, time/batch=0.074\n",
      "6107/67600 (epoch 4), train_loss = 1.253, time/batch=0.077\n",
      "6108/67600 (epoch 4), train_loss = 1.289, time/batch=0.074\n",
      "6109/67600 (epoch 4), train_loss = 1.322, time/batch=0.072\n",
      "6110/67600 (epoch 4), train_loss = 1.284, time/batch=0.188\n",
      "6111/67600 (epoch 4), train_loss = 1.236, time/batch=0.095\n",
      "6112/67600 (epoch 4), train_loss = 1.279, time/batch=0.097\n",
      "6113/67600 (epoch 4), train_loss = 1.266, time/batch=0.078\n",
      "6114/67600 (epoch 4), train_loss = 1.260, time/batch=0.071\n",
      "6115/67600 (epoch 4), train_loss = 1.315, time/batch=0.072\n",
      "6116/67600 (epoch 4), train_loss = 1.295, time/batch=0.074\n",
      "6117/67600 (epoch 4), train_loss = 1.247, time/batch=0.074\n",
      "6118/67600 (epoch 4), train_loss = 1.276, time/batch=0.141\n",
      "6119/67600 (epoch 4), train_loss = 1.189, time/batch=0.089\n",
      "6120/67600 (epoch 4), train_loss = 1.283, time/batch=0.176\n",
      "6121/67600 (epoch 4), train_loss = 1.294, time/batch=0.132\n",
      "6122/67600 (epoch 4), train_loss = 1.278, time/batch=0.082\n",
      "6123/67600 (epoch 4), train_loss = 1.261, time/batch=0.076\n",
      "6124/67600 (epoch 4), train_loss = 1.224, time/batch=0.077\n",
      "6125/67600 (epoch 4), train_loss = 1.271, time/batch=0.079\n",
      "6126/67600 (epoch 4), train_loss = 1.238, time/batch=0.072\n",
      "6127/67600 (epoch 4), train_loss = 1.261, time/batch=0.074\n",
      "6128/67600 (epoch 4), train_loss = 1.261, time/batch=0.230\n",
      "6129/67600 (epoch 4), train_loss = 1.298, time/batch=0.143\n",
      "6130/67600 (epoch 4), train_loss = 1.279, time/batch=0.095\n",
      "6131/67600 (epoch 4), train_loss = 1.288, time/batch=0.072\n",
      "6132/67600 (epoch 4), train_loss = 1.271, time/batch=0.095\n",
      "6133/67600 (epoch 4), train_loss = 1.296, time/batch=0.098\n",
      "6134/67600 (epoch 4), train_loss = 1.277, time/batch=0.072\n",
      "6135/67600 (epoch 4), train_loss = 1.297, time/batch=0.070\n",
      "6136/67600 (epoch 4), train_loss = 1.289, time/batch=0.068\n",
      "6137/67600 (epoch 4), train_loss = 1.257, time/batch=0.070\n",
      "6138/67600 (epoch 4), train_loss = 1.277, time/batch=0.204\n",
      "6139/67600 (epoch 4), train_loss = 1.299, time/batch=0.129\n",
      "6140/67600 (epoch 4), train_loss = 1.288, time/batch=0.092\n",
      "6141/67600 (epoch 4), train_loss = 1.270, time/batch=0.072\n",
      "6142/67600 (epoch 4), train_loss = 1.301, time/batch=0.076\n",
      "6143/67600 (epoch 4), train_loss = 1.241, time/batch=0.071\n",
      "6144/67600 (epoch 4), train_loss = 1.334, time/batch=0.069\n",
      "6145/67600 (epoch 4), train_loss = 1.256, time/batch=0.073\n",
      "6146/67600 (epoch 4), train_loss = 1.227, time/batch=0.072\n",
      "6147/67600 (epoch 4), train_loss = 1.298, time/batch=0.068\n",
      "6148/67600 (epoch 4), train_loss = 1.199, time/batch=0.084\n",
      "6149/67600 (epoch 4), train_loss = 1.242, time/batch=0.245\n",
      "6150/67600 (epoch 4), train_loss = 1.215, time/batch=0.101\n",
      "6151/67600 (epoch 4), train_loss = 1.266, time/batch=0.067\n",
      "6152/67600 (epoch 4), train_loss = 1.283, time/batch=0.071\n",
      "6153/67600 (epoch 4), train_loss = 1.294, time/batch=0.070\n",
      "6154/67600 (epoch 4), train_loss = 1.263, time/batch=0.072\n",
      "6155/67600 (epoch 4), train_loss = 1.270, time/batch=0.076\n",
      "6156/67600 (epoch 4), train_loss = 1.296, time/batch=0.092\n",
      "6157/67600 (epoch 4), train_loss = 1.254, time/batch=0.098\n",
      "6158/67600 (epoch 4), train_loss = 1.231, time/batch=0.079\n",
      "6159/67600 (epoch 4), train_loss = 1.235, time/batch=0.112\n",
      "6160/67600 (epoch 4), train_loss = 1.270, time/batch=0.158\n",
      "6161/67600 (epoch 4), train_loss = 1.316, time/batch=0.089\n",
      "6162/67600 (epoch 4), train_loss = 1.254, time/batch=0.074\n",
      "6163/67600 (epoch 4), train_loss = 1.267, time/batch=0.070\n",
      "6164/67600 (epoch 4), train_loss = 1.342, time/batch=0.071\n",
      "6165/67600 (epoch 4), train_loss = 1.270, time/batch=0.091\n",
      "6166/67600 (epoch 4), train_loss = 1.263, time/batch=0.102\n",
      "6167/67600 (epoch 4), train_loss = 1.245, time/batch=0.090\n",
      "6168/67600 (epoch 4), train_loss = 1.257, time/batch=0.075\n",
      "6169/67600 (epoch 4), train_loss = 1.265, time/batch=0.071\n",
      "6170/67600 (epoch 4), train_loss = 1.255, time/batch=0.104\n",
      "6171/67600 (epoch 4), train_loss = 1.326, time/batch=0.182\n",
      "6172/67600 (epoch 4), train_loss = 1.326, time/batch=0.079\n",
      "6173/67600 (epoch 4), train_loss = 1.242, time/batch=0.092\n",
      "6174/67600 (epoch 4), train_loss = 1.285, time/batch=0.102\n",
      "6175/67600 (epoch 4), train_loss = 1.275, time/batch=0.081\n",
      "6176/67600 (epoch 4), train_loss = 1.292, time/batch=0.069\n",
      "6177/67600 (epoch 4), train_loss = 1.309, time/batch=0.080\n",
      "6178/67600 (epoch 4), train_loss = 1.254, time/batch=0.231\n",
      "6179/67600 (epoch 4), train_loss = 1.330, time/batch=0.100\n",
      "6180/67600 (epoch 4), train_loss = 1.296, time/batch=0.068\n",
      "6181/67600 (epoch 4), train_loss = 1.263, time/batch=0.072\n",
      "6182/67600 (epoch 4), train_loss = 1.322, time/batch=0.093\n",
      "6183/67600 (epoch 4), train_loss = 1.351, time/batch=0.070\n",
      "6184/67600 (epoch 4), train_loss = 1.317, time/batch=0.073\n",
      "6185/67600 (epoch 4), train_loss = 1.293, time/batch=0.073\n",
      "6186/67600 (epoch 4), train_loss = 1.273, time/batch=0.096\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6187/67600 (epoch 4), train_loss = 1.310, time/batch=0.105\n",
      "6188/67600 (epoch 4), train_loss = 1.326, time/batch=0.117\n",
      "6189/67600 (epoch 4), train_loss = 1.274, time/batch=0.092\n",
      "6190/67600 (epoch 4), train_loss = 1.257, time/batch=0.088\n",
      "6191/67600 (epoch 4), train_loss = 1.296, time/batch=0.073\n",
      "6192/67600 (epoch 4), train_loss = 1.272, time/batch=0.071\n",
      "6193/67600 (epoch 4), train_loss = 1.303, time/batch=0.071\n",
      "6194/67600 (epoch 4), train_loss = 1.295, time/batch=0.074\n",
      "6195/67600 (epoch 4), train_loss = 1.287, time/batch=0.072\n",
      "6196/67600 (epoch 4), train_loss = 1.303, time/batch=0.073\n",
      "6197/67600 (epoch 4), train_loss = 1.254, time/batch=0.156\n",
      "6198/67600 (epoch 4), train_loss = 1.274, time/batch=0.161\n",
      "6199/67600 (epoch 4), train_loss = 1.273, time/batch=0.093\n",
      "6200/67600 (epoch 4), train_loss = 1.253, time/batch=0.071\n",
      "6201/67600 (epoch 4), train_loss = 1.315, time/batch=0.071\n",
      "6202/67600 (epoch 4), train_loss = 1.271, time/batch=0.084\n",
      "6203/67600 (epoch 4), train_loss = 1.291, time/batch=0.107\n",
      "6204/67600 (epoch 4), train_loss = 1.340, time/batch=0.076\n",
      "6205/67600 (epoch 4), train_loss = 1.298, time/batch=0.082\n",
      "6206/67600 (epoch 4), train_loss = 1.315, time/batch=0.074\n",
      "6207/67600 (epoch 4), train_loss = 1.284, time/batch=0.074\n",
      "6208/67600 (epoch 4), train_loss = 1.283, time/batch=0.101\n",
      "6209/67600 (epoch 4), train_loss = 1.287, time/batch=0.203\n",
      "6210/67600 (epoch 4), train_loss = 1.272, time/batch=0.079\n",
      "6211/67600 (epoch 4), train_loss = 1.285, time/batch=0.072\n",
      "6212/67600 (epoch 4), train_loss = 1.256, time/batch=0.076\n",
      "6213/67600 (epoch 4), train_loss = 1.237, time/batch=0.076\n",
      "6214/67600 (epoch 4), train_loss = 1.294, time/batch=0.070\n",
      "6215/67600 (epoch 4), train_loss = 1.248, time/batch=0.074\n",
      "6216/67600 (epoch 4), train_loss = 1.200, time/batch=0.075\n",
      "6217/67600 (epoch 4), train_loss = 1.298, time/batch=0.179\n",
      "6218/67600 (epoch 4), train_loss = 1.231, time/batch=0.071\n",
      "6219/67600 (epoch 4), train_loss = 1.315, time/batch=0.100\n",
      "6220/67600 (epoch 4), train_loss = 1.301, time/batch=0.074\n",
      "6221/67600 (epoch 4), train_loss = 1.295, time/batch=0.069\n",
      "6222/67600 (epoch 4), train_loss = 1.324, time/batch=0.087\n",
      "6223/67600 (epoch 4), train_loss = 1.228, time/batch=0.072\n",
      "6224/67600 (epoch 4), train_loss = 1.331, time/batch=0.074\n",
      "6225/67600 (epoch 4), train_loss = 1.245, time/batch=0.078\n",
      "6226/67600 (epoch 4), train_loss = 1.256, time/batch=0.073\n",
      "6227/67600 (epoch 4), train_loss = 1.278, time/batch=0.073\n",
      "6228/67600 (epoch 4), train_loss = 1.198, time/batch=0.173\n",
      "6229/67600 (epoch 4), train_loss = 1.317, time/batch=0.092\n",
      "6230/67600 (epoch 4), train_loss = 1.270, time/batch=0.113\n",
      "6231/67600 (epoch 4), train_loss = 1.357, time/batch=0.068\n",
      "6232/67600 (epoch 4), train_loss = 1.305, time/batch=0.073\n",
      "6233/67600 (epoch 4), train_loss = 1.323, time/batch=0.081\n",
      "6234/67600 (epoch 4), train_loss = 1.424, time/batch=0.076\n",
      "6235/67600 (epoch 4), train_loss = 1.259, time/batch=0.073\n",
      "6236/67600 (epoch 4), train_loss = 1.284, time/batch=0.079\n",
      "6237/67600 (epoch 4), train_loss = 1.323, time/batch=0.094\n",
      "6238/67600 (epoch 4), train_loss = 1.353, time/batch=0.076\n",
      "6239/67600 (epoch 4), train_loss = 1.275, time/batch=0.180\n",
      "6240/67600 (epoch 4), train_loss = 1.275, time/batch=0.091\n",
      "6241/67600 (epoch 4), train_loss = 1.285, time/batch=0.113\n",
      "6242/67600 (epoch 4), train_loss = 1.236, time/batch=0.069\n",
      "6243/67600 (epoch 4), train_loss = 1.321, time/batch=0.131\n",
      "6244/67600 (epoch 4), train_loss = 1.171, time/batch=0.119\n",
      "6245/67600 (epoch 4), train_loss = 1.319, time/batch=0.131\n",
      "6246/67600 (epoch 4), train_loss = 1.210, time/batch=0.074\n",
      "6247/67600 (epoch 4), train_loss = 1.266, time/batch=0.077\n",
      "6248/67600 (epoch 4), train_loss = 1.325, time/batch=0.081\n",
      "6249/67600 (epoch 4), train_loss = 1.289, time/batch=0.190\n",
      "6250/67600 (epoch 4), train_loss = 1.282, time/batch=0.106\n",
      "6251/67600 (epoch 4), train_loss = 1.302, time/batch=0.085\n",
      "6252/67600 (epoch 4), train_loss = 1.282, time/batch=0.078\n",
      "6253/67600 (epoch 4), train_loss = 1.268, time/batch=0.078\n",
      "6254/67600 (epoch 4), train_loss = 1.261, time/batch=0.073\n",
      "6255/67600 (epoch 4), train_loss = 1.264, time/batch=0.073\n",
      "6256/67600 (epoch 4), train_loss = 1.303, time/batch=0.073\n",
      "6257/67600 (epoch 4), train_loss = 1.268, time/batch=0.075\n",
      "6258/67600 (epoch 4), train_loss = 1.267, time/batch=0.070\n",
      "6259/67600 (epoch 4), train_loss = 1.360, time/batch=0.069\n",
      "6260/67600 (epoch 4), train_loss = 1.360, time/batch=0.199\n",
      "6261/67600 (epoch 4), train_loss = 1.336, time/batch=0.071\n",
      "6262/67600 (epoch 4), train_loss = 1.258, time/batch=0.091\n",
      "6263/67600 (epoch 4), train_loss = 1.329, time/batch=0.075\n",
      "6264/67600 (epoch 4), train_loss = 1.291, time/batch=0.069\n",
      "6265/67600 (epoch 4), train_loss = 1.276, time/batch=0.070\n",
      "6266/67600 (epoch 4), train_loss = 1.323, time/batch=0.069\n",
      "6267/67600 (epoch 4), train_loss = 1.320, time/batch=0.073\n",
      "6268/67600 (epoch 4), train_loss = 1.290, time/batch=0.087\n",
      "6269/67600 (epoch 4), train_loss = 1.340, time/batch=0.089\n",
      "6270/67600 (epoch 4), train_loss = 1.363, time/batch=0.083\n",
      "6271/67600 (epoch 4), train_loss = 1.320, time/batch=0.153\n",
      "6272/67600 (epoch 4), train_loss = 1.247, time/batch=0.154\n",
      "6273/67600 (epoch 4), train_loss = 1.341, time/batch=0.077\n",
      "6274/67600 (epoch 4), train_loss = 1.326, time/batch=0.080\n",
      "6275/67600 (epoch 4), train_loss = 1.252, time/batch=0.075\n",
      "6276/67600 (epoch 4), train_loss = 1.282, time/batch=0.074\n",
      "6277/67600 (epoch 4), train_loss = 1.275, time/batch=0.074\n",
      "6278/67600 (epoch 4), train_loss = 1.287, time/batch=0.071\n",
      "6279/67600 (epoch 4), train_loss = 1.267, time/batch=0.172\n",
      "6280/67600 (epoch 4), train_loss = 1.318, time/batch=0.071\n",
      "6281/67600 (epoch 4), train_loss = 1.256, time/batch=0.110\n",
      "6282/67600 (epoch 4), train_loss = 1.286, time/batch=0.083\n",
      "6283/67600 (epoch 4), train_loss = 1.345, time/batch=0.098\n",
      "6284/67600 (epoch 4), train_loss = 1.311, time/batch=0.086\n",
      "6285/67600 (epoch 4), train_loss = 1.193, time/batch=0.069\n",
      "6286/67600 (epoch 4), train_loss = 1.269, time/batch=0.079\n",
      "6287/67600 (epoch 4), train_loss = 1.186, time/batch=0.070\n",
      "6288/67600 (epoch 4), train_loss = 1.243, time/batch=0.074\n",
      "6289/67600 (epoch 4), train_loss = 1.262, time/batch=0.079\n",
      "6290/67600 (epoch 4), train_loss = 1.269, time/batch=0.239\n",
      "6291/67600 (epoch 4), train_loss = 1.285, time/batch=0.116\n",
      "6292/67600 (epoch 4), train_loss = 1.253, time/batch=0.074\n",
      "6293/67600 (epoch 4), train_loss = 1.273, time/batch=0.089\n",
      "6294/67600 (epoch 4), train_loss = 1.250, time/batch=0.071\n",
      "6295/67600 (epoch 4), train_loss = 1.212, time/batch=0.075\n",
      "6296/67600 (epoch 4), train_loss = 1.347, time/batch=0.072\n",
      "6297/67600 (epoch 4), train_loss = 1.307, time/batch=0.072\n",
      "6298/67600 (epoch 4), train_loss = 1.337, time/batch=0.072\n",
      "6299/67600 (epoch 4), train_loss = 1.325, time/batch=0.074\n",
      "6300/67600 (epoch 4), train_loss = 1.312, time/batch=0.080\n",
      "6301/67600 (epoch 4), train_loss = 1.275, time/batch=0.187\n",
      "6302/67600 (epoch 4), train_loss = 1.314, time/batch=0.070\n",
      "6303/67600 (epoch 4), train_loss = 1.262, time/batch=0.102\n",
      "6304/67600 (epoch 4), train_loss = 1.275, time/batch=0.073\n",
      "6305/67600 (epoch 4), train_loss = 1.335, time/batch=0.086\n",
      "6306/67600 (epoch 4), train_loss = 1.315, time/batch=0.078\n",
      "6307/67600 (epoch 4), train_loss = 1.317, time/batch=0.074\n",
      "6308/67600 (epoch 4), train_loss = 1.283, time/batch=0.070\n",
      "6309/67600 (epoch 4), train_loss = 1.342, time/batch=0.068\n",
      "6310/67600 (epoch 4), train_loss = 1.332, time/batch=0.088\n",
      "6311/67600 (epoch 4), train_loss = 1.218, time/batch=0.088\n",
      "6312/67600 (epoch 4), train_loss = 1.266, time/batch=0.202\n",
      "6313/67600 (epoch 4), train_loss = 1.317, time/batch=0.076\n",
      "6314/67600 (epoch 4), train_loss = 1.268, time/batch=0.090\n",
      "6315/67600 (epoch 4), train_loss = 1.257, time/batch=0.080\n",
      "6316/67600 (epoch 4), train_loss = 1.327, time/batch=0.077\n",
      "6317/67600 (epoch 4), train_loss = 1.267, time/batch=0.072\n",
      "6318/67600 (epoch 4), train_loss = 1.271, time/batch=0.072\n",
      "6319/67600 (epoch 4), train_loss = 1.318, time/batch=0.069\n",
      "6320/67600 (epoch 4), train_loss = 1.267, time/batch=0.071\n",
      "6321/67600 (epoch 4), train_loss = 1.302, time/batch=0.075\n",
      "6322/67600 (epoch 4), train_loss = 1.336, time/batch=0.074\n",
      "6323/67600 (epoch 4), train_loss = 1.262, time/batch=0.075\n",
      "6324/67600 (epoch 4), train_loss = 1.285, time/batch=0.209\n",
      "6325/67600 (epoch 4), train_loss = 1.261, time/batch=0.084\n",
      "6326/67600 (epoch 4), train_loss = 1.298, time/batch=0.072\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6327/67600 (epoch 4), train_loss = 1.290, time/batch=0.074\n",
      "6328/67600 (epoch 4), train_loss = 1.305, time/batch=0.074\n",
      "6329/67600 (epoch 4), train_loss = 1.277, time/batch=0.073\n",
      "6330/67600 (epoch 4), train_loss = 1.311, time/batch=0.072\n",
      "6331/67600 (epoch 4), train_loss = 1.264, time/batch=0.069\n",
      "6332/67600 (epoch 4), train_loss = 1.236, time/batch=0.071\n",
      "6333/67600 (epoch 4), train_loss = 1.271, time/batch=0.077\n",
      "6334/67600 (epoch 4), train_loss = 1.261, time/batch=0.129\n",
      "6335/67600 (epoch 4), train_loss = 1.281, time/batch=0.251\n",
      "6336/67600 (epoch 4), train_loss = 1.263, time/batch=0.087\n",
      "6337/67600 (epoch 4), train_loss = 1.273, time/batch=0.072\n",
      "6338/67600 (epoch 4), train_loss = 1.236, time/batch=0.075\n",
      "6339/67600 (epoch 4), train_loss = 1.287, time/batch=0.073\n",
      "6340/67600 (epoch 4), train_loss = 1.250, time/batch=0.069\n",
      "6341/67600 (epoch 4), train_loss = 1.233, time/batch=0.077\n",
      "6342/67600 (epoch 4), train_loss = 1.259, time/batch=0.133\n",
      "6343/67600 (epoch 4), train_loss = 1.244, time/batch=0.077\n",
      "6344/67600 (epoch 4), train_loss = 1.304, time/batch=0.084\n",
      "6345/67600 (epoch 4), train_loss = 1.269, time/batch=0.072\n",
      "6346/67600 (epoch 4), train_loss = 1.253, time/batch=0.083\n",
      "6347/67600 (epoch 4), train_loss = 1.258, time/batch=0.071\n",
      "6348/67600 (epoch 4), train_loss = 1.270, time/batch=0.084\n",
      "6349/67600 (epoch 4), train_loss = 1.238, time/batch=0.088\n",
      "6350/67600 (epoch 4), train_loss = 1.213, time/batch=0.071\n",
      "6351/67600 (epoch 4), train_loss = 1.321, time/batch=0.304\n",
      "6352/67600 (epoch 4), train_loss = 1.274, time/batch=0.147\n",
      "6353/67600 (epoch 4), train_loss = 1.293, time/batch=0.099\n",
      "6354/67600 (epoch 4), train_loss = 1.259, time/batch=0.072\n",
      "6355/67600 (epoch 4), train_loss = 1.228, time/batch=0.072\n",
      "6356/67600 (epoch 4), train_loss = 1.284, time/batch=0.071\n",
      "6357/67600 (epoch 4), train_loss = 1.246, time/batch=0.069\n",
      "6358/67600 (epoch 4), train_loss = 1.304, time/batch=0.086\n",
      "6359/67600 (epoch 4), train_loss = 1.246, time/batch=0.106\n",
      "6360/67600 (epoch 4), train_loss = 1.308, time/batch=0.082\n",
      "6361/67600 (epoch 4), train_loss = 1.229, time/batch=0.235\n",
      "6362/67600 (epoch 4), train_loss = 1.207, time/batch=0.081\n",
      "6363/67600 (epoch 4), train_loss = 1.340, time/batch=0.073\n",
      "6364/67600 (epoch 4), train_loss = 1.293, time/batch=0.073\n",
      "6365/67600 (epoch 4), train_loss = 1.295, time/batch=0.070\n",
      "6366/67600 (epoch 4), train_loss = 1.237, time/batch=0.070\n",
      "6367/67600 (epoch 4), train_loss = 1.252, time/batch=0.080\n",
      "6368/67600 (epoch 4), train_loss = 1.248, time/batch=0.101\n",
      "6369/67600 (epoch 4), train_loss = 1.186, time/batch=0.145\n",
      "6370/67600 (epoch 4), train_loss = 1.212, time/batch=0.098\n",
      "6371/67600 (epoch 4), train_loss = 1.209, time/batch=0.071\n",
      "6372/67600 (epoch 4), train_loss = 1.202, time/batch=0.073\n",
      "6373/67600 (epoch 4), train_loss = 1.282, time/batch=0.093\n",
      "6374/67600 (epoch 4), train_loss = 1.283, time/batch=0.077\n",
      "6375/67600 (epoch 4), train_loss = 1.216, time/batch=0.076\n",
      "6376/67600 (epoch 4), train_loss = 1.240, time/batch=0.069\n",
      "6377/67600 (epoch 4), train_loss = 1.239, time/batch=0.072\n",
      "6378/67600 (epoch 4), train_loss = 1.277, time/batch=0.074\n",
      "6379/67600 (epoch 4), train_loss = 1.275, time/batch=0.069\n",
      "6380/67600 (epoch 4), train_loss = 1.227, time/batch=0.177\n",
      "6381/67600 (epoch 4), train_loss = 1.285, time/batch=0.093\n",
      "6382/67600 (epoch 4), train_loss = 1.302, time/batch=0.111\n",
      "6383/67600 (epoch 4), train_loss = 1.216, time/batch=0.072\n",
      "6384/67600 (epoch 4), train_loss = 1.196, time/batch=0.072\n",
      "6385/67600 (epoch 4), train_loss = 1.236, time/batch=0.077\n",
      "6386/67600 (epoch 4), train_loss = 1.287, time/batch=0.074\n",
      "6387/67600 (epoch 4), train_loss = 1.259, time/batch=0.076\n",
      "6388/67600 (epoch 4), train_loss = 1.272, time/batch=0.069\n",
      "6389/67600 (epoch 4), train_loss = 1.235, time/batch=0.069\n",
      "6390/67600 (epoch 4), train_loss = 1.232, time/batch=0.073\n",
      "6391/67600 (epoch 4), train_loss = 1.291, time/batch=0.068\n",
      "6392/67600 (epoch 4), train_loss = 1.230, time/batch=0.187\n",
      "6393/67600 (epoch 4), train_loss = 1.336, time/batch=0.081\n",
      "6394/67600 (epoch 4), train_loss = 1.273, time/batch=0.094\n",
      "6395/67600 (epoch 4), train_loss = 1.345, time/batch=0.073\n",
      "6396/67600 (epoch 4), train_loss = 1.233, time/batch=0.070\n",
      "6397/67600 (epoch 4), train_loss = 1.248, time/batch=0.076\n",
      "6398/67600 (epoch 4), train_loss = 1.283, time/batch=0.079\n",
      "6399/67600 (epoch 4), train_loss = 1.251, time/batch=0.076\n",
      "6400/67600 (epoch 4), train_loss = 1.315, time/batch=0.076\n",
      "6401/67600 (epoch 4), train_loss = 1.271, time/batch=0.071\n",
      "6402/67600 (epoch 4), train_loss = 1.258, time/batch=0.073\n",
      "6403/67600 (epoch 4), train_loss = 1.267, time/batch=0.141\n",
      "6404/67600 (epoch 4), train_loss = 1.269, time/batch=0.125\n",
      "6405/67600 (epoch 4), train_loss = 1.289, time/batch=0.108\n",
      "6406/67600 (epoch 4), train_loss = 1.215, time/batch=0.068\n",
      "6407/67600 (epoch 4), train_loss = 1.243, time/batch=0.072\n",
      "6408/67600 (epoch 4), train_loss = 1.252, time/batch=0.077\n",
      "6409/67600 (epoch 4), train_loss = 1.267, time/batch=0.101\n",
      "6410/67600 (epoch 4), train_loss = 1.249, time/batch=0.105\n",
      "6411/67600 (epoch 4), train_loss = 1.273, time/batch=0.097\n",
      "6412/67600 (epoch 4), train_loss = 1.207, time/batch=0.108\n",
      "6413/67600 (epoch 4), train_loss = 1.280, time/batch=0.229\n",
      "6414/67600 (epoch 4), train_loss = 1.270, time/batch=0.112\n",
      "6415/67600 (epoch 4), train_loss = 1.233, time/batch=0.091\n",
      "6416/67600 (epoch 4), train_loss = 1.271, time/batch=0.095\n",
      "6417/67600 (epoch 4), train_loss = 1.228, time/batch=0.109\n",
      "6418/67600 (epoch 4), train_loss = 1.248, time/batch=0.097\n",
      "6419/67600 (epoch 4), train_loss = 1.243, time/batch=0.080\n",
      "6420/67600 (epoch 4), train_loss = 1.212, time/batch=0.078\n",
      "6421/67600 (epoch 4), train_loss = 1.232, time/batch=0.073\n",
      "6422/67600 (epoch 4), train_loss = 1.243, time/batch=0.082\n",
      "6423/67600 (epoch 4), train_loss = 1.250, time/batch=0.230\n",
      "6424/67600 (epoch 4), train_loss = 1.242, time/batch=0.080\n",
      "6425/67600 (epoch 4), train_loss = 1.284, time/batch=0.085\n",
      "6426/67600 (epoch 4), train_loss = 1.260, time/batch=0.073\n",
      "6427/67600 (epoch 4), train_loss = 1.266, time/batch=0.092\n",
      "6428/67600 (epoch 4), train_loss = 1.257, time/batch=0.087\n",
      "6429/67600 (epoch 4), train_loss = 1.247, time/batch=0.074\n",
      "6430/67600 (epoch 4), train_loss = 1.246, time/batch=0.187\n",
      "6431/67600 (epoch 4), train_loss = 1.255, time/batch=0.071\n",
      "6432/67600 (epoch 4), train_loss = 1.262, time/batch=0.118\n",
      "6433/67600 (epoch 4), train_loss = 1.217, time/batch=0.071\n",
      "6434/67600 (epoch 4), train_loss = 1.299, time/batch=0.080\n",
      "6435/67600 (epoch 4), train_loss = 1.218, time/batch=0.078\n",
      "6436/67600 (epoch 4), train_loss = 1.321, time/batch=0.076\n",
      "6437/67600 (epoch 4), train_loss = 1.291, time/batch=0.073\n",
      "6438/67600 (epoch 4), train_loss = 1.306, time/batch=0.072\n",
      "6439/67600 (epoch 4), train_loss = 1.301, time/batch=0.071\n",
      "6440/67600 (epoch 4), train_loss = 1.269, time/batch=0.073\n",
      "6441/67600 (epoch 4), train_loss = 1.236, time/batch=0.090\n",
      "6442/67600 (epoch 4), train_loss = 1.274, time/batch=0.170\n",
      "6443/67600 (epoch 4), train_loss = 1.240, time/batch=0.107\n",
      "6444/67600 (epoch 4), train_loss = 1.222, time/batch=0.070\n",
      "6445/67600 (epoch 4), train_loss = 1.221, time/batch=0.073\n",
      "6446/67600 (epoch 4), train_loss = 1.259, time/batch=0.080\n",
      "6447/67600 (epoch 4), train_loss = 1.238, time/batch=0.070\n",
      "6448/67600 (epoch 4), train_loss = 1.264, time/batch=0.086\n",
      "6449/67600 (epoch 4), train_loss = 1.263, time/batch=0.089\n",
      "6450/67600 (epoch 4), train_loss = 1.311, time/batch=0.092\n",
      "6451/67600 (epoch 4), train_loss = 1.166, time/batch=0.074\n",
      "6452/67600 (epoch 4), train_loss = 1.259, time/batch=0.068\n",
      "6453/67600 (epoch 4), train_loss = 1.249, time/batch=0.187\n",
      "6454/67600 (epoch 4), train_loss = 1.265, time/batch=0.081\n",
      "6455/67600 (epoch 4), train_loss = 1.323, time/batch=0.089\n",
      "6456/67600 (epoch 4), train_loss = 1.303, time/batch=0.073\n",
      "6457/67600 (epoch 4), train_loss = 1.285, time/batch=0.070\n",
      "6458/67600 (epoch 4), train_loss = 1.256, time/batch=0.072\n",
      "6459/67600 (epoch 4), train_loss = 1.229, time/batch=0.075\n",
      "6460/67600 (epoch 4), train_loss = 1.283, time/batch=0.066\n",
      "6461/67600 (epoch 4), train_loss = 1.266, time/batch=0.070\n",
      "6462/67600 (epoch 4), train_loss = 1.296, time/batch=0.074\n",
      "6463/67600 (epoch 4), train_loss = 1.268, time/batch=0.084\n",
      "6464/67600 (epoch 4), train_loss = 1.195, time/batch=0.133\n",
      "6465/67600 (epoch 4), train_loss = 1.310, time/batch=0.144\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6466/67600 (epoch 4), train_loss = 1.335, time/batch=0.102\n",
      "6467/67600 (epoch 4), train_loss = 1.255, time/batch=0.070\n",
      "6468/67600 (epoch 4), train_loss = 1.283, time/batch=0.072\n",
      "6469/67600 (epoch 4), train_loss = 1.283, time/batch=0.080\n",
      "6470/67600 (epoch 4), train_loss = 1.260, time/batch=0.080\n",
      "6471/67600 (epoch 4), train_loss = 1.220, time/batch=0.084\n",
      "6472/67600 (epoch 4), train_loss = 1.269, time/batch=0.084\n",
      "6473/67600 (epoch 4), train_loss = 1.266, time/batch=0.075\n",
      "6474/67600 (epoch 4), train_loss = 1.261, time/batch=0.077\n",
      "6475/67600 (epoch 4), train_loss = 1.294, time/batch=0.189\n",
      "6476/67600 (epoch 4), train_loss = 1.248, time/batch=0.113\n",
      "6477/67600 (epoch 4), train_loss = 1.292, time/batch=0.096\n",
      "6478/67600 (epoch 4), train_loss = 1.307, time/batch=0.068\n",
      "6479/67600 (epoch 4), train_loss = 1.317, time/batch=0.070\n",
      "6480/67600 (epoch 4), train_loss = 1.266, time/batch=0.089\n",
      "6481/67600 (epoch 4), train_loss = 1.249, time/batch=0.071\n",
      "6482/67600 (epoch 4), train_loss = 1.235, time/batch=0.070\n",
      "6483/67600 (epoch 4), train_loss = 1.263, time/batch=0.073\n",
      "6484/67600 (epoch 4), train_loss = 1.307, time/batch=0.073\n",
      "6485/67600 (epoch 4), train_loss = 1.294, time/batch=0.072\n",
      "6486/67600 (epoch 4), train_loss = 1.298, time/batch=0.072\n",
      "6487/67600 (epoch 4), train_loss = 1.308, time/batch=0.220\n",
      "6488/67600 (epoch 4), train_loss = 1.318, time/batch=0.073\n",
      "6489/67600 (epoch 4), train_loss = 1.240, time/batch=0.072\n",
      "6490/67600 (epoch 4), train_loss = 1.309, time/batch=0.073\n",
      "6491/67600 (epoch 4), train_loss = 1.232, time/batch=0.084\n",
      "6492/67600 (epoch 4), train_loss = 1.227, time/batch=0.071\n",
      "6493/67600 (epoch 4), train_loss = 1.350, time/batch=0.073\n",
      "6494/67600 (epoch 4), train_loss = 1.304, time/batch=0.075\n",
      "6495/67600 (epoch 4), train_loss = 1.212, time/batch=0.118\n",
      "6496/67600 (epoch 4), train_loss = 1.246, time/batch=0.080\n",
      "6497/67600 (epoch 4), train_loss = 1.232, time/batch=0.070\n",
      "6498/67600 (epoch 4), train_loss = 1.297, time/batch=0.070\n",
      "6499/67600 (epoch 4), train_loss = 1.258, time/batch=0.079\n",
      "6500/67600 (epoch 4), train_loss = 1.312, time/batch=0.074\n",
      "model saved to ./save/model.ckpt\n",
      "6501/67600 (epoch 4), train_loss = 1.257, time/batch=0.076\n",
      "6502/67600 (epoch 4), train_loss = 1.259, time/batch=0.076\n",
      "6503/67600 (epoch 4), train_loss = 1.246, time/batch=0.085\n",
      "6504/67600 (epoch 4), train_loss = 1.269, time/batch=0.070\n",
      "6505/67600 (epoch 4), train_loss = 1.264, time/batch=0.079\n",
      "6506/67600 (epoch 4), train_loss = 1.230, time/batch=0.195\n",
      "6507/67600 (epoch 4), train_loss = 1.193, time/batch=0.085\n",
      "6508/67600 (epoch 4), train_loss = 1.264, time/batch=0.107\n",
      "6509/67600 (epoch 4), train_loss = 1.255, time/batch=0.072\n",
      "6510/67600 (epoch 4), train_loss = 1.247, time/batch=0.069\n",
      "6511/67600 (epoch 4), train_loss = 1.226, time/batch=0.078\n",
      "6512/67600 (epoch 4), train_loss = 1.352, time/batch=0.096\n",
      "6513/67600 (epoch 4), train_loss = 1.239, time/batch=0.086\n",
      "6514/67600 (epoch 4), train_loss = 1.252, time/batch=0.074\n",
      "6515/67600 (epoch 4), train_loss = 1.293, time/batch=0.079\n",
      "6516/67600 (epoch 4), train_loss = 1.257, time/batch=0.068\n",
      "6517/67600 (epoch 4), train_loss = 1.275, time/batch=0.161\n",
      "6518/67600 (epoch 4), train_loss = 1.287, time/batch=0.094\n",
      "6519/67600 (epoch 4), train_loss = 1.262, time/batch=0.124\n",
      "6520/67600 (epoch 4), train_loss = 1.306, time/batch=0.077\n",
      "6521/67600 (epoch 4), train_loss = 1.320, time/batch=0.083\n",
      "6522/67600 (epoch 4), train_loss = 1.307, time/batch=0.073\n",
      "6523/67600 (epoch 4), train_loss = 1.358, time/batch=0.078\n",
      "6524/67600 (epoch 4), train_loss = 1.258, time/batch=0.076\n",
      "6525/67600 (epoch 4), train_loss = 1.293, time/batch=0.072\n",
      "6526/67600 (epoch 4), train_loss = 1.264, time/batch=0.073\n",
      "6527/67600 (epoch 4), train_loss = 1.370, time/batch=0.090\n",
      "6528/67600 (epoch 4), train_loss = 1.268, time/batch=0.214\n",
      "6529/67600 (epoch 4), train_loss = 1.303, time/batch=0.079\n",
      "6530/67600 (epoch 4), train_loss = 1.377, time/batch=0.101\n",
      "6531/67600 (epoch 4), train_loss = 1.283, time/batch=0.078\n",
      "6532/67600 (epoch 4), train_loss = 1.269, time/batch=0.071\n",
      "6533/67600 (epoch 4), train_loss = 1.268, time/batch=0.072\n",
      "6534/67600 (epoch 4), train_loss = 1.334, time/batch=0.092\n",
      "6535/67600 (epoch 4), train_loss = 1.265, time/batch=0.069\n",
      "6536/67600 (epoch 4), train_loss = 1.294, time/batch=0.076\n",
      "6537/67600 (epoch 4), train_loss = 1.286, time/batch=0.075\n",
      "6538/67600 (epoch 4), train_loss = 1.282, time/batch=0.078\n",
      "6539/67600 (epoch 4), train_loss = 1.309, time/batch=0.203\n",
      "6540/67600 (epoch 4), train_loss = 1.255, time/batch=0.070\n",
      "6541/67600 (epoch 4), train_loss = 1.316, time/batch=0.089\n",
      "6542/67600 (epoch 4), train_loss = 1.341, time/batch=0.074\n",
      "6543/67600 (epoch 4), train_loss = 1.348, time/batch=0.092\n",
      "6544/67600 (epoch 4), train_loss = 1.306, time/batch=0.100\n",
      "6545/67600 (epoch 4), train_loss = 1.283, time/batch=0.072\n",
      "6546/67600 (epoch 4), train_loss = 1.292, time/batch=0.071\n",
      "6547/67600 (epoch 4), train_loss = 1.323, time/batch=0.073\n",
      "6548/67600 (epoch 4), train_loss = 1.276, time/batch=0.072\n",
      "6549/67600 (epoch 4), train_loss = 1.272, time/batch=0.074\n",
      "6550/67600 (epoch 4), train_loss = 1.310, time/batch=0.224\n",
      "6551/67600 (epoch 4), train_loss = 1.320, time/batch=0.100\n",
      "6552/67600 (epoch 4), train_loss = 1.293, time/batch=0.082\n",
      "6553/67600 (epoch 4), train_loss = 1.242, time/batch=0.073\n",
      "6554/67600 (epoch 4), train_loss = 1.251, time/batch=0.079\n",
      "6555/67600 (epoch 4), train_loss = 1.241, time/batch=0.080\n",
      "6556/67600 (epoch 4), train_loss = 1.239, time/batch=0.071\n",
      "6557/67600 (epoch 4), train_loss = 1.263, time/batch=0.078\n",
      "6558/67600 (epoch 4), train_loss = 1.209, time/batch=0.179\n",
      "6559/67600 (epoch 4), train_loss = 1.310, time/batch=0.071\n",
      "6560/67600 (epoch 4), train_loss = 1.268, time/batch=0.122\n",
      "6561/67600 (epoch 4), train_loss = 1.251, time/batch=0.073\n",
      "6562/67600 (epoch 4), train_loss = 1.284, time/batch=0.068\n",
      "6563/67600 (epoch 4), train_loss = 1.256, time/batch=0.088\n",
      "6564/67600 (epoch 4), train_loss = 1.259, time/batch=0.072\n",
      "6565/67600 (epoch 4), train_loss = 1.212, time/batch=0.080\n",
      "6566/67600 (epoch 4), train_loss = 1.309, time/batch=0.077\n",
      "6567/67600 (epoch 4), train_loss = 1.301, time/batch=0.083\n",
      "6568/67600 (epoch 4), train_loss = 1.221, time/batch=0.076\n",
      "6569/67600 (epoch 4), train_loss = 1.243, time/batch=0.194\n",
      "6570/67600 (epoch 4), train_loss = 1.260, time/batch=0.072\n",
      "6571/67600 (epoch 4), train_loss = 1.225, time/batch=0.105\n",
      "6572/67600 (epoch 4), train_loss = 1.287, time/batch=0.073\n",
      "6573/67600 (epoch 4), train_loss = 1.219, time/batch=0.070\n",
      "6574/67600 (epoch 4), train_loss = 1.242, time/batch=0.078\n",
      "6575/67600 (epoch 4), train_loss = 1.263, time/batch=0.074\n",
      "6576/67600 (epoch 4), train_loss = 1.291, time/batch=0.070\n",
      "6577/67600 (epoch 4), train_loss = 1.201, time/batch=0.086\n",
      "6578/67600 (epoch 4), train_loss = 1.235, time/batch=0.072\n",
      "6579/67600 (epoch 4), train_loss = 1.226, time/batch=0.071\n",
      "6580/67600 (epoch 4), train_loss = 1.255, time/batch=0.089\n",
      "6581/67600 (epoch 4), train_loss = 1.254, time/batch=0.169\n",
      "6582/67600 (epoch 4), train_loss = 1.246, time/batch=0.106\n",
      "6583/67600 (epoch 4), train_loss = 1.265, time/batch=0.069\n",
      "6584/67600 (epoch 4), train_loss = 1.266, time/batch=0.071\n",
      "6585/67600 (epoch 4), train_loss = 1.281, time/batch=0.069\n",
      "6586/67600 (epoch 4), train_loss = 1.299, time/batch=0.070\n",
      "6587/67600 (epoch 4), train_loss = 1.376, time/batch=0.070\n",
      "6588/67600 (epoch 4), train_loss = 1.344, time/batch=0.068\n",
      "6589/67600 (epoch 4), train_loss = 1.294, time/batch=0.074\n",
      "6590/67600 (epoch 4), train_loss = 1.272, time/batch=0.078\n",
      "6591/67600 (epoch 4), train_loss = 1.258, time/batch=0.073\n",
      "6592/67600 (epoch 4), train_loss = 1.281, time/batch=0.148\n",
      "6593/67600 (epoch 4), train_loss = 1.201, time/batch=0.159\n",
      "6594/67600 (epoch 4), train_loss = 1.236, time/batch=0.099\n",
      "6595/67600 (epoch 4), train_loss = 1.325, time/batch=0.071\n",
      "6596/67600 (epoch 4), train_loss = 1.272, time/batch=0.073\n",
      "6597/67600 (epoch 4), train_loss = 1.236, time/batch=0.073\n",
      "6598/67600 (epoch 4), train_loss = 1.267, time/batch=0.069\n",
      "6599/67600 (epoch 4), train_loss = 1.249, time/batch=0.087\n",
      "6600/67600 (epoch 4), train_loss = 1.262, time/batch=0.073\n",
      "6601/67600 (epoch 4), train_loss = 1.261, time/batch=0.079\n",
      "6602/67600 (epoch 4), train_loss = 1.212, time/batch=0.077\n",
      "6603/67600 (epoch 4), train_loss = 1.246, time/batch=0.173\n",
      "6604/67600 (epoch 4), train_loss = 1.287, time/batch=0.122\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6605/67600 (epoch 4), train_loss = 1.299, time/batch=0.088\n",
      "6606/67600 (epoch 4), train_loss = 1.293, time/batch=0.081\n",
      "6607/67600 (epoch 4), train_loss = 1.258, time/batch=0.070\n",
      "6608/67600 (epoch 4), train_loss = 1.274, time/batch=0.073\n",
      "6609/67600 (epoch 4), train_loss = 1.254, time/batch=0.078\n",
      "6610/67600 (epoch 4), train_loss = 1.246, time/batch=0.095\n",
      "6611/67600 (epoch 4), train_loss = 1.235, time/batch=0.095\n",
      "6612/67600 (epoch 4), train_loss = 1.357, time/batch=0.086\n",
      "6613/67600 (epoch 4), train_loss = 1.261, time/batch=0.073\n",
      "6614/67600 (epoch 4), train_loss = 1.231, time/batch=0.226\n",
      "6615/67600 (epoch 4), train_loss = 1.283, time/batch=0.072\n",
      "6616/67600 (epoch 4), train_loss = 1.237, time/batch=0.074\n",
      "6617/67600 (epoch 4), train_loss = 1.227, time/batch=0.078\n",
      "6618/67600 (epoch 4), train_loss = 1.272, time/batch=0.070\n",
      "6619/67600 (epoch 4), train_loss = 1.243, time/batch=0.090\n",
      "6620/67600 (epoch 4), train_loss = 1.220, time/batch=0.077\n",
      "6621/67600 (epoch 4), train_loss = 1.259, time/batch=0.088\n",
      "6622/67600 (epoch 4), train_loss = 1.299, time/batch=0.127\n",
      "6623/67600 (epoch 4), train_loss = 1.249, time/batch=0.074\n",
      "6624/67600 (epoch 4), train_loss = 1.271, time/batch=0.078\n",
      "6625/67600 (epoch 4), train_loss = 1.260, time/batch=0.074\n",
      "6626/67600 (epoch 4), train_loss = 1.253, time/batch=0.072\n",
      "6627/67600 (epoch 4), train_loss = 1.263, time/batch=0.070\n",
      "6628/67600 (epoch 4), train_loss = 1.254, time/batch=0.070\n",
      "6629/67600 (epoch 4), train_loss = 1.242, time/batch=0.075\n",
      "6630/67600 (epoch 4), train_loss = 1.290, time/batch=0.071\n",
      "6631/67600 (epoch 4), train_loss = 1.248, time/batch=0.257\n",
      "6632/67600 (epoch 4), train_loss = 1.297, time/batch=0.097\n",
      "6633/67600 (epoch 4), train_loss = 1.292, time/batch=0.088\n",
      "6634/67600 (epoch 4), train_loss = 1.299, time/batch=0.076\n",
      "6635/67600 (epoch 4), train_loss = 1.269, time/batch=0.073\n",
      "6636/67600 (epoch 4), train_loss = 1.325, time/batch=0.073\n",
      "6637/67600 (epoch 4), train_loss = 1.240, time/batch=0.075\n",
      "6638/67600 (epoch 4), train_loss = 1.278, time/batch=0.070\n",
      "6639/67600 (epoch 4), train_loss = 1.290, time/batch=0.070\n",
      "6640/67600 (epoch 4), train_loss = 1.358, time/batch=0.072\n",
      "6641/67600 (epoch 4), train_loss = 1.332, time/batch=0.071\n",
      "6642/67600 (epoch 4), train_loss = 1.230, time/batch=0.069\n",
      "6643/67600 (epoch 4), train_loss = 1.265, time/batch=0.219\n",
      "6644/67600 (epoch 4), train_loss = 1.261, time/batch=0.082\n",
      "6645/67600 (epoch 4), train_loss = 1.282, time/batch=0.070\n",
      "6646/67600 (epoch 4), train_loss = 1.248, time/batch=0.071\n",
      "6647/67600 (epoch 4), train_loss = 1.243, time/batch=0.069\n",
      "6648/67600 (epoch 4), train_loss = 1.323, time/batch=0.069\n",
      "6649/67600 (epoch 4), train_loss = 1.245, time/batch=0.074\n",
      "6650/67600 (epoch 4), train_loss = 1.264, time/batch=0.076\n",
      "6651/67600 (epoch 4), train_loss = 1.292, time/batch=0.096\n",
      "6652/67600 (epoch 4), train_loss = 1.370, time/batch=0.071\n",
      "6653/67600 (epoch 4), train_loss = 1.277, time/batch=0.070\n",
      "6654/67600 (epoch 4), train_loss = 1.271, time/batch=0.237\n",
      "6655/67600 (epoch 4), train_loss = 1.266, time/batch=0.077\n",
      "6656/67600 (epoch 4), train_loss = 1.296, time/batch=0.075\n",
      "6657/67600 (epoch 4), train_loss = 1.272, time/batch=0.090\n",
      "6658/67600 (epoch 4), train_loss = 1.241, time/batch=0.106\n",
      "6659/67600 (epoch 4), train_loss = 1.322, time/batch=0.149\n",
      "6660/67600 (epoch 4), train_loss = 1.224, time/batch=0.251\n",
      "6661/67600 (epoch 4), train_loss = 1.340, time/batch=0.233\n",
      "6662/67600 (epoch 4), train_loss = 1.281, time/batch=0.114\n",
      "6663/67600 (epoch 4), train_loss = 1.316, time/batch=0.094\n",
      "6664/67600 (epoch 4), train_loss = 1.310, time/batch=0.134\n",
      "6665/67600 (epoch 4), train_loss = 1.296, time/batch=0.127\n",
      "6666/67600 (epoch 4), train_loss = 1.332, time/batch=0.108\n",
      "6667/67600 (epoch 4), train_loss = 1.285, time/batch=0.231\n",
      "6668/67600 (epoch 4), train_loss = 1.292, time/batch=0.199\n",
      "6669/67600 (epoch 4), train_loss = 1.249, time/batch=0.117\n",
      "6670/67600 (epoch 4), train_loss = 1.351, time/batch=0.094\n",
      "6671/67600 (epoch 4), train_loss = 1.340, time/batch=0.097\n",
      "6672/67600 (epoch 4), train_loss = 1.333, time/batch=0.091\n",
      "6673/67600 (epoch 4), train_loss = 1.259, time/batch=0.097\n",
      "6674/67600 (epoch 4), train_loss = 1.346, time/batch=0.094\n",
      "6675/67600 (epoch 4), train_loss = 1.247, time/batch=0.228\n",
      "6676/67600 (epoch 4), train_loss = 1.213, time/batch=0.139\n",
      "6677/67600 (epoch 4), train_loss = 1.271, time/batch=0.100\n",
      "6678/67600 (epoch 4), train_loss = 1.259, time/batch=0.084\n",
      "6679/67600 (epoch 4), train_loss = 1.218, time/batch=0.112\n",
      "6680/67600 (epoch 4), train_loss = 1.270, time/batch=0.097\n",
      "6681/67600 (epoch 4), train_loss = 1.276, time/batch=0.090\n",
      "6682/67600 (epoch 4), train_loss = 1.260, time/batch=0.125\n",
      "6683/67600 (epoch 4), train_loss = 1.310, time/batch=0.220\n",
      "6684/67600 (epoch 4), train_loss = 1.296, time/batch=0.138\n",
      "6685/67600 (epoch 4), train_loss = 1.282, time/batch=0.104\n",
      "6686/67600 (epoch 4), train_loss = 1.217, time/batch=0.091\n",
      "6687/67600 (epoch 4), train_loss = 1.211, time/batch=0.075\n",
      "6688/67600 (epoch 4), train_loss = 1.242, time/batch=0.075\n",
      "6689/67600 (epoch 4), train_loss = 1.275, time/batch=0.071\n",
      "6690/67600 (epoch 4), train_loss = 1.226, time/batch=0.075\n",
      "6691/67600 (epoch 4), train_loss = 1.284, time/batch=0.073\n",
      "6692/67600 (epoch 4), train_loss = 1.294, time/batch=0.071\n",
      "6693/67600 (epoch 4), train_loss = 1.266, time/batch=0.214\n",
      "6694/67600 (epoch 4), train_loss = 1.232, time/batch=0.083\n",
      "6695/67600 (epoch 4), train_loss = 1.313, time/batch=0.106\n",
      "6696/67600 (epoch 4), train_loss = 1.252, time/batch=0.105\n",
      "6697/67600 (epoch 4), train_loss = 1.305, time/batch=0.073\n",
      "6698/67600 (epoch 4), train_loss = 1.349, time/batch=0.072\n",
      "6699/67600 (epoch 4), train_loss = 1.307, time/batch=0.078\n",
      "6700/67600 (epoch 4), train_loss = 1.247, time/batch=0.171\n",
      "6701/67600 (epoch 4), train_loss = 1.278, time/batch=0.072\n",
      "6702/67600 (epoch 4), train_loss = 1.281, time/batch=0.108\n",
      "6703/67600 (epoch 4), train_loss = 1.258, time/batch=0.068\n",
      "6704/67600 (epoch 4), train_loss = 1.278, time/batch=0.071\n",
      "6705/67600 (epoch 4), train_loss = 1.287, time/batch=0.083\n",
      "6706/67600 (epoch 4), train_loss = 1.233, time/batch=0.089\n",
      "6707/67600 (epoch 4), train_loss = 1.293, time/batch=0.106\n",
      "6708/67600 (epoch 4), train_loss = 1.324, time/batch=0.095\n",
      "6709/67600 (epoch 4), train_loss = 1.266, time/batch=0.070\n",
      "6710/67600 (epoch 4), train_loss = 1.231, time/batch=0.080\n",
      "6711/67600 (epoch 4), train_loss = 1.267, time/batch=0.183\n",
      "6712/67600 (epoch 4), train_loss = 1.293, time/batch=0.074\n",
      "6713/67600 (epoch 4), train_loss = 1.222, time/batch=0.106\n",
      "6714/67600 (epoch 4), train_loss = 1.292, time/batch=0.070\n",
      "6715/67600 (epoch 4), train_loss = 1.273, time/batch=0.072\n",
      "6716/67600 (epoch 4), train_loss = 1.284, time/batch=0.074\n",
      "6717/67600 (epoch 4), train_loss = 1.279, time/batch=0.071\n",
      "6718/67600 (epoch 4), train_loss = 1.249, time/batch=0.080\n",
      "6719/67600 (epoch 4), train_loss = 1.268, time/batch=0.072\n",
      "6720/67600 (epoch 4), train_loss = 1.271, time/batch=0.070\n",
      "6721/67600 (epoch 4), train_loss = 1.325, time/batch=0.074\n",
      "6722/67600 (epoch 4), train_loss = 1.345, time/batch=0.070\n",
      "6723/67600 (epoch 4), train_loss = 1.277, time/batch=0.232\n",
      "6724/67600 (epoch 4), train_loss = 1.294, time/batch=0.108\n",
      "6725/67600 (epoch 4), train_loss = 1.317, time/batch=0.074\n",
      "6726/67600 (epoch 4), train_loss = 1.294, time/batch=0.087\n",
      "6727/67600 (epoch 4), train_loss = 1.256, time/batch=0.078\n",
      "6728/67600 (epoch 4), train_loss = 1.273, time/batch=0.082\n",
      "6729/67600 (epoch 4), train_loss = 1.263, time/batch=0.077\n",
      "6730/67600 (epoch 4), train_loss = 1.239, time/batch=0.081\n",
      "6731/67600 (epoch 4), train_loss = 1.273, time/batch=0.074\n",
      "6732/67600 (epoch 4), train_loss = 1.325, time/batch=0.113\n",
      "6733/67600 (epoch 4), train_loss = 1.273, time/batch=0.238\n",
      "6734/67600 (epoch 4), train_loss = 1.283, time/batch=0.088\n",
      "6735/67600 (epoch 4), train_loss = 1.268, time/batch=0.087\n",
      "6736/67600 (epoch 4), train_loss = 1.269, time/batch=0.089\n",
      "6737/67600 (epoch 4), train_loss = 1.298, time/batch=0.069\n",
      "6738/67600 (epoch 4), train_loss = 1.321, time/batch=0.083\n",
      "6739/67600 (epoch 4), train_loss = 1.326, time/batch=0.099\n",
      "6740/67600 (epoch 4), train_loss = 1.276, time/batch=0.072\n",
      "6741/67600 (epoch 4), train_loss = 1.262, time/batch=0.074\n",
      "6742/67600 (epoch 4), train_loss = 1.228, time/batch=0.081\n",
      "6743/67600 (epoch 4), train_loss = 1.299, time/batch=0.251\n",
      "6744/67600 (epoch 4), train_loss = 1.303, time/batch=0.085\n",
      "6745/67600 (epoch 4), train_loss = 1.273, time/batch=0.076\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6746/67600 (epoch 4), train_loss = 1.306, time/batch=0.080\n",
      "6747/67600 (epoch 4), train_loss = 1.267, time/batch=0.078\n",
      "6748/67600 (epoch 4), train_loss = 1.247, time/batch=0.077\n",
      "6749/67600 (epoch 4), train_loss = 1.279, time/batch=0.076\n",
      "6750/67600 (epoch 4), train_loss = 1.306, time/batch=0.240\n",
      "6751/67600 (epoch 4), train_loss = 1.266, time/batch=0.108\n",
      "6752/67600 (epoch 4), train_loss = 1.242, time/batch=0.078\n",
      "6753/67600 (epoch 4), train_loss = 1.283, time/batch=0.078\n",
      "6754/67600 (epoch 4), train_loss = 1.241, time/batch=0.091\n",
      "6755/67600 (epoch 4), train_loss = 1.281, time/batch=0.078\n",
      "6756/67600 (epoch 4), train_loss = 1.333, time/batch=0.080\n",
      "6757/67600 (epoch 4), train_loss = 1.376, time/batch=0.083\n",
      "6758/67600 (epoch 4), train_loss = 1.277, time/batch=0.079\n",
      "6759/67600 (epoch 4), train_loss = 1.285, time/batch=0.074\n",
      "6760/67600 (epoch 5), train_loss = 1.457, time/batch=0.123\n",
      "6761/67600 (epoch 5), train_loss = 1.231, time/batch=0.070\n",
      "6762/67600 (epoch 5), train_loss = 1.319, time/batch=0.070\n",
      "6763/67600 (epoch 5), train_loss = 1.257, time/batch=0.077\n",
      "6764/67600 (epoch 5), train_loss = 1.286, time/batch=0.071\n",
      "6765/67600 (epoch 5), train_loss = 1.318, time/batch=0.069\n",
      "6766/67600 (epoch 5), train_loss = 1.262, time/batch=0.070\n",
      "6767/67600 (epoch 5), train_loss = 1.293, time/batch=0.072\n",
      "6768/67600 (epoch 5), train_loss = 1.306, time/batch=0.070\n",
      "6769/67600 (epoch 5), train_loss = 1.269, time/batch=0.071\n",
      "6770/67600 (epoch 5), train_loss = 1.238, time/batch=0.283\n",
      "6771/67600 (epoch 5), train_loss = 1.251, time/batch=0.092\n",
      "6772/67600 (epoch 5), train_loss = 1.256, time/batch=0.070\n",
      "6773/67600 (epoch 5), train_loss = 1.323, time/batch=0.072\n",
      "6774/67600 (epoch 5), train_loss = 1.287, time/batch=0.073\n",
      "6775/67600 (epoch 5), train_loss = 1.261, time/batch=0.073\n",
      "6776/67600 (epoch 5), train_loss = 1.277, time/batch=0.071\n",
      "6777/67600 (epoch 5), train_loss = 1.304, time/batch=0.077\n",
      "6778/67600 (epoch 5), train_loss = 1.273, time/batch=0.073\n",
      "6779/67600 (epoch 5), train_loss = 1.283, time/batch=0.071\n",
      "6780/67600 (epoch 5), train_loss = 1.274, time/batch=0.071\n",
      "6781/67600 (epoch 5), train_loss = 1.218, time/batch=0.223\n",
      "6782/67600 (epoch 5), train_loss = 1.321, time/batch=0.073\n",
      "6783/67600 (epoch 5), train_loss = 1.314, time/batch=0.076\n",
      "6784/67600 (epoch 5), train_loss = 1.358, time/batch=0.079\n",
      "6785/67600 (epoch 5), train_loss = 1.203, time/batch=0.069\n",
      "6786/67600 (epoch 5), train_loss = 1.280, time/batch=0.072\n",
      "6787/67600 (epoch 5), train_loss = 1.322, time/batch=0.074\n",
      "6788/67600 (epoch 5), train_loss = 1.341, time/batch=0.068\n",
      "6789/67600 (epoch 5), train_loss = 1.279, time/batch=0.084\n",
      "6790/67600 (epoch 5), train_loss = 1.264, time/batch=0.161\n",
      "6791/67600 (epoch 5), train_loss = 1.343, time/batch=0.087\n",
      "6792/67600 (epoch 5), train_loss = 1.276, time/batch=0.086\n",
      "6793/67600 (epoch 5), train_loss = 1.321, time/batch=0.075\n",
      "6794/67600 (epoch 5), train_loss = 1.294, time/batch=0.071\n",
      "6795/67600 (epoch 5), train_loss = 1.287, time/batch=0.089\n",
      "6796/67600 (epoch 5), train_loss = 1.237, time/batch=0.088\n",
      "6797/67600 (epoch 5), train_loss = 1.296, time/batch=0.069\n",
      "6798/67600 (epoch 5), train_loss = 1.288, time/batch=0.078\n",
      "6799/67600 (epoch 5), train_loss = 1.286, time/batch=0.082\n",
      "6800/67600 (epoch 5), train_loss = 1.206, time/batch=0.072\n",
      "6801/67600 (epoch 5), train_loss = 1.311, time/batch=0.181\n",
      "6802/67600 (epoch 5), train_loss = 1.317, time/batch=0.068\n",
      "6803/67600 (epoch 5), train_loss = 1.306, time/batch=0.110\n",
      "6804/67600 (epoch 5), train_loss = 1.322, time/batch=0.075\n",
      "6805/67600 (epoch 5), train_loss = 1.269, time/batch=0.070\n",
      "6806/67600 (epoch 5), train_loss = 1.239, time/batch=0.075\n",
      "6807/67600 (epoch 5), train_loss = 1.286, time/batch=0.073\n",
      "6808/67600 (epoch 5), train_loss = 1.249, time/batch=0.068\n",
      "6809/67600 (epoch 5), train_loss = 1.248, time/batch=0.071\n",
      "6810/67600 (epoch 5), train_loss = 1.349, time/batch=0.069\n",
      "6811/67600 (epoch 5), train_loss = 1.251, time/batch=0.074\n",
      "6812/67600 (epoch 5), train_loss = 1.264, time/batch=0.072\n",
      "6813/67600 (epoch 5), train_loss = 1.359, time/batch=0.184\n",
      "6814/67600 (epoch 5), train_loss = 1.322, time/batch=0.070\n",
      "6815/67600 (epoch 5), train_loss = 1.284, time/batch=0.109\n",
      "6816/67600 (epoch 5), train_loss = 1.291, time/batch=0.073\n",
      "6817/67600 (epoch 5), train_loss = 1.287, time/batch=0.072\n",
      "6818/67600 (epoch 5), train_loss = 1.283, time/batch=0.079\n",
      "6819/67600 (epoch 5), train_loss = 1.299, time/batch=0.079\n",
      "6820/67600 (epoch 5), train_loss = 1.285, time/batch=0.074\n",
      "6821/67600 (epoch 5), train_loss = 1.269, time/batch=0.077\n",
      "6822/67600 (epoch 5), train_loss = 1.316, time/batch=0.079\n",
      "6823/67600 (epoch 5), train_loss = 1.320, time/batch=0.075\n",
      "6824/67600 (epoch 5), train_loss = 1.280, time/batch=0.216\n",
      "6825/67600 (epoch 5), train_loss = 1.263, time/batch=0.089\n",
      "6826/67600 (epoch 5), train_loss = 1.269, time/batch=0.099\n",
      "6827/67600 (epoch 5), train_loss = 1.296, time/batch=0.076\n",
      "6828/67600 (epoch 5), train_loss = 1.315, time/batch=0.074\n",
      "6829/67600 (epoch 5), train_loss = 1.298, time/batch=0.072\n",
      "6830/67600 (epoch 5), train_loss = 1.301, time/batch=0.077\n",
      "6831/67600 (epoch 5), train_loss = 1.304, time/batch=0.075\n",
      "6832/67600 (epoch 5), train_loss = 1.266, time/batch=0.096\n",
      "6833/67600 (epoch 5), train_loss = 1.338, time/batch=0.094\n",
      "6834/67600 (epoch 5), train_loss = 1.272, time/batch=0.071\n",
      "6835/67600 (epoch 5), train_loss = 1.323, time/batch=0.205\n",
      "6836/67600 (epoch 5), train_loss = 1.331, time/batch=0.091\n",
      "6837/67600 (epoch 5), train_loss = 1.411, time/batch=0.086\n",
      "6838/67600 (epoch 5), train_loss = 1.329, time/batch=0.077\n",
      "6839/67600 (epoch 5), train_loss = 1.259, time/batch=0.073\n",
      "6840/67600 (epoch 5), train_loss = 1.244, time/batch=0.071\n",
      "6841/67600 (epoch 5), train_loss = 1.284, time/batch=0.072\n",
      "6842/67600 (epoch 5), train_loss = 1.293, time/batch=0.070\n",
      "6843/67600 (epoch 5), train_loss = 1.282, time/batch=0.069\n",
      "6844/67600 (epoch 5), train_loss = 1.286, time/batch=0.072\n",
      "6845/67600 (epoch 5), train_loss = 1.275, time/batch=0.072\n",
      "6846/67600 (epoch 5), train_loss = 1.218, time/batch=0.158\n",
      "6847/67600 (epoch 5), train_loss = 1.336, time/batch=0.122\n",
      "6848/67600 (epoch 5), train_loss = 1.308, time/batch=0.076\n",
      "6849/67600 (epoch 5), train_loss = 1.311, time/batch=0.091\n",
      "6850/67600 (epoch 5), train_loss = 1.293, time/batch=0.071\n",
      "6851/67600 (epoch 5), train_loss = 1.299, time/batch=0.074\n",
      "6852/67600 (epoch 5), train_loss = 1.234, time/batch=0.078\n",
      "6853/67600 (epoch 5), train_loss = 1.248, time/batch=0.071\n",
      "6854/67600 (epoch 5), train_loss = 1.244, time/batch=0.198\n",
      "6855/67600 (epoch 5), train_loss = 1.188, time/batch=0.070\n",
      "6856/67600 (epoch 5), train_loss = 1.204, time/batch=0.107\n",
      "6857/67600 (epoch 5), train_loss = 1.285, time/batch=0.072\n",
      "6858/67600 (epoch 5), train_loss = 1.266, time/batch=0.069\n",
      "6859/67600 (epoch 5), train_loss = 1.322, time/batch=0.080\n",
      "6860/67600 (epoch 5), train_loss = 1.177, time/batch=0.075\n",
      "6861/67600 (epoch 5), train_loss = 1.259, time/batch=0.078\n",
      "6862/67600 (epoch 5), train_loss = 1.303, time/batch=0.081\n",
      "6863/67600 (epoch 5), train_loss = 1.212, time/batch=0.076\n",
      "6864/67600 (epoch 5), train_loss = 1.244, time/batch=0.079\n",
      "6865/67600 (epoch 5), train_loss = 1.294, time/batch=0.083\n",
      "6866/67600 (epoch 5), train_loss = 1.251, time/batch=0.196\n",
      "6867/67600 (epoch 5), train_loss = 1.283, time/batch=0.117\n",
      "6868/67600 (epoch 5), train_loss = 1.319, time/batch=0.081\n",
      "6869/67600 (epoch 5), train_loss = 1.280, time/batch=0.088\n",
      "6870/67600 (epoch 5), train_loss = 1.237, time/batch=0.072\n",
      "6871/67600 (epoch 5), train_loss = 1.281, time/batch=0.075\n",
      "6872/67600 (epoch 5), train_loss = 1.262, time/batch=0.071\n",
      "6873/67600 (epoch 5), train_loss = 1.301, time/batch=0.070\n",
      "6874/67600 (epoch 5), train_loss = 1.301, time/batch=0.070\n",
      "6875/67600 (epoch 5), train_loss = 1.240, time/batch=0.076\n",
      "6876/67600 (epoch 5), train_loss = 1.231, time/batch=0.071\n",
      "6877/67600 (epoch 5), train_loss = 1.270, time/batch=0.195\n",
      "6878/67600 (epoch 5), train_loss = 1.289, time/batch=0.119\n",
      "6879/67600 (epoch 5), train_loss = 1.304, time/batch=0.075\n",
      "6880/67600 (epoch 5), train_loss = 1.288, time/batch=0.086\n",
      "6881/67600 (epoch 5), train_loss = 1.294, time/batch=0.075\n",
      "6882/67600 (epoch 5), train_loss = 1.270, time/batch=0.073\n",
      "6883/67600 (epoch 5), train_loss = 1.256, time/batch=0.074\n",
      "6884/67600 (epoch 5), train_loss = 1.258, time/batch=0.070\n",
      "6885/67600 (epoch 5), train_loss = 1.190, time/batch=0.072\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6886/67600 (epoch 5), train_loss = 1.277, time/batch=0.082\n",
      "6887/67600 (epoch 5), train_loss = 1.307, time/batch=0.083\n",
      "6888/67600 (epoch 5), train_loss = 1.247, time/batch=0.196\n",
      "6889/67600 (epoch 5), train_loss = 1.264, time/batch=0.088\n",
      "6890/67600 (epoch 5), train_loss = 1.289, time/batch=0.071\n",
      "6891/67600 (epoch 5), train_loss = 1.271, time/batch=0.073\n",
      "6892/67600 (epoch 5), train_loss = 1.322, time/batch=0.078\n",
      "6893/67600 (epoch 5), train_loss = 1.261, time/batch=0.069\n",
      "6894/67600 (epoch 5), train_loss = 1.288, time/batch=0.068\n",
      "6895/67600 (epoch 5), train_loss = 1.280, time/batch=0.068\n",
      "6896/67600 (epoch 5), train_loss = 1.298, time/batch=0.069\n",
      "6897/67600 (epoch 5), train_loss = 1.280, time/batch=0.073\n",
      "6898/67600 (epoch 5), train_loss = 1.282, time/batch=0.067\n",
      "6899/67600 (epoch 5), train_loss = 1.252, time/batch=0.064\n",
      "6900/67600 (epoch 5), train_loss = 1.244, time/batch=0.209\n",
      "6901/67600 (epoch 5), train_loss = 1.223, time/batch=0.073\n",
      "6902/67600 (epoch 5), train_loss = 1.301, time/batch=0.070\n",
      "6903/67600 (epoch 5), train_loss = 1.226, time/batch=0.073\n",
      "6904/67600 (epoch 5), train_loss = 1.314, time/batch=0.069\n",
      "6905/67600 (epoch 5), train_loss = 1.364, time/batch=0.073\n",
      "6906/67600 (epoch 5), train_loss = 1.279, time/batch=0.073\n",
      "6907/67600 (epoch 5), train_loss = 1.274, time/batch=0.069\n",
      "6908/67600 (epoch 5), train_loss = 1.315, time/batch=0.106\n",
      "6909/67600 (epoch 5), train_loss = 1.206, time/batch=0.143\n",
      "6910/67600 (epoch 5), train_loss = 1.285, time/batch=0.087\n",
      "6911/67600 (epoch 5), train_loss = 1.243, time/batch=0.082\n",
      "6912/67600 (epoch 5), train_loss = 1.223, time/batch=0.071\n",
      "6913/67600 (epoch 5), train_loss = 1.265, time/batch=0.071\n",
      "6914/67600 (epoch 5), train_loss = 1.245, time/batch=0.089\n",
      "6915/67600 (epoch 5), train_loss = 1.292, time/batch=0.072\n",
      "6916/67600 (epoch 5), train_loss = 1.310, time/batch=0.078\n",
      "6917/67600 (epoch 5), train_loss = 1.304, time/batch=0.077\n",
      "6918/67600 (epoch 5), train_loss = 1.288, time/batch=0.073\n",
      "6919/67600 (epoch 5), train_loss = 1.260, time/batch=0.071\n",
      "6920/67600 (epoch 5), train_loss = 1.253, time/batch=0.115\n",
      "6921/67600 (epoch 5), train_loss = 1.219, time/batch=0.075\n",
      "6922/67600 (epoch 5), train_loss = 1.279, time/batch=0.069\n",
      "6923/67600 (epoch 5), train_loss = 1.274, time/batch=0.071\n",
      "6924/67600 (epoch 5), train_loss = 1.173, time/batch=0.080\n",
      "6925/67600 (epoch 5), train_loss = 1.269, time/batch=0.070\n",
      "6926/67600 (epoch 5), train_loss = 1.265, time/batch=0.077\n",
      "6927/67600 (epoch 5), train_loss = 1.240, time/batch=0.080\n",
      "6928/67600 (epoch 5), train_loss = 1.292, time/batch=0.072\n",
      "6929/67600 (epoch 5), train_loss = 1.306, time/batch=0.070\n",
      "6930/67600 (epoch 5), train_loss = 1.287, time/batch=0.245\n",
      "6931/67600 (epoch 5), train_loss = 1.220, time/batch=0.070\n",
      "6932/67600 (epoch 5), train_loss = 1.294, time/batch=0.096\n",
      "6933/67600 (epoch 5), train_loss = 1.248, time/batch=0.072\n",
      "6934/67600 (epoch 5), train_loss = 1.239, time/batch=0.072\n",
      "6935/67600 (epoch 5), train_loss = 1.237, time/batch=0.069\n",
      "6936/67600 (epoch 5), train_loss = 1.284, time/batch=0.072\n",
      "6937/67600 (epoch 5), train_loss = 1.317, time/batch=0.071\n",
      "6938/67600 (epoch 5), train_loss = 1.242, time/batch=0.071\n",
      "6939/67600 (epoch 5), train_loss = 1.249, time/batch=0.071\n",
      "6940/67600 (epoch 5), train_loss = 1.209, time/batch=0.068\n",
      "6941/67600 (epoch 5), train_loss = 1.212, time/batch=0.071\n",
      "6942/67600 (epoch 5), train_loss = 1.257, time/batch=0.213\n",
      "6943/67600 (epoch 5), train_loss = 1.352, time/batch=0.081\n",
      "6944/67600 (epoch 5), train_loss = 1.376, time/batch=0.072\n",
      "6945/67600 (epoch 5), train_loss = 1.342, time/batch=0.071\n",
      "6946/67600 (epoch 5), train_loss = 1.362, time/batch=0.070\n",
      "6947/67600 (epoch 5), train_loss = 1.277, time/batch=0.073\n",
      "6948/67600 (epoch 5), train_loss = 1.280, time/batch=0.071\n",
      "6949/67600 (epoch 5), train_loss = 1.271, time/batch=0.075\n",
      "6950/67600 (epoch 5), train_loss = 1.342, time/batch=0.073\n",
      "6951/67600 (epoch 5), train_loss = 1.305, time/batch=0.072\n",
      "6952/67600 (epoch 5), train_loss = 1.260, time/batch=0.072\n",
      "6953/67600 (epoch 5), train_loss = 1.291, time/batch=0.071\n",
      "6954/67600 (epoch 5), train_loss = 1.298, time/batch=0.221\n",
      "6955/67600 (epoch 5), train_loss = 1.287, time/batch=0.083\n",
      "6956/67600 (epoch 5), train_loss = 1.266, time/batch=0.066\n",
      "6957/67600 (epoch 5), train_loss = 1.262, time/batch=0.070\n",
      "6958/67600 (epoch 5), train_loss = 1.285, time/batch=0.071\n",
      "6959/67600 (epoch 5), train_loss = 1.246, time/batch=0.073\n",
      "6960/67600 (epoch 5), train_loss = 1.228, time/batch=0.073\n",
      "6961/67600 (epoch 5), train_loss = 1.209, time/batch=0.070\n",
      "6962/67600 (epoch 5), train_loss = 1.320, time/batch=0.180\n",
      "6963/67600 (epoch 5), train_loss = 1.288, time/batch=0.071\n",
      "6964/67600 (epoch 5), train_loss = 1.299, time/batch=0.106\n",
      "6965/67600 (epoch 5), train_loss = 1.208, time/batch=0.071\n",
      "6966/67600 (epoch 5), train_loss = 1.211, time/batch=0.070\n",
      "6967/67600 (epoch 5), train_loss = 1.239, time/batch=0.083\n",
      "6968/67600 (epoch 5), train_loss = 1.296, time/batch=0.071\n",
      "6969/67600 (epoch 5), train_loss = 1.326, time/batch=0.071\n",
      "6970/67600 (epoch 5), train_loss = 1.290, time/batch=0.070\n",
      "6971/67600 (epoch 5), train_loss = 1.353, time/batch=0.071\n",
      "6972/67600 (epoch 5), train_loss = 1.244, time/batch=0.071\n",
      "6973/67600 (epoch 5), train_loss = 1.260, time/batch=0.078\n",
      "6974/67600 (epoch 5), train_loss = 1.274, time/batch=0.212\n",
      "6975/67600 (epoch 5), train_loss = 1.315, time/batch=0.121\n",
      "6976/67600 (epoch 5), train_loss = 1.252, time/batch=0.094\n",
      "6977/67600 (epoch 5), train_loss = 1.264, time/batch=0.087\n",
      "6978/67600 (epoch 5), train_loss = 1.239, time/batch=0.091\n",
      "6979/67600 (epoch 5), train_loss = 1.236, time/batch=0.078\n",
      "6980/67600 (epoch 5), train_loss = 1.329, time/batch=0.070\n",
      "6981/67600 (epoch 5), train_loss = 1.243, time/batch=0.075\n",
      "6982/67600 (epoch 5), train_loss = 1.272, time/batch=0.076\n",
      "6983/67600 (epoch 5), train_loss = 1.270, time/batch=0.074\n",
      "6984/67600 (epoch 5), train_loss = 1.272, time/batch=0.200\n",
      "6985/67600 (epoch 5), train_loss = 1.253, time/batch=0.084\n",
      "6986/67600 (epoch 5), train_loss = 1.308, time/batch=0.109\n",
      "6987/67600 (epoch 5), train_loss = 1.229, time/batch=0.077\n",
      "6988/67600 (epoch 5), train_loss = 1.249, time/batch=0.074\n",
      "6989/67600 (epoch 5), train_loss = 1.245, time/batch=0.078\n",
      "6990/67600 (epoch 5), train_loss = 1.273, time/batch=0.086\n",
      "6991/67600 (epoch 5), train_loss = 1.275, time/batch=0.075\n",
      "6992/67600 (epoch 5), train_loss = 1.212, time/batch=0.077\n",
      "6993/67600 (epoch 5), train_loss = 1.210, time/batch=0.073\n",
      "6994/67600 (epoch 5), train_loss = 1.286, time/batch=0.069\n",
      "6995/67600 (epoch 5), train_loss = 1.265, time/batch=0.215\n",
      "6996/67600 (epoch 5), train_loss = 1.254, time/batch=0.072\n",
      "6997/67600 (epoch 5), train_loss = 1.254, time/batch=0.090\n",
      "6998/67600 (epoch 5), train_loss = 1.317, time/batch=0.074\n",
      "6999/67600 (epoch 5), train_loss = 1.280, time/batch=0.071\n",
      "7000/67600 (epoch 5), train_loss = 1.280, time/batch=0.071\n",
      "model saved to ./save/model.ckpt\n",
      "7001/67600 (epoch 5), train_loss = 1.221, time/batch=0.236\n",
      "7002/67600 (epoch 5), train_loss = 1.267, time/batch=0.169\n",
      "7003/67600 (epoch 5), train_loss = 1.278, time/batch=0.075\n",
      "7004/67600 (epoch 5), train_loss = 1.222, time/batch=0.068\n",
      "7005/67600 (epoch 5), train_loss = 1.275, time/batch=0.084\n",
      "7006/67600 (epoch 5), train_loss = 1.260, time/batch=0.073\n",
      "7007/67600 (epoch 5), train_loss = 1.269, time/batch=0.083\n",
      "7008/67600 (epoch 5), train_loss = 1.292, time/batch=0.071\n",
      "7009/67600 (epoch 5), train_loss = 1.233, time/batch=0.071\n",
      "7010/67600 (epoch 5), train_loss = 1.234, time/batch=0.069\n",
      "7011/67600 (epoch 5), train_loss = 1.315, time/batch=0.201\n",
      "7012/67600 (epoch 5), train_loss = 1.242, time/batch=0.103\n",
      "7013/67600 (epoch 5), train_loss = 1.271, time/batch=0.086\n",
      "7014/67600 (epoch 5), train_loss = 1.284, time/batch=0.102\n",
      "7015/67600 (epoch 5), train_loss = 1.328, time/batch=0.091\n",
      "7016/67600 (epoch 5), train_loss = 1.306, time/batch=0.099\n",
      "7017/67600 (epoch 5), train_loss = 1.318, time/batch=0.086\n",
      "7018/67600 (epoch 5), train_loss = 1.222, time/batch=0.072\n",
      "7019/67600 (epoch 5), train_loss = 1.235, time/batch=0.096\n",
      "7020/67600 (epoch 5), train_loss = 1.250, time/batch=0.071\n",
      "7021/67600 (epoch 5), train_loss = 1.250, time/batch=0.238\n",
      "7022/67600 (epoch 5), train_loss = 1.259, time/batch=0.104\n",
      "7023/67600 (epoch 5), train_loss = 1.286, time/batch=0.079\n",
      "7024/67600 (epoch 5), train_loss = 1.245, time/batch=0.084\n",
      "7025/67600 (epoch 5), train_loss = 1.248, time/batch=0.071\n",
      "7026/67600 (epoch 5), train_loss = 1.229, time/batch=0.081\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7027/67600 (epoch 5), train_loss = 1.275, time/batch=0.083\n",
      "7028/67600 (epoch 5), train_loss = 1.240, time/batch=0.077\n",
      "7029/67600 (epoch 5), train_loss = 1.242, time/batch=0.093\n",
      "7030/67600 (epoch 5), train_loss = 1.303, time/batch=0.095\n",
      "7031/67600 (epoch 5), train_loss = 1.264, time/batch=0.245\n",
      "7032/67600 (epoch 5), train_loss = 1.276, time/batch=0.085\n",
      "7033/67600 (epoch 5), train_loss = 1.319, time/batch=0.072\n",
      "7034/67600 (epoch 5), train_loss = 1.281, time/batch=0.077\n",
      "7035/67600 (epoch 5), train_loss = 1.273, time/batch=0.072\n",
      "7036/67600 (epoch 5), train_loss = 1.275, time/batch=0.078\n",
      "7037/67600 (epoch 5), train_loss = 1.232, time/batch=0.077\n",
      "7038/67600 (epoch 5), train_loss = 1.229, time/batch=0.081\n",
      "7039/67600 (epoch 5), train_loss = 1.306, time/batch=0.074\n",
      "7040/67600 (epoch 5), train_loss = 1.314, time/batch=0.080\n",
      "7041/67600 (epoch 5), train_loss = 1.252, time/batch=0.200\n",
      "7042/67600 (epoch 5), train_loss = 1.200, time/batch=0.098\n",
      "7043/67600 (epoch 5), train_loss = 1.279, time/batch=0.075\n",
      "7044/67600 (epoch 5), train_loss = 1.238, time/batch=0.072\n",
      "7045/67600 (epoch 5), train_loss = 1.353, time/batch=0.072\n",
      "7046/67600 (epoch 5), train_loss = 1.289, time/batch=0.076\n",
      "7047/67600 (epoch 5), train_loss = 1.275, time/batch=0.072\n",
      "7048/67600 (epoch 5), train_loss = 1.303, time/batch=0.073\n",
      "7049/67600 (epoch 5), train_loss = 1.292, time/batch=0.083\n",
      "7050/67600 (epoch 5), train_loss = 1.290, time/batch=0.107\n",
      "7051/67600 (epoch 5), train_loss = 1.285, time/batch=0.071\n",
      "7052/67600 (epoch 5), train_loss = 1.278, time/batch=0.072\n",
      "7053/67600 (epoch 5), train_loss = 1.273, time/batch=0.074\n",
      "7054/67600 (epoch 5), train_loss = 1.278, time/batch=0.073\n",
      "7055/67600 (epoch 5), train_loss = 1.295, time/batch=0.073\n",
      "7056/67600 (epoch 5), train_loss = 1.287, time/batch=0.077\n",
      "7057/67600 (epoch 5), train_loss = 1.250, time/batch=0.079\n",
      "7058/67600 (epoch 5), train_loss = 1.250, time/batch=0.073\n",
      "7059/67600 (epoch 5), train_loss = 1.305, time/batch=0.234\n",
      "7060/67600 (epoch 5), train_loss = 1.278, time/batch=0.089\n",
      "7061/67600 (epoch 5), train_loss = 1.300, time/batch=0.090\n",
      "7062/67600 (epoch 5), train_loss = 1.263, time/batch=0.071\n",
      "7063/67600 (epoch 5), train_loss = 1.290, time/batch=0.073\n",
      "7064/67600 (epoch 5), train_loss = 1.293, time/batch=0.071\n",
      "7065/67600 (epoch 5), train_loss = 1.300, time/batch=0.076\n",
      "7066/67600 (epoch 5), train_loss = 1.326, time/batch=0.074\n",
      "7067/67600 (epoch 5), train_loss = 1.299, time/batch=0.077\n",
      "7068/67600 (epoch 5), train_loss = 1.318, time/batch=0.077\n",
      "7069/67600 (epoch 5), train_loss = 1.307, time/batch=0.074\n",
      "7070/67600 (epoch 5), train_loss = 1.282, time/batch=0.074\n",
      "7071/67600 (epoch 5), train_loss = 1.229, time/batch=0.227\n",
      "7072/67600 (epoch 5), train_loss = 1.249, time/batch=0.092\n",
      "7073/67600 (epoch 5), train_loss = 1.302, time/batch=0.076\n",
      "7074/67600 (epoch 5), train_loss = 1.261, time/batch=0.071\n",
      "7075/67600 (epoch 5), train_loss = 1.355, time/batch=0.065\n",
      "7076/67600 (epoch 5), train_loss = 1.266, time/batch=0.080\n",
      "7077/67600 (epoch 5), train_loss = 1.285, time/batch=0.081\n",
      "7078/67600 (epoch 5), train_loss = 1.299, time/batch=0.074\n",
      "7079/67600 (epoch 5), train_loss = 1.303, time/batch=0.075\n",
      "7080/67600 (epoch 5), train_loss = 1.327, time/batch=0.080\n",
      "7081/67600 (epoch 5), train_loss = 1.271, time/batch=0.080\n",
      "7082/67600 (epoch 5), train_loss = 1.280, time/batch=0.239\n",
      "7083/67600 (epoch 5), train_loss = 1.245, time/batch=0.086\n",
      "7084/67600 (epoch 5), train_loss = 1.266, time/batch=0.072\n",
      "7085/67600 (epoch 5), train_loss = 1.244, time/batch=0.074\n",
      "7086/67600 (epoch 5), train_loss = 1.238, time/batch=0.077\n",
      "7087/67600 (epoch 5), train_loss = 1.294, time/batch=0.085\n",
      "7088/67600 (epoch 5), train_loss = 1.263, time/batch=0.092\n",
      "7089/67600 (epoch 5), train_loss = 1.275, time/batch=0.199\n",
      "7090/67600 (epoch 5), train_loss = 1.306, time/batch=0.073\n",
      "7091/67600 (epoch 5), train_loss = 1.214, time/batch=0.110\n",
      "7092/67600 (epoch 5), train_loss = 1.284, time/batch=0.072\n",
      "7093/67600 (epoch 5), train_loss = 1.263, time/batch=0.072\n",
      "7094/67600 (epoch 5), train_loss = 1.277, time/batch=0.077\n",
      "7095/67600 (epoch 5), train_loss = 1.311, time/batch=0.067\n",
      "7096/67600 (epoch 5), train_loss = 1.257, time/batch=0.072\n",
      "7097/67600 (epoch 5), train_loss = 1.247, time/batch=0.073\n",
      "7098/67600 (epoch 5), train_loss = 1.284, time/batch=0.072\n",
      "7099/67600 (epoch 5), train_loss = 1.305, time/batch=0.076\n",
      "7100/67600 (epoch 5), train_loss = 1.260, time/batch=0.070\n",
      "7101/67600 (epoch 5), train_loss = 1.253, time/batch=0.192\n",
      "7102/67600 (epoch 5), train_loss = 1.241, time/batch=0.072\n",
      "7103/67600 (epoch 5), train_loss = 1.227, time/batch=0.108\n",
      "7104/67600 (epoch 5), train_loss = 1.326, time/batch=0.064\n",
      "7105/67600 (epoch 5), train_loss = 1.345, time/batch=0.066\n",
      "7106/67600 (epoch 5), train_loss = 1.280, time/batch=0.064\n",
      "7107/67600 (epoch 5), train_loss = 1.279, time/batch=0.066\n",
      "7108/67600 (epoch 5), train_loss = 1.319, time/batch=0.072\n",
      "7109/67600 (epoch 5), train_loss = 1.325, time/batch=0.072\n",
      "7110/67600 (epoch 5), train_loss = 1.233, time/batch=0.065\n",
      "7111/67600 (epoch 5), train_loss = 1.224, time/batch=0.065\n",
      "7112/67600 (epoch 5), train_loss = 1.209, time/batch=0.069\n",
      "7113/67600 (epoch 5), train_loss = 1.247, time/batch=0.165\n",
      "7114/67600 (epoch 5), train_loss = 1.245, time/batch=0.073\n",
      "7115/67600 (epoch 5), train_loss = 1.320, time/batch=0.091\n",
      "7116/67600 (epoch 5), train_loss = 1.242, time/batch=0.067\n",
      "7117/67600 (epoch 5), train_loss = 1.262, time/batch=0.071\n",
      "7118/67600 (epoch 5), train_loss = 1.217, time/batch=0.069\n",
      "7119/67600 (epoch 5), train_loss = 1.363, time/batch=0.067\n",
      "7120/67600 (epoch 5), train_loss = 1.271, time/batch=0.066\n",
      "7121/67600 (epoch 5), train_loss = 1.225, time/batch=0.064\n",
      "7122/67600 (epoch 5), train_loss = 1.235, time/batch=0.074\n",
      "7123/67600 (epoch 5), train_loss = 1.326, time/batch=0.066\n",
      "7124/67600 (epoch 5), train_loss = 1.266, time/batch=0.065\n",
      "7125/67600 (epoch 5), train_loss = 1.253, time/batch=0.065\n",
      "7126/67600 (epoch 5), train_loss = 1.268, time/batch=0.182\n",
      "7127/67600 (epoch 5), train_loss = 1.213, time/batch=0.073\n",
      "7128/67600 (epoch 5), train_loss = 1.260, time/batch=0.084\n",
      "7129/67600 (epoch 5), train_loss = 1.333, time/batch=0.066\n",
      "7130/67600 (epoch 5), train_loss = 1.265, time/batch=0.062\n",
      "7131/67600 (epoch 5), train_loss = 1.265, time/batch=0.063\n",
      "7132/67600 (epoch 5), train_loss = 1.297, time/batch=0.067\n",
      "7133/67600 (epoch 5), train_loss = 1.273, time/batch=0.068\n",
      "7134/67600 (epoch 5), train_loss = 1.337, time/batch=0.066\n",
      "7135/67600 (epoch 5), train_loss = 1.345, time/batch=0.066\n",
      "7136/67600 (epoch 5), train_loss = 1.296, time/batch=0.066\n",
      "7137/67600 (epoch 5), train_loss = 1.278, time/batch=0.066\n",
      "7138/67600 (epoch 5), train_loss = 1.339, time/batch=0.065\n",
      "7139/67600 (epoch 5), train_loss = 1.359, time/batch=0.144\n",
      "7140/67600 (epoch 5), train_loss = 1.310, time/batch=0.114\n",
      "7141/67600 (epoch 5), train_loss = 1.274, time/batch=0.082\n",
      "7142/67600 (epoch 5), train_loss = 1.273, time/batch=0.066\n",
      "7143/67600 (epoch 5), train_loss = 1.309, time/batch=0.065\n",
      "7144/67600 (epoch 5), train_loss = 1.365, time/batch=0.065\n",
      "7145/67600 (epoch 5), train_loss = 1.278, time/batch=0.065\n",
      "7146/67600 (epoch 5), train_loss = 1.258, time/batch=0.068\n",
      "7147/67600 (epoch 5), train_loss = 1.258, time/batch=0.066\n",
      "7148/67600 (epoch 5), train_loss = 1.318, time/batch=0.085\n",
      "7149/67600 (epoch 5), train_loss = 1.289, time/batch=0.137\n",
      "7150/67600 (epoch 5), train_loss = 1.264, time/batch=0.065\n",
      "7151/67600 (epoch 5), train_loss = 1.261, time/batch=0.106\n",
      "7152/67600 (epoch 5), train_loss = 1.257, time/batch=0.076\n",
      "7153/67600 (epoch 5), train_loss = 1.288, time/batch=0.064\n",
      "7154/67600 (epoch 5), train_loss = 1.264, time/batch=0.071\n",
      "7155/67600 (epoch 5), train_loss = 1.258, time/batch=0.070\n",
      "7156/67600 (epoch 5), train_loss = 1.322, time/batch=0.065\n",
      "7157/67600 (epoch 5), train_loss = 1.326, time/batch=0.063\n",
      "7158/67600 (epoch 5), train_loss = 1.273, time/batch=0.063\n",
      "7159/67600 (epoch 5), train_loss = 1.254, time/batch=0.068\n",
      "7160/67600 (epoch 5), train_loss = 1.315, time/batch=0.066\n",
      "7161/67600 (epoch 5), train_loss = 1.350, time/batch=0.076\n",
      "7162/67600 (epoch 5), train_loss = 1.341, time/batch=0.155\n",
      "7163/67600 (epoch 5), train_loss = 1.292, time/batch=0.065\n",
      "7164/67600 (epoch 5), train_loss = 1.372, time/batch=0.100\n",
      "7165/67600 (epoch 5), train_loss = 1.319, time/batch=0.066\n",
      "7166/67600 (epoch 5), train_loss = 1.334, time/batch=0.067\n",
      "7167/67600 (epoch 5), train_loss = 1.263, time/batch=0.066\n",
      "7168/67600 (epoch 5), train_loss = 1.304, time/batch=0.064\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7169/67600 (epoch 5), train_loss = 1.310, time/batch=0.068\n",
      "7170/67600 (epoch 5), train_loss = 1.303, time/batch=0.065\n",
      "7171/67600 (epoch 5), train_loss = 1.251, time/batch=0.065\n",
      "7172/67600 (epoch 5), train_loss = 1.265, time/batch=0.065\n",
      "7173/67600 (epoch 5), train_loss = 1.285, time/batch=0.070\n",
      "7174/67600 (epoch 5), train_loss = 1.274, time/batch=0.134\n",
      "7175/67600 (epoch 5), train_loss = 1.320, time/batch=0.119\n",
      "7176/67600 (epoch 5), train_loss = 1.287, time/batch=0.081\n",
      "7177/67600 (epoch 5), train_loss = 1.316, time/batch=0.077\n",
      "7178/67600 (epoch 5), train_loss = 1.323, time/batch=0.068\n",
      "7179/67600 (epoch 5), train_loss = 1.263, time/batch=0.082\n",
      "7180/67600 (epoch 5), train_loss = 1.202, time/batch=0.071\n",
      "7181/67600 (epoch 5), train_loss = 1.222, time/batch=0.068\n",
      "7182/67600 (epoch 5), train_loss = 1.266, time/batch=0.071\n",
      "7183/67600 (epoch 5), train_loss = 1.236, time/batch=0.087\n",
      "7184/67600 (epoch 5), train_loss = 1.279, time/batch=0.067\n",
      "7185/67600 (epoch 5), train_loss = 1.247, time/batch=0.065\n",
      "7186/67600 (epoch 5), train_loss = 1.269, time/batch=0.105\n",
      "7187/67600 (epoch 5), train_loss = 1.267, time/batch=0.182\n",
      "7188/67600 (epoch 5), train_loss = 1.185, time/batch=0.088\n",
      "7189/67600 (epoch 5), train_loss = 1.248, time/batch=0.076\n",
      "7190/67600 (epoch 5), train_loss = 1.318, time/batch=0.066\n",
      "7191/67600 (epoch 5), train_loss = 1.236, time/batch=0.066\n",
      "7192/67600 (epoch 5), train_loss = 1.297, time/batch=0.065\n",
      "7193/67600 (epoch 5), train_loss = 1.295, time/batch=0.065\n",
      "7194/67600 (epoch 5), train_loss = 1.234, time/batch=0.067\n",
      "7195/67600 (epoch 5), train_loss = 1.335, time/batch=0.065\n",
      "7196/67600 (epoch 5), train_loss = 1.264, time/batch=0.066\n",
      "7197/67600 (epoch 5), train_loss = 1.278, time/batch=0.069\n",
      "7198/67600 (epoch 5), train_loss = 1.289, time/batch=0.064\n",
      "7199/67600 (epoch 5), train_loss = 1.261, time/batch=0.162\n",
      "7200/67600 (epoch 5), train_loss = 1.250, time/batch=0.094\n",
      "7201/67600 (epoch 5), train_loss = 1.287, time/batch=0.072\n",
      "7202/67600 (epoch 5), train_loss = 1.254, time/batch=0.065\n",
      "7203/67600 (epoch 5), train_loss = 1.243, time/batch=0.067\n",
      "7204/67600 (epoch 5), train_loss = 1.277, time/batch=0.092\n",
      "7205/67600 (epoch 5), train_loss = 1.314, time/batch=0.068\n",
      "7206/67600 (epoch 5), train_loss = 1.232, time/batch=0.081\n",
      "7207/67600 (epoch 5), train_loss = 1.246, time/batch=0.063\n",
      "7208/67600 (epoch 5), train_loss = 1.216, time/batch=0.175\n",
      "7209/67600 (epoch 5), train_loss = 1.245, time/batch=0.077\n",
      "7210/67600 (epoch 5), train_loss = 1.196, time/batch=0.089\n",
      "7211/67600 (epoch 5), train_loss = 1.310, time/batch=0.082\n",
      "7212/67600 (epoch 5), train_loss = 1.314, time/batch=0.073\n",
      "7213/67600 (epoch 5), train_loss = 1.210, time/batch=0.083\n",
      "7214/67600 (epoch 5), train_loss = 1.192, time/batch=0.087\n",
      "7215/67600 (epoch 5), train_loss = 1.235, time/batch=0.068\n",
      "7216/67600 (epoch 5), train_loss = 1.254, time/batch=0.072\n",
      "7217/67600 (epoch 5), train_loss = 1.273, time/batch=0.083\n",
      "7218/67600 (epoch 5), train_loss = 1.293, time/batch=0.067\n",
      "7219/67600 (epoch 5), train_loss = 1.270, time/batch=0.082\n",
      "7220/67600 (epoch 5), train_loss = 1.282, time/batch=0.097\n",
      "7221/67600 (epoch 5), train_loss = 1.234, time/batch=0.068\n",
      "7222/67600 (epoch 5), train_loss = 1.301, time/batch=0.068\n",
      "7223/67600 (epoch 5), train_loss = 1.266, time/batch=0.069\n",
      "7224/67600 (epoch 5), train_loss = 1.231, time/batch=0.082\n",
      "7225/67600 (epoch 5), train_loss = 1.253, time/batch=0.067\n",
      "7226/67600 (epoch 5), train_loss = 1.252, time/batch=0.069\n",
      "7227/67600 (epoch 5), train_loss = 1.320, time/batch=0.074\n",
      "7228/67600 (epoch 5), train_loss = 1.270, time/batch=0.066\n",
      "7229/67600 (epoch 5), train_loss = 1.240, time/batch=0.063\n",
      "7230/67600 (epoch 5), train_loss = 1.257, time/batch=0.246\n",
      "7231/67600 (epoch 5), train_loss = 1.266, time/batch=0.107\n",
      "7232/67600 (epoch 5), train_loss = 1.228, time/batch=0.078\n",
      "7233/67600 (epoch 5), train_loss = 1.274, time/batch=0.066\n",
      "7234/67600 (epoch 5), train_loss = 1.240, time/batch=0.077\n",
      "7235/67600 (epoch 5), train_loss = 1.209, time/batch=0.064\n",
      "7236/67600 (epoch 5), train_loss = 1.292, time/batch=0.075\n",
      "7237/67600 (epoch 5), train_loss = 1.224, time/batch=0.067\n",
      "7238/67600 (epoch 5), train_loss = 1.253, time/batch=0.080\n",
      "7239/67600 (epoch 5), train_loss = 1.278, time/batch=0.066\n",
      "7240/67600 (epoch 5), train_loss = 1.219, time/batch=0.079\n",
      "7241/67600 (epoch 5), train_loss = 1.265, time/batch=0.120\n",
      "7242/67600 (epoch 5), train_loss = 1.250, time/batch=0.161\n",
      "7243/67600 (epoch 5), train_loss = 1.225, time/batch=0.093\n",
      "7244/67600 (epoch 5), train_loss = 1.278, time/batch=0.066\n",
      "7245/67600 (epoch 5), train_loss = 1.286, time/batch=0.066\n",
      "7246/67600 (epoch 5), train_loss = 1.309, time/batch=0.077\n",
      "7247/67600 (epoch 5), train_loss = 1.274, time/batch=0.077\n",
      "7248/67600 (epoch 5), train_loss = 1.337, time/batch=0.071\n",
      "7249/67600 (epoch 5), train_loss = 1.302, time/batch=0.066\n",
      "7250/67600 (epoch 5), train_loss = 1.227, time/batch=0.076\n",
      "7251/67600 (epoch 5), train_loss = 1.271, time/batch=0.065\n",
      "7252/67600 (epoch 5), train_loss = 1.280, time/batch=0.077\n",
      "7253/67600 (epoch 5), train_loss = 1.241, time/batch=0.138\n",
      "7254/67600 (epoch 5), train_loss = 1.322, time/batch=0.125\n",
      "7255/67600 (epoch 5), train_loss = 1.288, time/batch=0.073\n",
      "7256/67600 (epoch 5), train_loss = 1.248, time/batch=0.067\n",
      "7257/67600 (epoch 5), train_loss = 1.281, time/batch=0.065\n",
      "7258/67600 (epoch 5), train_loss = 1.329, time/batch=0.085\n",
      "7259/67600 (epoch 5), train_loss = 1.259, time/batch=0.069\n",
      "7260/67600 (epoch 5), train_loss = 1.205, time/batch=0.066\n",
      "7261/67600 (epoch 5), train_loss = 1.223, time/batch=0.066\n",
      "7262/67600 (epoch 5), train_loss = 1.251, time/batch=0.113\n",
      "7263/67600 (epoch 5), train_loss = 1.291, time/batch=0.116\n",
      "7264/67600 (epoch 5), train_loss = 1.295, time/batch=0.114\n",
      "7265/67600 (epoch 5), train_loss = 1.308, time/batch=0.065\n",
      "7266/67600 (epoch 5), train_loss = 1.294, time/batch=0.063\n",
      "7267/67600 (epoch 5), train_loss = 1.282, time/batch=0.063\n",
      "7268/67600 (epoch 5), train_loss = 1.224, time/batch=0.070\n",
      "7269/67600 (epoch 5), train_loss = 1.255, time/batch=0.062\n",
      "7270/67600 (epoch 5), train_loss = 1.303, time/batch=0.062\n",
      "7271/67600 (epoch 5), train_loss = 1.265, time/batch=0.066\n",
      "7272/67600 (epoch 5), train_loss = 1.284, time/batch=0.068\n",
      "7273/67600 (epoch 5), train_loss = 1.253, time/batch=0.066\n",
      "7274/67600 (epoch 5), train_loss = 1.278, time/batch=0.065\n",
      "7275/67600 (epoch 5), train_loss = 1.317, time/batch=0.153\n",
      "7276/67600 (epoch 5), train_loss = 1.315, time/batch=0.091\n",
      "7277/67600 (epoch 5), train_loss = 1.306, time/batch=0.076\n",
      "7278/67600 (epoch 5), train_loss = 1.284, time/batch=0.091\n",
      "7279/67600 (epoch 5), train_loss = 1.197, time/batch=0.065\n",
      "7280/67600 (epoch 5), train_loss = 1.318, time/batch=0.065\n",
      "7281/67600 (epoch 5), train_loss = 1.318, time/batch=0.065\n",
      "7282/67600 (epoch 5), train_loss = 1.337, time/batch=0.065\n",
      "7283/67600 (epoch 5), train_loss = 1.270, time/batch=0.064\n",
      "7284/67600 (epoch 5), train_loss = 1.274, time/batch=0.064\n",
      "7285/67600 (epoch 5), train_loss = 1.273, time/batch=0.069\n",
      "7286/67600 (epoch 5), train_loss = 1.288, time/batch=0.066\n",
      "7287/67600 (epoch 5), train_loss = 1.238, time/batch=0.071\n",
      "7288/67600 (epoch 5), train_loss = 1.297, time/batch=0.183\n",
      "7289/67600 (epoch 5), train_loss = 1.262, time/batch=0.077\n",
      "7290/67600 (epoch 5), train_loss = 1.323, time/batch=0.104\n",
      "7291/67600 (epoch 5), train_loss = 1.323, time/batch=0.077\n",
      "7292/67600 (epoch 5), train_loss = 1.293, time/batch=0.065\n",
      "7293/67600 (epoch 5), train_loss = 1.247, time/batch=0.077\n",
      "7294/67600 (epoch 5), train_loss = 1.257, time/batch=0.068\n",
      "7295/67600 (epoch 5), train_loss = 1.221, time/batch=0.077\n",
      "7296/67600 (epoch 5), train_loss = 1.243, time/batch=0.067\n",
      "7297/67600 (epoch 5), train_loss = 1.269, time/batch=0.080\n",
      "7298/67600 (epoch 5), train_loss = 1.256, time/batch=0.067\n",
      "7299/67600 (epoch 5), train_loss = 1.275, time/batch=0.078\n",
      "7300/67600 (epoch 5), train_loss = 1.285, time/batch=0.202\n",
      "7301/67600 (epoch 5), train_loss = 1.218, time/batch=0.077\n",
      "7302/67600 (epoch 5), train_loss = 1.261, time/batch=0.096\n",
      "7303/67600 (epoch 5), train_loss = 1.233, time/batch=0.079\n",
      "7304/67600 (epoch 5), train_loss = 1.306, time/batch=0.065\n",
      "7305/67600 (epoch 5), train_loss = 1.275, time/batch=0.075\n",
      "7306/67600 (epoch 5), train_loss = 1.253, time/batch=0.067\n",
      "7307/67600 (epoch 5), train_loss = 1.269, time/batch=0.065\n",
      "7308/67600 (epoch 5), train_loss = 1.395, time/batch=0.090\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7309/67600 (epoch 5), train_loss = 1.301, time/batch=0.080\n",
      "7310/67600 (epoch 5), train_loss = 1.252, time/batch=0.075\n",
      "7311/67600 (epoch 5), train_loss = 1.313, time/batch=0.102\n",
      "7312/67600 (epoch 5), train_loss = 1.246, time/batch=0.164\n",
      "7313/67600 (epoch 5), train_loss = 1.264, time/batch=0.098\n",
      "7314/67600 (epoch 5), train_loss = 1.298, time/batch=0.065\n",
      "7315/67600 (epoch 5), train_loss = 1.255, time/batch=0.065\n",
      "7316/67600 (epoch 5), train_loss = 1.324, time/batch=0.063\n",
      "7317/67600 (epoch 5), train_loss = 1.265, time/batch=0.070\n",
      "7318/67600 (epoch 5), train_loss = 1.242, time/batch=0.068\n",
      "7319/67600 (epoch 5), train_loss = 1.205, time/batch=0.085\n",
      "7320/67600 (epoch 5), train_loss = 1.236, time/batch=0.187\n",
      "7321/67600 (epoch 5), train_loss = 1.259, time/batch=0.073\n",
      "7322/67600 (epoch 5), train_loss = 1.218, time/batch=0.103\n",
      "7323/67600 (epoch 5), train_loss = 1.263, time/batch=0.080\n",
      "7324/67600 (epoch 5), train_loss = 1.230, time/batch=0.073\n",
      "7325/67600 (epoch 5), train_loss = 1.247, time/batch=0.087\n",
      "7326/67600 (epoch 5), train_loss = 1.290, time/batch=0.066\n",
      "7327/67600 (epoch 5), train_loss = 1.294, time/batch=0.066\n",
      "7328/67600 (epoch 5), train_loss = 1.288, time/batch=0.079\n",
      "7329/67600 (epoch 5), train_loss = 1.249, time/batch=0.075\n",
      "7330/67600 (epoch 5), train_loss = 1.230, time/batch=0.089\n",
      "7331/67600 (epoch 5), train_loss = 1.221, time/batch=0.167\n",
      "7332/67600 (epoch 5), train_loss = 1.254, time/batch=0.082\n",
      "7333/67600 (epoch 5), train_loss = 1.266, time/batch=0.126\n",
      "7334/67600 (epoch 5), train_loss = 1.280, time/batch=0.067\n",
      "7335/67600 (epoch 5), train_loss = 1.238, time/batch=0.066\n",
      "7336/67600 (epoch 5), train_loss = 1.290, time/batch=0.066\n",
      "7337/67600 (epoch 5), train_loss = 1.276, time/batch=0.066\n",
      "7338/67600 (epoch 5), train_loss = 1.299, time/batch=0.079\n",
      "7339/67600 (epoch 5), train_loss = 1.260, time/batch=0.065\n",
      "7340/67600 (epoch 5), train_loss = 1.285, time/batch=0.069\n",
      "7341/67600 (epoch 5), train_loss = 1.274, time/batch=0.065\n",
      "7342/67600 (epoch 5), train_loss = 1.232, time/batch=0.085\n",
      "7343/67600 (epoch 5), train_loss = 1.237, time/batch=0.179\n",
      "7344/67600 (epoch 5), train_loss = 1.258, time/batch=0.073\n",
      "7345/67600 (epoch 5), train_loss = 1.325, time/batch=0.091\n",
      "7346/67600 (epoch 5), train_loss = 1.239, time/batch=0.066\n",
      "7347/67600 (epoch 5), train_loss = 1.320, time/batch=0.065\n",
      "7348/67600 (epoch 5), train_loss = 1.237, time/batch=0.066\n",
      "7349/67600 (epoch 5), train_loss = 1.275, time/batch=0.064\n",
      "7350/67600 (epoch 5), train_loss = 1.336, time/batch=0.066\n",
      "7351/67600 (epoch 5), train_loss = 1.236, time/batch=0.078\n",
      "7352/67600 (epoch 5), train_loss = 1.245, time/batch=0.066\n",
      "7353/67600 (epoch 5), train_loss = 1.270, time/batch=0.067\n",
      "7354/67600 (epoch 5), train_loss = 1.217, time/batch=0.072\n",
      "7355/67600 (epoch 5), train_loss = 1.266, time/batch=0.068\n",
      "7356/67600 (epoch 5), train_loss = 1.282, time/batch=0.158\n",
      "7357/67600 (epoch 5), train_loss = 1.231, time/batch=0.105\n",
      "7358/67600 (epoch 5), train_loss = 1.252, time/batch=0.079\n",
      "7359/67600 (epoch 5), train_loss = 1.242, time/batch=0.081\n",
      "7360/67600 (epoch 5), train_loss = 1.296, time/batch=0.065\n",
      "7361/67600 (epoch 5), train_loss = 1.208, time/batch=0.064\n",
      "7362/67600 (epoch 5), train_loss = 1.267, time/batch=0.066\n",
      "7363/67600 (epoch 5), train_loss = 1.256, time/batch=0.066\n",
      "7364/67600 (epoch 5), train_loss = 1.297, time/batch=0.065\n",
      "7365/67600 (epoch 5), train_loss = 1.241, time/batch=0.065\n",
      "7366/67600 (epoch 5), train_loss = 1.315, time/batch=0.066\n",
      "7367/67600 (epoch 5), train_loss = 1.242, time/batch=0.070\n",
      "7368/67600 (epoch 5), train_loss = 1.332, time/batch=0.063\n",
      "7369/67600 (epoch 5), train_loss = 1.264, time/batch=0.207\n",
      "7370/67600 (epoch 5), train_loss = 1.279, time/batch=0.071\n",
      "7371/67600 (epoch 5), train_loss = 1.358, time/batch=0.071\n",
      "7372/67600 (epoch 5), train_loss = 1.260, time/batch=0.067\n",
      "7373/67600 (epoch 5), train_loss = 1.258, time/batch=0.065\n",
      "7374/67600 (epoch 5), train_loss = 1.290, time/batch=0.066\n",
      "7375/67600 (epoch 5), train_loss = 1.327, time/batch=0.067\n",
      "7376/67600 (epoch 5), train_loss = 1.288, time/batch=0.073\n",
      "7377/67600 (epoch 5), train_loss = 1.345, time/batch=0.065\n",
      "7378/67600 (epoch 5), train_loss = 1.265, time/batch=0.075\n",
      "7379/67600 (epoch 5), train_loss = 1.227, time/batch=0.067\n",
      "7380/67600 (epoch 5), train_loss = 1.220, time/batch=0.067\n",
      "7381/67600 (epoch 5), train_loss = 1.268, time/batch=0.110\n",
      "7382/67600 (epoch 5), train_loss = 1.275, time/batch=0.167\n",
      "7383/67600 (epoch 5), train_loss = 1.236, time/batch=0.077\n",
      "7384/67600 (epoch 5), train_loss = 1.271, time/batch=0.076\n",
      "7385/67600 (epoch 5), train_loss = 1.252, time/batch=0.068\n",
      "7386/67600 (epoch 5), train_loss = 1.299, time/batch=0.071\n",
      "7387/67600 (epoch 5), train_loss = 1.316, time/batch=0.084\n",
      "7388/67600 (epoch 5), train_loss = 1.303, time/batch=0.068\n",
      "7389/67600 (epoch 5), train_loss = 1.271, time/batch=0.074\n",
      "7390/67600 (epoch 5), train_loss = 1.305, time/batch=0.104\n",
      "7391/67600 (epoch 5), train_loss = 1.338, time/batch=0.067\n",
      "7392/67600 (epoch 5), train_loss = 1.247, time/batch=0.063\n",
      "7393/67600 (epoch 5), train_loss = 1.334, time/batch=0.065\n",
      "7394/67600 (epoch 5), train_loss = 1.330, time/batch=0.064\n",
      "7395/67600 (epoch 5), train_loss = 1.199, time/batch=0.065\n",
      "7396/67600 (epoch 5), train_loss = 1.349, time/batch=0.064\n",
      "7397/67600 (epoch 5), train_loss = 1.238, time/batch=0.074\n",
      "7398/67600 (epoch 5), train_loss = 1.209, time/batch=0.067\n",
      "7399/67600 (epoch 5), train_loss = 1.195, time/batch=0.083\n",
      "7400/67600 (epoch 5), train_loss = 1.267, time/batch=0.241\n",
      "7401/67600 (epoch 5), train_loss = 1.244, time/batch=0.088\n",
      "7402/67600 (epoch 5), train_loss = 1.304, time/batch=0.083\n",
      "7403/67600 (epoch 5), train_loss = 1.344, time/batch=0.065\n",
      "7404/67600 (epoch 5), train_loss = 1.321, time/batch=0.063\n",
      "7405/67600 (epoch 5), train_loss = 1.255, time/batch=0.064\n",
      "7406/67600 (epoch 5), train_loss = 1.294, time/batch=0.064\n",
      "7407/67600 (epoch 5), train_loss = 1.288, time/batch=0.068\n",
      "7408/67600 (epoch 5), train_loss = 1.308, time/batch=0.067\n",
      "7409/67600 (epoch 5), train_loss = 1.279, time/batch=0.067\n",
      "7410/67600 (epoch 5), train_loss = 1.320, time/batch=0.065\n",
      "7411/67600 (epoch 5), train_loss = 1.342, time/batch=0.066\n",
      "7412/67600 (epoch 5), train_loss = 1.262, time/batch=0.065\n",
      "7413/67600 (epoch 5), train_loss = 1.255, time/batch=0.126\n",
      "7414/67600 (epoch 5), train_loss = 1.276, time/batch=0.137\n",
      "7415/67600 (epoch 5), train_loss = 1.268, time/batch=0.075\n",
      "7416/67600 (epoch 5), train_loss = 1.268, time/batch=0.065\n",
      "7417/67600 (epoch 5), train_loss = 1.331, time/batch=0.066\n",
      "7418/67600 (epoch 5), train_loss = 1.290, time/batch=0.063\n",
      "7419/67600 (epoch 5), train_loss = 1.218, time/batch=0.064\n",
      "7420/67600 (epoch 5), train_loss = 1.277, time/batch=0.064\n",
      "7421/67600 (epoch 5), train_loss = 1.264, time/batch=0.064\n",
      "7422/67600 (epoch 5), train_loss = 1.191, time/batch=0.075\n",
      "7423/67600 (epoch 5), train_loss = 1.212, time/batch=0.075\n",
      "7424/67600 (epoch 5), train_loss = 1.301, time/batch=0.067\n",
      "7425/67600 (epoch 5), train_loss = 1.282, time/batch=0.096\n",
      "7426/67600 (epoch 5), train_loss = 1.298, time/batch=0.215\n",
      "7427/67600 (epoch 5), train_loss = 1.263, time/batch=0.072\n",
      "7428/67600 (epoch 5), train_loss = 1.329, time/batch=0.073\n",
      "7429/67600 (epoch 5), train_loss = 1.235, time/batch=0.072\n",
      "7430/67600 (epoch 5), train_loss = 1.171, time/batch=0.065\n",
      "7431/67600 (epoch 5), train_loss = 1.263, time/batch=0.075\n",
      "7432/67600 (epoch 5), train_loss = 1.184, time/batch=0.068\n",
      "7433/67600 (epoch 5), train_loss = 1.331, time/batch=0.065\n",
      "7434/67600 (epoch 5), train_loss = 1.316, time/batch=0.121\n",
      "7435/67600 (epoch 5), train_loss = 1.243, time/batch=0.126\n",
      "7436/67600 (epoch 5), train_loss = 1.284, time/batch=0.093\n",
      "7437/67600 (epoch 5), train_loss = 1.310, time/batch=0.080\n",
      "7438/67600 (epoch 5), train_loss = 1.320, time/batch=0.069\n",
      "7439/67600 (epoch 5), train_loss = 1.262, time/batch=0.067\n",
      "7440/67600 (epoch 5), train_loss = 1.265, time/batch=0.069\n",
      "7441/67600 (epoch 5), train_loss = 1.296, time/batch=0.066\n",
      "7442/67600 (epoch 5), train_loss = 1.287, time/batch=0.066\n",
      "7443/67600 (epoch 5), train_loss = 1.250, time/batch=0.065\n",
      "7444/67600 (epoch 5), train_loss = 1.243, time/batch=0.065\n",
      "7445/67600 (epoch 5), train_loss = 1.320, time/batch=0.072\n",
      "7446/67600 (epoch 5), train_loss = 1.285, time/batch=0.065\n",
      "7447/67600 (epoch 5), train_loss = 1.235, time/batch=0.164\n",
      "7448/67600 (epoch 5), train_loss = 1.272, time/batch=0.070\n",
      "7449/67600 (epoch 5), train_loss = 1.230, time/batch=0.105\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7450/67600 (epoch 5), train_loss = 1.265, time/batch=0.082\n",
      "7451/67600 (epoch 5), train_loss = 1.261, time/batch=0.065\n",
      "7452/67600 (epoch 5), train_loss = 1.243, time/batch=0.066\n",
      "7453/67600 (epoch 5), train_loss = 1.290, time/batch=0.065\n",
      "7454/67600 (epoch 5), train_loss = 1.282, time/batch=0.065\n",
      "7455/67600 (epoch 5), train_loss = 1.202, time/batch=0.064\n",
      "7456/67600 (epoch 5), train_loss = 1.292, time/batch=0.067\n",
      "7457/67600 (epoch 5), train_loss = 1.313, time/batch=0.065\n",
      "7458/67600 (epoch 5), train_loss = 1.294, time/batch=0.072\n",
      "7459/67600 (epoch 5), train_loss = 1.239, time/batch=0.067\n",
      "7460/67600 (epoch 5), train_loss = 1.275, time/batch=0.168\n",
      "7461/67600 (epoch 5), train_loss = 1.307, time/batch=0.069\n",
      "7462/67600 (epoch 5), train_loss = 1.272, time/batch=0.093\n",
      "7463/67600 (epoch 5), train_loss = 1.219, time/batch=0.084\n",
      "7464/67600 (epoch 5), train_loss = 1.269, time/batch=0.074\n",
      "7465/67600 (epoch 5), train_loss = 1.254, time/batch=0.083\n",
      "7466/67600 (epoch 5), train_loss = 1.246, time/batch=0.072\n",
      "7467/67600 (epoch 5), train_loss = 1.299, time/batch=0.066\n",
      "7468/67600 (epoch 5), train_loss = 1.280, time/batch=0.075\n",
      "7469/67600 (epoch 5), train_loss = 1.230, time/batch=0.076\n",
      "7470/67600 (epoch 5), train_loss = 1.262, time/batch=0.067\n",
      "7471/67600 (epoch 5), train_loss = 1.174, time/batch=0.080\n",
      "7472/67600 (epoch 5), train_loss = 1.270, time/batch=0.199\n",
      "7473/67600 (epoch 5), train_loss = 1.275, time/batch=0.082\n",
      "7474/67600 (epoch 5), train_loss = 1.265, time/batch=0.075\n",
      "7475/67600 (epoch 5), train_loss = 1.245, time/batch=0.067\n",
      "7476/67600 (epoch 5), train_loss = 1.212, time/batch=0.074\n",
      "7477/67600 (epoch 5), train_loss = 1.261, time/batch=0.070\n",
      "7478/67600 (epoch 5), train_loss = 1.231, time/batch=0.075\n",
      "7479/67600 (epoch 5), train_loss = 1.249, time/batch=0.079\n",
      "7480/67600 (epoch 5), train_loss = 1.254, time/batch=0.071\n",
      "7481/67600 (epoch 5), train_loss = 1.289, time/batch=0.067\n",
      "7482/67600 (epoch 5), train_loss = 1.264, time/batch=0.075\n",
      "7483/67600 (epoch 5), train_loss = 1.282, time/batch=0.064\n",
      "7484/67600 (epoch 5), train_loss = 1.263, time/batch=0.211\n",
      "7485/67600 (epoch 5), train_loss = 1.284, time/batch=0.088\n",
      "7486/67600 (epoch 5), train_loss = 1.265, time/batch=0.071\n",
      "7487/67600 (epoch 5), train_loss = 1.274, time/batch=0.073\n",
      "7488/67600 (epoch 5), train_loss = 1.275, time/batch=0.065\n",
      "7489/67600 (epoch 5), train_loss = 1.241, time/batch=0.080\n",
      "7490/67600 (epoch 5), train_loss = 1.270, time/batch=0.074\n",
      "7491/67600 (epoch 5), train_loss = 1.290, time/batch=0.080\n",
      "7492/67600 (epoch 5), train_loss = 1.285, time/batch=0.167\n",
      "7493/67600 (epoch 5), train_loss = 1.262, time/batch=0.065\n",
      "7494/67600 (epoch 5), train_loss = 1.290, time/batch=0.097\n",
      "7495/67600 (epoch 5), train_loss = 1.229, time/batch=0.067\n",
      "7496/67600 (epoch 5), train_loss = 1.325, time/batch=0.067\n",
      "7497/67600 (epoch 5), train_loss = 1.244, time/batch=0.072\n",
      "7498/67600 (epoch 5), train_loss = 1.220, time/batch=0.068\n",
      "7499/67600 (epoch 5), train_loss = 1.291, time/batch=0.065\n",
      "7500/67600 (epoch 5), train_loss = 1.188, time/batch=0.065\n",
      "model saved to ./save/model.ckpt\n",
      "7501/67600 (epoch 5), train_loss = 1.234, time/batch=0.072\n",
      "7502/67600 (epoch 5), train_loss = 1.206, time/batch=0.063\n",
      "7503/67600 (epoch 5), train_loss = 1.250, time/batch=0.064\n",
      "7504/67600 (epoch 5), train_loss = 1.272, time/batch=0.206\n",
      "7505/67600 (epoch 5), train_loss = 1.283, time/batch=0.092\n",
      "7506/67600 (epoch 5), train_loss = 1.248, time/batch=0.066\n",
      "7507/67600 (epoch 5), train_loss = 1.257, time/batch=0.073\n",
      "7508/67600 (epoch 5), train_loss = 1.286, time/batch=0.064\n",
      "7509/67600 (epoch 5), train_loss = 1.234, time/batch=0.075\n",
      "7510/67600 (epoch 5), train_loss = 1.215, time/batch=0.071\n",
      "7511/67600 (epoch 5), train_loss = 1.222, time/batch=0.070\n",
      "7512/67600 (epoch 5), train_loss = 1.256, time/batch=0.064\n",
      "7513/67600 (epoch 5), train_loss = 1.302, time/batch=0.075\n",
      "7514/67600 (epoch 5), train_loss = 1.243, time/batch=0.068\n",
      "7515/67600 (epoch 5), train_loss = 1.254, time/batch=0.076\n",
      "7516/67600 (epoch 5), train_loss = 1.331, time/batch=0.205\n",
      "7517/67600 (epoch 5), train_loss = 1.256, time/batch=0.086\n",
      "7518/67600 (epoch 5), train_loss = 1.251, time/batch=0.074\n",
      "7519/67600 (epoch 5), train_loss = 1.234, time/batch=0.077\n",
      "7520/67600 (epoch 5), train_loss = 1.243, time/batch=0.067\n",
      "7521/67600 (epoch 5), train_loss = 1.254, time/batch=0.083\n",
      "7522/67600 (epoch 5), train_loss = 1.249, time/batch=0.067\n",
      "7523/67600 (epoch 5), train_loss = 1.309, time/batch=0.080\n",
      "7524/67600 (epoch 5), train_loss = 1.312, time/batch=0.085\n",
      "7525/67600 (epoch 5), train_loss = 1.229, time/batch=0.066\n",
      "7526/67600 (epoch 5), train_loss = 1.269, time/batch=0.064\n",
      "7527/67600 (epoch 5), train_loss = 1.264, time/batch=0.106\n",
      "7528/67600 (epoch 5), train_loss = 1.281, time/batch=0.165\n",
      "7529/67600 (epoch 5), train_loss = 1.294, time/batch=0.069\n",
      "7530/67600 (epoch 5), train_loss = 1.239, time/batch=0.064\n",
      "7531/67600 (epoch 5), train_loss = 1.319, time/batch=0.066\n",
      "7532/67600 (epoch 5), train_loss = 1.284, time/batch=0.070\n",
      "7533/67600 (epoch 5), train_loss = 1.249, time/batch=0.068\n",
      "7534/67600 (epoch 5), train_loss = 1.306, time/batch=0.065\n",
      "7535/67600 (epoch 5), train_loss = 1.336, time/batch=0.066\n",
      "7536/67600 (epoch 5), train_loss = 1.306, time/batch=0.098\n",
      "7537/67600 (epoch 5), train_loss = 1.280, time/batch=0.080\n",
      "7538/67600 (epoch 5), train_loss = 1.259, time/batch=0.090\n",
      "7539/67600 (epoch 5), train_loss = 1.290, time/batch=0.070\n",
      "7540/67600 (epoch 5), train_loss = 1.308, time/batch=0.065\n",
      "7541/67600 (epoch 5), train_loss = 1.256, time/batch=0.064\n",
      "7542/67600 (epoch 5), train_loss = 1.248, time/batch=0.066\n",
      "7543/67600 (epoch 5), train_loss = 1.275, time/batch=0.070\n",
      "7544/67600 (epoch 5), train_loss = 1.259, time/batch=0.065\n",
      "7545/67600 (epoch 5), train_loss = 1.292, time/batch=0.066\n",
      "7546/67600 (epoch 5), train_loss = 1.278, time/batch=0.065\n",
      "7547/67600 (epoch 5), train_loss = 1.279, time/batch=0.209\n",
      "7548/67600 (epoch 5), train_loss = 1.292, time/batch=0.070\n",
      "7549/67600 (epoch 5), train_loss = 1.239, time/batch=0.086\n",
      "7550/67600 (epoch 5), train_loss = 1.261, time/batch=0.066\n",
      "7551/67600 (epoch 5), train_loss = 1.260, time/batch=0.064\n",
      "7552/67600 (epoch 5), train_loss = 1.240, time/batch=0.064\n",
      "7553/67600 (epoch 5), train_loss = 1.300, time/batch=0.066\n",
      "7554/67600 (epoch 5), train_loss = 1.262, time/batch=0.067\n",
      "7555/67600 (epoch 5), train_loss = 1.274, time/batch=0.065\n",
      "7556/67600 (epoch 5), train_loss = 1.330, time/batch=0.066\n",
      "7557/67600 (epoch 5), train_loss = 1.286, time/batch=0.073\n",
      "7558/67600 (epoch 5), train_loss = 1.302, time/batch=0.070\n",
      "7559/67600 (epoch 5), train_loss = 1.266, time/batch=0.070\n",
      "7560/67600 (epoch 5), train_loss = 1.271, time/batch=0.238\n",
      "7561/67600 (epoch 5), train_loss = 1.269, time/batch=0.075\n",
      "7562/67600 (epoch 5), train_loss = 1.256, time/batch=0.081\n",
      "7563/67600 (epoch 5), train_loss = 1.267, time/batch=0.066\n",
      "7564/67600 (epoch 5), train_loss = 1.238, time/batch=0.065\n",
      "7565/67600 (epoch 5), train_loss = 1.222, time/batch=0.068\n",
      "7566/67600 (epoch 5), train_loss = 1.282, time/batch=0.066\n",
      "7567/67600 (epoch 5), train_loss = 1.239, time/batch=0.068\n",
      "7568/67600 (epoch 5), train_loss = 1.186, time/batch=0.066\n",
      "7569/67600 (epoch 5), train_loss = 1.283, time/batch=0.069\n",
      "7570/67600 (epoch 5), train_loss = 1.221, time/batch=0.067\n",
      "7571/67600 (epoch 5), train_loss = 1.304, time/batch=0.072\n",
      "7572/67600 (epoch 5), train_loss = 1.286, time/batch=0.148\n",
      "7573/67600 (epoch 5), train_loss = 1.283, time/batch=0.110\n",
      "7574/67600 (epoch 5), train_loss = 1.311, time/batch=0.073\n",
      "7575/67600 (epoch 5), train_loss = 1.216, time/batch=0.084\n",
      "7576/67600 (epoch 5), train_loss = 1.318, time/batch=0.075\n",
      "7577/67600 (epoch 5), train_loss = 1.236, time/batch=0.067\n",
      "7578/67600 (epoch 5), train_loss = 1.240, time/batch=0.066\n",
      "7579/67600 (epoch 5), train_loss = 1.262, time/batch=0.066\n",
      "7580/67600 (epoch 5), train_loss = 1.189, time/batch=0.062\n",
      "7581/67600 (epoch 5), train_loss = 1.302, time/batch=0.124\n",
      "7582/67600 (epoch 5), train_loss = 1.260, time/batch=0.108\n",
      "7583/67600 (epoch 5), train_loss = 1.345, time/batch=0.112\n",
      "7584/67600 (epoch 5), train_loss = 1.288, time/batch=0.078\n",
      "7585/67600 (epoch 5), train_loss = 1.309, time/batch=0.065\n",
      "7586/67600 (epoch 5), train_loss = 1.410, time/batch=0.072\n",
      "7587/67600 (epoch 5), train_loss = 1.237, time/batch=0.064\n",
      "7588/67600 (epoch 5), train_loss = 1.271, time/batch=0.063\n",
      "7589/67600 (epoch 5), train_loss = 1.310, time/batch=0.065\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7590/67600 (epoch 5), train_loss = 1.349, time/batch=0.068\n",
      "7591/67600 (epoch 5), train_loss = 1.257, time/batch=0.063\n",
      "7592/67600 (epoch 5), train_loss = 1.265, time/batch=0.064\n",
      "7593/67600 (epoch 5), train_loss = 1.274, time/batch=0.065\n",
      "7594/67600 (epoch 5), train_loss = 1.227, time/batch=0.160\n",
      "7595/67600 (epoch 5), train_loss = 1.306, time/batch=0.078\n",
      "7596/67600 (epoch 5), train_loss = 1.157, time/batch=0.104\n",
      "7597/67600 (epoch 5), train_loss = 1.305, time/batch=0.066\n",
      "7598/67600 (epoch 5), train_loss = 1.202, time/batch=0.066\n",
      "7599/67600 (epoch 5), train_loss = 1.256, time/batch=0.066\n",
      "7600/67600 (epoch 5), train_loss = 1.314, time/batch=0.072\n",
      "7601/67600 (epoch 5), train_loss = 1.278, time/batch=0.079\n",
      "7602/67600 (epoch 5), train_loss = 1.271, time/batch=0.076\n",
      "7603/67600 (epoch 5), train_loss = 1.290, time/batch=0.085\n",
      "7604/67600 (epoch 5), train_loss = 1.268, time/batch=0.074\n",
      "7605/67600 (epoch 5), train_loss = 1.257, time/batch=0.070\n",
      "7606/67600 (epoch 5), train_loss = 1.249, time/batch=0.196\n",
      "7607/67600 (epoch 5), train_loss = 1.250, time/batch=0.076\n",
      "7608/67600 (epoch 5), train_loss = 1.285, time/batch=0.122\n",
      "7609/67600 (epoch 5), train_loss = 1.253, time/batch=0.088\n",
      "7610/67600 (epoch 5), train_loss = 1.252, time/batch=0.097\n",
      "7611/67600 (epoch 5), train_loss = 1.345, time/batch=0.099\n",
      "7612/67600 (epoch 5), train_loss = 1.348, time/batch=0.109\n",
      "7613/67600 (epoch 5), train_loss = 1.326, time/batch=0.081\n",
      "7614/67600 (epoch 5), train_loss = 1.250, time/batch=0.067\n",
      "7615/67600 (epoch 5), train_loss = 1.314, time/batch=0.093\n",
      "7616/67600 (epoch 5), train_loss = 1.281, time/batch=0.252\n",
      "7617/67600 (epoch 5), train_loss = 1.267, time/batch=0.129\n",
      "7618/67600 (epoch 5), train_loss = 1.307, time/batch=0.070\n",
      "7619/67600 (epoch 5), train_loss = 1.312, time/batch=0.071\n",
      "7620/67600 (epoch 5), train_loss = 1.279, time/batch=0.069\n",
      "7621/67600 (epoch 5), train_loss = 1.329, time/batch=0.088\n",
      "7622/67600 (epoch 5), train_loss = 1.351, time/batch=0.096\n",
      "7623/67600 (epoch 5), train_loss = 1.306, time/batch=0.076\n",
      "7624/67600 (epoch 5), train_loss = 1.234, time/batch=0.073\n",
      "7625/67600 (epoch 5), train_loss = 1.331, time/batch=0.070\n",
      "7626/67600 (epoch 5), train_loss = 1.310, time/batch=0.242\n",
      "7627/67600 (epoch 5), train_loss = 1.242, time/batch=0.103\n",
      "7628/67600 (epoch 5), train_loss = 1.273, time/batch=0.071\n",
      "7629/67600 (epoch 5), train_loss = 1.261, time/batch=0.064\n",
      "7630/67600 (epoch 5), train_loss = 1.276, time/batch=0.064\n",
      "7631/67600 (epoch 5), train_loss = 1.251, time/batch=0.064\n",
      "7632/67600 (epoch 5), train_loss = 1.306, time/batch=0.064\n",
      "7633/67600 (epoch 5), train_loss = 1.245, time/batch=0.068\n",
      "7634/67600 (epoch 5), train_loss = 1.276, time/batch=0.174\n",
      "7635/67600 (epoch 5), train_loss = 1.328, time/batch=0.077\n",
      "7636/67600 (epoch 5), train_loss = 1.304, time/batch=0.125\n",
      "7637/67600 (epoch 5), train_loss = 1.182, time/batch=0.094\n",
      "7638/67600 (epoch 5), train_loss = 1.259, time/batch=0.082\n",
      "7639/67600 (epoch 5), train_loss = 1.175, time/batch=0.069\n",
      "7640/67600 (epoch 5), train_loss = 1.234, time/batch=0.070\n",
      "7641/67600 (epoch 5), train_loss = 1.250, time/batch=0.066\n",
      "7642/67600 (epoch 5), train_loss = 1.256, time/batch=0.065\n",
      "7643/67600 (epoch 5), train_loss = 1.274, time/batch=0.065\n",
      "7644/67600 (epoch 5), train_loss = 1.242, time/batch=0.066\n",
      "7645/67600 (epoch 5), train_loss = 1.260, time/batch=0.067\n",
      "7646/67600 (epoch 5), train_loss = 1.237, time/batch=0.168\n",
      "7647/67600 (epoch 5), train_loss = 1.199, time/batch=0.069\n",
      "7648/67600 (epoch 5), train_loss = 1.334, time/batch=0.097\n",
      "7649/67600 (epoch 5), train_loss = 1.299, time/batch=0.066\n",
      "7650/67600 (epoch 5), train_loss = 1.326, time/batch=0.065\n",
      "7651/67600 (epoch 5), train_loss = 1.314, time/batch=0.080\n",
      "7652/67600 (epoch 5), train_loss = 1.293, time/batch=0.079\n",
      "7653/67600 (epoch 5), train_loss = 1.257, time/batch=0.075\n",
      "7654/67600 (epoch 5), train_loss = 1.303, time/batch=0.085\n",
      "7655/67600 (epoch 5), train_loss = 1.248, time/batch=0.080\n",
      "7656/67600 (epoch 5), train_loss = 1.269, time/batch=0.079\n",
      "7657/67600 (epoch 5), train_loss = 1.328, time/batch=0.253\n",
      "7658/67600 (epoch 5), train_loss = 1.307, time/batch=0.125\n",
      "7659/67600 (epoch 5), train_loss = 1.307, time/batch=0.071\n",
      "7660/67600 (epoch 5), train_loss = 1.276, time/batch=0.074\n",
      "7661/67600 (epoch 5), train_loss = 1.326, time/batch=0.075\n",
      "7662/67600 (epoch 5), train_loss = 1.322, time/batch=0.074\n",
      "7663/67600 (epoch 5), train_loss = 1.205, time/batch=0.074\n",
      "7664/67600 (epoch 5), train_loss = 1.254, time/batch=0.074\n",
      "7665/67600 (epoch 5), train_loss = 1.305, time/batch=0.085\n",
      "7666/67600 (epoch 5), train_loss = 1.257, time/batch=0.082\n",
      "7667/67600 (epoch 5), train_loss = 1.248, time/batch=0.113\n",
      "7668/67600 (epoch 5), train_loss = 1.319, time/batch=0.198\n",
      "7669/67600 (epoch 5), train_loss = 1.255, time/batch=0.101\n",
      "7670/67600 (epoch 5), train_loss = 1.261, time/batch=0.075\n",
      "7671/67600 (epoch 5), train_loss = 1.307, time/batch=0.077\n",
      "7672/67600 (epoch 5), train_loss = 1.255, time/batch=0.078\n",
      "7673/67600 (epoch 5), train_loss = 1.289, time/batch=0.080\n",
      "7674/67600 (epoch 5), train_loss = 1.322, time/batch=0.075\n",
      "7675/67600 (epoch 5), train_loss = 1.257, time/batch=0.073\n",
      "7676/67600 (epoch 5), train_loss = 1.277, time/batch=0.081\n",
      "7677/67600 (epoch 5), train_loss = 1.252, time/batch=0.075\n",
      "7678/67600 (epoch 5), train_loss = 1.288, time/batch=0.159\n",
      "7679/67600 (epoch 5), train_loss = 1.280, time/batch=0.140\n",
      "7680/67600 (epoch 5), train_loss = 1.295, time/batch=0.095\n",
      "7681/67600 (epoch 5), train_loss = 1.264, time/batch=0.070\n",
      "7682/67600 (epoch 5), train_loss = 1.295, time/batch=0.078\n",
      "7683/67600 (epoch 5), train_loss = 1.245, time/batch=0.075\n",
      "7684/67600 (epoch 5), train_loss = 1.227, time/batch=0.072\n",
      "7685/67600 (epoch 5), train_loss = 1.254, time/batch=0.067\n",
      "7686/67600 (epoch 5), train_loss = 1.247, time/batch=0.068\n",
      "7687/67600 (epoch 5), train_loss = 1.270, time/batch=0.071\n",
      "7688/67600 (epoch 5), train_loss = 1.250, time/batch=0.071\n",
      "7689/67600 (epoch 5), train_loss = 1.260, time/batch=0.072\n",
      "7690/67600 (epoch 5), train_loss = 1.225, time/batch=0.213\n",
      "7691/67600 (epoch 5), train_loss = 1.274, time/batch=0.080\n",
      "7692/67600 (epoch 5), train_loss = 1.234, time/batch=0.078\n",
      "7693/67600 (epoch 5), train_loss = 1.221, time/batch=0.070\n",
      "7694/67600 (epoch 5), train_loss = 1.248, time/batch=0.065\n",
      "7695/67600 (epoch 5), train_loss = 1.234, time/batch=0.068\n",
      "7696/67600 (epoch 5), train_loss = 1.295, time/batch=0.065\n",
      "7697/67600 (epoch 5), train_loss = 1.260, time/batch=0.065\n",
      "7698/67600 (epoch 5), train_loss = 1.245, time/batch=0.086\n",
      "7699/67600 (epoch 5), train_loss = 1.243, time/batch=0.097\n",
      "7700/67600 (epoch 5), train_loss = 1.259, time/batch=0.066\n",
      "7701/67600 (epoch 5), train_loss = 1.226, time/batch=0.078\n",
      "7702/67600 (epoch 5), train_loss = 1.200, time/batch=0.078\n",
      "7703/67600 (epoch 5), train_loss = 1.303, time/batch=0.065\n",
      "7704/67600 (epoch 5), train_loss = 1.258, time/batch=0.066\n",
      "7705/67600 (epoch 5), train_loss = 1.281, time/batch=0.065\n",
      "7706/67600 (epoch 5), train_loss = 1.246, time/batch=0.066\n",
      "7707/67600 (epoch 5), train_loss = 1.219, time/batch=0.075\n",
      "7708/67600 (epoch 5), train_loss = 1.269, time/batch=0.065\n",
      "7709/67600 (epoch 5), train_loss = 1.229, time/batch=0.278\n",
      "7710/67600 (epoch 5), train_loss = 1.288, time/batch=0.106\n",
      "7711/67600 (epoch 5), train_loss = 1.230, time/batch=0.068\n",
      "7712/67600 (epoch 5), train_loss = 1.291, time/batch=0.078\n",
      "7713/67600 (epoch 5), train_loss = 1.215, time/batch=0.077\n",
      "7714/67600 (epoch 5), train_loss = 1.196, time/batch=0.067\n",
      "7715/67600 (epoch 5), train_loss = 1.324, time/batch=0.065\n",
      "7716/67600 (epoch 5), train_loss = 1.284, time/batch=0.075\n",
      "7717/67600 (epoch 5), train_loss = 1.282, time/batch=0.073\n",
      "7718/67600 (epoch 5), train_loss = 1.225, time/batch=0.067\n",
      "7719/67600 (epoch 5), train_loss = 1.236, time/batch=0.064\n",
      "7720/67600 (epoch 5), train_loss = 1.235, time/batch=0.171\n",
      "7721/67600 (epoch 5), train_loss = 1.177, time/batch=0.108\n",
      "7722/67600 (epoch 5), train_loss = 1.202, time/batch=0.076\n",
      "7723/67600 (epoch 5), train_loss = 1.193, time/batch=0.075\n",
      "7724/67600 (epoch 5), train_loss = 1.190, time/batch=0.067\n",
      "7725/67600 (epoch 5), train_loss = 1.271, time/batch=0.079\n",
      "7726/67600 (epoch 5), train_loss = 1.269, time/batch=0.068\n",
      "7727/67600 (epoch 5), train_loss = 1.208, time/batch=0.076\n",
      "7728/67600 (epoch 5), train_loss = 1.229, time/batch=0.076\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7729/67600 (epoch 5), train_loss = 1.228, time/batch=0.067\n",
      "7730/67600 (epoch 5), train_loss = 1.260, time/batch=0.065\n",
      "7731/67600 (epoch 5), train_loss = 1.263, time/batch=0.067\n",
      "7732/67600 (epoch 5), train_loss = 1.215, time/batch=0.113\n",
      "7733/67600 (epoch 5), train_loss = 1.274, time/batch=0.156\n",
      "7734/67600 (epoch 5), train_loss = 1.291, time/batch=0.085\n",
      "7735/67600 (epoch 5), train_loss = 1.203, time/batch=0.074\n",
      "7736/67600 (epoch 5), train_loss = 1.185, time/batch=0.075\n",
      "7737/67600 (epoch 5), train_loss = 1.226, time/batch=0.069\n",
      "7738/67600 (epoch 5), train_loss = 1.272, time/batch=0.076\n",
      "7739/67600 (epoch 5), train_loss = 1.245, time/batch=0.076\n",
      "7740/67600 (epoch 5), train_loss = 1.259, time/batch=0.068\n",
      "7741/67600 (epoch 5), train_loss = 1.222, time/batch=0.177\n",
      "7742/67600 (epoch 5), train_loss = 1.227, time/batch=0.067\n",
      "7743/67600 (epoch 5), train_loss = 1.278, time/batch=0.111\n",
      "7744/67600 (epoch 5), train_loss = 1.219, time/batch=0.065\n",
      "7745/67600 (epoch 5), train_loss = 1.321, time/batch=0.068\n",
      "7746/67600 (epoch 5), train_loss = 1.263, time/batch=0.080\n",
      "7747/67600 (epoch 5), train_loss = 1.326, time/batch=0.085\n",
      "7748/67600 (epoch 5), train_loss = 1.222, time/batch=0.073\n",
      "7749/67600 (epoch 5), train_loss = 1.238, time/batch=0.066\n",
      "7750/67600 (epoch 5), train_loss = 1.269, time/batch=0.078\n",
      "7751/67600 (epoch 5), train_loss = 1.242, time/batch=0.073\n",
      "7752/67600 (epoch 5), train_loss = 1.303, time/batch=0.065\n",
      "7753/67600 (epoch 5), train_loss = 1.260, time/batch=0.197\n",
      "7754/67600 (epoch 5), train_loss = 1.246, time/batch=0.093\n",
      "7755/67600 (epoch 5), train_loss = 1.258, time/batch=0.094\n",
      "7756/67600 (epoch 5), train_loss = 1.260, time/batch=0.067\n",
      "7757/67600 (epoch 5), train_loss = 1.277, time/batch=0.065\n",
      "7758/67600 (epoch 5), train_loss = 1.211, time/batch=0.064\n",
      "7759/67600 (epoch 5), train_loss = 1.235, time/batch=0.064\n",
      "7760/67600 (epoch 5), train_loss = 1.245, time/batch=0.066\n",
      "7761/67600 (epoch 5), train_loss = 1.256, time/batch=0.065\n",
      "7762/67600 (epoch 5), train_loss = 1.237, time/batch=0.065\n",
      "7763/67600 (epoch 5), train_loss = 1.263, time/batch=0.069\n",
      "7764/67600 (epoch 5), train_loss = 1.197, time/batch=0.067\n",
      "7765/67600 (epoch 5), train_loss = 1.273, time/batch=0.164\n",
      "7766/67600 (epoch 5), train_loss = 1.257, time/batch=0.073\n",
      "7767/67600 (epoch 5), train_loss = 1.221, time/batch=0.093\n",
      "7768/67600 (epoch 5), train_loss = 1.259, time/batch=0.067\n",
      "7769/67600 (epoch 5), train_loss = 1.217, time/batch=0.070\n",
      "7770/67600 (epoch 5), train_loss = 1.231, time/batch=0.065\n",
      "7771/67600 (epoch 5), train_loss = 1.226, time/batch=0.065\n",
      "7772/67600 (epoch 5), train_loss = 1.198, time/batch=0.063\n",
      "7773/67600 (epoch 5), train_loss = 1.225, time/batch=0.065\n",
      "7774/67600 (epoch 5), train_loss = 1.230, time/batch=0.064\n",
      "7775/67600 (epoch 5), train_loss = 1.242, time/batch=0.063\n",
      "7776/67600 (epoch 5), train_loss = 1.227, time/batch=0.063\n",
      "7777/67600 (epoch 5), train_loss = 1.274, time/batch=0.071\n",
      "7778/67600 (epoch 5), train_loss = 1.246, time/batch=0.122\n",
      "7779/67600 (epoch 5), train_loss = 1.256, time/batch=0.124\n",
      "7780/67600 (epoch 5), train_loss = 1.243, time/batch=0.084\n",
      "7781/67600 (epoch 5), train_loss = 1.238, time/batch=0.066\n",
      "7782/67600 (epoch 5), train_loss = 1.236, time/batch=0.066\n",
      "7783/67600 (epoch 5), train_loss = 1.243, time/batch=0.069\n",
      "7784/67600 (epoch 5), train_loss = 1.248, time/batch=0.065\n",
      "7785/67600 (epoch 5), train_loss = 1.201, time/batch=0.065\n",
      "7786/67600 (epoch 5), train_loss = 1.287, time/batch=0.068\n",
      "7787/67600 (epoch 5), train_loss = 1.202, time/batch=0.065\n",
      "7788/67600 (epoch 5), train_loss = 1.307, time/batch=0.070\n",
      "7789/67600 (epoch 5), train_loss = 1.275, time/batch=0.067\n",
      "7790/67600 (epoch 5), train_loss = 1.292, time/batch=0.071\n",
      "7791/67600 (epoch 5), train_loss = 1.288, time/batch=0.151\n",
      "7792/67600 (epoch 5), train_loss = 1.257, time/batch=0.113\n",
      "7793/67600 (epoch 5), train_loss = 1.230, time/batch=0.071\n",
      "7794/67600 (epoch 5), train_loss = 1.263, time/batch=0.075\n",
      "7795/67600 (epoch 5), train_loss = 1.230, time/batch=0.066\n",
      "7796/67600 (epoch 5), train_loss = 1.211, time/batch=0.065\n",
      "7797/67600 (epoch 5), train_loss = 1.207, time/batch=0.087\n",
      "7798/67600 (epoch 5), train_loss = 1.251, time/batch=0.066\n",
      "7799/67600 (epoch 5), train_loss = 1.225, time/batch=0.068\n",
      "7800/67600 (epoch 5), train_loss = 1.253, time/batch=0.167\n",
      "7801/67600 (epoch 5), train_loss = 1.258, time/batch=0.067\n",
      "7802/67600 (epoch 5), train_loss = 1.299, time/batch=0.100\n",
      "7803/67600 (epoch 5), train_loss = 1.156, time/batch=0.069\n",
      "7804/67600 (epoch 5), train_loss = 1.247, time/batch=0.067\n",
      "7805/67600 (epoch 5), train_loss = 1.239, time/batch=0.088\n",
      "7806/67600 (epoch 5), train_loss = 1.255, time/batch=0.068\n",
      "7807/67600 (epoch 5), train_loss = 1.310, time/batch=0.066\n",
      "7808/67600 (epoch 5), train_loss = 1.289, time/batch=0.082\n",
      "7809/67600 (epoch 5), train_loss = 1.276, time/batch=0.082\n",
      "7810/67600 (epoch 5), train_loss = 1.249, time/batch=0.067\n",
      "7811/67600 (epoch 5), train_loss = 1.218, time/batch=0.066\n",
      "7812/67600 (epoch 5), train_loss = 1.271, time/batch=0.191\n",
      "7813/67600 (epoch 5), train_loss = 1.253, time/batch=0.071\n",
      "7814/67600 (epoch 5), train_loss = 1.278, time/batch=0.116\n",
      "7815/67600 (epoch 5), train_loss = 1.258, time/batch=0.083\n",
      "7816/67600 (epoch 5), train_loss = 1.181, time/batch=0.079\n",
      "7817/67600 (epoch 5), train_loss = 1.298, time/batch=0.068\n",
      "7818/67600 (epoch 5), train_loss = 1.323, time/batch=0.067\n",
      "7819/67600 (epoch 5), train_loss = 1.244, time/batch=0.065\n",
      "7820/67600 (epoch 5), train_loss = 1.275, time/batch=0.065\n",
      "7821/67600 (epoch 5), train_loss = 1.273, time/batch=0.068\n",
      "7822/67600 (epoch 5), train_loss = 1.249, time/batch=0.073\n",
      "7823/67600 (epoch 5), train_loss = 1.208, time/batch=0.077\n",
      "7824/67600 (epoch 5), train_loss = 1.261, time/batch=0.174\n",
      "7825/67600 (epoch 5), train_loss = 1.253, time/batch=0.070\n",
      "7826/67600 (epoch 5), train_loss = 1.248, time/batch=0.101\n",
      "7827/67600 (epoch 5), train_loss = 1.285, time/batch=0.079\n",
      "7828/67600 (epoch 5), train_loss = 1.230, time/batch=0.070\n",
      "7829/67600 (epoch 5), train_loss = 1.278, time/batch=0.075\n",
      "7830/67600 (epoch 5), train_loss = 1.297, time/batch=0.074\n",
      "7831/67600 (epoch 5), train_loss = 1.311, time/batch=0.064\n",
      "7832/67600 (epoch 5), train_loss = 1.258, time/batch=0.064\n",
      "7833/67600 (epoch 5), train_loss = 1.239, time/batch=0.066\n",
      "7834/67600 (epoch 5), train_loss = 1.224, time/batch=0.066\n",
      "7835/67600 (epoch 5), train_loss = 1.249, time/batch=0.068\n",
      "7836/67600 (epoch 5), train_loss = 1.301, time/batch=0.100\n",
      "7837/67600 (epoch 5), train_loss = 1.285, time/batch=0.152\n",
      "7838/67600 (epoch 5), train_loss = 1.295, time/batch=0.094\n",
      "7839/67600 (epoch 5), train_loss = 1.295, time/batch=0.074\n",
      "7840/67600 (epoch 5), train_loss = 1.310, time/batch=0.076\n",
      "7841/67600 (epoch 5), train_loss = 1.230, time/batch=0.067\n",
      "7842/67600 (epoch 5), train_loss = 1.295, time/batch=0.066\n",
      "7843/67600 (epoch 5), train_loss = 1.222, time/batch=0.074\n",
      "7844/67600 (epoch 5), train_loss = 1.214, time/batch=0.069\n",
      "7845/67600 (epoch 5), train_loss = 1.335, time/batch=0.072\n",
      "7846/67600 (epoch 5), train_loss = 1.294, time/batch=0.068\n",
      "7847/67600 (epoch 5), train_loss = 1.204, time/batch=0.067\n",
      "7848/67600 (epoch 5), train_loss = 1.237, time/batch=0.065\n",
      "7849/67600 (epoch 5), train_loss = 1.226, time/batch=0.222\n",
      "7850/67600 (epoch 5), train_loss = 1.282, time/batch=0.077\n",
      "7851/67600 (epoch 5), train_loss = 1.244, time/batch=0.066\n",
      "7852/67600 (epoch 5), train_loss = 1.303, time/batch=0.086\n",
      "7853/67600 (epoch 5), train_loss = 1.248, time/batch=0.068\n",
      "7854/67600 (epoch 5), train_loss = 1.249, time/batch=0.066\n",
      "7855/67600 (epoch 5), train_loss = 1.229, time/batch=0.069\n",
      "7856/67600 (epoch 5), train_loss = 1.256, time/batch=0.070\n",
      "7857/67600 (epoch 5), train_loss = 1.254, time/batch=0.064\n",
      "7858/67600 (epoch 5), train_loss = 1.219, time/batch=0.071\n",
      "7859/67600 (epoch 5), train_loss = 1.183, time/batch=0.081\n",
      "7860/67600 (epoch 5), train_loss = 1.254, time/batch=0.073\n",
      "7861/67600 (epoch 5), train_loss = 1.246, time/batch=0.218\n",
      "7862/67600 (epoch 5), train_loss = 1.237, time/batch=0.072\n",
      "7863/67600 (epoch 5), train_loss = 1.213, time/batch=0.072\n",
      "7864/67600 (epoch 5), train_loss = 1.338, time/batch=0.081\n",
      "7865/67600 (epoch 5), train_loss = 1.233, time/batch=0.066\n",
      "7866/67600 (epoch 5), train_loss = 1.240, time/batch=0.074\n",
      "7867/67600 (epoch 5), train_loss = 1.284, time/batch=0.077\n",
      "7868/67600 (epoch 5), train_loss = 1.240, time/batch=0.069\n",
      "7869/67600 (epoch 5), train_loss = 1.263, time/batch=0.126\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7870/67600 (epoch 5), train_loss = 1.276, time/batch=0.067\n",
      "7871/67600 (epoch 5), train_loss = 1.256, time/batch=0.065\n",
      "7872/67600 (epoch 5), train_loss = 1.296, time/batch=0.065\n",
      "7873/67600 (epoch 5), train_loss = 1.306, time/batch=0.065\n",
      "7874/67600 (epoch 5), train_loss = 1.287, time/batch=0.074\n",
      "7875/67600 (epoch 5), train_loss = 1.348, time/batch=0.073\n",
      "7876/67600 (epoch 5), train_loss = 1.251, time/batch=0.068\n",
      "7877/67600 (epoch 5), train_loss = 1.285, time/batch=0.068\n",
      "7878/67600 (epoch 5), train_loss = 1.255, time/batch=0.068\n",
      "7879/67600 (epoch 5), train_loss = 1.357, time/batch=0.147\n",
      "7880/67600 (epoch 5), train_loss = 1.254, time/batch=0.146\n",
      "7881/67600 (epoch 5), train_loss = 1.290, time/batch=0.089\n",
      "7882/67600 (epoch 5), train_loss = 1.361, time/batch=0.069\n",
      "7883/67600 (epoch 5), train_loss = 1.271, time/batch=0.065\n",
      "7884/67600 (epoch 5), train_loss = 1.257, time/batch=0.067\n",
      "7885/67600 (epoch 5), train_loss = 1.259, time/batch=0.076\n",
      "7886/67600 (epoch 5), train_loss = 1.316, time/batch=0.068\n",
      "7887/67600 (epoch 5), train_loss = 1.257, time/batch=0.069\n",
      "7888/67600 (epoch 5), train_loss = 1.287, time/batch=0.065\n",
      "7889/67600 (epoch 5), train_loss = 1.277, time/batch=0.066\n",
      "7890/67600 (epoch 5), train_loss = 1.272, time/batch=0.065\n",
      "7891/67600 (epoch 5), train_loss = 1.300, time/batch=0.069\n",
      "7892/67600 (epoch 5), train_loss = 1.242, time/batch=0.199\n",
      "7893/67600 (epoch 5), train_loss = 1.305, time/batch=0.073\n",
      "7894/67600 (epoch 5), train_loss = 1.333, time/batch=0.075\n",
      "7895/67600 (epoch 5), train_loss = 1.335, time/batch=0.065\n",
      "7896/67600 (epoch 5), train_loss = 1.296, time/batch=0.067\n",
      "7897/67600 (epoch 5), train_loss = 1.268, time/batch=0.067\n",
      "7898/67600 (epoch 5), train_loss = 1.274, time/batch=0.070\n",
      "7899/67600 (epoch 5), train_loss = 1.310, time/batch=0.071\n",
      "7900/67600 (epoch 5), train_loss = 1.264, time/batch=0.065\n",
      "7901/67600 (epoch 5), train_loss = 1.262, time/batch=0.065\n",
      "7902/67600 (epoch 5), train_loss = 1.300, time/batch=0.065\n",
      "7903/67600 (epoch 5), train_loss = 1.303, time/batch=0.067\n",
      "7904/67600 (epoch 5), train_loss = 1.287, time/batch=0.066\n",
      "7905/67600 (epoch 5), train_loss = 1.233, time/batch=0.202\n",
      "7906/67600 (epoch 5), train_loss = 1.239, time/batch=0.065\n",
      "7907/67600 (epoch 5), train_loss = 1.228, time/batch=0.070\n",
      "7908/67600 (epoch 5), train_loss = 1.225, time/batch=0.064\n",
      "7909/67600 (epoch 5), train_loss = 1.249, time/batch=0.065\n",
      "7910/67600 (epoch 5), train_loss = 1.200, time/batch=0.065\n",
      "7911/67600 (epoch 5), train_loss = 1.298, time/batch=0.064\n",
      "7912/67600 (epoch 5), train_loss = 1.262, time/batch=0.065\n",
      "7913/67600 (epoch 5), train_loss = 1.240, time/batch=0.068\n",
      "7914/67600 (epoch 5), train_loss = 1.269, time/batch=0.119\n",
      "7915/67600 (epoch 5), train_loss = 1.247, time/batch=0.108\n",
      "7916/67600 (epoch 5), train_loss = 1.251, time/batch=0.118\n",
      "7917/67600 (epoch 5), train_loss = 1.198, time/batch=0.065\n",
      "7918/67600 (epoch 5), train_loss = 1.298, time/batch=0.068\n",
      "7919/67600 (epoch 5), train_loss = 1.286, time/batch=0.086\n",
      "7920/67600 (epoch 5), train_loss = 1.212, time/batch=0.080\n",
      "7921/67600 (epoch 5), train_loss = 1.229, time/batch=0.068\n",
      "7922/67600 (epoch 5), train_loss = 1.253, time/batch=0.064\n",
      "7923/67600 (epoch 5), train_loss = 1.213, time/batch=0.065\n",
      "7924/67600 (epoch 5), train_loss = 1.272, time/batch=0.064\n",
      "7925/67600 (epoch 5), train_loss = 1.208, time/batch=0.065\n",
      "7926/67600 (epoch 5), train_loss = 1.232, time/batch=0.107\n",
      "7927/67600 (epoch 5), train_loss = 1.255, time/batch=0.159\n",
      "7928/67600 (epoch 5), train_loss = 1.278, time/batch=0.094\n",
      "7929/67600 (epoch 5), train_loss = 1.190, time/batch=0.072\n",
      "7930/67600 (epoch 5), train_loss = 1.220, time/batch=0.068\n",
      "7931/67600 (epoch 5), train_loss = 1.213, time/batch=0.065\n",
      "7932/67600 (epoch 5), train_loss = 1.246, time/batch=0.066\n",
      "7933/67600 (epoch 5), train_loss = 1.245, time/batch=0.075\n",
      "7934/67600 (epoch 5), train_loss = 1.240, time/batch=0.069\n",
      "7935/67600 (epoch 5), train_loss = 1.250, time/batch=0.066\n",
      "7936/67600 (epoch 5), train_loss = 1.257, time/batch=0.066\n",
      "7937/67600 (epoch 5), train_loss = 1.269, time/batch=0.066\n",
      "7938/67600 (epoch 5), train_loss = 1.291, time/batch=0.066\n",
      "7939/67600 (epoch 5), train_loss = 1.370, time/batch=0.150\n",
      "7940/67600 (epoch 5), train_loss = 1.329, time/batch=0.095\n",
      "7941/67600 (epoch 5), train_loss = 1.278, time/batch=0.099\n",
      "7942/67600 (epoch 5), train_loss = 1.267, time/batch=0.066\n",
      "7943/67600 (epoch 5), train_loss = 1.246, time/batch=0.065\n",
      "7944/67600 (epoch 5), train_loss = 1.276, time/batch=0.065\n",
      "7945/67600 (epoch 5), train_loss = 1.185, time/batch=0.066\n",
      "7946/67600 (epoch 5), train_loss = 1.224, time/batch=0.067\n",
      "7947/67600 (epoch 5), train_loss = 1.314, time/batch=0.064\n",
      "7948/67600 (epoch 5), train_loss = 1.257, time/batch=0.068\n",
      "7949/67600 (epoch 5), train_loss = 1.223, time/batch=0.066\n",
      "7950/67600 (epoch 5), train_loss = 1.256, time/batch=0.066\n",
      "7951/67600 (epoch 5), train_loss = 1.232, time/batch=0.065\n",
      "7952/67600 (epoch 5), train_loss = 1.248, time/batch=0.197\n",
      "7953/67600 (epoch 5), train_loss = 1.251, time/batch=0.078\n",
      "7954/67600 (epoch 5), train_loss = 1.199, time/batch=0.085\n",
      "7955/67600 (epoch 5), train_loss = 1.239, time/batch=0.069\n",
      "7956/67600 (epoch 5), train_loss = 1.278, time/batch=0.072\n",
      "7957/67600 (epoch 5), train_loss = 1.291, time/batch=0.071\n",
      "7958/67600 (epoch 5), train_loss = 1.283, time/batch=0.081\n",
      "7959/67600 (epoch 5), train_loss = 1.244, time/batch=0.065\n",
      "7960/67600 (epoch 5), train_loss = 1.262, time/batch=0.068\n",
      "7961/67600 (epoch 5), train_loss = 1.245, time/batch=0.077\n",
      "7962/67600 (epoch 5), train_loss = 1.230, time/batch=0.065\n",
      "7963/67600 (epoch 5), train_loss = 1.225, time/batch=0.078\n",
      "7964/67600 (epoch 5), train_loss = 1.343, time/batch=0.189\n",
      "7965/67600 (epoch 5), train_loss = 1.248, time/batch=0.068\n",
      "7966/67600 (epoch 5), train_loss = 1.217, time/batch=0.085\n",
      "7967/67600 (epoch 5), train_loss = 1.272, time/batch=0.067\n",
      "7968/67600 (epoch 5), train_loss = 1.226, time/batch=0.065\n",
      "7969/67600 (epoch 5), train_loss = 1.220, time/batch=0.067\n",
      "7970/67600 (epoch 5), train_loss = 1.266, time/batch=0.066\n",
      "7971/67600 (epoch 5), train_loss = 1.232, time/batch=0.077\n",
      "7972/67600 (epoch 5), train_loss = 1.211, time/batch=0.073\n",
      "7973/67600 (epoch 5), train_loss = 1.249, time/batch=0.180\n",
      "7974/67600 (epoch 5), train_loss = 1.289, time/batch=0.070\n",
      "7975/67600 (epoch 5), train_loss = 1.238, time/batch=0.103\n",
      "7976/67600 (epoch 5), train_loss = 1.264, time/batch=0.067\n",
      "7977/67600 (epoch 5), train_loss = 1.249, time/batch=0.077\n",
      "7978/67600 (epoch 5), train_loss = 1.242, time/batch=0.076\n",
      "7979/67600 (epoch 5), train_loss = 1.255, time/batch=0.067\n",
      "7980/67600 (epoch 5), train_loss = 1.240, time/batch=0.066\n",
      "7981/67600 (epoch 5), train_loss = 1.231, time/batch=0.065\n",
      "7982/67600 (epoch 5), train_loss = 1.276, time/batch=0.067\n",
      "7983/67600 (epoch 5), train_loss = 1.238, time/batch=0.066\n",
      "7984/67600 (epoch 5), train_loss = 1.284, time/batch=0.063\n",
      "7985/67600 (epoch 5), train_loss = 1.282, time/batch=0.083\n",
      "7986/67600 (epoch 5), train_loss = 1.288, time/batch=0.149\n",
      "7987/67600 (epoch 5), train_loss = 1.260, time/batch=0.065\n",
      "7988/67600 (epoch 5), train_loss = 1.312, time/batch=0.108\n",
      "7989/67600 (epoch 5), train_loss = 1.227, time/batch=0.079\n",
      "7990/67600 (epoch 5), train_loss = 1.267, time/batch=0.081\n",
      "7991/67600 (epoch 5), train_loss = 1.279, time/batch=0.074\n",
      "7992/67600 (epoch 5), train_loss = 1.351, time/batch=0.073\n",
      "7993/67600 (epoch 5), train_loss = 1.319, time/batch=0.072\n",
      "7994/67600 (epoch 5), train_loss = 1.214, time/batch=0.077\n",
      "7995/67600 (epoch 5), train_loss = 1.257, time/batch=0.075\n",
      "7996/67600 (epoch 5), train_loss = 1.247, time/batch=0.093\n",
      "7997/67600 (epoch 5), train_loss = 1.274, time/batch=0.293\n",
      "7998/67600 (epoch 5), train_loss = 1.238, time/batch=0.088\n",
      "7999/67600 (epoch 5), train_loss = 1.236, time/batch=0.070\n",
      "8000/67600 (epoch 5), train_loss = 1.307, time/batch=0.074\n",
      "model saved to ./save/model.ckpt\n",
      "8001/67600 (epoch 5), train_loss = 1.236, time/batch=0.157\n",
      "8002/67600 (epoch 5), train_loss = 1.251, time/batch=0.202\n",
      "8003/67600 (epoch 5), train_loss = 1.279, time/batch=0.071\n",
      "8004/67600 (epoch 5), train_loss = 1.353, time/batch=0.069\n",
      "8005/67600 (epoch 5), train_loss = 1.268, time/batch=0.099\n",
      "8006/67600 (epoch 5), train_loss = 1.259, time/batch=0.077\n",
      "8007/67600 (epoch 5), train_loss = 1.257, time/batch=0.071\n",
      "8008/67600 (epoch 5), train_loss = 1.283, time/batch=0.122\n",
      "8009/67600 (epoch 5), train_loss = 1.256, time/batch=0.076\n",
      "8010/67600 (epoch 5), train_loss = 1.229, time/batch=0.076\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8011/67600 (epoch 5), train_loss = 1.314, time/batch=0.093\n",
      "8012/67600 (epoch 5), train_loss = 1.217, time/batch=0.080\n",
      "8013/67600 (epoch 5), train_loss = 1.324, time/batch=0.077\n",
      "8014/67600 (epoch 5), train_loss = 1.270, time/batch=0.074\n",
      "8015/67600 (epoch 5), train_loss = 1.302, time/batch=0.083\n",
      "8016/67600 (epoch 5), train_loss = 1.296, time/batch=0.109\n",
      "8017/67600 (epoch 5), train_loss = 1.287, time/batch=0.246\n",
      "8018/67600 (epoch 5), train_loss = 1.321, time/batch=0.118\n",
      "8019/67600 (epoch 5), train_loss = 1.274, time/batch=0.079\n",
      "8020/67600 (epoch 5), train_loss = 1.280, time/batch=0.073\n",
      "8021/67600 (epoch 5), train_loss = 1.235, time/batch=0.076\n",
      "8022/67600 (epoch 5), train_loss = 1.339, time/batch=0.077\n",
      "8023/67600 (epoch 5), train_loss = 1.330, time/batch=0.078\n",
      "8024/67600 (epoch 5), train_loss = 1.318, time/batch=0.075\n",
      "8025/67600 (epoch 5), train_loss = 1.251, time/batch=0.073\n",
      "8026/67600 (epoch 5), train_loss = 1.334, time/batch=0.098\n",
      "8027/67600 (epoch 5), train_loss = 1.238, time/batch=0.255\n",
      "8028/67600 (epoch 5), train_loss = 1.205, time/batch=0.092\n",
      "8029/67600 (epoch 5), train_loss = 1.266, time/batch=0.079\n",
      "8030/67600 (epoch 5), train_loss = 1.252, time/batch=0.082\n",
      "8031/67600 (epoch 5), train_loss = 1.207, time/batch=0.077\n",
      "8032/67600 (epoch 5), train_loss = 1.261, time/batch=0.074\n",
      "8033/67600 (epoch 5), train_loss = 1.261, time/batch=0.078\n",
      "8034/67600 (epoch 5), train_loss = 1.244, time/batch=0.071\n",
      "8035/67600 (epoch 5), train_loss = 1.300, time/batch=0.094\n",
      "8036/67600 (epoch 5), train_loss = 1.287, time/batch=0.079\n",
      "8037/67600 (epoch 5), train_loss = 1.269, time/batch=0.076\n",
      "8038/67600 (epoch 5), train_loss = 1.203, time/batch=0.236\n",
      "8039/67600 (epoch 5), train_loss = 1.204, time/batch=0.085\n",
      "8040/67600 (epoch 5), train_loss = 1.226, time/batch=0.081\n",
      "8041/67600 (epoch 5), train_loss = 1.269, time/batch=0.130\n",
      "8042/67600 (epoch 5), train_loss = 1.214, time/batch=0.082\n",
      "8043/67600 (epoch 5), train_loss = 1.271, time/batch=0.075\n",
      "8044/67600 (epoch 5), train_loss = 1.286, time/batch=0.074\n",
      "8045/67600 (epoch 5), train_loss = 1.256, time/batch=0.230\n",
      "8046/67600 (epoch 5), train_loss = 1.224, time/batch=0.114\n",
      "8047/67600 (epoch 5), train_loss = 1.303, time/batch=0.078\n",
      "8048/67600 (epoch 5), train_loss = 1.239, time/batch=0.081\n",
      "8049/67600 (epoch 5), train_loss = 1.298, time/batch=0.083\n",
      "8050/67600 (epoch 5), train_loss = 1.335, time/batch=0.074\n",
      "8051/67600 (epoch 5), train_loss = 1.294, time/batch=0.099\n",
      "8052/67600 (epoch 5), train_loss = 1.240, time/batch=0.094\n",
      "8053/67600 (epoch 5), train_loss = 1.262, time/batch=0.071\n",
      "8054/67600 (epoch 5), train_loss = 1.266, time/batch=0.078\n",
      "8055/67600 (epoch 5), train_loss = 1.249, time/batch=0.209\n",
      "8056/67600 (epoch 5), train_loss = 1.272, time/batch=0.108\n",
      "8057/67600 (epoch 5), train_loss = 1.274, time/batch=0.075\n",
      "8058/67600 (epoch 5), train_loss = 1.222, time/batch=0.078\n",
      "8059/67600 (epoch 5), train_loss = 1.282, time/batch=0.076\n",
      "8060/67600 (epoch 5), train_loss = 1.316, time/batch=0.075\n",
      "8061/67600 (epoch 5), train_loss = 1.252, time/batch=0.079\n",
      "8062/67600 (epoch 5), train_loss = 1.226, time/batch=0.075\n",
      "8063/67600 (epoch 5), train_loss = 1.253, time/batch=0.076\n",
      "8064/67600 (epoch 5), train_loss = 1.284, time/batch=0.073\n",
      "8065/67600 (epoch 5), train_loss = 1.210, time/batch=0.073\n",
      "8066/67600 (epoch 5), train_loss = 1.282, time/batch=0.243\n",
      "8067/67600 (epoch 5), train_loss = 1.265, time/batch=0.107\n",
      "8068/67600 (epoch 5), train_loss = 1.274, time/batch=0.077\n",
      "8069/67600 (epoch 5), train_loss = 1.268, time/batch=0.073\n",
      "8070/67600 (epoch 5), train_loss = 1.237, time/batch=0.072\n",
      "8071/67600 (epoch 5), train_loss = 1.256, time/batch=0.074\n",
      "8072/67600 (epoch 5), train_loss = 1.259, time/batch=0.071\n",
      "8073/67600 (epoch 5), train_loss = 1.320, time/batch=0.081\n",
      "8074/67600 (epoch 5), train_loss = 1.332, time/batch=0.070\n",
      "8075/67600 (epoch 5), train_loss = 1.268, time/batch=0.071\n",
      "8076/67600 (epoch 5), train_loss = 1.282, time/batch=0.074\n",
      "8077/67600 (epoch 5), train_loss = 1.308, time/batch=0.190\n",
      "8078/67600 (epoch 5), train_loss = 1.278, time/batch=0.102\n",
      "8079/67600 (epoch 5), train_loss = 1.242, time/batch=0.070\n",
      "8080/67600 (epoch 5), train_loss = 1.266, time/batch=0.075\n",
      "8081/67600 (epoch 5), train_loss = 1.252, time/batch=0.077\n",
      "8082/67600 (epoch 5), train_loss = 1.229, time/batch=0.086\n",
      "8083/67600 (epoch 5), train_loss = 1.264, time/batch=0.078\n",
      "8084/67600 (epoch 5), train_loss = 1.309, time/batch=0.074\n",
      "8085/67600 (epoch 5), train_loss = 1.260, time/batch=0.074\n",
      "8086/67600 (epoch 5), train_loss = 1.273, time/batch=0.073\n",
      "8087/67600 (epoch 5), train_loss = 1.257, time/batch=0.074\n",
      "8088/67600 (epoch 5), train_loss = 1.260, time/batch=0.224\n",
      "8089/67600 (epoch 5), train_loss = 1.291, time/batch=0.081\n",
      "8090/67600 (epoch 5), train_loss = 1.317, time/batch=0.075\n",
      "8091/67600 (epoch 5), train_loss = 1.318, time/batch=0.086\n",
      "8092/67600 (epoch 5), train_loss = 1.264, time/batch=0.103\n",
      "8093/67600 (epoch 5), train_loss = 1.257, time/batch=0.075\n",
      "8094/67600 (epoch 5), train_loss = 1.219, time/batch=0.079\n",
      "8095/67600 (epoch 5), train_loss = 1.286, time/batch=0.184\n",
      "8096/67600 (epoch 5), train_loss = 1.296, time/batch=0.072\n",
      "8097/67600 (epoch 5), train_loss = 1.262, time/batch=0.113\n",
      "8098/67600 (epoch 5), train_loss = 1.294, time/batch=0.078\n",
      "8099/67600 (epoch 5), train_loss = 1.257, time/batch=0.074\n",
      "8100/67600 (epoch 5), train_loss = 1.237, time/batch=0.085\n",
      "8101/67600 (epoch 5), train_loss = 1.270, time/batch=0.075\n",
      "8102/67600 (epoch 5), train_loss = 1.291, time/batch=0.082\n",
      "8103/67600 (epoch 5), train_loss = 1.255, time/batch=0.078\n",
      "8104/67600 (epoch 5), train_loss = 1.225, time/batch=0.078\n",
      "8105/67600 (epoch 5), train_loss = 1.269, time/batch=0.078\n",
      "8106/67600 (epoch 5), train_loss = 1.233, time/batch=0.191\n",
      "8107/67600 (epoch 5), train_loss = 1.268, time/batch=0.081\n",
      "8108/67600 (epoch 5), train_loss = 1.320, time/batch=0.114\n",
      "8109/67600 (epoch 5), train_loss = 1.366, time/batch=0.072\n",
      "8110/67600 (epoch 5), train_loss = 1.271, time/batch=0.077\n",
      "8111/67600 (epoch 5), train_loss = 1.279, time/batch=0.073\n",
      "8112/67600 (epoch 6), train_loss = 1.447, time/batch=0.071\n",
      "8113/67600 (epoch 6), train_loss = 1.219, time/batch=0.074\n",
      "8114/67600 (epoch 6), train_loss = 1.305, time/batch=0.070\n",
      "8115/67600 (epoch 6), train_loss = 1.246, time/batch=0.069\n",
      "8116/67600 (epoch 6), train_loss = 1.274, time/batch=0.072\n",
      "8117/67600 (epoch 6), train_loss = 1.301, time/batch=0.208\n",
      "8118/67600 (epoch 6), train_loss = 1.253, time/batch=0.073\n",
      "8119/67600 (epoch 6), train_loss = 1.276, time/batch=0.103\n",
      "8120/67600 (epoch 6), train_loss = 1.291, time/batch=0.069\n",
      "8121/67600 (epoch 6), train_loss = 1.255, time/batch=0.091\n",
      "8122/67600 (epoch 6), train_loss = 1.227, time/batch=0.065\n",
      "8123/67600 (epoch 6), train_loss = 1.242, time/batch=0.068\n",
      "8124/67600 (epoch 6), train_loss = 1.244, time/batch=0.068\n",
      "8125/67600 (epoch 6), train_loss = 1.314, time/batch=0.067\n",
      "8126/67600 (epoch 6), train_loss = 1.278, time/batch=0.066\n",
      "8127/67600 (epoch 6), train_loss = 1.251, time/batch=0.079\n",
      "8128/67600 (epoch 6), train_loss = 1.268, time/batch=0.076\n",
      "8129/67600 (epoch 6), train_loss = 1.284, time/batch=0.223\n",
      "8130/67600 (epoch 6), train_loss = 1.264, time/batch=0.095\n",
      "8131/67600 (epoch 6), train_loss = 1.262, time/batch=0.094\n",
      "8132/67600 (epoch 6), train_loss = 1.258, time/batch=0.082\n",
      "8133/67600 (epoch 6), train_loss = 1.208, time/batch=0.075\n",
      "8134/67600 (epoch 6), train_loss = 1.316, time/batch=0.080\n",
      "8135/67600 (epoch 6), train_loss = 1.304, time/batch=0.079\n",
      "8136/67600 (epoch 6), train_loss = 1.348, time/batch=0.191\n",
      "8137/67600 (epoch 6), train_loss = 1.194, time/batch=0.075\n",
      "8138/67600 (epoch 6), train_loss = 1.272, time/batch=0.101\n",
      "8139/67600 (epoch 6), train_loss = 1.313, time/batch=0.072\n",
      "8140/67600 (epoch 6), train_loss = 1.330, time/batch=0.075\n",
      "8141/67600 (epoch 6), train_loss = 1.267, time/batch=0.106\n",
      "8142/67600 (epoch 6), train_loss = 1.253, time/batch=0.074\n",
      "8143/67600 (epoch 6), train_loss = 1.329, time/batch=0.089\n",
      "8144/67600 (epoch 6), train_loss = 1.262, time/batch=0.110\n",
      "8145/67600 (epoch 6), train_loss = 1.311, time/batch=0.109\n",
      "8146/67600 (epoch 6), train_loss = 1.286, time/batch=0.089\n",
      "8147/67600 (epoch 6), train_loss = 1.275, time/batch=0.069\n",
      "8148/67600 (epoch 6), train_loss = 1.227, time/batch=0.075\n",
      "8149/67600 (epoch 6), train_loss = 1.283, time/batch=0.197\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8150/67600 (epoch 6), train_loss = 1.273, time/batch=0.180\n",
      "8151/67600 (epoch 6), train_loss = 1.269, time/batch=0.084\n",
      "8152/67600 (epoch 6), train_loss = 1.193, time/batch=0.069\n",
      "8153/67600 (epoch 6), train_loss = 1.299, time/batch=0.074\n",
      "8154/67600 (epoch 6), train_loss = 1.311, time/batch=0.074\n",
      "8155/67600 (epoch 6), train_loss = 1.294, time/batch=0.072\n",
      "8156/67600 (epoch 6), train_loss = 1.308, time/batch=0.143\n",
      "8157/67600 (epoch 6), train_loss = 1.258, time/batch=0.101\n",
      "8158/67600 (epoch 6), train_loss = 1.236, time/batch=0.074\n",
      "8159/67600 (epoch 6), train_loss = 1.276, time/batch=0.069\n",
      "8160/67600 (epoch 6), train_loss = 1.238, time/batch=0.071\n",
      "8161/67600 (epoch 6), train_loss = 1.240, time/batch=0.072\n",
      "8162/67600 (epoch 6), train_loss = 1.330, time/batch=0.067\n",
      "8163/67600 (epoch 6), train_loss = 1.246, time/batch=0.067\n",
      "8164/67600 (epoch 6), train_loss = 1.253, time/batch=0.071\n",
      "8165/67600 (epoch 6), train_loss = 1.351, time/batch=0.086\n",
      "8166/67600 (epoch 6), train_loss = 1.311, time/batch=0.250\n",
      "8167/67600 (epoch 6), train_loss = 1.275, time/batch=0.089\n",
      "8168/67600 (epoch 6), train_loss = 1.273, time/batch=0.072\n",
      "8169/67600 (epoch 6), train_loss = 1.272, time/batch=0.071\n",
      "8170/67600 (epoch 6), train_loss = 1.275, time/batch=0.074\n",
      "8171/67600 (epoch 6), train_loss = 1.284, time/batch=0.090\n",
      "8172/67600 (epoch 6), train_loss = 1.274, time/batch=0.075\n",
      "8173/67600 (epoch 6), train_loss = 1.260, time/batch=0.075\n",
      "8174/67600 (epoch 6), train_loss = 1.302, time/batch=0.070\n",
      "8175/67600 (epoch 6), train_loss = 1.316, time/batch=0.073\n",
      "8176/67600 (epoch 6), train_loss = 1.264, time/batch=0.070\n",
      "8177/67600 (epoch 6), train_loss = 1.252, time/batch=0.230\n",
      "8178/67600 (epoch 6), train_loss = 1.256, time/batch=0.083\n",
      "8179/67600 (epoch 6), train_loss = 1.283, time/batch=0.077\n",
      "8180/67600 (epoch 6), train_loss = 1.300, time/batch=0.073\n",
      "8181/67600 (epoch 6), train_loss = 1.293, time/batch=0.083\n",
      "8182/67600 (epoch 6), train_loss = 1.288, time/batch=0.108\n",
      "8183/67600 (epoch 6), train_loss = 1.290, time/batch=0.086\n",
      "8184/67600 (epoch 6), train_loss = 1.253, time/batch=0.078\n",
      "8185/67600 (epoch 6), train_loss = 1.321, time/batch=0.091\n",
      "8186/67600 (epoch 6), train_loss = 1.263, time/batch=0.074\n",
      "8187/67600 (epoch 6), train_loss = 1.313, time/batch=0.195\n",
      "8188/67600 (epoch 6), train_loss = 1.313, time/batch=0.126\n",
      "8189/67600 (epoch 6), train_loss = 1.401, time/batch=0.101\n",
      "8190/67600 (epoch 6), train_loss = 1.317, time/batch=0.072\n",
      "8191/67600 (epoch 6), train_loss = 1.250, time/batch=0.075\n",
      "8192/67600 (epoch 6), train_loss = 1.230, time/batch=0.069\n",
      "8193/67600 (epoch 6), train_loss = 1.275, time/batch=0.069\n",
      "8194/67600 (epoch 6), train_loss = 1.285, time/batch=0.074\n",
      "8195/67600 (epoch 6), train_loss = 1.270, time/batch=0.187\n",
      "8196/67600 (epoch 6), train_loss = 1.270, time/batch=0.074\n",
      "8197/67600 (epoch 6), train_loss = 1.259, time/batch=0.110\n",
      "8198/67600 (epoch 6), train_loss = 1.206, time/batch=0.076\n",
      "8199/67600 (epoch 6), train_loss = 1.322, time/batch=0.076\n",
      "8200/67600 (epoch 6), train_loss = 1.300, time/batch=0.080\n",
      "8201/67600 (epoch 6), train_loss = 1.299, time/batch=0.071\n",
      "8202/67600 (epoch 6), train_loss = 1.283, time/batch=0.075\n",
      "8203/67600 (epoch 6), train_loss = 1.286, time/batch=0.073\n",
      "8204/67600 (epoch 6), train_loss = 1.222, time/batch=0.073\n",
      "8205/67600 (epoch 6), train_loss = 1.237, time/batch=0.077\n",
      "8206/67600 (epoch 6), train_loss = 1.237, time/batch=0.214\n",
      "8207/67600 (epoch 6), train_loss = 1.177, time/batch=0.072\n",
      "8208/67600 (epoch 6), train_loss = 1.196, time/batch=0.109\n",
      "8209/67600 (epoch 6), train_loss = 1.276, time/batch=0.086\n",
      "8210/67600 (epoch 6), train_loss = 1.257, time/batch=0.082\n",
      "8211/67600 (epoch 6), train_loss = 1.315, time/batch=0.081\n",
      "8212/67600 (epoch 6), train_loss = 1.171, time/batch=0.081\n",
      "8213/67600 (epoch 6), train_loss = 1.250, time/batch=0.063\n",
      "8214/67600 (epoch 6), train_loss = 1.289, time/batch=0.066\n",
      "8215/67600 (epoch 6), train_loss = 1.201, time/batch=0.064\n",
      "8216/67600 (epoch 6), train_loss = 1.235, time/batch=0.073\n",
      "8217/67600 (epoch 6), train_loss = 1.285, time/batch=0.225\n",
      "8218/67600 (epoch 6), train_loss = 1.240, time/batch=0.081\n",
      "8219/67600 (epoch 6), train_loss = 1.275, time/batch=0.122\n",
      "8220/67600 (epoch 6), train_loss = 1.309, time/batch=0.091\n",
      "8221/67600 (epoch 6), train_loss = 1.271, time/batch=0.086\n",
      "8222/67600 (epoch 6), train_loss = 1.225, time/batch=0.093\n",
      "8223/67600 (epoch 6), train_loss = 1.271, time/batch=0.146\n",
      "8224/67600 (epoch 6), train_loss = 1.254, time/batch=0.091\n",
      "8225/67600 (epoch 6), train_loss = 1.293, time/batch=0.091\n",
      "8226/67600 (epoch 6), train_loss = 1.289, time/batch=0.229\n",
      "8227/67600 (epoch 6), train_loss = 1.234, time/batch=0.117\n",
      "8228/67600 (epoch 6), train_loss = 1.218, time/batch=0.094\n",
      "8229/67600 (epoch 6), train_loss = 1.257, time/batch=0.082\n",
      "8230/67600 (epoch 6), train_loss = 1.283, time/batch=0.088\n",
      "8231/67600 (epoch 6), train_loss = 1.286, time/batch=0.089\n",
      "8232/67600 (epoch 6), train_loss = 1.276, time/batch=0.087\n",
      "8233/67600 (epoch 6), train_loss = 1.285, time/batch=0.100\n",
      "8234/67600 (epoch 6), train_loss = 1.259, time/batch=0.117\n",
      "8235/67600 (epoch 6), train_loss = 1.241, time/batch=0.241\n",
      "8236/67600 (epoch 6), train_loss = 1.249, time/batch=0.124\n",
      "8237/67600 (epoch 6), train_loss = 1.179, time/batch=0.112\n",
      "8238/67600 (epoch 6), train_loss = 1.262, time/batch=0.087\n",
      "8239/67600 (epoch 6), train_loss = 1.298, time/batch=0.092\n",
      "8240/67600 (epoch 6), train_loss = 1.235, time/batch=0.088\n",
      "8241/67600 (epoch 6), train_loss = 1.255, time/batch=0.191\n",
      "8242/67600 (epoch 6), train_loss = 1.281, time/batch=0.091\n",
      "8243/67600 (epoch 6), train_loss = 1.257, time/batch=0.120\n",
      "8244/67600 (epoch 6), train_loss = 1.309, time/batch=0.088\n",
      "8245/67600 (epoch 6), train_loss = 1.252, time/batch=0.090\n",
      "8246/67600 (epoch 6), train_loss = 1.275, time/batch=0.085\n",
      "8247/67600 (epoch 6), train_loss = 1.272, time/batch=0.087\n",
      "8248/67600 (epoch 6), train_loss = 1.289, time/batch=0.086\n",
      "8249/67600 (epoch 6), train_loss = 1.269, time/batch=0.089\n",
      "8250/67600 (epoch 6), train_loss = 1.269, time/batch=0.088\n",
      "8251/67600 (epoch 6), train_loss = 1.243, time/batch=0.273\n",
      "8252/67600 (epoch 6), train_loss = 1.236, time/batch=0.107\n",
      "8253/67600 (epoch 6), train_loss = 1.214, time/batch=0.101\n",
      "8254/67600 (epoch 6), train_loss = 1.282, time/batch=0.099\n",
      "8255/67600 (epoch 6), train_loss = 1.223, time/batch=0.072\n",
      "8256/67600 (epoch 6), train_loss = 1.304, time/batch=0.076\n",
      "8257/67600 (epoch 6), train_loss = 1.353, time/batch=0.065\n",
      "8258/67600 (epoch 6), train_loss = 1.268, time/batch=0.066\n",
      "8259/67600 (epoch 6), train_loss = 1.259, time/batch=0.070\n",
      "8260/67600 (epoch 6), train_loss = 1.309, time/batch=0.066\n",
      "8261/67600 (epoch 6), train_loss = 1.191, time/batch=0.185\n",
      "8262/67600 (epoch 6), train_loss = 1.278, time/batch=0.080\n",
      "8263/67600 (epoch 6), train_loss = 1.239, time/batch=0.109\n",
      "8264/67600 (epoch 6), train_loss = 1.216, time/batch=0.080\n",
      "8265/67600 (epoch 6), train_loss = 1.253, time/batch=0.078\n",
      "8266/67600 (epoch 6), train_loss = 1.235, time/batch=0.078\n",
      "8267/67600 (epoch 6), train_loss = 1.283, time/batch=0.086\n",
      "8268/67600 (epoch 6), train_loss = 1.295, time/batch=0.081\n",
      "8269/67600 (epoch 6), train_loss = 1.291, time/batch=0.096\n",
      "8270/67600 (epoch 6), train_loss = 1.274, time/batch=0.086\n",
      "8271/67600 (epoch 6), train_loss = 1.250, time/batch=0.108\n",
      "8272/67600 (epoch 6), train_loss = 1.245, time/batch=0.178\n",
      "8273/67600 (epoch 6), train_loss = 1.210, time/batch=0.101\n",
      "8274/67600 (epoch 6), train_loss = 1.265, time/batch=0.102\n",
      "8275/67600 (epoch 6), train_loss = 1.271, time/batch=0.068\n",
      "8276/67600 (epoch 6), train_loss = 1.165, time/batch=0.078\n",
      "8277/67600 (epoch 6), train_loss = 1.256, time/batch=0.075\n",
      "8278/67600 (epoch 6), train_loss = 1.254, time/batch=0.072\n",
      "8279/67600 (epoch 6), train_loss = 1.230, time/batch=0.069\n",
      "8280/67600 (epoch 6), train_loss = 1.277, time/batch=0.072\n",
      "8281/67600 (epoch 6), train_loss = 1.296, time/batch=0.084\n",
      "8282/67600 (epoch 6), train_loss = 1.283, time/batch=0.232\n",
      "8283/67600 (epoch 6), train_loss = 1.216, time/batch=0.080\n",
      "8284/67600 (epoch 6), train_loss = 1.286, time/batch=0.077\n",
      "8285/67600 (epoch 6), train_loss = 1.239, time/batch=0.108\n",
      "8286/67600 (epoch 6), train_loss = 1.228, time/batch=0.075\n",
      "8287/67600 (epoch 6), train_loss = 1.223, time/batch=0.077\n",
      "8288/67600 (epoch 6), train_loss = 1.276, time/batch=0.069\n",
      "8289/67600 (epoch 6), train_loss = 1.307, time/batch=0.065\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8290/67600 (epoch 6), train_loss = 1.227, time/batch=0.206\n",
      "8291/67600 (epoch 6), train_loss = 1.237, time/batch=0.074\n",
      "8292/67600 (epoch 6), train_loss = 1.196, time/batch=0.096\n",
      "8293/67600 (epoch 6), train_loss = 1.199, time/batch=0.069\n",
      "8294/67600 (epoch 6), train_loss = 1.242, time/batch=0.076\n",
      "8295/67600 (epoch 6), train_loss = 1.338, time/batch=0.096\n",
      "8296/67600 (epoch 6), train_loss = 1.359, time/batch=0.073\n",
      "8297/67600 (epoch 6), train_loss = 1.328, time/batch=0.072\n",
      "8298/67600 (epoch 6), train_loss = 1.350, time/batch=0.076\n",
      "8299/67600 (epoch 6), train_loss = 1.266, time/batch=0.081\n",
      "8300/67600 (epoch 6), train_loss = 1.268, time/batch=0.071\n",
      "8301/67600 (epoch 6), train_loss = 1.262, time/batch=0.127\n",
      "8302/67600 (epoch 6), train_loss = 1.336, time/batch=0.072\n",
      "8303/67600 (epoch 6), train_loss = 1.296, time/batch=0.074\n",
      "8304/67600 (epoch 6), train_loss = 1.249, time/batch=0.070\n",
      "8305/67600 (epoch 6), train_loss = 1.287, time/batch=0.071\n",
      "8306/67600 (epoch 6), train_loss = 1.287, time/batch=0.068\n",
      "8307/67600 (epoch 6), train_loss = 1.275, time/batch=0.073\n",
      "8308/67600 (epoch 6), train_loss = 1.258, time/batch=0.072\n",
      "8309/67600 (epoch 6), train_loss = 1.257, time/batch=0.069\n",
      "8310/67600 (epoch 6), train_loss = 1.277, time/batch=0.073\n",
      "8311/67600 (epoch 6), train_loss = 1.234, time/batch=0.247\n",
      "8312/67600 (epoch 6), train_loss = 1.217, time/batch=0.074\n",
      "8313/67600 (epoch 6), train_loss = 1.196, time/batch=0.091\n",
      "8314/67600 (epoch 6), train_loss = 1.314, time/batch=0.077\n",
      "8315/67600 (epoch 6), train_loss = 1.271, time/batch=0.072\n",
      "8316/67600 (epoch 6), train_loss = 1.288, time/batch=0.070\n",
      "8317/67600 (epoch 6), train_loss = 1.199, time/batch=0.073\n",
      "8318/67600 (epoch 6), train_loss = 1.201, time/batch=0.066\n",
      "8319/67600 (epoch 6), train_loss = 1.230, time/batch=0.066\n",
      "8320/67600 (epoch 6), train_loss = 1.281, time/batch=0.066\n",
      "8321/67600 (epoch 6), train_loss = 1.317, time/batch=0.067\n",
      "8322/67600 (epoch 6), train_loss = 1.280, time/batch=0.065\n",
      "8323/67600 (epoch 6), train_loss = 1.341, time/batch=0.215\n",
      "8324/67600 (epoch 6), train_loss = 1.234, time/batch=0.089\n",
      "8325/67600 (epoch 6), train_loss = 1.250, time/batch=0.085\n",
      "8326/67600 (epoch 6), train_loss = 1.259, time/batch=0.074\n",
      "8327/67600 (epoch 6), train_loss = 1.303, time/batch=0.073\n",
      "8328/67600 (epoch 6), train_loss = 1.241, time/batch=0.074\n",
      "8329/67600 (epoch 6), train_loss = 1.259, time/batch=0.072\n",
      "8330/67600 (epoch 6), train_loss = 1.230, time/batch=0.068\n",
      "8331/67600 (epoch 6), train_loss = 1.222, time/batch=0.076\n",
      "8332/67600 (epoch 6), train_loss = 1.317, time/batch=0.076\n",
      "8333/67600 (epoch 6), train_loss = 1.229, time/batch=0.070\n",
      "8334/67600 (epoch 6), train_loss = 1.268, time/batch=0.071\n",
      "8335/67600 (epoch 6), train_loss = 1.261, time/batch=0.215\n",
      "8336/67600 (epoch 6), train_loss = 1.261, time/batch=0.079\n",
      "8337/67600 (epoch 6), train_loss = 1.240, time/batch=0.071\n",
      "8338/67600 (epoch 6), train_loss = 1.301, time/batch=0.090\n",
      "8339/67600 (epoch 6), train_loss = 1.217, time/batch=0.091\n",
      "8340/67600 (epoch 6), train_loss = 1.235, time/batch=0.085\n",
      "8341/67600 (epoch 6), train_loss = 1.231, time/batch=0.071\n",
      "8342/67600 (epoch 6), train_loss = 1.265, time/batch=0.112\n",
      "8343/67600 (epoch 6), train_loss = 1.264, time/batch=0.139\n",
      "8344/67600 (epoch 6), train_loss = 1.199, time/batch=0.124\n",
      "8345/67600 (epoch 6), train_loss = 1.200, time/batch=0.102\n",
      "8346/67600 (epoch 6), train_loss = 1.267, time/batch=0.088\n",
      "8347/67600 (epoch 6), train_loss = 1.251, time/batch=0.083\n",
      "8348/67600 (epoch 6), train_loss = 1.245, time/batch=0.071\n",
      "8349/67600 (epoch 6), train_loss = 1.243, time/batch=0.072\n",
      "8350/67600 (epoch 6), train_loss = 1.303, time/batch=0.072\n",
      "8351/67600 (epoch 6), train_loss = 1.272, time/batch=0.074\n",
      "8352/67600 (epoch 6), train_loss = 1.270, time/batch=0.067\n",
      "8353/67600 (epoch 6), train_loss = 1.212, time/batch=0.082\n",
      "8354/67600 (epoch 6), train_loss = 1.256, time/batch=0.146\n",
      "8355/67600 (epoch 6), train_loss = 1.271, time/batch=0.065\n",
      "8356/67600 (epoch 6), train_loss = 1.213, time/batch=0.104\n",
      "8357/67600 (epoch 6), train_loss = 1.270, time/batch=0.067\n",
      "8358/67600 (epoch 6), train_loss = 1.249, time/batch=0.081\n",
      "8359/67600 (epoch 6), train_loss = 1.260, time/batch=0.081\n",
      "8360/67600 (epoch 6), train_loss = 1.283, time/batch=0.080\n",
      "8361/67600 (epoch 6), train_loss = 1.225, time/batch=0.084\n",
      "8362/67600 (epoch 6), train_loss = 1.224, time/batch=0.096\n",
      "8363/67600 (epoch 6), train_loss = 1.307, time/batch=0.075\n",
      "8364/67600 (epoch 6), train_loss = 1.229, time/batch=0.082\n",
      "8365/67600 (epoch 6), train_loss = 1.267, time/batch=0.192\n",
      "8366/67600 (epoch 6), train_loss = 1.276, time/batch=0.068\n",
      "8367/67600 (epoch 6), train_loss = 1.321, time/batch=0.113\n",
      "8368/67600 (epoch 6), train_loss = 1.301, time/batch=0.069\n",
      "8369/67600 (epoch 6), train_loss = 1.306, time/batch=0.070\n",
      "8370/67600 (epoch 6), train_loss = 1.213, time/batch=0.068\n",
      "8371/67600 (epoch 6), train_loss = 1.226, time/batch=0.070\n",
      "8372/67600 (epoch 6), train_loss = 1.244, time/batch=0.075\n",
      "8373/67600 (epoch 6), train_loss = 1.240, time/batch=0.066\n",
      "8374/67600 (epoch 6), train_loss = 1.253, time/batch=0.068\n",
      "8375/67600 (epoch 6), train_loss = 1.273, time/batch=0.067\n",
      "8376/67600 (epoch 6), train_loss = 1.239, time/batch=0.065\n",
      "8377/67600 (epoch 6), train_loss = 1.239, time/batch=0.178\n",
      "8378/67600 (epoch 6), train_loss = 1.222, time/batch=0.069\n",
      "8379/67600 (epoch 6), train_loss = 1.263, time/batch=0.096\n",
      "8380/67600 (epoch 6), train_loss = 1.236, time/batch=0.075\n",
      "8381/67600 (epoch 6), train_loss = 1.229, time/batch=0.065\n",
      "8382/67600 (epoch 6), train_loss = 1.289, time/batch=0.066\n",
      "8383/67600 (epoch 6), train_loss = 1.256, time/batch=0.066\n",
      "8384/67600 (epoch 6), train_loss = 1.268, time/batch=0.081\n",
      "8385/67600 (epoch 6), train_loss = 1.309, time/batch=0.064\n",
      "8386/67600 (epoch 6), train_loss = 1.272, time/batch=0.063\n",
      "8387/67600 (epoch 6), train_loss = 1.259, time/batch=0.065\n",
      "8388/67600 (epoch 6), train_loss = 1.265, time/batch=0.066\n",
      "8389/67600 (epoch 6), train_loss = 1.222, time/batch=0.066\n",
      "8390/67600 (epoch 6), train_loss = 1.220, time/batch=0.212\n",
      "8391/67600 (epoch 6), train_loss = 1.290, time/batch=0.081\n",
      "8392/67600 (epoch 6), train_loss = 1.299, time/batch=0.074\n",
      "8393/67600 (epoch 6), train_loss = 1.241, time/batch=0.069\n",
      "8394/67600 (epoch 6), train_loss = 1.191, time/batch=0.073\n",
      "8395/67600 (epoch 6), train_loss = 1.275, time/batch=0.072\n",
      "8396/67600 (epoch 6), train_loss = 1.225, time/batch=0.071\n",
      "8397/67600 (epoch 6), train_loss = 1.343, time/batch=0.068\n",
      "8398/67600 (epoch 6), train_loss = 1.277, time/batch=0.175\n",
      "8399/67600 (epoch 6), train_loss = 1.258, time/batch=0.071\n",
      "8400/67600 (epoch 6), train_loss = 1.294, time/batch=0.106\n",
      "8401/67600 (epoch 6), train_loss = 1.284, time/batch=0.072\n",
      "8402/67600 (epoch 6), train_loss = 1.280, time/batch=0.072\n",
      "8403/67600 (epoch 6), train_loss = 1.272, time/batch=0.083\n",
      "8404/67600 (epoch 6), train_loss = 1.265, time/batch=0.076\n",
      "8405/67600 (epoch 6), train_loss = 1.265, time/batch=0.074\n",
      "8406/67600 (epoch 6), train_loss = 1.271, time/batch=0.076\n",
      "8407/67600 (epoch 6), train_loss = 1.279, time/batch=0.074\n",
      "8408/67600 (epoch 6), train_loss = 1.275, time/batch=0.071\n",
      "8409/67600 (epoch 6), train_loss = 1.239, time/batch=0.072\n",
      "8410/67600 (epoch 6), train_loss = 1.238, time/batch=0.184\n",
      "8411/67600 (epoch 6), train_loss = 1.298, time/batch=0.074\n",
      "8412/67600 (epoch 6), train_loss = 1.263, time/batch=0.107\n",
      "8413/67600 (epoch 6), train_loss = 1.292, time/batch=0.071\n",
      "8414/67600 (epoch 6), train_loss = 1.254, time/batch=0.070\n",
      "8415/67600 (epoch 6), train_loss = 1.280, time/batch=0.076\n",
      "8416/67600 (epoch 6), train_loss = 1.278, time/batch=0.075\n",
      "8417/67600 (epoch 6), train_loss = 1.287, time/batch=0.072\n",
      "8418/67600 (epoch 6), train_loss = 1.315, time/batch=0.080\n",
      "8419/67600 (epoch 6), train_loss = 1.285, time/batch=0.076\n",
      "8420/67600 (epoch 6), train_loss = 1.304, time/batch=0.072\n",
      "8421/67600 (epoch 6), train_loss = 1.299, time/batch=0.182\n",
      "8422/67600 (epoch 6), train_loss = 1.270, time/batch=0.074\n",
      "8423/67600 (epoch 6), train_loss = 1.219, time/batch=0.101\n",
      "8424/67600 (epoch 6), train_loss = 1.240, time/batch=0.075\n",
      "8425/67600 (epoch 6), train_loss = 1.293, time/batch=0.072\n",
      "8426/67600 (epoch 6), train_loss = 1.256, time/batch=0.071\n",
      "8427/67600 (epoch 6), train_loss = 1.344, time/batch=0.073\n",
      "8428/67600 (epoch 6), train_loss = 1.255, time/batch=0.071\n",
      "8429/67600 (epoch 6), train_loss = 1.282, time/batch=0.068\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8430/67600 (epoch 6), train_loss = 1.290, time/batch=0.071\n",
      "8431/67600 (epoch 6), train_loss = 1.294, time/batch=0.070\n",
      "8432/67600 (epoch 6), train_loss = 1.318, time/batch=0.067\n",
      "8433/67600 (epoch 6), train_loss = 1.264, time/batch=0.103\n",
      "8434/67600 (epoch 6), train_loss = 1.272, time/batch=0.158\n",
      "8435/67600 (epoch 6), train_loss = 1.232, time/batch=0.087\n",
      "8436/67600 (epoch 6), train_loss = 1.257, time/batch=0.065\n",
      "8437/67600 (epoch 6), train_loss = 1.230, time/batch=0.065\n",
      "8438/67600 (epoch 6), train_loss = 1.230, time/batch=0.065\n",
      "8439/67600 (epoch 6), train_loss = 1.289, time/batch=0.076\n",
      "8440/67600 (epoch 6), train_loss = 1.254, time/batch=0.063\n",
      "8441/67600 (epoch 6), train_loss = 1.266, time/batch=0.064\n",
      "8442/67600 (epoch 6), train_loss = 1.297, time/batch=0.065\n",
      "8443/67600 (epoch 6), train_loss = 1.208, time/batch=0.070\n",
      "8444/67600 (epoch 6), train_loss = 1.274, time/batch=0.102\n",
      "8445/67600 (epoch 6), train_loss = 1.259, time/batch=0.078\n",
      "8446/67600 (epoch 6), train_loss = 1.273, time/batch=0.205\n",
      "8447/67600 (epoch 6), train_loss = 1.298, time/batch=0.087\n",
      "8448/67600 (epoch 6), train_loss = 1.247, time/batch=0.105\n",
      "8449/67600 (epoch 6), train_loss = 1.235, time/batch=0.070\n",
      "8450/67600 (epoch 6), train_loss = 1.270, time/batch=0.068\n",
      "8451/67600 (epoch 6), train_loss = 1.301, time/batch=0.066\n",
      "8452/67600 (epoch 6), train_loss = 1.252, time/batch=0.098\n",
      "8453/67600 (epoch 6), train_loss = 1.238, time/batch=0.079\n",
      "8454/67600 (epoch 6), train_loss = 1.228, time/batch=0.065\n",
      "8455/67600 (epoch 6), train_loss = 1.215, time/batch=0.068\n",
      "8456/67600 (epoch 6), train_loss = 1.313, time/batch=0.099\n",
      "8457/67600 (epoch 6), train_loss = 1.334, time/batch=0.211\n",
      "8458/67600 (epoch 6), train_loss = 1.272, time/batch=0.083\n",
      "8459/67600 (epoch 6), train_loss = 1.264, time/batch=0.102\n",
      "8460/67600 (epoch 6), train_loss = 1.309, time/batch=0.067\n",
      "8461/67600 (epoch 6), train_loss = 1.312, time/batch=0.066\n",
      "8462/67600 (epoch 6), train_loss = 1.227, time/batch=0.069\n",
      "8463/67600 (epoch 6), train_loss = 1.218, time/batch=0.066\n",
      "8464/67600 (epoch 6), train_loss = 1.202, time/batch=0.066\n",
      "8465/67600 (epoch 6), train_loss = 1.233, time/batch=0.105\n",
      "8466/67600 (epoch 6), train_loss = 1.236, time/batch=0.081\n",
      "8467/67600 (epoch 6), train_loss = 1.304, time/batch=0.066\n",
      "8468/67600 (epoch 6), train_loss = 1.233, time/batch=0.076\n",
      "8469/67600 (epoch 6), train_loss = 1.252, time/batch=0.064\n",
      "8470/67600 (epoch 6), train_loss = 1.204, time/batch=0.063\n",
      "8471/67600 (epoch 6), train_loss = 1.347, time/batch=0.063\n",
      "8472/67600 (epoch 6), train_loss = 1.258, time/batch=0.062\n",
      "8473/67600 (epoch 6), train_loss = 1.220, time/batch=0.066\n",
      "8474/67600 (epoch 6), train_loss = 1.225, time/batch=0.066\n",
      "8475/67600 (epoch 6), train_loss = 1.312, time/batch=0.084\n",
      "8476/67600 (epoch 6), train_loss = 1.258, time/batch=0.197\n",
      "8477/67600 (epoch 6), train_loss = 1.241, time/batch=0.100\n",
      "8478/67600 (epoch 6), train_loss = 1.253, time/batch=0.082\n",
      "8479/67600 (epoch 6), train_loss = 1.204, time/batch=0.079\n",
      "8480/67600 (epoch 6), train_loss = 1.255, time/batch=0.080\n",
      "8481/67600 (epoch 6), train_loss = 1.326, time/batch=0.074\n",
      "8482/67600 (epoch 6), train_loss = 1.258, time/batch=0.078\n",
      "8483/67600 (epoch 6), train_loss = 1.257, time/batch=0.079\n",
      "8484/67600 (epoch 6), train_loss = 1.289, time/batch=0.079\n",
      "8485/67600 (epoch 6), train_loss = 1.264, time/batch=0.075\n",
      "8486/67600 (epoch 6), train_loss = 1.330, time/batch=0.073\n",
      "8487/67600 (epoch 6), train_loss = 1.331, time/batch=0.251\n",
      "8488/67600 (epoch 6), train_loss = 1.287, time/batch=0.093\n",
      "8489/67600 (epoch 6), train_loss = 1.270, time/batch=0.069\n",
      "8490/67600 (epoch 6), train_loss = 1.331, time/batch=0.072\n",
      "8491/67600 (epoch 6), train_loss = 1.347, time/batch=0.077\n",
      "8492/67600 (epoch 6), train_loss = 1.298, time/batch=0.073\n",
      "8493/67600 (epoch 6), train_loss = 1.264, time/batch=0.078\n",
      "8494/67600 (epoch 6), train_loss = 1.258, time/batch=0.073\n",
      "8495/67600 (epoch 6), train_loss = 1.295, time/batch=0.073\n",
      "8496/67600 (epoch 6), train_loss = 1.348, time/batch=0.071\n",
      "8497/67600 (epoch 6), train_loss = 1.262, time/batch=0.078\n",
      "8498/67600 (epoch 6), train_loss = 1.248, time/batch=0.213\n",
      "8499/67600 (epoch 6), train_loss = 1.253, time/batch=0.076\n",
      "8500/67600 (epoch 6), train_loss = 1.307, time/batch=0.073\n",
      "model saved to ./save/model.ckpt\n",
      "8501/67600 (epoch 6), train_loss = 1.280, time/batch=0.066\n",
      "8502/67600 (epoch 6), train_loss = 1.253, time/batch=0.089\n",
      "8503/67600 (epoch 6), train_loss = 1.250, time/batch=0.147\n",
      "8504/67600 (epoch 6), train_loss = 1.246, time/batch=0.066\n",
      "8505/67600 (epoch 6), train_loss = 1.271, time/batch=0.091\n",
      "8506/67600 (epoch 6), train_loss = 1.253, time/batch=0.067\n",
      "8507/67600 (epoch 6), train_loss = 1.252, time/batch=0.065\n",
      "8508/67600 (epoch 6), train_loss = 1.313, time/batch=0.072\n",
      "8509/67600 (epoch 6), train_loss = 1.313, time/batch=0.066\n",
      "8510/67600 (epoch 6), train_loss = 1.262, time/batch=0.065\n",
      "8511/67600 (epoch 6), train_loss = 1.244, time/batch=0.066\n",
      "8512/67600 (epoch 6), train_loss = 1.299, time/batch=0.099\n",
      "8513/67600 (epoch 6), train_loss = 1.340, time/batch=0.090\n",
      "8514/67600 (epoch 6), train_loss = 1.328, time/batch=0.066\n",
      "8515/67600 (epoch 6), train_loss = 1.282, time/batch=0.186\n",
      "8516/67600 (epoch 6), train_loss = 1.355, time/batch=0.066\n",
      "8517/67600 (epoch 6), train_loss = 1.305, time/batch=0.077\n",
      "8518/67600 (epoch 6), train_loss = 1.322, time/batch=0.066\n",
      "8519/67600 (epoch 6), train_loss = 1.255, time/batch=0.067\n",
      "8520/67600 (epoch 6), train_loss = 1.297, time/batch=0.067\n",
      "8521/67600 (epoch 6), train_loss = 1.297, time/batch=0.064\n",
      "8522/67600 (epoch 6), train_loss = 1.296, time/batch=0.064\n",
      "8523/67600 (epoch 6), train_loss = 1.238, time/batch=0.065\n",
      "8524/67600 (epoch 6), train_loss = 1.260, time/batch=0.080\n",
      "8525/67600 (epoch 6), train_loss = 1.275, time/batch=0.090\n",
      "8526/67600 (epoch 6), train_loss = 1.261, time/batch=0.070\n",
      "8527/67600 (epoch 6), train_loss = 1.314, time/batch=0.117\n",
      "8528/67600 (epoch 6), train_loss = 1.277, time/batch=0.204\n",
      "8529/67600 (epoch 6), train_loss = 1.306, time/batch=0.076\n",
      "8530/67600 (epoch 6), train_loss = 1.313, time/batch=0.072\n",
      "8531/67600 (epoch 6), train_loss = 1.249, time/batch=0.088\n",
      "8532/67600 (epoch 6), train_loss = 1.192, time/batch=0.086\n",
      "8533/67600 (epoch 6), train_loss = 1.209, time/batch=0.072\n",
      "8534/67600 (epoch 6), train_loss = 1.258, time/batch=0.066\n",
      "8535/67600 (epoch 6), train_loss = 1.224, time/batch=0.211\n",
      "8536/67600 (epoch 6), train_loss = 1.264, time/batch=0.087\n",
      "8537/67600 (epoch 6), train_loss = 1.241, time/batch=0.073\n",
      "8538/67600 (epoch 6), train_loss = 1.255, time/batch=0.067\n",
      "8539/67600 (epoch 6), train_loss = 1.256, time/batch=0.068\n",
      "8540/67600 (epoch 6), train_loss = 1.176, time/batch=0.070\n",
      "8541/67600 (epoch 6), train_loss = 1.238, time/batch=0.062\n",
      "8542/67600 (epoch 6), train_loss = 1.304, time/batch=0.078\n",
      "8543/67600 (epoch 6), train_loss = 1.227, time/batch=0.089\n",
      "8544/67600 (epoch 6), train_loss = 1.289, time/batch=0.086\n",
      "8545/67600 (epoch 6), train_loss = 1.284, time/batch=0.067\n",
      "8546/67600 (epoch 6), train_loss = 1.224, time/batch=0.076\n",
      "8547/67600 (epoch 6), train_loss = 1.326, time/batch=0.150\n",
      "8548/67600 (epoch 6), train_loss = 1.258, time/batch=0.067\n",
      "8549/67600 (epoch 6), train_loss = 1.271, time/batch=0.097\n",
      "8550/67600 (epoch 6), train_loss = 1.279, time/batch=0.067\n",
      "8551/67600 (epoch 6), train_loss = 1.251, time/batch=0.074\n",
      "8552/67600 (epoch 6), train_loss = 1.241, time/batch=0.066\n",
      "8553/67600 (epoch 6), train_loss = 1.280, time/batch=0.073\n",
      "8554/67600 (epoch 6), train_loss = 1.245, time/batch=0.079\n",
      "8555/67600 (epoch 6), train_loss = 1.234, time/batch=0.088\n",
      "8556/67600 (epoch 6), train_loss = 1.273, time/batch=0.077\n",
      "8557/67600 (epoch 6), train_loss = 1.303, time/batch=0.065\n",
      "8558/67600 (epoch 6), train_loss = 1.223, time/batch=0.074\n",
      "8559/67600 (epoch 6), train_loss = 1.237, time/batch=0.210\n",
      "8560/67600 (epoch 6), train_loss = 1.208, time/batch=0.093\n",
      "8561/67600 (epoch 6), train_loss = 1.233, time/batch=0.077\n",
      "8562/67600 (epoch 6), train_loss = 1.186, time/batch=0.098\n",
      "8563/67600 (epoch 6), train_loss = 1.300, time/batch=0.078\n",
      "8564/67600 (epoch 6), train_loss = 1.306, time/batch=0.064\n",
      "8565/67600 (epoch 6), train_loss = 1.195, time/batch=0.064\n",
      "8566/67600 (epoch 6), train_loss = 1.184, time/batch=0.063\n",
      "8567/67600 (epoch 6), train_loss = 1.222, time/batch=0.092\n",
      "8568/67600 (epoch 6), train_loss = 1.247, time/batch=0.088\n",
      "8569/67600 (epoch 6), train_loss = 1.262, time/batch=0.067\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8570/67600 (epoch 6), train_loss = 1.285, time/batch=0.196\n",
      "8571/67600 (epoch 6), train_loss = 1.257, time/batch=0.115\n",
      "8572/67600 (epoch 6), train_loss = 1.273, time/batch=0.071\n",
      "8573/67600 (epoch 6), train_loss = 1.226, time/batch=0.069\n",
      "8574/67600 (epoch 6), train_loss = 1.288, time/batch=0.068\n",
      "8575/67600 (epoch 6), train_loss = 1.256, time/batch=0.064\n",
      "8576/67600 (epoch 6), train_loss = 1.224, time/batch=0.062\n",
      "8577/67600 (epoch 6), train_loss = 1.245, time/batch=0.064\n",
      "8578/67600 (epoch 6), train_loss = 1.240, time/batch=0.065\n",
      "8579/67600 (epoch 6), train_loss = 1.308, time/batch=0.063\n",
      "8580/67600 (epoch 6), train_loss = 1.260, time/batch=0.063\n",
      "8581/67600 (epoch 6), train_loss = 1.228, time/batch=0.067\n",
      "8582/67600 (epoch 6), train_loss = 1.248, time/batch=0.092\n",
      "8583/67600 (epoch 6), train_loss = 1.254, time/batch=0.163\n",
      "8584/67600 (epoch 6), train_loss = 1.218, time/batch=0.077\n",
      "8585/67600 (epoch 6), train_loss = 1.265, time/batch=0.066\n",
      "8586/67600 (epoch 6), train_loss = 1.229, time/batch=0.067\n",
      "8587/67600 (epoch 6), train_loss = 1.196, time/batch=0.065\n",
      "8588/67600 (epoch 6), train_loss = 1.284, time/batch=0.075\n",
      "8589/67600 (epoch 6), train_loss = 1.216, time/batch=0.067\n",
      "8590/67600 (epoch 6), train_loss = 1.239, time/batch=0.066\n",
      "8591/67600 (epoch 6), train_loss = 1.268, time/batch=0.082\n",
      "8592/67600 (epoch 6), train_loss = 1.213, time/batch=0.067\n",
      "8593/67600 (epoch 6), train_loss = 1.254, time/batch=0.065\n",
      "8594/67600 (epoch 6), train_loss = 1.238, time/batch=0.064\n",
      "8595/67600 (epoch 6), train_loss = 1.213, time/batch=0.174\n",
      "8596/67600 (epoch 6), train_loss = 1.271, time/batch=0.087\n",
      "8597/67600 (epoch 6), train_loss = 1.276, time/batch=0.071\n",
      "8598/67600 (epoch 6), train_loss = 1.300, time/batch=0.067\n",
      "8599/67600 (epoch 6), train_loss = 1.266, time/batch=0.065\n",
      "8600/67600 (epoch 6), train_loss = 1.325, time/batch=0.066\n",
      "8601/67600 (epoch 6), train_loss = 1.292, time/batch=0.066\n",
      "8602/67600 (epoch 6), train_loss = 1.221, time/batch=0.065\n",
      "8603/67600 (epoch 6), train_loss = 1.260, time/batch=0.065\n",
      "8604/67600 (epoch 6), train_loss = 1.273, time/batch=0.071\n",
      "8605/67600 (epoch 6), train_loss = 1.230, time/batch=0.095\n",
      "8606/67600 (epoch 6), train_loss = 1.308, time/batch=0.069\n",
      "8607/67600 (epoch 6), train_loss = 1.277, time/batch=0.066\n",
      "8608/67600 (epoch 6), train_loss = 1.241, time/batch=0.066\n",
      "8609/67600 (epoch 6), train_loss = 1.267, time/batch=0.064\n",
      "8610/67600 (epoch 6), train_loss = 1.320, time/batch=0.063\n",
      "8611/67600 (epoch 6), train_loss = 1.254, time/batch=0.061\n",
      "8612/67600 (epoch 6), train_loss = 1.194, time/batch=0.066\n",
      "8613/67600 (epoch 6), train_loss = 1.210, time/batch=0.065\n",
      "8614/67600 (epoch 6), train_loss = 1.240, time/batch=0.066\n",
      "8615/67600 (epoch 6), train_loss = 1.277, time/batch=0.094\n",
      "8616/67600 (epoch 6), train_loss = 1.286, time/batch=0.234\n",
      "8617/67600 (epoch 6), train_loss = 1.295, time/batch=0.092\n",
      "8618/67600 (epoch 6), train_loss = 1.282, time/batch=0.076\n",
      "8619/67600 (epoch 6), train_loss = 1.277, time/batch=0.070\n",
      "8620/67600 (epoch 6), train_loss = 1.214, time/batch=0.077\n",
      "8621/67600 (epoch 6), train_loss = 1.244, time/batch=0.076\n",
      "8622/67600 (epoch 6), train_loss = 1.289, time/batch=0.079\n",
      "8623/67600 (epoch 6), train_loss = 1.254, time/batch=0.115\n",
      "8624/67600 (epoch 6), train_loss = 1.273, time/batch=0.162\n",
      "8625/67600 (epoch 6), train_loss = 1.246, time/batch=0.104\n",
      "8626/67600 (epoch 6), train_loss = 1.270, time/batch=0.073\n",
      "8627/67600 (epoch 6), train_loss = 1.305, time/batch=0.081\n",
      "8628/67600 (epoch 6), train_loss = 1.304, time/batch=0.107\n",
      "8629/67600 (epoch 6), train_loss = 1.289, time/batch=0.077\n",
      "8630/67600 (epoch 6), train_loss = 1.274, time/batch=0.076\n",
      "8631/67600 (epoch 6), train_loss = 1.187, time/batch=0.104\n",
      "8632/67600 (epoch 6), train_loss = 1.310, time/batch=0.076\n",
      "8633/67600 (epoch 6), train_loss = 1.315, time/batch=0.088\n",
      "8634/67600 (epoch 6), train_loss = 1.328, time/batch=0.081\n",
      "8635/67600 (epoch 6), train_loss = 1.263, time/batch=0.074\n",
      "8636/67600 (epoch 6), train_loss = 1.259, time/batch=0.079\n",
      "8637/67600 (epoch 6), train_loss = 1.262, time/batch=0.258\n",
      "8638/67600 (epoch 6), train_loss = 1.280, time/batch=0.101\n",
      "8639/67600 (epoch 6), train_loss = 1.235, time/batch=0.097\n",
      "8640/67600 (epoch 6), train_loss = 1.289, time/batch=0.079\n",
      "8641/67600 (epoch 6), train_loss = 1.253, time/batch=0.078\n",
      "8642/67600 (epoch 6), train_loss = 1.313, time/batch=0.070\n",
      "8643/67600 (epoch 6), train_loss = 1.306, time/batch=0.074\n",
      "8644/67600 (epoch 6), train_loss = 1.284, time/batch=0.184\n",
      "8645/67600 (epoch 6), train_loss = 1.238, time/batch=0.090\n",
      "8646/67600 (epoch 6), train_loss = 1.251, time/batch=0.102\n",
      "8647/67600 (epoch 6), train_loss = 1.212, time/batch=0.075\n",
      "8648/67600 (epoch 6), train_loss = 1.233, time/batch=0.082\n",
      "8649/67600 (epoch 6), train_loss = 1.261, time/batch=0.076\n",
      "8650/67600 (epoch 6), train_loss = 1.248, time/batch=0.080\n",
      "8651/67600 (epoch 6), train_loss = 1.264, time/batch=0.077\n",
      "8652/67600 (epoch 6), train_loss = 1.272, time/batch=0.068\n",
      "8653/67600 (epoch 6), train_loss = 1.210, time/batch=0.069\n",
      "8654/67600 (epoch 6), train_loss = 1.255, time/batch=0.074\n",
      "8655/67600 (epoch 6), train_loss = 1.225, time/batch=0.213\n",
      "8656/67600 (epoch 6), train_loss = 1.298, time/batch=0.072\n",
      "8657/67600 (epoch 6), train_loss = 1.269, time/batch=0.117\n",
      "8658/67600 (epoch 6), train_loss = 1.240, time/batch=0.074\n",
      "8659/67600 (epoch 6), train_loss = 1.263, time/batch=0.075\n",
      "8660/67600 (epoch 6), train_loss = 1.384, time/batch=0.071\n",
      "8661/67600 (epoch 6), train_loss = 1.290, time/batch=0.089\n",
      "8662/67600 (epoch 6), train_loss = 1.244, time/batch=0.116\n",
      "8663/67600 (epoch 6), train_loss = 1.301, time/batch=0.079\n",
      "8664/67600 (epoch 6), train_loss = 1.239, time/batch=0.091\n",
      "8665/67600 (epoch 6), train_loss = 1.254, time/batch=0.209\n",
      "8666/67600 (epoch 6), train_loss = 1.287, time/batch=0.072\n",
      "8667/67600 (epoch 6), train_loss = 1.243, time/batch=0.103\n",
      "8668/67600 (epoch 6), train_loss = 1.319, time/batch=0.074\n",
      "8669/67600 (epoch 6), train_loss = 1.253, time/batch=0.071\n",
      "8670/67600 (epoch 6), train_loss = 1.234, time/batch=0.071\n",
      "8671/67600 (epoch 6), train_loss = 1.194, time/batch=0.072\n",
      "8672/67600 (epoch 6), train_loss = 1.230, time/batch=0.071\n",
      "8673/67600 (epoch 6), train_loss = 1.246, time/batch=0.073\n",
      "8674/67600 (epoch 6), train_loss = 1.204, time/batch=0.069\n",
      "8675/67600 (epoch 6), train_loss = 1.251, time/batch=0.071\n",
      "8676/67600 (epoch 6), train_loss = 1.217, time/batch=0.072\n",
      "8677/67600 (epoch 6), train_loss = 1.237, time/batch=0.200\n",
      "8678/67600 (epoch 6), train_loss = 1.278, time/batch=0.072\n",
      "8679/67600 (epoch 6), train_loss = 1.285, time/batch=0.077\n",
      "8680/67600 (epoch 6), train_loss = 1.279, time/batch=0.076\n",
      "8681/67600 (epoch 6), train_loss = 1.243, time/batch=0.077\n",
      "8682/67600 (epoch 6), train_loss = 1.219, time/batch=0.070\n",
      "8683/67600 (epoch 6), train_loss = 1.217, time/batch=0.070\n",
      "8684/67600 (epoch 6), train_loss = 1.243, time/batch=0.071\n",
      "8685/67600 (epoch 6), train_loss = 1.259, time/batch=0.072\n",
      "8686/67600 (epoch 6), train_loss = 1.273, time/batch=0.071\n",
      "8687/67600 (epoch 6), train_loss = 1.230, time/batch=0.071\n",
      "8688/67600 (epoch 6), train_loss = 1.283, time/batch=0.072\n",
      "8689/67600 (epoch 6), train_loss = 1.264, time/batch=0.209\n",
      "8690/67600 (epoch 6), train_loss = 1.289, time/batch=0.076\n",
      "8691/67600 (epoch 6), train_loss = 1.250, time/batch=0.069\n",
      "8692/67600 (epoch 6), train_loss = 1.277, time/batch=0.073\n",
      "8693/67600 (epoch 6), train_loss = 1.263, time/batch=0.072\n",
      "8694/67600 (epoch 6), train_loss = 1.221, time/batch=0.069\n",
      "8695/67600 (epoch 6), train_loss = 1.227, time/batch=0.072\n",
      "8696/67600 (epoch 6), train_loss = 1.248, time/batch=0.069\n",
      "8697/67600 (epoch 6), train_loss = 1.314, time/batch=0.132\n",
      "8698/67600 (epoch 6), train_loss = 1.230, time/batch=0.105\n",
      "8699/67600 (epoch 6), train_loss = 1.309, time/batch=0.089\n",
      "8700/67600 (epoch 6), train_loss = 1.227, time/batch=0.087\n",
      "8701/67600 (epoch 6), train_loss = 1.260, time/batch=0.071\n",
      "8702/67600 (epoch 6), train_loss = 1.327, time/batch=0.071\n",
      "8703/67600 (epoch 6), train_loss = 1.225, time/batch=0.076\n",
      "8704/67600 (epoch 6), train_loss = 1.233, time/batch=0.073\n",
      "8705/67600 (epoch 6), train_loss = 1.261, time/batch=0.077\n",
      "8706/67600 (epoch 6), train_loss = 1.209, time/batch=0.073\n",
      "8707/67600 (epoch 6), train_loss = 1.253, time/batch=0.074\n",
      "8708/67600 (epoch 6), train_loss = 1.274, time/batch=0.069\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8709/67600 (epoch 6), train_loss = 1.221, time/batch=0.155\n",
      "8710/67600 (epoch 6), train_loss = 1.246, time/batch=0.096\n",
      "8711/67600 (epoch 6), train_loss = 1.233, time/batch=0.110\n",
      "8712/67600 (epoch 6), train_loss = 1.290, time/batch=0.073\n",
      "8713/67600 (epoch 6), train_loss = 1.195, time/batch=0.071\n",
      "8714/67600 (epoch 6), train_loss = 1.265, time/batch=0.073\n",
      "8715/67600 (epoch 6), train_loss = 1.250, time/batch=0.071\n",
      "8716/67600 (epoch 6), train_loss = 1.288, time/batch=0.072\n",
      "8717/67600 (epoch 6), train_loss = 1.232, time/batch=0.070\n",
      "8718/67600 (epoch 6), train_loss = 1.307, time/batch=0.071\n",
      "8719/67600 (epoch 6), train_loss = 1.235, time/batch=0.072\n",
      "8720/67600 (epoch 6), train_loss = 1.329, time/batch=0.069\n",
      "8721/67600 (epoch 6), train_loss = 1.254, time/batch=0.171\n",
      "8722/67600 (epoch 6), train_loss = 1.270, time/batch=0.084\n",
      "8723/67600 (epoch 6), train_loss = 1.348, time/batch=0.100\n",
      "8724/67600 (epoch 6), train_loss = 1.253, time/batch=0.080\n",
      "8725/67600 (epoch 6), train_loss = 1.255, time/batch=0.070\n",
      "8726/67600 (epoch 6), train_loss = 1.284, time/batch=0.069\n",
      "8727/67600 (epoch 6), train_loss = 1.318, time/batch=0.071\n",
      "8728/67600 (epoch 6), train_loss = 1.274, time/batch=0.077\n",
      "8729/67600 (epoch 6), train_loss = 1.336, time/batch=0.068\n",
      "8730/67600 (epoch 6), train_loss = 1.254, time/batch=0.071\n",
      "8731/67600 (epoch 6), train_loss = 1.220, time/batch=0.076\n",
      "8732/67600 (epoch 6), train_loss = 1.208, time/batch=0.069\n",
      "8733/67600 (epoch 6), train_loss = 1.260, time/batch=0.164\n",
      "8734/67600 (epoch 6), train_loss = 1.262, time/batch=0.112\n",
      "8735/67600 (epoch 6), train_loss = 1.221, time/batch=0.090\n",
      "8736/67600 (epoch 6), train_loss = 1.263, time/batch=0.074\n",
      "8737/67600 (epoch 6), train_loss = 1.248, time/batch=0.070\n",
      "8738/67600 (epoch 6), train_loss = 1.294, time/batch=0.073\n",
      "8739/67600 (epoch 6), train_loss = 1.302, time/batch=0.072\n",
      "8740/67600 (epoch 6), train_loss = 1.294, time/batch=0.071\n",
      "8741/67600 (epoch 6), train_loss = 1.263, time/batch=0.069\n",
      "8742/67600 (epoch 6), train_loss = 1.299, time/batch=0.071\n",
      "8743/67600 (epoch 6), train_loss = 1.326, time/batch=0.081\n",
      "8744/67600 (epoch 6), train_loss = 1.242, time/batch=0.073\n",
      "8745/67600 (epoch 6), train_loss = 1.319, time/batch=0.209\n",
      "8746/67600 (epoch 6), train_loss = 1.317, time/batch=0.070\n",
      "8747/67600 (epoch 6), train_loss = 1.188, time/batch=0.076\n",
      "8748/67600 (epoch 6), train_loss = 1.336, time/batch=0.073\n",
      "8749/67600 (epoch 6), train_loss = 1.230, time/batch=0.069\n",
      "8750/67600 (epoch 6), train_loss = 1.193, time/batch=0.072\n",
      "8751/67600 (epoch 6), train_loss = 1.187, time/batch=0.075\n",
      "8752/67600 (epoch 6), train_loss = 1.260, time/batch=0.070\n",
      "8753/67600 (epoch 6), train_loss = 1.238, time/batch=0.082\n",
      "8754/67600 (epoch 6), train_loss = 1.292, time/batch=0.163\n",
      "8755/67600 (epoch 6), train_loss = 1.336, time/batch=0.082\n",
      "8756/67600 (epoch 6), train_loss = 1.311, time/batch=0.090\n",
      "8757/67600 (epoch 6), train_loss = 1.246, time/batch=0.070\n",
      "8758/67600 (epoch 6), train_loss = 1.285, time/batch=0.071\n",
      "8759/67600 (epoch 6), train_loss = 1.279, time/batch=0.093\n",
      "8760/67600 (epoch 6), train_loss = 1.298, time/batch=0.075\n",
      "8761/67600 (epoch 6), train_loss = 1.271, time/batch=0.070\n",
      "8762/67600 (epoch 6), train_loss = 1.311, time/batch=0.071\n",
      "8763/67600 (epoch 6), train_loss = 1.334, time/batch=0.073\n",
      "8764/67600 (epoch 6), train_loss = 1.257, time/batch=0.076\n",
      "8765/67600 (epoch 6), train_loss = 1.249, time/batch=0.116\n",
      "8766/67600 (epoch 6), train_loss = 1.271, time/batch=0.072\n",
      "8767/67600 (epoch 6), train_loss = 1.265, time/batch=0.072\n",
      "8768/67600 (epoch 6), train_loss = 1.260, time/batch=0.072\n",
      "8769/67600 (epoch 6), train_loss = 1.324, time/batch=0.074\n",
      "8770/67600 (epoch 6), train_loss = 1.283, time/batch=0.070\n",
      "8771/67600 (epoch 6), train_loss = 1.208, time/batch=0.074\n",
      "8772/67600 (epoch 6), train_loss = 1.265, time/batch=0.077\n",
      "8773/67600 (epoch 6), train_loss = 1.254, time/batch=0.073\n",
      "8774/67600 (epoch 6), train_loss = 1.180, time/batch=0.071\n",
      "8775/67600 (epoch 6), train_loss = 1.203, time/batch=0.217\n",
      "8776/67600 (epoch 6), train_loss = 1.294, time/batch=0.089\n",
      "8777/67600 (epoch 6), train_loss = 1.271, time/batch=0.091\n",
      "8778/67600 (epoch 6), train_loss = 1.287, time/batch=0.072\n",
      "8779/67600 (epoch 6), train_loss = 1.256, time/batch=0.069\n",
      "8780/67600 (epoch 6), train_loss = 1.320, time/batch=0.071\n",
      "8781/67600 (epoch 6), train_loss = 1.221, time/batch=0.073\n",
      "8782/67600 (epoch 6), train_loss = 1.160, time/batch=0.072\n",
      "8783/67600 (epoch 6), train_loss = 1.248, time/batch=0.071\n",
      "8784/67600 (epoch 6), train_loss = 1.174, time/batch=0.073\n",
      "8785/67600 (epoch 6), train_loss = 1.322, time/batch=0.075\n",
      "8786/67600 (epoch 6), train_loss = 1.310, time/batch=0.072\n",
      "8787/67600 (epoch 6), train_loss = 1.234, time/batch=0.173\n",
      "8788/67600 (epoch 6), train_loss = 1.274, time/batch=0.105\n",
      "8789/67600 (epoch 6), train_loss = 1.299, time/batch=0.081\n",
      "8790/67600 (epoch 6), train_loss = 1.314, time/batch=0.073\n",
      "8791/67600 (epoch 6), train_loss = 1.253, time/batch=0.068\n",
      "8792/67600 (epoch 6), train_loss = 1.258, time/batch=0.070\n",
      "8793/67600 (epoch 6), train_loss = 1.290, time/batch=0.071\n",
      "8794/67600 (epoch 6), train_loss = 1.280, time/batch=0.073\n",
      "8795/67600 (epoch 6), train_loss = 1.242, time/batch=0.069\n",
      "8796/67600 (epoch 6), train_loss = 1.238, time/batch=0.074\n",
      "8797/67600 (epoch 6), train_loss = 1.312, time/batch=0.071\n",
      "8798/67600 (epoch 6), train_loss = 1.276, time/batch=0.070\n",
      "8799/67600 (epoch 6), train_loss = 1.221, time/batch=0.162\n",
      "8800/67600 (epoch 6), train_loss = 1.266, time/batch=0.128\n",
      "8801/67600 (epoch 6), train_loss = 1.219, time/batch=0.076\n",
      "8802/67600 (epoch 6), train_loss = 1.250, time/batch=0.073\n",
      "8803/67600 (epoch 6), train_loss = 1.254, time/batch=0.071\n",
      "8804/67600 (epoch 6), train_loss = 1.236, time/batch=0.075\n",
      "8805/67600 (epoch 6), train_loss = 1.282, time/batch=0.072\n",
      "8806/67600 (epoch 6), train_loss = 1.273, time/batch=0.071\n",
      "8807/67600 (epoch 6), train_loss = 1.189, time/batch=0.075\n",
      "8808/67600 (epoch 6), train_loss = 1.282, time/batch=0.176\n",
      "8809/67600 (epoch 6), train_loss = 1.301, time/batch=0.072\n",
      "8810/67600 (epoch 6), train_loss = 1.288, time/batch=0.109\n",
      "8811/67600 (epoch 6), train_loss = 1.228, time/batch=0.068\n",
      "8812/67600 (epoch 6), train_loss = 1.268, time/batch=0.070\n",
      "8813/67600 (epoch 6), train_loss = 1.292, time/batch=0.075\n",
      "8814/67600 (epoch 6), train_loss = 1.259, time/batch=0.071\n",
      "8815/67600 (epoch 6), train_loss = 1.208, time/batch=0.072\n",
      "8816/67600 (epoch 6), train_loss = 1.259, time/batch=0.070\n",
      "8817/67600 (epoch 6), train_loss = 1.244, time/batch=0.068\n",
      "8818/67600 (epoch 6), train_loss = 1.236, time/batch=0.070\n",
      "8819/67600 (epoch 6), train_loss = 1.287, time/batch=0.069\n",
      "8820/67600 (epoch 6), train_loss = 1.272, time/batch=0.182\n",
      "8821/67600 (epoch 6), train_loss = 1.219, time/batch=0.072\n",
      "8822/67600 (epoch 6), train_loss = 1.259, time/batch=0.109\n",
      "8823/67600 (epoch 6), train_loss = 1.167, time/batch=0.073\n",
      "8824/67600 (epoch 6), train_loss = 1.261, time/batch=0.069\n",
      "8825/67600 (epoch 6), train_loss = 1.264, time/batch=0.071\n",
      "8826/67600 (epoch 6), train_loss = 1.251, time/batch=0.073\n",
      "8827/67600 (epoch 6), train_loss = 1.234, time/batch=0.069\n",
      "8828/67600 (epoch 6), train_loss = 1.200, time/batch=0.068\n",
      "8829/67600 (epoch 6), train_loss = 1.249, time/batch=0.079\n",
      "8830/67600 (epoch 6), train_loss = 1.224, time/batch=0.073\n",
      "8831/67600 (epoch 6), train_loss = 1.237, time/batch=0.081\n",
      "8832/67600 (epoch 6), train_loss = 1.244, time/batch=0.182\n",
      "8833/67600 (epoch 6), train_loss = 1.280, time/batch=0.109\n",
      "8834/67600 (epoch 6), train_loss = 1.257, time/batch=0.072\n",
      "8835/67600 (epoch 6), train_loss = 1.274, time/batch=0.074\n",
      "8836/67600 (epoch 6), train_loss = 1.252, time/batch=0.071\n",
      "8837/67600 (epoch 6), train_loss = 1.277, time/batch=0.089\n",
      "8838/67600 (epoch 6), train_loss = 1.258, time/batch=0.106\n",
      "8839/67600 (epoch 6), train_loss = 1.264, time/batch=0.111\n",
      "8840/67600 (epoch 6), train_loss = 1.270, time/batch=0.077\n",
      "8841/67600 (epoch 6), train_loss = 1.234, time/batch=0.072\n",
      "8842/67600 (epoch 6), train_loss = 1.264, time/batch=0.216\n",
      "8843/67600 (epoch 6), train_loss = 1.290, time/batch=0.124\n",
      "8844/67600 (epoch 6), train_loss = 1.278, time/batch=0.096\n",
      "8845/67600 (epoch 6), train_loss = 1.255, time/batch=0.071\n",
      "8846/67600 (epoch 6), train_loss = 1.277, time/batch=0.073\n",
      "8847/67600 (epoch 6), train_loss = 1.220, time/batch=0.076\n",
      "8848/67600 (epoch 6), train_loss = 1.315, time/batch=0.071\n",
      "8849/67600 (epoch 6), train_loss = 1.238, time/batch=0.073\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8850/67600 (epoch 6), train_loss = 1.213, time/batch=0.072\n",
      "8851/67600 (epoch 6), train_loss = 1.285, time/batch=0.069\n",
      "8852/67600 (epoch 6), train_loss = 1.183, time/batch=0.072\n",
      "8853/67600 (epoch 6), train_loss = 1.223, time/batch=0.268\n",
      "8854/67600 (epoch 6), train_loss = 1.201, time/batch=0.073\n",
      "8855/67600 (epoch 6), train_loss = 1.239, time/batch=0.076\n",
      "8856/67600 (epoch 6), train_loss = 1.262, time/batch=0.072\n",
      "8857/67600 (epoch 6), train_loss = 1.272, time/batch=0.070\n",
      "8858/67600 (epoch 6), train_loss = 1.236, time/batch=0.070\n",
      "8859/67600 (epoch 6), train_loss = 1.253, time/batch=0.070\n",
      "8860/67600 (epoch 6), train_loss = 1.279, time/batch=0.068\n",
      "8861/67600 (epoch 6), train_loss = 1.224, time/batch=0.170\n",
      "8862/67600 (epoch 6), train_loss = 1.201, time/batch=0.072\n",
      "8863/67600 (epoch 6), train_loss = 1.213, time/batch=0.104\n",
      "8864/67600 (epoch 6), train_loss = 1.246, time/batch=0.070\n",
      "8865/67600 (epoch 6), train_loss = 1.294, time/batch=0.072\n",
      "8866/67600 (epoch 6), train_loss = 1.239, time/batch=0.080\n",
      "8867/67600 (epoch 6), train_loss = 1.245, time/batch=0.082\n",
      "8868/67600 (epoch 6), train_loss = 1.322, time/batch=0.106\n",
      "8869/67600 (epoch 6), train_loss = 1.251, time/batch=0.083\n",
      "8870/67600 (epoch 6), train_loss = 1.241, time/batch=0.072\n",
      "8871/67600 (epoch 6), train_loss = 1.221, time/batch=0.074\n",
      "8872/67600 (epoch 6), train_loss = 1.236, time/batch=0.185\n",
      "8873/67600 (epoch 6), train_loss = 1.243, time/batch=0.073\n",
      "8874/67600 (epoch 6), train_loss = 1.245, time/batch=0.108\n",
      "8875/67600 (epoch 6), train_loss = 1.294, time/batch=0.071\n",
      "8876/67600 (epoch 6), train_loss = 1.301, time/batch=0.068\n",
      "8877/67600 (epoch 6), train_loss = 1.220, time/batch=0.072\n",
      "8878/67600 (epoch 6), train_loss = 1.262, time/batch=0.076\n",
      "8879/67600 (epoch 6), train_loss = 1.256, time/batch=0.074\n",
      "8880/67600 (epoch 6), train_loss = 1.276, time/batch=0.072\n",
      "8881/67600 (epoch 6), train_loss = 1.285, time/batch=0.071\n",
      "8882/67600 (epoch 6), train_loss = 1.232, time/batch=0.072\n",
      "8883/67600 (epoch 6), train_loss = 1.310, time/batch=0.076\n",
      "8884/67600 (epoch 6), train_loss = 1.277, time/batch=0.202\n",
      "8885/67600 (epoch 6), train_loss = 1.240, time/batch=0.108\n",
      "8886/67600 (epoch 6), train_loss = 1.292, time/batch=0.077\n",
      "8887/67600 (epoch 6), train_loss = 1.328, time/batch=0.076\n",
      "8888/67600 (epoch 6), train_loss = 1.296, time/batch=0.097\n",
      "8889/67600 (epoch 6), train_loss = 1.267, time/batch=0.076\n",
      "8890/67600 (epoch 6), train_loss = 1.248, time/batch=0.088\n",
      "8891/67600 (epoch 6), train_loss = 1.277, time/batch=0.093\n",
      "8892/67600 (epoch 6), train_loss = 1.301, time/batch=0.077\n",
      "8893/67600 (epoch 6), train_loss = 1.249, time/batch=0.081\n",
      "8894/67600 (epoch 6), train_loss = 1.236, time/batch=0.220\n",
      "8895/67600 (epoch 6), train_loss = 1.261, time/batch=0.112\n",
      "8896/67600 (epoch 6), train_loss = 1.249, time/batch=0.076\n",
      "8897/67600 (epoch 6), train_loss = 1.286, time/batch=0.078\n",
      "8898/67600 (epoch 6), train_loss = 1.266, time/batch=0.077\n",
      "8899/67600 (epoch 6), train_loss = 1.271, time/batch=0.070\n",
      "8900/67600 (epoch 6), train_loss = 1.278, time/batch=0.072\n",
      "8901/67600 (epoch 6), train_loss = 1.231, time/batch=0.081\n",
      "8902/67600 (epoch 6), train_loss = 1.249, time/batch=0.071\n",
      "8903/67600 (epoch 6), train_loss = 1.256, time/batch=0.075\n",
      "8904/67600 (epoch 6), train_loss = 1.231, time/batch=0.089\n",
      "8905/67600 (epoch 6), train_loss = 1.290, time/batch=0.231\n",
      "8906/67600 (epoch 6), train_loss = 1.252, time/batch=0.090\n",
      "8907/67600 (epoch 6), train_loss = 1.262, time/batch=0.069\n",
      "8908/67600 (epoch 6), train_loss = 1.316, time/batch=0.082\n",
      "8909/67600 (epoch 6), train_loss = 1.274, time/batch=0.070\n",
      "8910/67600 (epoch 6), train_loss = 1.295, time/batch=0.075\n",
      "8911/67600 (epoch 6), train_loss = 1.256, time/batch=0.082\n",
      "8912/67600 (epoch 6), train_loss = 1.266, time/batch=0.082\n",
      "8913/67600 (epoch 6), train_loss = 1.264, time/batch=0.072\n",
      "8914/67600 (epoch 6), train_loss = 1.249, time/batch=0.080\n",
      "8915/67600 (epoch 6), train_loss = 1.259, time/batch=0.074\n",
      "8916/67600 (epoch 6), train_loss = 1.230, time/batch=0.239\n",
      "8917/67600 (epoch 6), train_loss = 1.214, time/batch=0.075\n",
      "8918/67600 (epoch 6), train_loss = 1.274, time/batch=0.083\n",
      "8919/67600 (epoch 6), train_loss = 1.231, time/batch=0.077\n",
      "8920/67600 (epoch 6), train_loss = 1.177, time/batch=0.072\n",
      "8921/67600 (epoch 6), train_loss = 1.274, time/batch=0.069\n",
      "8922/67600 (epoch 6), train_loss = 1.210, time/batch=0.072\n",
      "8923/67600 (epoch 6), train_loss = 1.296, time/batch=0.086\n",
      "8924/67600 (epoch 6), train_loss = 1.277, time/batch=0.106\n",
      "8925/67600 (epoch 6), train_loss = 1.275, time/batch=0.076\n",
      "8926/67600 (epoch 6), train_loss = 1.302, time/batch=0.075\n",
      "8927/67600 (epoch 6), train_loss = 1.205, time/batch=0.069\n",
      "8928/67600 (epoch 6), train_loss = 1.307, time/batch=0.071\n",
      "8929/67600 (epoch 6), train_loss = 1.229, time/batch=0.096\n",
      "8930/67600 (epoch 6), train_loss = 1.227, time/batch=0.073\n",
      "8931/67600 (epoch 6), train_loss = 1.250, time/batch=0.083\n",
      "8932/67600 (epoch 6), train_loss = 1.181, time/batch=0.073\n",
      "8933/67600 (epoch 6), train_loss = 1.293, time/batch=0.255\n",
      "8934/67600 (epoch 6), train_loss = 1.254, time/batch=0.103\n",
      "8935/67600 (epoch 6), train_loss = 1.332, time/batch=0.069\n",
      "8936/67600 (epoch 6), train_loss = 1.272, time/batch=0.080\n",
      "8937/67600 (epoch 6), train_loss = 1.299, time/batch=0.075\n",
      "8938/67600 (epoch 6), train_loss = 1.402, time/batch=0.081\n",
      "8939/67600 (epoch 6), train_loss = 1.224, time/batch=0.075\n",
      "8940/67600 (epoch 6), train_loss = 1.263, time/batch=0.072\n",
      "8941/67600 (epoch 6), train_loss = 1.295, time/batch=0.084\n",
      "8942/67600 (epoch 6), train_loss = 1.342, time/batch=0.075\n",
      "8943/67600 (epoch 6), train_loss = 1.242, time/batch=0.069\n",
      "8944/67600 (epoch 6), train_loss = 1.258, time/batch=0.239\n",
      "8945/67600 (epoch 6), train_loss = 1.265, time/batch=0.093\n",
      "8946/67600 (epoch 6), train_loss = 1.221, time/batch=0.069\n",
      "8947/67600 (epoch 6), train_loss = 1.296, time/batch=0.078\n",
      "8948/67600 (epoch 6), train_loss = 1.149, time/batch=0.075\n",
      "8949/67600 (epoch 6), train_loss = 1.295, time/batch=0.068\n",
      "8950/67600 (epoch 6), train_loss = 1.196, time/batch=0.083\n",
      "8951/67600 (epoch 6), train_loss = 1.248, time/batch=0.071\n",
      "8952/67600 (epoch 6), train_loss = 1.306, time/batch=0.081\n",
      "8953/67600 (epoch 6), train_loss = 1.269, time/batch=0.083\n",
      "8954/67600 (epoch 6), train_loss = 1.261, time/batch=0.070\n",
      "8955/67600 (epoch 6), train_loss = 1.279, time/batch=0.223\n",
      "8956/67600 (epoch 6), train_loss = 1.259, time/batch=0.075\n",
      "8957/67600 (epoch 6), train_loss = 1.245, time/batch=0.070\n",
      "8958/67600 (epoch 6), train_loss = 1.237, time/batch=0.073\n",
      "8959/67600 (epoch 6), train_loss = 1.244, time/batch=0.071\n",
      "8960/67600 (epoch 6), train_loss = 1.274, time/batch=0.069\n",
      "8961/67600 (epoch 6), train_loss = 1.246, time/batch=0.144\n",
      "8962/67600 (epoch 6), train_loss = 1.245, time/batch=0.199\n",
      "8963/67600 (epoch 6), train_loss = 1.335, time/batch=0.110\n",
      "8964/67600 (epoch 6), train_loss = 1.338, time/batch=0.107\n",
      "8965/67600 (epoch 6), train_loss = 1.320, time/batch=0.089\n",
      "8966/67600 (epoch 6), train_loss = 1.244, time/batch=0.097\n",
      "8967/67600 (epoch 6), train_loss = 1.298, time/batch=0.088\n",
      "8968/67600 (epoch 6), train_loss = 1.269, time/batch=0.086\n",
      "8969/67600 (epoch 6), train_loss = 1.264, time/batch=0.102\n",
      "8970/67600 (epoch 6), train_loss = 1.297, time/batch=0.117\n",
      "8971/67600 (epoch 6), train_loss = 1.305, time/batch=0.215\n",
      "8972/67600 (epoch 6), train_loss = 1.272, time/batch=0.084\n",
      "8973/67600 (epoch 6), train_loss = 1.321, time/batch=0.130\n",
      "8974/67600 (epoch 6), train_loss = 1.343, time/batch=0.098\n",
      "8975/67600 (epoch 6), train_loss = 1.296, time/batch=0.125\n",
      "8976/67600 (epoch 6), train_loss = 1.224, time/batch=0.096\n",
      "8977/67600 (epoch 6), train_loss = 1.320, time/batch=0.095\n",
      "8978/67600 (epoch 6), train_loss = 1.300, time/batch=0.089\n",
      "8979/67600 (epoch 6), train_loss = 1.233, time/batch=0.088\n",
      "8980/67600 (epoch 6), train_loss = 1.266, time/batch=0.212\n",
      "8981/67600 (epoch 6), train_loss = 1.258, time/batch=0.118\n",
      "8982/67600 (epoch 6), train_loss = 1.263, time/batch=0.124\n",
      "8983/67600 (epoch 6), train_loss = 1.242, time/batch=0.093\n",
      "8984/67600 (epoch 6), train_loss = 1.298, time/batch=0.087\n",
      "8985/67600 (epoch 6), train_loss = 1.233, time/batch=0.086\n",
      "8986/67600 (epoch 6), train_loss = 1.268, time/batch=0.073\n",
      "8987/67600 (epoch 6), train_loss = 1.318, time/batch=0.076\n",
      "8988/67600 (epoch 6), train_loss = 1.297, time/batch=0.081\n",
      "8989/67600 (epoch 6), train_loss = 1.169, time/batch=0.077\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8990/67600 (epoch 6), train_loss = 1.253, time/batch=0.222\n",
      "8991/67600 (epoch 6), train_loss = 1.167, time/batch=0.096\n",
      "8992/67600 (epoch 6), train_loss = 1.225, time/batch=0.075\n",
      "8993/67600 (epoch 6), train_loss = 1.237, time/batch=0.075\n",
      "8994/67600 (epoch 6), train_loss = 1.245, time/batch=0.073\n",
      "8995/67600 (epoch 6), train_loss = 1.263, time/batch=0.070\n",
      "8996/67600 (epoch 6), train_loss = 1.235, time/batch=0.085\n",
      "8997/67600 (epoch 6), train_loss = 1.249, time/batch=0.100\n",
      "8998/67600 (epoch 6), train_loss = 1.230, time/batch=0.079\n",
      "8999/67600 (epoch 6), train_loss = 1.191, time/batch=0.074\n",
      "9000/67600 (epoch 6), train_loss = 1.323, time/batch=0.223\n",
      "model saved to ./save/model.ckpt\n",
      "9001/67600 (epoch 6), train_loss = 1.290, time/batch=0.167\n",
      "9002/67600 (epoch 6), train_loss = 1.318, time/batch=0.098\n",
      "9003/67600 (epoch 6), train_loss = 1.303, time/batch=0.099\n",
      "9004/67600 (epoch 6), train_loss = 1.282, time/batch=0.069\n",
      "9005/67600 (epoch 6), train_loss = 1.242, time/batch=0.072\n",
      "9006/67600 (epoch 6), train_loss = 1.295, time/batch=0.071\n",
      "9007/67600 (epoch 6), train_loss = 1.241, time/batch=0.072\n",
      "9008/67600 (epoch 6), train_loss = 1.260, time/batch=0.076\n",
      "9009/67600 (epoch 6), train_loss = 1.321, time/batch=0.073\n",
      "9010/67600 (epoch 6), train_loss = 1.297, time/batch=0.071\n",
      "9011/67600 (epoch 6), train_loss = 1.298, time/batch=0.071\n",
      "9012/67600 (epoch 6), train_loss = 1.268, time/batch=0.096\n",
      "9013/67600 (epoch 6), train_loss = 1.313, time/batch=0.218\n",
      "9014/67600 (epoch 6), train_loss = 1.315, time/batch=0.085\n",
      "9015/67600 (epoch 6), train_loss = 1.198, time/batch=0.090\n",
      "9016/67600 (epoch 6), train_loss = 1.245, time/batch=0.097\n",
      "9017/67600 (epoch 6), train_loss = 1.294, time/batch=0.072\n",
      "9018/67600 (epoch 6), train_loss = 1.247, time/batch=0.069\n",
      "9019/67600 (epoch 6), train_loss = 1.238, time/batch=0.071\n",
      "9020/67600 (epoch 6), train_loss = 1.310, time/batch=0.071\n",
      "9021/67600 (epoch 6), train_loss = 1.248, time/batch=0.090\n",
      "9022/67600 (epoch 6), train_loss = 1.251, time/batch=0.091\n",
      "9023/67600 (epoch 6), train_loss = 1.294, time/batch=0.143\n",
      "9024/67600 (epoch 6), train_loss = 1.247, time/batch=0.134\n",
      "9025/67600 (epoch 6), train_loss = 1.279, time/batch=0.104\n",
      "9026/67600 (epoch 6), train_loss = 1.311, time/batch=0.075\n",
      "9027/67600 (epoch 6), train_loss = 1.250, time/batch=0.067\n",
      "9028/67600 (epoch 6), train_loss = 1.265, time/batch=0.067\n",
      "9029/67600 (epoch 6), train_loss = 1.247, time/batch=0.066\n",
      "9030/67600 (epoch 6), train_loss = 1.277, time/batch=0.065\n",
      "9031/67600 (epoch 6), train_loss = 1.268, time/batch=0.066\n",
      "9032/67600 (epoch 6), train_loss = 1.286, time/batch=0.068\n",
      "9033/67600 (epoch 6), train_loss = 1.258, time/batch=0.074\n",
      "9034/67600 (epoch 6), train_loss = 1.283, time/batch=0.067\n",
      "9035/67600 (epoch 6), train_loss = 1.231, time/batch=0.062\n",
      "9036/67600 (epoch 6), train_loss = 1.219, time/batch=0.198\n",
      "9037/67600 (epoch 6), train_loss = 1.244, time/batch=0.080\n",
      "9038/67600 (epoch 6), train_loss = 1.239, time/batch=0.070\n",
      "9039/67600 (epoch 6), train_loss = 1.261, time/batch=0.075\n",
      "9040/67600 (epoch 6), train_loss = 1.238, time/batch=0.075\n",
      "9041/67600 (epoch 6), train_loss = 1.250, time/batch=0.089\n",
      "9042/67600 (epoch 6), train_loss = 1.217, time/batch=0.076\n",
      "9043/67600 (epoch 6), train_loss = 1.264, time/batch=0.075\n",
      "9044/67600 (epoch 6), train_loss = 1.227, time/batch=0.123\n",
      "9045/67600 (epoch 6), train_loss = 1.211, time/batch=0.078\n",
      "9046/67600 (epoch 6), train_loss = 1.237, time/batch=0.077\n",
      "9047/67600 (epoch 6), train_loss = 1.226, time/batch=0.105\n",
      "9048/67600 (epoch 6), train_loss = 1.289, time/batch=0.089\n",
      "9049/67600 (epoch 6), train_loss = 1.251, time/batch=0.072\n",
      "9050/67600 (epoch 6), train_loss = 1.235, time/batch=0.068\n",
      "9051/67600 (epoch 6), train_loss = 1.237, time/batch=0.094\n",
      "9052/67600 (epoch 6), train_loss = 1.255, time/batch=0.088\n",
      "9053/67600 (epoch 6), train_loss = 1.215, time/batch=0.263\n",
      "9054/67600 (epoch 6), train_loss = 1.191, time/batch=0.091\n",
      "9055/67600 (epoch 6), train_loss = 1.290, time/batch=0.072\n",
      "9056/67600 (epoch 6), train_loss = 1.245, time/batch=0.072\n",
      "9057/67600 (epoch 6), train_loss = 1.274, time/batch=0.077\n",
      "9058/67600 (epoch 6), train_loss = 1.233, time/batch=0.075\n",
      "9059/67600 (epoch 6), train_loss = 1.212, time/batch=0.075\n",
      "9060/67600 (epoch 6), train_loss = 1.264, time/batch=0.074\n",
      "9061/67600 (epoch 6), train_loss = 1.221, time/batch=0.074\n",
      "9062/67600 (epoch 6), train_loss = 1.281, time/batch=0.078\n",
      "9063/67600 (epoch 6), train_loss = 1.222, time/batch=0.077\n",
      "9064/67600 (epoch 6), train_loss = 1.282, time/batch=0.219\n",
      "9065/67600 (epoch 6), train_loss = 1.209, time/batch=0.087\n",
      "9066/67600 (epoch 6), train_loss = 1.188, time/batch=0.070\n",
      "9067/67600 (epoch 6), train_loss = 1.314, time/batch=0.071\n",
      "9068/67600 (epoch 6), train_loss = 1.274, time/batch=0.068\n",
      "9069/67600 (epoch 6), train_loss = 1.275, time/batch=0.069\n",
      "9070/67600 (epoch 6), train_loss = 1.216, time/batch=0.072\n",
      "9071/67600 (epoch 6), train_loss = 1.230, time/batch=0.074\n",
      "9072/67600 (epoch 6), train_loss = 1.223, time/batch=0.069\n",
      "9073/67600 (epoch 6), train_loss = 1.173, time/batch=0.070\n",
      "9074/67600 (epoch 6), train_loss = 1.191, time/batch=0.074\n",
      "9075/67600 (epoch 6), train_loss = 1.179, time/batch=0.100\n",
      "9076/67600 (epoch 6), train_loss = 1.181, time/batch=0.196\n",
      "9077/67600 (epoch 6), train_loss = 1.265, time/batch=0.075\n",
      "9078/67600 (epoch 6), train_loss = 1.261, time/batch=0.067\n",
      "9079/67600 (epoch 6), train_loss = 1.202, time/batch=0.074\n",
      "9080/67600 (epoch 6), train_loss = 1.221, time/batch=0.087\n",
      "9081/67600 (epoch 6), train_loss = 1.218, time/batch=0.076\n",
      "9082/67600 (epoch 6), train_loss = 1.246, time/batch=0.069\n",
      "9083/67600 (epoch 6), train_loss = 1.252, time/batch=0.100\n",
      "9084/67600 (epoch 6), train_loss = 1.204, time/batch=0.190\n",
      "9085/67600 (epoch 6), train_loss = 1.262, time/batch=0.111\n",
      "9086/67600 (epoch 6), train_loss = 1.288, time/batch=0.090\n",
      "9087/67600 (epoch 6), train_loss = 1.192, time/batch=0.086\n",
      "9088/67600 (epoch 6), train_loss = 1.177, time/batch=0.076\n",
      "9089/67600 (epoch 6), train_loss = 1.217, time/batch=0.076\n",
      "9090/67600 (epoch 6), train_loss = 1.259, time/batch=0.070\n",
      "9091/67600 (epoch 6), train_loss = 1.233, time/batch=0.068\n",
      "9092/67600 (epoch 6), train_loss = 1.253, time/batch=0.065\n",
      "9093/67600 (epoch 6), train_loss = 1.210, time/batch=0.066\n",
      "9094/67600 (epoch 6), train_loss = 1.224, time/batch=0.067\n",
      "9095/67600 (epoch 6), train_loss = 1.268, time/batch=0.166\n",
      "9096/67600 (epoch 6), train_loss = 1.217, time/batch=0.067\n",
      "9097/67600 (epoch 6), train_loss = 1.314, time/batch=0.109\n",
      "9098/67600 (epoch 6), train_loss = 1.253, time/batch=0.064\n",
      "9099/67600 (epoch 6), train_loss = 1.316, time/batch=0.068\n",
      "9100/67600 (epoch 6), train_loss = 1.214, time/batch=0.066\n",
      "9101/67600 (epoch 6), train_loss = 1.234, time/batch=0.064\n",
      "9102/67600 (epoch 6), train_loss = 1.263, time/batch=0.064\n",
      "9103/67600 (epoch 6), train_loss = 1.234, time/batch=0.071\n",
      "9104/67600 (epoch 6), train_loss = 1.293, time/batch=0.067\n",
      "9105/67600 (epoch 6), train_loss = 1.248, time/batch=0.065\n",
      "9106/67600 (epoch 6), train_loss = 1.238, time/batch=0.077\n",
      "9107/67600 (epoch 6), train_loss = 1.248, time/batch=0.120\n",
      "9108/67600 (epoch 6), train_loss = 1.254, time/batch=0.146\n",
      "9109/67600 (epoch 6), train_loss = 1.267, time/batch=0.101\n",
      "9110/67600 (epoch 6), train_loss = 1.207, time/batch=0.067\n",
      "9111/67600 (epoch 6), train_loss = 1.226, time/batch=0.072\n",
      "9112/67600 (epoch 6), train_loss = 1.243, time/batch=0.073\n",
      "9113/67600 (epoch 6), train_loss = 1.252, time/batch=0.067\n",
      "9114/67600 (epoch 6), train_loss = 1.229, time/batch=0.072\n",
      "9115/67600 (epoch 6), train_loss = 1.255, time/batch=0.070\n",
      "9116/67600 (epoch 6), train_loss = 1.188, time/batch=0.070\n",
      "9117/67600 (epoch 6), train_loss = 1.266, time/batch=0.071\n",
      "9118/67600 (epoch 6), train_loss = 1.245, time/batch=0.073\n",
      "9119/67600 (epoch 6), train_loss = 1.207, time/batch=0.143\n",
      "9120/67600 (epoch 6), train_loss = 1.247, time/batch=0.148\n",
      "9121/67600 (epoch 6), train_loss = 1.206, time/batch=0.097\n",
      "9122/67600 (epoch 6), train_loss = 1.220, time/batch=0.074\n",
      "9123/67600 (epoch 6), train_loss = 1.220, time/batch=0.073\n",
      "9124/67600 (epoch 6), train_loss = 1.187, time/batch=0.076\n",
      "9125/67600 (epoch 6), train_loss = 1.216, time/batch=0.071\n",
      "9126/67600 (epoch 6), train_loss = 1.223, time/batch=0.067\n",
      "9127/67600 (epoch 6), train_loss = 1.237, time/batch=0.075\n",
      "9128/67600 (epoch 6), train_loss = 1.214, time/batch=0.104\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9129/67600 (epoch 6), train_loss = 1.269, time/batch=0.098\n",
      "9130/67600 (epoch 6), train_loss = 1.239, time/batch=0.206\n",
      "9131/67600 (epoch 6), train_loss = 1.251, time/batch=0.071\n",
      "9132/67600 (epoch 6), train_loss = 1.232, time/batch=0.071\n",
      "9133/67600 (epoch 6), train_loss = 1.228, time/batch=0.071\n",
      "9134/67600 (epoch 6), train_loss = 1.226, time/batch=0.077\n",
      "9135/67600 (epoch 6), train_loss = 1.232, time/batch=0.085\n",
      "9136/67600 (epoch 6), train_loss = 1.234, time/batch=0.072\n",
      "9137/67600 (epoch 6), train_loss = 1.192, time/batch=0.063\n",
      "9138/67600 (epoch 6), train_loss = 1.274, time/batch=0.064\n",
      "9139/67600 (epoch 6), train_loss = 1.192, time/batch=0.157\n",
      "9140/67600 (epoch 6), train_loss = 1.294, time/batch=0.066\n",
      "9141/67600 (epoch 6), train_loss = 1.259, time/batch=0.099\n",
      "9142/67600 (epoch 6), train_loss = 1.284, time/batch=0.066\n",
      "9143/67600 (epoch 6), train_loss = 1.279, time/batch=0.070\n",
      "9144/67600 (epoch 6), train_loss = 1.248, time/batch=0.079\n",
      "9145/67600 (epoch 6), train_loss = 1.224, time/batch=0.075\n",
      "9146/67600 (epoch 6), train_loss = 1.253, time/batch=0.071\n",
      "9147/67600 (epoch 6), train_loss = 1.217, time/batch=0.072\n",
      "9148/67600 (epoch 6), train_loss = 1.204, time/batch=0.069\n",
      "9149/67600 (epoch 6), train_loss = 1.199, time/batch=0.067\n",
      "9150/67600 (epoch 6), train_loss = 1.243, time/batch=0.066\n",
      "9151/67600 (epoch 6), train_loss = 1.220, time/batch=0.120\n",
      "9152/67600 (epoch 6), train_loss = 1.244, time/batch=0.111\n",
      "9153/67600 (epoch 6), train_loss = 1.246, time/batch=0.066\n",
      "9154/67600 (epoch 6), train_loss = 1.288, time/batch=0.091\n",
      "9155/67600 (epoch 6), train_loss = 1.144, time/batch=0.064\n",
      "9156/67600 (epoch 6), train_loss = 1.235, time/batch=0.066\n",
      "9157/67600 (epoch 6), train_loss = 1.231, time/batch=0.078\n",
      "9158/67600 (epoch 6), train_loss = 1.247, time/batch=0.079\n",
      "9159/67600 (epoch 6), train_loss = 1.301, time/batch=0.077\n",
      "9160/67600 (epoch 6), train_loss = 1.280, time/batch=0.071\n",
      "9161/67600 (epoch 6), train_loss = 1.265, time/batch=0.077\n",
      "9162/67600 (epoch 6), train_loss = 1.238, time/batch=0.077\n",
      "9163/67600 (epoch 6), train_loss = 1.211, time/batch=0.271\n",
      "9164/67600 (epoch 6), train_loss = 1.261, time/batch=0.102\n",
      "9165/67600 (epoch 6), train_loss = 1.244, time/batch=0.068\n",
      "9166/67600 (epoch 6), train_loss = 1.268, time/batch=0.076\n",
      "9167/67600 (epoch 6), train_loss = 1.249, time/batch=0.076\n",
      "9168/67600 (epoch 6), train_loss = 1.171, time/batch=0.077\n",
      "9169/67600 (epoch 6), train_loss = 1.287, time/batch=0.073\n",
      "9170/67600 (epoch 6), train_loss = 1.317, time/batch=0.078\n",
      "9171/67600 (epoch 6), train_loss = 1.233, time/batch=0.077\n",
      "9172/67600 (epoch 6), train_loss = 1.262, time/batch=0.068\n",
      "9173/67600 (epoch 6), train_loss = 1.266, time/batch=0.083\n",
      "9174/67600 (epoch 6), train_loss = 1.239, time/batch=0.238\n",
      "9175/67600 (epoch 6), train_loss = 1.200, time/batch=0.090\n",
      "9176/67600 (epoch 6), train_loss = 1.252, time/batch=0.098\n",
      "9177/67600 (epoch 6), train_loss = 1.246, time/batch=0.077\n",
      "9178/67600 (epoch 6), train_loss = 1.239, time/batch=0.081\n",
      "9179/67600 (epoch 6), train_loss = 1.279, time/batch=0.077\n",
      "9180/67600 (epoch 6), train_loss = 1.217, time/batch=0.077\n",
      "9181/67600 (epoch 6), train_loss = 1.266, time/batch=0.081\n",
      "9182/67600 (epoch 6), train_loss = 1.289, time/batch=0.084\n",
      "9183/67600 (epoch 6), train_loss = 1.307, time/batch=0.078\n",
      "9184/67600 (epoch 6), train_loss = 1.251, time/batch=0.205\n",
      "9185/67600 (epoch 6), train_loss = 1.234, time/batch=0.082\n",
      "9186/67600 (epoch 6), train_loss = 1.213, time/batch=0.081\n",
      "9187/67600 (epoch 6), train_loss = 1.240, time/batch=0.070\n",
      "9188/67600 (epoch 6), train_loss = 1.293, time/batch=0.075\n",
      "9189/67600 (epoch 6), train_loss = 1.278, time/batch=0.079\n",
      "9190/67600 (epoch 6), train_loss = 1.291, time/batch=0.096\n",
      "9191/67600 (epoch 6), train_loss = 1.285, time/batch=0.069\n",
      "9192/67600 (epoch 6), train_loss = 1.300, time/batch=0.164\n",
      "9193/67600 (epoch 6), train_loss = 1.219, time/batch=0.079\n",
      "9194/67600 (epoch 6), train_loss = 1.283, time/batch=0.122\n",
      "9195/67600 (epoch 6), train_loss = 1.216, time/batch=0.084\n",
      "9196/67600 (epoch 6), train_loss = 1.203, time/batch=0.076\n",
      "9197/67600 (epoch 6), train_loss = 1.328, time/batch=0.084\n",
      "9198/67600 (epoch 6), train_loss = 1.286, time/batch=0.065\n",
      "9199/67600 (epoch 6), train_loss = 1.197, time/batch=0.067\n",
      "9200/67600 (epoch 6), train_loss = 1.231, time/batch=0.068\n",
      "9201/67600 (epoch 6), train_loss = 1.219, time/batch=0.066\n",
      "9202/67600 (epoch 6), train_loss = 1.273, time/batch=0.065\n",
      "9203/67600 (epoch 6), train_loss = 1.233, time/batch=0.065\n",
      "9204/67600 (epoch 6), train_loss = 1.292, time/batch=0.108\n",
      "9205/67600 (epoch 6), train_loss = 1.239, time/batch=0.064\n",
      "9206/67600 (epoch 6), train_loss = 1.241, time/batch=0.067\n",
      "9207/67600 (epoch 6), train_loss = 1.220, time/batch=0.067\n",
      "9208/67600 (epoch 6), train_loss = 1.250, time/batch=0.068\n",
      "9209/67600 (epoch 6), train_loss = 1.247, time/batch=0.065\n",
      "9210/67600 (epoch 6), train_loss = 1.211, time/batch=0.067\n",
      "9211/67600 (epoch 6), train_loss = 1.178, time/batch=0.065\n",
      "9212/67600 (epoch 6), train_loss = 1.245, time/batch=0.074\n",
      "9213/67600 (epoch 6), train_loss = 1.241, time/batch=0.078\n",
      "9214/67600 (epoch 6), train_loss = 1.230, time/batch=0.146\n",
      "9215/67600 (epoch 6), train_loss = 1.206, time/batch=0.166\n",
      "9216/67600 (epoch 6), train_loss = 1.330, time/batch=0.069\n",
      "9217/67600 (epoch 6), train_loss = 1.225, time/batch=0.087\n",
      "9218/67600 (epoch 6), train_loss = 1.233, time/batch=0.065\n",
      "9219/67600 (epoch 6), train_loss = 1.277, time/batch=0.068\n",
      "9220/67600 (epoch 6), train_loss = 1.228, time/batch=0.066\n",
      "9221/67600 (epoch 6), train_loss = 1.256, time/batch=0.064\n",
      "9222/67600 (epoch 6), train_loss = 1.270, time/batch=0.063\n",
      "9223/67600 (epoch 6), train_loss = 1.248, time/batch=0.066\n",
      "9224/67600 (epoch 6), train_loss = 1.292, time/batch=0.067\n",
      "9225/67600 (epoch 6), train_loss = 1.299, time/batch=0.063\n",
      "9226/67600 (epoch 6), train_loss = 1.273, time/batch=0.064\n",
      "9227/67600 (epoch 6), train_loss = 1.344, time/batch=0.067\n",
      "9228/67600 (epoch 6), train_loss = 1.244, time/batch=0.189\n",
      "9229/67600 (epoch 6), train_loss = 1.279, time/batch=0.067\n",
      "9230/67600 (epoch 6), train_loss = 1.250, time/batch=0.075\n",
      "9231/67600 (epoch 6), train_loss = 1.346, time/batch=0.065\n",
      "9232/67600 (epoch 6), train_loss = 1.242, time/batch=0.068\n",
      "9233/67600 (epoch 6), train_loss = 1.279, time/batch=0.067\n",
      "9234/67600 (epoch 6), train_loss = 1.350, time/batch=0.064\n",
      "9235/67600 (epoch 6), train_loss = 1.265, time/batch=0.072\n",
      "9236/67600 (epoch 6), train_loss = 1.251, time/batch=0.066\n",
      "9237/67600 (epoch 6), train_loss = 1.251, time/batch=0.067\n",
      "9238/67600 (epoch 6), train_loss = 1.307, time/batch=0.077\n",
      "9239/67600 (epoch 6), train_loss = 1.249, time/batch=0.074\n",
      "9240/67600 (epoch 6), train_loss = 1.282, time/batch=0.086\n",
      "9241/67600 (epoch 6), train_loss = 1.273, time/batch=0.186\n",
      "9242/67600 (epoch 6), train_loss = 1.265, time/batch=0.087\n",
      "9243/67600 (epoch 6), train_loss = 1.289, time/batch=0.067\n",
      "9244/67600 (epoch 6), train_loss = 1.237, time/batch=0.071\n",
      "9245/67600 (epoch 6), train_loss = 1.293, time/batch=0.070\n",
      "9246/67600 (epoch 6), train_loss = 1.328, time/batch=0.064\n",
      "9247/67600 (epoch 6), train_loss = 1.324, time/batch=0.083\n",
      "9248/67600 (epoch 6), train_loss = 1.291, time/batch=0.067\n",
      "9249/67600 (epoch 6), train_loss = 1.260, time/batch=0.182\n",
      "9250/67600 (epoch 6), train_loss = 1.263, time/batch=0.084\n",
      "9251/67600 (epoch 6), train_loss = 1.303, time/batch=0.111\n",
      "9252/67600 (epoch 6), train_loss = 1.256, time/batch=0.066\n",
      "9253/67600 (epoch 6), train_loss = 1.256, time/batch=0.065\n",
      "9254/67600 (epoch 6), train_loss = 1.290, time/batch=0.069\n",
      "9255/67600 (epoch 6), train_loss = 1.293, time/batch=0.064\n",
      "9256/67600 (epoch 6), train_loss = 1.282, time/batch=0.065\n",
      "9257/67600 (epoch 6), train_loss = 1.227, time/batch=0.064\n",
      "9258/67600 (epoch 6), train_loss = 1.228, time/batch=0.064\n",
      "9259/67600 (epoch 6), train_loss = 1.219, time/batch=0.065\n",
      "9260/67600 (epoch 6), train_loss = 1.219, time/batch=0.067\n",
      "9261/67600 (epoch 6), train_loss = 1.241, time/batch=0.149\n",
      "9262/67600 (epoch 6), train_loss = 1.192, time/batch=0.120\n",
      "9263/67600 (epoch 6), train_loss = 1.287, time/batch=0.111\n",
      "9264/67600 (epoch 6), train_loss = 1.255, time/batch=0.068\n",
      "9265/67600 (epoch 6), train_loss = 1.232, time/batch=0.074\n",
      "9266/67600 (epoch 6), train_loss = 1.261, time/batch=0.075\n",
      "9267/67600 (epoch 6), train_loss = 1.241, time/batch=0.067\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9268/67600 (epoch 6), train_loss = 1.242, time/batch=0.073\n",
      "9269/67600 (epoch 6), train_loss = 1.188, time/batch=0.094\n",
      "9270/67600 (epoch 6), train_loss = 1.289, time/batch=0.082\n",
      "9271/67600 (epoch 6), train_loss = 1.279, time/batch=0.081\n",
      "9272/67600 (epoch 6), train_loss = 1.207, time/batch=0.067\n",
      "9273/67600 (epoch 6), train_loss = 1.223, time/batch=0.191\n",
      "9274/67600 (epoch 6), train_loss = 1.246, time/batch=0.105\n",
      "9275/67600 (epoch 6), train_loss = 1.204, time/batch=0.072\n",
      "9276/67600 (epoch 6), train_loss = 1.259, time/batch=0.072\n",
      "9277/67600 (epoch 6), train_loss = 1.204, time/batch=0.069\n",
      "9278/67600 (epoch 6), train_loss = 1.225, time/batch=0.071\n",
      "9279/67600 (epoch 6), train_loss = 1.249, time/batch=0.074\n",
      "9280/67600 (epoch 6), train_loss = 1.264, time/batch=0.074\n",
      "9281/67600 (epoch 6), train_loss = 1.180, time/batch=0.070\n",
      "9282/67600 (epoch 6), train_loss = 1.210, time/batch=0.073\n",
      "9283/67600 (epoch 6), train_loss = 1.208, time/batch=0.071\n",
      "9284/67600 (epoch 6), train_loss = 1.241, time/batch=0.275\n",
      "9285/67600 (epoch 6), train_loss = 1.237, time/batch=0.130\n",
      "9286/67600 (epoch 6), train_loss = 1.237, time/batch=0.073\n",
      "9287/67600 (epoch 6), train_loss = 1.238, time/batch=0.070\n",
      "9288/67600 (epoch 6), train_loss = 1.252, time/batch=0.070\n",
      "9289/67600 (epoch 6), train_loss = 1.256, time/batch=0.070\n",
      "9290/67600 (epoch 6), train_loss = 1.281, time/batch=0.071\n",
      "9291/67600 (epoch 6), train_loss = 1.359, time/batch=0.073\n",
      "9292/67600 (epoch 6), train_loss = 1.315, time/batch=0.082\n",
      "9293/67600 (epoch 6), train_loss = 1.270, time/batch=0.095\n",
      "9294/67600 (epoch 6), train_loss = 1.261, time/batch=0.248\n",
      "9295/67600 (epoch 6), train_loss = 1.241, time/batch=0.102\n",
      "9296/67600 (epoch 6), train_loss = 1.270, time/batch=0.071\n",
      "9297/67600 (epoch 6), train_loss = 1.176, time/batch=0.069\n",
      "9298/67600 (epoch 6), train_loss = 1.213, time/batch=0.069\n",
      "9299/67600 (epoch 6), train_loss = 1.300, time/batch=0.072\n",
      "9300/67600 (epoch 6), train_loss = 1.243, time/batch=0.070\n",
      "9301/67600 (epoch 6), train_loss = 1.216, time/batch=0.069\n",
      "9302/67600 (epoch 6), train_loss = 1.248, time/batch=0.178\n",
      "9303/67600 (epoch 6), train_loss = 1.225, time/batch=0.070\n",
      "9304/67600 (epoch 6), train_loss = 1.240, time/batch=0.110\n",
      "9305/67600 (epoch 6), train_loss = 1.242, time/batch=0.070\n",
      "9306/67600 (epoch 6), train_loss = 1.191, time/batch=0.076\n",
      "9307/67600 (epoch 6), train_loss = 1.229, time/batch=0.079\n",
      "9308/67600 (epoch 6), train_loss = 1.267, time/batch=0.075\n",
      "9309/67600 (epoch 6), train_loss = 1.281, time/batch=0.071\n",
      "9310/67600 (epoch 6), train_loss = 1.274, time/batch=0.070\n",
      "9311/67600 (epoch 6), train_loss = 1.232, time/batch=0.073\n",
      "9312/67600 (epoch 6), train_loss = 1.256, time/batch=0.072\n",
      "9313/67600 (epoch 6), train_loss = 1.237, time/batch=0.067\n",
      "9314/67600 (epoch 6), train_loss = 1.214, time/batch=0.179\n",
      "9315/67600 (epoch 6), train_loss = 1.220, time/batch=0.077\n",
      "9316/67600 (epoch 6), train_loss = 1.331, time/batch=0.110\n",
      "9317/67600 (epoch 6), train_loss = 1.240, time/batch=0.073\n",
      "9318/67600 (epoch 6), train_loss = 1.207, time/batch=0.068\n",
      "9319/67600 (epoch 6), train_loss = 1.263, time/batch=0.071\n",
      "9320/67600 (epoch 6), train_loss = 1.215, time/batch=0.072\n",
      "9321/67600 (epoch 6), train_loss = 1.211, time/batch=0.064\n",
      "9322/67600 (epoch 6), train_loss = 1.257, time/batch=0.076\n",
      "9323/67600 (epoch 6), train_loss = 1.218, time/batch=0.074\n",
      "9324/67600 (epoch 6), train_loss = 1.205, time/batch=0.070\n",
      "9325/67600 (epoch 6), train_loss = 1.244, time/batch=0.070\n",
      "9326/67600 (epoch 6), train_loss = 1.283, time/batch=0.207\n",
      "9327/67600 (epoch 6), train_loss = 1.231, time/batch=0.108\n",
      "9328/67600 (epoch 6), train_loss = 1.258, time/batch=0.078\n",
      "9329/67600 (epoch 6), train_loss = 1.242, time/batch=0.083\n",
      "9330/67600 (epoch 6), train_loss = 1.234, time/batch=0.077\n",
      "9331/67600 (epoch 6), train_loss = 1.247, time/batch=0.072\n",
      "9332/67600 (epoch 6), train_loss = 1.232, time/batch=0.075\n",
      "9333/67600 (epoch 6), train_loss = 1.226, time/batch=0.076\n",
      "9334/67600 (epoch 6), train_loss = 1.271, time/batch=0.075\n",
      "9335/67600 (epoch 6), train_loss = 1.231, time/batch=0.073\n",
      "9336/67600 (epoch 6), train_loss = 1.275, time/batch=0.294\n",
      "9337/67600 (epoch 6), train_loss = 1.274, time/batch=0.097\n",
      "9338/67600 (epoch 6), train_loss = 1.283, time/batch=0.074\n",
      "9339/67600 (epoch 6), train_loss = 1.254, time/batch=0.077\n",
      "9340/67600 (epoch 6), train_loss = 1.305, time/batch=0.074\n",
      "9341/67600 (epoch 6), train_loss = 1.221, time/batch=0.073\n",
      "9342/67600 (epoch 6), train_loss = 1.259, time/batch=0.080\n",
      "9343/67600 (epoch 6), train_loss = 1.269, time/batch=0.077\n",
      "9344/67600 (epoch 6), train_loss = 1.345, time/batch=0.073\n",
      "9345/67600 (epoch 6), train_loss = 1.309, time/batch=0.073\n",
      "9346/67600 (epoch 6), train_loss = 1.204, time/batch=0.077\n",
      "9347/67600 (epoch 6), train_loss = 1.250, time/batch=0.219\n",
      "9348/67600 (epoch 6), train_loss = 1.240, time/batch=0.080\n",
      "9349/67600 (epoch 6), train_loss = 1.269, time/batch=0.071\n",
      "9350/67600 (epoch 6), train_loss = 1.233, time/batch=0.074\n",
      "9351/67600 (epoch 6), train_loss = 1.231, time/batch=0.069\n",
      "9352/67600 (epoch 6), train_loss = 1.298, time/batch=0.074\n",
      "9353/67600 (epoch 6), train_loss = 1.232, time/batch=0.072\n",
      "9354/67600 (epoch 6), train_loss = 1.242, time/batch=0.073\n",
      "9355/67600 (epoch 6), train_loss = 1.269, time/batch=0.153\n",
      "9356/67600 (epoch 6), train_loss = 1.344, time/batch=0.115\n",
      "9357/67600 (epoch 6), train_loss = 1.263, time/batch=0.127\n",
      "9358/67600 (epoch 6), train_loss = 1.250, time/batch=0.071\n",
      "9359/67600 (epoch 6), train_loss = 1.251, time/batch=0.077\n",
      "9360/67600 (epoch 6), train_loss = 1.272, time/batch=0.093\n",
      "9361/67600 (epoch 6), train_loss = 1.244, time/batch=0.069\n",
      "9362/67600 (epoch 6), train_loss = 1.222, time/batch=0.070\n",
      "9363/67600 (epoch 6), train_loss = 1.310, time/batch=0.070\n",
      "9364/67600 (epoch 6), train_loss = 1.209, time/batch=0.077\n",
      "9365/67600 (epoch 6), train_loss = 1.311, time/batch=0.069\n",
      "9366/67600 (epoch 6), train_loss = 1.266, time/batch=0.108\n",
      "9367/67600 (epoch 6), train_loss = 1.291, time/batch=0.083\n",
      "9368/67600 (epoch 6), train_loss = 1.285, time/batch=0.072\n",
      "9369/67600 (epoch 6), train_loss = 1.279, time/batch=0.074\n",
      "9370/67600 (epoch 6), train_loss = 1.311, time/batch=0.081\n",
      "9371/67600 (epoch 6), train_loss = 1.267, time/batch=0.080\n",
      "9372/67600 (epoch 6), train_loss = 1.269, time/batch=0.088\n",
      "9373/67600 (epoch 6), train_loss = 1.225, time/batch=0.110\n",
      "9374/67600 (epoch 6), train_loss = 1.329, time/batch=0.073\n",
      "9375/67600 (epoch 6), train_loss = 1.321, time/batch=0.235\n",
      "9376/67600 (epoch 6), train_loss = 1.302, time/batch=0.090\n",
      "9377/67600 (epoch 6), train_loss = 1.243, time/batch=0.092\n",
      "9378/67600 (epoch 6), train_loss = 1.320, time/batch=0.083\n",
      "9379/67600 (epoch 6), train_loss = 1.229, time/batch=0.086\n",
      "9380/67600 (epoch 6), train_loss = 1.197, time/batch=0.071\n",
      "9381/67600 (epoch 6), train_loss = 1.258, time/batch=0.075\n",
      "9382/67600 (epoch 6), train_loss = 1.247, time/batch=0.072\n",
      "9383/67600 (epoch 6), train_loss = 1.197, time/batch=0.069\n",
      "9384/67600 (epoch 6), train_loss = 1.258, time/batch=0.071\n",
      "9385/67600 (epoch 6), train_loss = 1.251, time/batch=0.071\n",
      "9386/67600 (epoch 6), train_loss = 1.236, time/batch=0.070\n",
      "9387/67600 (epoch 6), train_loss = 1.290, time/batch=0.223\n",
      "9388/67600 (epoch 6), train_loss = 1.279, time/batch=0.113\n",
      "9389/67600 (epoch 6), train_loss = 1.266, time/batch=0.070\n",
      "9390/67600 (epoch 6), train_loss = 1.194, time/batch=0.071\n",
      "9391/67600 (epoch 6), train_loss = 1.197, time/batch=0.073\n",
      "9392/67600 (epoch 6), train_loss = 1.216, time/batch=0.068\n",
      "9393/67600 (epoch 6), train_loss = 1.260, time/batch=0.074\n",
      "9394/67600 (epoch 6), train_loss = 1.204, time/batch=0.083\n",
      "9395/67600 (epoch 6), train_loss = 1.260, time/batch=0.081\n",
      "9396/67600 (epoch 6), train_loss = 1.276, time/batch=0.095\n",
      "9397/67600 (epoch 6), train_loss = 1.247, time/batch=0.248\n",
      "9398/67600 (epoch 6), train_loss = 1.219, time/batch=0.097\n",
      "9399/67600 (epoch 6), train_loss = 1.296, time/batch=0.096\n",
      "9400/67600 (epoch 6), train_loss = 1.228, time/batch=0.073\n",
      "9401/67600 (epoch 6), train_loss = 1.292, time/batch=0.072\n",
      "9402/67600 (epoch 6), train_loss = 1.321, time/batch=0.069\n",
      "9403/67600 (epoch 6), train_loss = 1.283, time/batch=0.077\n",
      "9404/67600 (epoch 6), train_loss = 1.236, time/batch=0.074\n",
      "9405/67600 (epoch 6), train_loss = 1.246, time/batch=0.185\n",
      "9406/67600 (epoch 6), train_loss = 1.255, time/batch=0.069\n",
      "9407/67600 (epoch 6), train_loss = 1.239, time/batch=0.108\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9408/67600 (epoch 6), train_loss = 1.264, time/batch=0.073\n",
      "9409/67600 (epoch 6), train_loss = 1.262, time/batch=0.100\n",
      "9410/67600 (epoch 6), train_loss = 1.214, time/batch=0.082\n",
      "9411/67600 (epoch 6), train_loss = 1.275, time/batch=0.087\n",
      "9412/67600 (epoch 6), train_loss = 1.307, time/batch=0.098\n",
      "9413/67600 (epoch 6), train_loss = 1.241, time/batch=0.072\n",
      "9414/67600 (epoch 6), train_loss = 1.221, time/batch=0.097\n",
      "9415/67600 (epoch 6), train_loss = 1.248, time/batch=0.232\n",
      "9416/67600 (epoch 6), train_loss = 1.277, time/batch=0.119\n",
      "9417/67600 (epoch 6), train_loss = 1.201, time/batch=0.094\n",
      "9418/67600 (epoch 6), train_loss = 1.275, time/batch=0.072\n",
      "9419/67600 (epoch 6), train_loss = 1.256, time/batch=0.072\n",
      "9420/67600 (epoch 6), train_loss = 1.264, time/batch=0.072\n",
      "9421/67600 (epoch 6), train_loss = 1.260, time/batch=0.081\n",
      "9422/67600 (epoch 6), train_loss = 1.227, time/batch=0.073\n",
      "9423/67600 (epoch 6), train_loss = 1.247, time/batch=0.075\n",
      "9424/67600 (epoch 6), train_loss = 1.246, time/batch=0.092\n",
      "9425/67600 (epoch 6), train_loss = 1.311, time/batch=0.197\n",
      "9426/67600 (epoch 6), train_loss = 1.319, time/batch=0.073\n",
      "9427/67600 (epoch 6), train_loss = 1.260, time/batch=0.100\n",
      "9428/67600 (epoch 6), train_loss = 1.274, time/batch=0.071\n",
      "9429/67600 (epoch 6), train_loss = 1.299, time/batch=0.070\n",
      "9430/67600 (epoch 6), train_loss = 1.265, time/batch=0.071\n",
      "9431/67600 (epoch 6), train_loss = 1.237, time/batch=0.083\n",
      "9432/67600 (epoch 6), train_loss = 1.259, time/batch=0.082\n",
      "9433/67600 (epoch 6), train_loss = 1.243, time/batch=0.071\n",
      "9434/67600 (epoch 6), train_loss = 1.224, time/batch=0.081\n",
      "9435/67600 (epoch 6), train_loss = 1.255, time/batch=0.072\n",
      "9436/67600 (epoch 6), train_loss = 1.303, time/batch=0.081\n",
      "9437/67600 (epoch 6), train_loss = 1.253, time/batch=0.229\n",
      "9438/67600 (epoch 6), train_loss = 1.264, time/batch=0.109\n",
      "9439/67600 (epoch 6), train_loss = 1.250, time/batch=0.088\n",
      "9440/67600 (epoch 6), train_loss = 1.251, time/batch=0.074\n",
      "9441/67600 (epoch 6), train_loss = 1.280, time/batch=0.072\n",
      "9442/67600 (epoch 6), train_loss = 1.308, time/batch=0.075\n",
      "9443/67600 (epoch 6), train_loss = 1.315, time/batch=0.082\n",
      "9444/67600 (epoch 6), train_loss = 1.252, time/batch=0.069\n",
      "9445/67600 (epoch 6), train_loss = 1.250, time/batch=0.069\n",
      "9446/67600 (epoch 6), train_loss = 1.212, time/batch=0.072\n",
      "9447/67600 (epoch 6), train_loss = 1.277, time/batch=0.104\n",
      "9448/67600 (epoch 6), train_loss = 1.291, time/batch=0.193\n",
      "9449/67600 (epoch 6), train_loss = 1.251, time/batch=0.077\n",
      "9450/67600 (epoch 6), train_loss = 1.288, time/batch=0.083\n",
      "9451/67600 (epoch 6), train_loss = 1.251, time/batch=0.070\n",
      "9452/67600 (epoch 6), train_loss = 1.226, time/batch=0.071\n",
      "9453/67600 (epoch 6), train_loss = 1.261, time/batch=0.080\n",
      "9454/67600 (epoch 6), train_loss = 1.277, time/batch=0.082\n",
      "9455/67600 (epoch 6), train_loss = 1.244, time/batch=0.117\n",
      "9456/67600 (epoch 6), train_loss = 1.213, time/batch=0.136\n",
      "9457/67600 (epoch 6), train_loss = 1.259, time/batch=0.118\n",
      "9458/67600 (epoch 6), train_loss = 1.229, time/batch=0.081\n",
      "9459/67600 (epoch 6), train_loss = 1.255, time/batch=0.078\n",
      "9460/67600 (epoch 6), train_loss = 1.310, time/batch=0.085\n",
      "9461/67600 (epoch 6), train_loss = 1.353, time/batch=0.072\n",
      "9462/67600 (epoch 6), train_loss = 1.265, time/batch=0.073\n",
      "9463/67600 (epoch 6), train_loss = 1.278, time/batch=0.073\n",
      "9464/67600 (epoch 7), train_loss = 1.441, time/batch=0.071\n",
      "9465/67600 (epoch 7), train_loss = 1.211, time/batch=0.070\n",
      "9466/67600 (epoch 7), train_loss = 1.293, time/batch=0.181\n",
      "9467/67600 (epoch 7), train_loss = 1.241, time/batch=0.070\n",
      "9468/67600 (epoch 7), train_loss = 1.266, time/batch=0.107\n",
      "9469/67600 (epoch 7), train_loss = 1.294, time/batch=0.070\n",
      "9470/67600 (epoch 7), train_loss = 1.247, time/batch=0.068\n",
      "9471/67600 (epoch 7), train_loss = 1.264, time/batch=0.084\n",
      "9472/67600 (epoch 7), train_loss = 1.281, time/batch=0.075\n",
      "9473/67600 (epoch 7), train_loss = 1.248, time/batch=0.073\n",
      "9474/67600 (epoch 7), train_loss = 1.214, time/batch=0.073\n",
      "9475/67600 (epoch 7), train_loss = 1.236, time/batch=0.077\n",
      "9476/67600 (epoch 7), train_loss = 1.236, time/batch=0.083\n",
      "9477/67600 (epoch 7), train_loss = 1.304, time/batch=0.081\n",
      "9478/67600 (epoch 7), train_loss = 1.268, time/batch=0.197\n",
      "9479/67600 (epoch 7), train_loss = 1.248, time/batch=0.111\n",
      "9480/67600 (epoch 7), train_loss = 1.259, time/batch=0.077\n",
      "9481/67600 (epoch 7), train_loss = 1.273, time/batch=0.076\n",
      "9482/67600 (epoch 7), train_loss = 1.255, time/batch=0.070\n",
      "9483/67600 (epoch 7), train_loss = 1.251, time/batch=0.087\n",
      "9484/67600 (epoch 7), train_loss = 1.248, time/batch=0.073\n",
      "9485/67600 (epoch 7), train_loss = 1.200, time/batch=0.086\n",
      "9486/67600 (epoch 7), train_loss = 1.311, time/batch=0.081\n",
      "9487/67600 (epoch 7), train_loss = 1.293, time/batch=0.073\n",
      "9488/67600 (epoch 7), train_loss = 1.336, time/batch=0.088\n",
      "9489/67600 (epoch 7), train_loss = 1.185, time/batch=0.183\n",
      "9490/67600 (epoch 7), train_loss = 1.269, time/batch=0.091\n",
      "9491/67600 (epoch 7), train_loss = 1.305, time/batch=0.070\n",
      "9492/67600 (epoch 7), train_loss = 1.320, time/batch=0.071\n",
      "9493/67600 (epoch 7), train_loss = 1.256, time/batch=0.072\n",
      "9494/67600 (epoch 7), train_loss = 1.243, time/batch=0.069\n",
      "9495/67600 (epoch 7), train_loss = 1.321, time/batch=0.069\n",
      "9496/67600 (epoch 7), train_loss = 1.250, time/batch=0.070\n",
      "9497/67600 (epoch 7), train_loss = 1.306, time/batch=0.074\n",
      "9498/67600 (epoch 7), train_loss = 1.279, time/batch=0.072\n",
      "9499/67600 (epoch 7), train_loss = 1.262, time/batch=0.071\n",
      "9500/67600 (epoch 7), train_loss = 1.220, time/batch=0.078\n",
      "model saved to ./save/model.ckpt\n",
      "9501/67600 (epoch 7), train_loss = 1.275, time/batch=0.084\n",
      "9502/67600 (epoch 7), train_loss = 1.267, time/batch=0.072\n",
      "9503/67600 (epoch 7), train_loss = 1.260, time/batch=0.072\n",
      "9504/67600 (epoch 7), train_loss = 1.187, time/batch=0.216\n",
      "9505/67600 (epoch 7), train_loss = 1.289, time/batch=0.145\n",
      "9506/67600 (epoch 7), train_loss = 1.304, time/batch=0.104\n",
      "9507/67600 (epoch 7), train_loss = 1.281, time/batch=0.070\n",
      "9508/67600 (epoch 7), train_loss = 1.300, time/batch=0.068\n",
      "9509/67600 (epoch 7), train_loss = 1.249, time/batch=0.093\n",
      "9510/67600 (epoch 7), train_loss = 1.228, time/batch=0.078\n",
      "9511/67600 (epoch 7), train_loss = 1.269, time/batch=0.068\n",
      "9512/67600 (epoch 7), train_loss = 1.230, time/batch=0.071\n",
      "9513/67600 (epoch 7), train_loss = 1.232, time/batch=0.072\n",
      "9514/67600 (epoch 7), train_loss = 1.320, time/batch=0.073\n",
      "9515/67600 (epoch 7), train_loss = 1.240, time/batch=0.102\n",
      "9516/67600 (epoch 7), train_loss = 1.245, time/batch=0.194\n",
      "9517/67600 (epoch 7), train_loss = 1.340, time/batch=0.088\n",
      "9518/67600 (epoch 7), train_loss = 1.299, time/batch=0.070\n",
      "9519/67600 (epoch 7), train_loss = 1.264, time/batch=0.072\n",
      "9520/67600 (epoch 7), train_loss = 1.264, time/batch=0.074\n",
      "9521/67600 (epoch 7), train_loss = 1.262, time/batch=0.072\n",
      "9522/67600 (epoch 7), train_loss = 1.267, time/batch=0.080\n",
      "9523/67600 (epoch 7), train_loss = 1.273, time/batch=0.223\n",
      "9524/67600 (epoch 7), train_loss = 1.267, time/batch=0.073\n",
      "9525/67600 (epoch 7), train_loss = 1.254, time/batch=0.123\n",
      "9526/67600 (epoch 7), train_loss = 1.291, time/batch=0.078\n",
      "9527/67600 (epoch 7), train_loss = 1.305, time/batch=0.095\n",
      "9528/67600 (epoch 7), train_loss = 1.253, time/batch=0.093\n",
      "9529/67600 (epoch 7), train_loss = 1.240, time/batch=0.072\n",
      "9530/67600 (epoch 7), train_loss = 1.248, time/batch=0.071\n",
      "9531/67600 (epoch 7), train_loss = 1.276, time/batch=0.070\n",
      "9532/67600 (epoch 7), train_loss = 1.292, time/batch=0.076\n",
      "9533/67600 (epoch 7), train_loss = 1.283, time/batch=0.070\n",
      "9534/67600 (epoch 7), train_loss = 1.279, time/batch=0.176\n",
      "9535/67600 (epoch 7), train_loss = 1.281, time/batch=0.071\n",
      "9536/67600 (epoch 7), train_loss = 1.243, time/batch=0.134\n",
      "9537/67600 (epoch 7), train_loss = 1.308, time/batch=0.073\n",
      "9538/67600 (epoch 7), train_loss = 1.256, time/batch=0.081\n",
      "9539/67600 (epoch 7), train_loss = 1.310, time/batch=0.074\n",
      "9540/67600 (epoch 7), train_loss = 1.302, time/batch=0.071\n",
      "9541/67600 (epoch 7), train_loss = 1.391, time/batch=0.073\n",
      "9542/67600 (epoch 7), train_loss = 1.309, time/batch=0.086\n",
      "9543/67600 (epoch 7), train_loss = 1.240, time/batch=0.074\n",
      "9544/67600 (epoch 7), train_loss = 1.221, time/batch=0.071\n",
      "9545/67600 (epoch 7), train_loss = 1.266, time/batch=0.211\n",
      "9546/67600 (epoch 7), train_loss = 1.274, time/batch=0.124\n",
      "9547/67600 (epoch 7), train_loss = 1.259, time/batch=0.070\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9548/67600 (epoch 7), train_loss = 1.261, time/batch=0.085\n",
      "9549/67600 (epoch 7), train_loss = 1.254, time/batch=0.085\n",
      "9550/67600 (epoch 7), train_loss = 1.198, time/batch=0.076\n",
      "9551/67600 (epoch 7), train_loss = 1.313, time/batch=0.100\n",
      "9552/67600 (epoch 7), train_loss = 1.297, time/batch=0.076\n",
      "9553/67600 (epoch 7), train_loss = 1.295, time/batch=0.080\n",
      "9554/67600 (epoch 7), train_loss = 1.269, time/batch=0.083\n",
      "9555/67600 (epoch 7), train_loss = 1.282, time/batch=0.200\n",
      "9556/67600 (epoch 7), train_loss = 1.216, time/batch=0.084\n",
      "9557/67600 (epoch 7), train_loss = 1.231, time/batch=0.100\n",
      "9558/67600 (epoch 7), train_loss = 1.228, time/batch=0.071\n",
      "9559/67600 (epoch 7), train_loss = 1.168, time/batch=0.074\n",
      "9560/67600 (epoch 7), train_loss = 1.188, time/batch=0.074\n",
      "9561/67600 (epoch 7), train_loss = 1.269, time/batch=0.080\n",
      "9562/67600 (epoch 7), train_loss = 1.249, time/batch=0.076\n",
      "9563/67600 (epoch 7), train_loss = 1.302, time/batch=0.071\n",
      "9564/67600 (epoch 7), train_loss = 1.168, time/batch=0.072\n",
      "9565/67600 (epoch 7), train_loss = 1.246, time/batch=0.077\n",
      "9566/67600 (epoch 7), train_loss = 1.282, time/batch=0.124\n",
      "9567/67600 (epoch 7), train_loss = 1.195, time/batch=0.180\n",
      "9568/67600 (epoch 7), train_loss = 1.226, time/batch=0.093\n",
      "9569/67600 (epoch 7), train_loss = 1.273, time/batch=0.072\n",
      "9570/67600 (epoch 7), train_loss = 1.230, time/batch=0.085\n",
      "9571/67600 (epoch 7), train_loss = 1.271, time/batch=0.084\n",
      "9572/67600 (epoch 7), train_loss = 1.298, time/batch=0.072\n",
      "9573/67600 (epoch 7), train_loss = 1.260, time/batch=0.073\n",
      "9574/67600 (epoch 7), train_loss = 1.223, time/batch=0.069\n",
      "9575/67600 (epoch 7), train_loss = 1.263, time/batch=0.094\n",
      "9576/67600 (epoch 7), train_loss = 1.248, time/batch=0.080\n",
      "9577/67600 (epoch 7), train_loss = 1.285, time/batch=0.227\n",
      "9578/67600 (epoch 7), train_loss = 1.281, time/batch=0.088\n",
      "9579/67600 (epoch 7), train_loss = 1.227, time/batch=0.073\n",
      "9580/67600 (epoch 7), train_loss = 1.212, time/batch=0.070\n",
      "9581/67600 (epoch 7), train_loss = 1.251, time/batch=0.072\n",
      "9582/67600 (epoch 7), train_loss = 1.280, time/batch=0.076\n",
      "9583/67600 (epoch 7), train_loss = 1.276, time/batch=0.089\n",
      "9584/67600 (epoch 7), train_loss = 1.269, time/batch=0.072\n",
      "9585/67600 (epoch 7), train_loss = 1.278, time/batch=0.182\n",
      "9586/67600 (epoch 7), train_loss = 1.249, time/batch=0.073\n",
      "9587/67600 (epoch 7), train_loss = 1.228, time/batch=0.119\n",
      "9588/67600 (epoch 7), train_loss = 1.245, time/batch=0.087\n",
      "9589/67600 (epoch 7), train_loss = 1.171, time/batch=0.074\n",
      "9590/67600 (epoch 7), train_loss = 1.253, time/batch=0.085\n",
      "9591/67600 (epoch 7), train_loss = 1.288, time/batch=0.073\n",
      "9592/67600 (epoch 7), train_loss = 1.228, time/batch=0.119\n",
      "9593/67600 (epoch 7), train_loss = 1.248, time/batch=0.071\n",
      "9594/67600 (epoch 7), train_loss = 1.273, time/batch=0.090\n",
      "9595/67600 (epoch 7), train_loss = 1.246, time/batch=0.179\n",
      "9596/67600 (epoch 7), train_loss = 1.299, time/batch=0.079\n",
      "9597/67600 (epoch 7), train_loss = 1.240, time/batch=0.101\n",
      "9598/67600 (epoch 7), train_loss = 1.264, time/batch=0.070\n",
      "9599/67600 (epoch 7), train_loss = 1.266, time/batch=0.078\n",
      "9600/67600 (epoch 7), train_loss = 1.281, time/batch=0.071\n",
      "9601/67600 (epoch 7), train_loss = 1.259, time/batch=0.070\n",
      "9602/67600 (epoch 7), train_loss = 1.262, time/batch=0.070\n",
      "9603/67600 (epoch 7), train_loss = 1.236, time/batch=0.073\n",
      "9604/67600 (epoch 7), train_loss = 1.229, time/batch=0.087\n",
      "9605/67600 (epoch 7), train_loss = 1.207, time/batch=0.087\n",
      "9606/67600 (epoch 7), train_loss = 1.267, time/batch=0.074\n",
      "9607/67600 (epoch 7), train_loss = 1.220, time/batch=0.215\n",
      "9608/67600 (epoch 7), train_loss = 1.302, time/batch=0.128\n",
      "9609/67600 (epoch 7), train_loss = 1.340, time/batch=0.072\n",
      "9610/67600 (epoch 7), train_loss = 1.260, time/batch=0.071\n",
      "9611/67600 (epoch 7), train_loss = 1.251, time/batch=0.073\n",
      "9612/67600 (epoch 7), train_loss = 1.305, time/batch=0.071\n",
      "9613/67600 (epoch 7), train_loss = 1.186, time/batch=0.073\n",
      "9614/67600 (epoch 7), train_loss = 1.269, time/batch=0.090\n",
      "9615/67600 (epoch 7), train_loss = 1.228, time/batch=0.106\n",
      "9616/67600 (epoch 7), train_loss = 1.207, time/batch=0.089\n",
      "9617/67600 (epoch 7), train_loss = 1.244, time/batch=0.229\n",
      "9618/67600 (epoch 7), train_loss = 1.223, time/batch=0.093\n",
      "9619/67600 (epoch 7), train_loss = 1.275, time/batch=0.070\n",
      "9620/67600 (epoch 7), train_loss = 1.285, time/batch=0.070\n",
      "9621/67600 (epoch 7), train_loss = 1.284, time/batch=0.071\n",
      "9622/67600 (epoch 7), train_loss = 1.268, time/batch=0.078\n",
      "9623/67600 (epoch 7), train_loss = 1.240, time/batch=0.085\n",
      "9624/67600 (epoch 7), train_loss = 1.235, time/batch=0.071\n",
      "9625/67600 (epoch 7), train_loss = 1.201, time/batch=0.095\n",
      "9626/67600 (epoch 7), train_loss = 1.255, time/batch=0.073\n",
      "9627/67600 (epoch 7), train_loss = 1.261, time/batch=0.079\n",
      "9628/67600 (epoch 7), train_loss = 1.157, time/batch=0.216\n",
      "9629/67600 (epoch 7), train_loss = 1.246, time/batch=0.116\n",
      "9630/67600 (epoch 7), train_loss = 1.243, time/batch=0.081\n",
      "9631/67600 (epoch 7), train_loss = 1.223, time/batch=0.091\n",
      "9632/67600 (epoch 7), train_loss = 1.266, time/batch=0.091\n",
      "9633/67600 (epoch 7), train_loss = 1.286, time/batch=0.075\n",
      "9634/67600 (epoch 7), train_loss = 1.275, time/batch=0.084\n",
      "9635/67600 (epoch 7), train_loss = 1.213, time/batch=0.072\n",
      "9636/67600 (epoch 7), train_loss = 1.279, time/batch=0.081\n",
      "9637/67600 (epoch 7), train_loss = 1.231, time/batch=0.089\n",
      "9638/67600 (epoch 7), train_loss = 1.222, time/batch=0.240\n",
      "9639/67600 (epoch 7), train_loss = 1.210, time/batch=0.085\n",
      "9640/67600 (epoch 7), train_loss = 1.271, time/batch=0.084\n",
      "9641/67600 (epoch 7), train_loss = 1.299, time/batch=0.072\n",
      "9642/67600 (epoch 7), train_loss = 1.217, time/batch=0.083\n",
      "9643/67600 (epoch 7), train_loss = 1.227, time/batch=0.069\n",
      "9644/67600 (epoch 7), train_loss = 1.190, time/batch=0.072\n",
      "9645/67600 (epoch 7), train_loss = 1.189, time/batch=0.092\n",
      "9646/67600 (epoch 7), train_loss = 1.228, time/batch=0.092\n",
      "9647/67600 (epoch 7), train_loss = 1.334, time/batch=0.069\n",
      "9648/67600 (epoch 7), train_loss = 1.348, time/batch=0.072\n",
      "9649/67600 (epoch 7), train_loss = 1.319, time/batch=0.076\n",
      "9650/67600 (epoch 7), train_loss = 1.345, time/batch=0.074\n",
      "9651/67600 (epoch 7), train_loss = 1.254, time/batch=0.070\n",
      "9652/67600 (epoch 7), train_loss = 1.260, time/batch=0.070\n",
      "9653/67600 (epoch 7), train_loss = 1.257, time/batch=0.071\n",
      "9654/67600 (epoch 7), train_loss = 1.326, time/batch=0.071\n",
      "9655/67600 (epoch 7), train_loss = 1.287, time/batch=0.170\n",
      "9656/67600 (epoch 7), train_loss = 1.242, time/batch=0.149\n",
      "9657/67600 (epoch 7), train_loss = 1.285, time/batch=0.095\n",
      "9658/67600 (epoch 7), train_loss = 1.280, time/batch=0.094\n",
      "9659/67600 (epoch 7), train_loss = 1.265, time/batch=0.072\n",
      "9660/67600 (epoch 7), train_loss = 1.250, time/batch=0.074\n",
      "9661/67600 (epoch 7), train_loss = 1.248, time/batch=0.068\n",
      "9662/67600 (epoch 7), train_loss = 1.273, time/batch=0.069\n",
      "9663/67600 (epoch 7), train_loss = 1.226, time/batch=0.069\n",
      "9664/67600 (epoch 7), train_loss = 1.212, time/batch=0.071\n",
      "9665/67600 (epoch 7), train_loss = 1.190, time/batch=0.076\n",
      "9666/67600 (epoch 7), train_loss = 1.313, time/batch=0.071\n",
      "9667/67600 (epoch 7), train_loss = 1.260, time/batch=0.213\n",
      "9668/67600 (epoch 7), train_loss = 1.281, time/batch=0.111\n",
      "9669/67600 (epoch 7), train_loss = 1.195, time/batch=0.100\n",
      "9670/67600 (epoch 7), train_loss = 1.194, time/batch=0.068\n",
      "9671/67600 (epoch 7), train_loss = 1.225, time/batch=0.066\n",
      "9672/67600 (epoch 7), train_loss = 1.270, time/batch=0.079\n",
      "9673/67600 (epoch 7), train_loss = 1.307, time/batch=0.066\n",
      "9674/67600 (epoch 7), train_loss = 1.275, time/batch=0.078\n",
      "9675/67600 (epoch 7), train_loss = 1.332, time/batch=0.072\n",
      "9676/67600 (epoch 7), train_loss = 1.229, time/batch=0.071\n",
      "9677/67600 (epoch 7), train_loss = 1.240, time/batch=0.067\n",
      "9678/67600 (epoch 7), train_loss = 1.248, time/batch=0.222\n",
      "9679/67600 (epoch 7), train_loss = 1.293, time/batch=0.098\n",
      "9680/67600 (epoch 7), train_loss = 1.233, time/batch=0.068\n",
      "9681/67600 (epoch 7), train_loss = 1.249, time/batch=0.066\n",
      "9682/67600 (epoch 7), train_loss = 1.223, time/batch=0.077\n",
      "9683/67600 (epoch 7), train_loss = 1.207, time/batch=0.077\n",
      "9684/67600 (epoch 7), train_loss = 1.312, time/batch=0.078\n",
      "9685/67600 (epoch 7), train_loss = 1.215, time/batch=0.071\n",
      "9686/67600 (epoch 7), train_loss = 1.263, time/batch=0.150\n",
      "9687/67600 (epoch 7), train_loss = 1.255, time/batch=0.108\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9688/67600 (epoch 7), train_loss = 1.252, time/batch=0.125\n",
      "9689/67600 (epoch 7), train_loss = 1.231, time/batch=0.071\n",
      "9690/67600 (epoch 7), train_loss = 1.293, time/batch=0.078\n",
      "9691/67600 (epoch 7), train_loss = 1.209, time/batch=0.073\n",
      "9692/67600 (epoch 7), train_loss = 1.222, time/batch=0.088\n",
      "9693/67600 (epoch 7), train_loss = 1.222, time/batch=0.068\n",
      "9694/67600 (epoch 7), train_loss = 1.260, time/batch=0.068\n",
      "9695/67600 (epoch 7), train_loss = 1.257, time/batch=0.064\n",
      "9696/67600 (epoch 7), train_loss = 1.189, time/batch=0.064\n",
      "9697/67600 (epoch 7), train_loss = 1.192, time/batch=0.063\n",
      "9698/67600 (epoch 7), train_loss = 1.259, time/batch=0.152\n",
      "9699/67600 (epoch 7), train_loss = 1.244, time/batch=0.095\n",
      "9700/67600 (epoch 7), train_loss = 1.233, time/batch=0.101\n",
      "9701/67600 (epoch 7), train_loss = 1.236, time/batch=0.067\n",
      "9702/67600 (epoch 7), train_loss = 1.296, time/batch=0.065\n",
      "9703/67600 (epoch 7), train_loss = 1.267, time/batch=0.067\n",
      "9704/67600 (epoch 7), train_loss = 1.265, time/batch=0.076\n",
      "9705/67600 (epoch 7), train_loss = 1.205, time/batch=0.075\n",
      "9706/67600 (epoch 7), train_loss = 1.250, time/batch=0.069\n",
      "9707/67600 (epoch 7), train_loss = 1.265, time/batch=0.077\n",
      "9708/67600 (epoch 7), train_loss = 1.204, time/batch=0.063\n",
      "9709/67600 (epoch 7), train_loss = 1.263, time/batch=0.064\n",
      "9710/67600 (epoch 7), train_loss = 1.243, time/batch=0.063\n",
      "9711/67600 (epoch 7), train_loss = 1.250, time/batch=0.186\n",
      "9712/67600 (epoch 7), train_loss = 1.276, time/batch=0.065\n",
      "9713/67600 (epoch 7), train_loss = 1.219, time/batch=0.091\n",
      "9714/67600 (epoch 7), train_loss = 1.217, time/batch=0.067\n",
      "9715/67600 (epoch 7), train_loss = 1.298, time/batch=0.067\n",
      "9716/67600 (epoch 7), train_loss = 1.218, time/batch=0.078\n",
      "9717/67600 (epoch 7), train_loss = 1.260, time/batch=0.092\n",
      "9718/67600 (epoch 7), train_loss = 1.268, time/batch=0.074\n",
      "9719/67600 (epoch 7), train_loss = 1.318, time/batch=0.066\n",
      "9720/67600 (epoch 7), train_loss = 1.294, time/batch=0.066\n",
      "9721/67600 (epoch 7), train_loss = 1.297, time/batch=0.066\n",
      "9722/67600 (epoch 7), train_loss = 1.207, time/batch=0.064\n",
      "9723/67600 (epoch 7), train_loss = 1.218, time/batch=0.191\n",
      "9724/67600 (epoch 7), train_loss = 1.238, time/batch=0.076\n",
      "9725/67600 (epoch 7), train_loss = 1.233, time/batch=0.083\n",
      "9726/67600 (epoch 7), train_loss = 1.247, time/batch=0.079\n",
      "9727/67600 (epoch 7), train_loss = 1.262, time/batch=0.066\n",
      "9728/67600 (epoch 7), train_loss = 1.232, time/batch=0.065\n",
      "9729/67600 (epoch 7), train_loss = 1.234, time/batch=0.085\n",
      "9730/67600 (epoch 7), train_loss = 1.215, time/batch=0.068\n",
      "9731/67600 (epoch 7), train_loss = 1.257, time/batch=0.066\n",
      "9732/67600 (epoch 7), train_loss = 1.232, time/batch=0.075\n",
      "9733/67600 (epoch 7), train_loss = 1.220, time/batch=0.064\n",
      "9734/67600 (epoch 7), train_loss = 1.281, time/batch=0.066\n",
      "9735/67600 (epoch 7), train_loss = 1.248, time/batch=0.207\n",
      "9736/67600 (epoch 7), train_loss = 1.256, time/batch=0.072\n",
      "9737/67600 (epoch 7), train_loss = 1.297, time/batch=0.071\n",
      "9738/67600 (epoch 7), train_loss = 1.265, time/batch=0.067\n",
      "9739/67600 (epoch 7), train_loss = 1.248, time/batch=0.073\n",
      "9740/67600 (epoch 7), train_loss = 1.262, time/batch=0.066\n",
      "9741/67600 (epoch 7), train_loss = 1.216, time/batch=0.067\n",
      "9742/67600 (epoch 7), train_loss = 1.216, time/batch=0.075\n",
      "9743/67600 (epoch 7), train_loss = 1.279, time/batch=0.077\n",
      "9744/67600 (epoch 7), train_loss = 1.291, time/batch=0.186\n",
      "9745/67600 (epoch 7), train_loss = 1.232, time/batch=0.068\n",
      "9746/67600 (epoch 7), train_loss = 1.184, time/batch=0.096\n",
      "9747/67600 (epoch 7), train_loss = 1.269, time/batch=0.068\n",
      "9748/67600 (epoch 7), train_loss = 1.218, time/batch=0.070\n",
      "9749/67600 (epoch 7), train_loss = 1.337, time/batch=0.072\n",
      "9750/67600 (epoch 7), train_loss = 1.267, time/batch=0.066\n",
      "9751/67600 (epoch 7), train_loss = 1.247, time/batch=0.068\n",
      "9752/67600 (epoch 7), train_loss = 1.283, time/batch=0.074\n",
      "9753/67600 (epoch 7), train_loss = 1.275, time/batch=0.066\n",
      "9754/67600 (epoch 7), train_loss = 1.272, time/batch=0.080\n",
      "9755/67600 (epoch 7), train_loss = 1.260, time/batch=0.070\n",
      "9756/67600 (epoch 7), train_loss = 1.260, time/batch=0.179\n",
      "9757/67600 (epoch 7), train_loss = 1.257, time/batch=0.068\n",
      "9758/67600 (epoch 7), train_loss = 1.262, time/batch=0.099\n",
      "9759/67600 (epoch 7), train_loss = 1.270, time/batch=0.066\n",
      "9760/67600 (epoch 7), train_loss = 1.263, time/batch=0.071\n",
      "9761/67600 (epoch 7), train_loss = 1.231, time/batch=0.065\n",
      "9762/67600 (epoch 7), train_loss = 1.232, time/batch=0.063\n",
      "9763/67600 (epoch 7), train_loss = 1.288, time/batch=0.076\n",
      "9764/67600 (epoch 7), train_loss = 1.253, time/batch=0.068\n",
      "9765/67600 (epoch 7), train_loss = 1.282, time/batch=0.065\n",
      "9766/67600 (epoch 7), train_loss = 1.244, time/batch=0.062\n",
      "9767/67600 (epoch 7), train_loss = 1.271, time/batch=0.067\n",
      "9768/67600 (epoch 7), train_loss = 1.269, time/batch=0.065\n",
      "9769/67600 (epoch 7), train_loss = 1.281, time/batch=0.172\n",
      "9770/67600 (epoch 7), train_loss = 1.308, time/batch=0.070\n",
      "9771/67600 (epoch 7), train_loss = 1.278, time/batch=0.094\n",
      "9772/67600 (epoch 7), train_loss = 1.292, time/batch=0.068\n",
      "9773/67600 (epoch 7), train_loss = 1.289, time/batch=0.068\n",
      "9774/67600 (epoch 7), train_loss = 1.256, time/batch=0.085\n",
      "9775/67600 (epoch 7), train_loss = 1.213, time/batch=0.080\n",
      "9776/67600 (epoch 7), train_loss = 1.230, time/batch=0.067\n",
      "9777/67600 (epoch 7), train_loss = 1.284, time/batch=0.065\n",
      "9778/67600 (epoch 7), train_loss = 1.253, time/batch=0.065\n",
      "9779/67600 (epoch 7), train_loss = 1.335, time/batch=0.066\n",
      "9780/67600 (epoch 7), train_loss = 1.246, time/batch=0.066\n",
      "9781/67600 (epoch 7), train_loss = 1.281, time/batch=0.089\n",
      "9782/67600 (epoch 7), train_loss = 1.284, time/batch=0.165\n",
      "9783/67600 (epoch 7), train_loss = 1.292, time/batch=0.091\n",
      "9784/67600 (epoch 7), train_loss = 1.308, time/batch=0.076\n",
      "9785/67600 (epoch 7), train_loss = 1.256, time/batch=0.067\n",
      "9786/67600 (epoch 7), train_loss = 1.266, time/batch=0.065\n",
      "9787/67600 (epoch 7), train_loss = 1.224, time/batch=0.067\n",
      "9788/67600 (epoch 7), train_loss = 1.250, time/batch=0.067\n",
      "9789/67600 (epoch 7), train_loss = 1.221, time/batch=0.071\n",
      "9790/67600 (epoch 7), train_loss = 1.222, time/batch=0.065\n",
      "9791/67600 (epoch 7), train_loss = 1.286, time/batch=0.064\n",
      "9792/67600 (epoch 7), train_loss = 1.247, time/batch=0.087\n",
      "9793/67600 (epoch 7), train_loss = 1.262, time/batch=0.070\n",
      "9794/67600 (epoch 7), train_loss = 1.289, time/batch=0.190\n",
      "9795/67600 (epoch 7), train_loss = 1.204, time/batch=0.089\n",
      "9796/67600 (epoch 7), train_loss = 1.264, time/batch=0.067\n",
      "9797/67600 (epoch 7), train_loss = 1.251, time/batch=0.065\n",
      "9798/67600 (epoch 7), train_loss = 1.268, time/batch=0.064\n",
      "9799/67600 (epoch 7), train_loss = 1.289, time/batch=0.065\n",
      "9800/67600 (epoch 7), train_loss = 1.243, time/batch=0.075\n",
      "9801/67600 (epoch 7), train_loss = 1.228, time/batch=0.066\n",
      "9802/67600 (epoch 7), train_loss = 1.261, time/batch=0.067\n",
      "9803/67600 (epoch 7), train_loss = 1.296, time/batch=0.076\n",
      "9804/67600 (epoch 7), train_loss = 1.245, time/batch=0.065\n",
      "9805/67600 (epoch 7), train_loss = 1.231, time/batch=0.066\n",
      "9806/67600 (epoch 7), train_loss = 1.220, time/batch=0.120\n",
      "9807/67600 (epoch 7), train_loss = 1.208, time/batch=0.143\n",
      "9808/67600 (epoch 7), train_loss = 1.304, time/batch=0.074\n",
      "9809/67600 (epoch 7), train_loss = 1.326, time/batch=0.068\n",
      "9810/67600 (epoch 7), train_loss = 1.264, time/batch=0.065\n",
      "9811/67600 (epoch 7), train_loss = 1.256, time/batch=0.065\n",
      "9812/67600 (epoch 7), train_loss = 1.303, time/batch=0.068\n",
      "9813/67600 (epoch 7), train_loss = 1.305, time/batch=0.066\n",
      "9814/67600 (epoch 7), train_loss = 1.217, time/batch=0.086\n",
      "9815/67600 (epoch 7), train_loss = 1.211, time/batch=0.124\n",
      "9816/67600 (epoch 7), train_loss = 1.197, time/batch=0.080\n",
      "9817/67600 (epoch 7), train_loss = 1.223, time/batch=0.070\n",
      "9818/67600 (epoch 7), train_loss = 1.229, time/batch=0.067\n",
      "9819/67600 (epoch 7), train_loss = 1.295, time/batch=0.065\n",
      "9820/67600 (epoch 7), train_loss = 1.230, time/batch=0.071\n",
      "9821/67600 (epoch 7), train_loss = 1.243, time/batch=0.066\n",
      "9822/67600 (epoch 7), train_loss = 1.196, time/batch=0.067\n",
      "9823/67600 (epoch 7), train_loss = 1.336, time/batch=0.071\n",
      "9824/67600 (epoch 7), train_loss = 1.252, time/batch=0.065\n",
      "9825/67600 (epoch 7), train_loss = 1.215, time/batch=0.077\n",
      "9826/67600 (epoch 7), train_loss = 1.219, time/batch=0.235\n",
      "9827/67600 (epoch 7), train_loss = 1.301, time/batch=0.081\n",
      "9828/67600 (epoch 7), train_loss = 1.250, time/batch=0.067\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9829/67600 (epoch 7), train_loss = 1.234, time/batch=0.067\n",
      "9830/67600 (epoch 7), train_loss = 1.245, time/batch=0.065\n",
      "9831/67600 (epoch 7), train_loss = 1.195, time/batch=0.083\n",
      "9832/67600 (epoch 7), train_loss = 1.251, time/batch=0.080\n",
      "9833/67600 (epoch 7), train_loss = 1.322, time/batch=0.070\n",
      "9834/67600 (epoch 7), train_loss = 1.250, time/batch=0.072\n",
      "9835/67600 (epoch 7), train_loss = 1.250, time/batch=0.073\n",
      "9836/67600 (epoch 7), train_loss = 1.284, time/batch=0.067\n",
      "9837/67600 (epoch 7), train_loss = 1.257, time/batch=0.106\n",
      "9838/67600 (epoch 7), train_loss = 1.319, time/batch=0.178\n",
      "9839/67600 (epoch 7), train_loss = 1.326, time/batch=0.076\n",
      "9840/67600 (epoch 7), train_loss = 1.278, time/batch=0.066\n",
      "9841/67600 (epoch 7), train_loss = 1.261, time/batch=0.065\n",
      "9842/67600 (epoch 7), train_loss = 1.324, time/batch=0.064\n",
      "9843/67600 (epoch 7), train_loss = 1.334, time/batch=0.067\n",
      "9844/67600 (epoch 7), train_loss = 1.288, time/batch=0.063\n",
      "9845/67600 (epoch 7), train_loss = 1.255, time/batch=0.083\n",
      "9846/67600 (epoch 7), train_loss = 1.250, time/batch=0.064\n",
      "9847/67600 (epoch 7), train_loss = 1.284, time/batch=0.066\n",
      "9848/67600 (epoch 7), train_loss = 1.339, time/batch=0.065\n",
      "9849/67600 (epoch 7), train_loss = 1.255, time/batch=0.070\n",
      "9850/67600 (epoch 7), train_loss = 1.244, time/batch=0.154\n",
      "9851/67600 (epoch 7), train_loss = 1.248, time/batch=0.117\n",
      "9852/67600 (epoch 7), train_loss = 1.298, time/batch=0.070\n",
      "9853/67600 (epoch 7), train_loss = 1.269, time/batch=0.071\n",
      "9854/67600 (epoch 7), train_loss = 1.246, time/batch=0.067\n",
      "9855/67600 (epoch 7), train_loss = 1.242, time/batch=0.081\n",
      "9856/67600 (epoch 7), train_loss = 1.243, time/batch=0.073\n",
      "9857/67600 (epoch 7), train_loss = 1.259, time/batch=0.066\n",
      "9858/67600 (epoch 7), train_loss = 1.244, time/batch=0.066\n",
      "9859/67600 (epoch 7), train_loss = 1.246, time/batch=0.133\n",
      "9860/67600 (epoch 7), train_loss = 1.307, time/batch=0.098\n",
      "9861/67600 (epoch 7), train_loss = 1.304, time/batch=0.112\n",
      "9862/67600 (epoch 7), train_loss = 1.257, time/batch=0.063\n",
      "9863/67600 (epoch 7), train_loss = 1.240, time/batch=0.084\n",
      "9864/67600 (epoch 7), train_loss = 1.288, time/batch=0.091\n",
      "9865/67600 (epoch 7), train_loss = 1.335, time/batch=0.073\n",
      "9866/67600 (epoch 7), train_loss = 1.319, time/batch=0.070\n",
      "9867/67600 (epoch 7), train_loss = 1.276, time/batch=0.075\n",
      "9868/67600 (epoch 7), train_loss = 1.344, time/batch=0.064\n",
      "9869/67600 (epoch 7), train_loss = 1.297, time/batch=0.085\n",
      "9870/67600 (epoch 7), train_loss = 1.312, time/batch=0.067\n",
      "9871/67600 (epoch 7), train_loss = 1.246, time/batch=0.170\n",
      "9872/67600 (epoch 7), train_loss = 1.290, time/batch=0.065\n",
      "9873/67600 (epoch 7), train_loss = 1.288, time/batch=0.102\n",
      "9874/67600 (epoch 7), train_loss = 1.286, time/batch=0.071\n",
      "9875/67600 (epoch 7), train_loss = 1.223, time/batch=0.067\n",
      "9876/67600 (epoch 7), train_loss = 1.254, time/batch=0.068\n",
      "9877/67600 (epoch 7), train_loss = 1.268, time/batch=0.062\n",
      "9878/67600 (epoch 7), train_loss = 1.247, time/batch=0.065\n",
      "9879/67600 (epoch 7), train_loss = 1.307, time/batch=0.063\n",
      "9880/67600 (epoch 7), train_loss = 1.268, time/batch=0.065\n",
      "9881/67600 (epoch 7), train_loss = 1.299, time/batch=0.075\n",
      "9882/67600 (epoch 7), train_loss = 1.307, time/batch=0.066\n",
      "9883/67600 (epoch 7), train_loss = 1.235, time/batch=0.071\n",
      "9884/67600 (epoch 7), train_loss = 1.181, time/batch=0.178\n",
      "9885/67600 (epoch 7), train_loss = 1.205, time/batch=0.067\n",
      "9886/67600 (epoch 7), train_loss = 1.254, time/batch=0.095\n",
      "9887/67600 (epoch 7), train_loss = 1.212, time/batch=0.077\n",
      "9888/67600 (epoch 7), train_loss = 1.256, time/batch=0.064\n",
      "9889/67600 (epoch 7), train_loss = 1.235, time/batch=0.068\n",
      "9890/67600 (epoch 7), train_loss = 1.242, time/batch=0.063\n",
      "9891/67600 (epoch 7), train_loss = 1.245, time/batch=0.067\n",
      "9892/67600 (epoch 7), train_loss = 1.166, time/batch=0.066\n",
      "9893/67600 (epoch 7), train_loss = 1.231, time/batch=0.065\n",
      "9894/67600 (epoch 7), train_loss = 1.293, time/batch=0.066\n",
      "9895/67600 (epoch 7), train_loss = 1.217, time/batch=0.082\n",
      "9896/67600 (epoch 7), train_loss = 1.282, time/batch=0.113\n",
      "9897/67600 (epoch 7), train_loss = 1.277, time/batch=0.156\n",
      "9898/67600 (epoch 7), train_loss = 1.220, time/batch=0.084\n",
      "9899/67600 (epoch 7), train_loss = 1.321, time/batch=0.074\n",
      "9900/67600 (epoch 7), train_loss = 1.253, time/batch=0.067\n",
      "9901/67600 (epoch 7), train_loss = 1.261, time/batch=0.071\n",
      "9902/67600 (epoch 7), train_loss = 1.270, time/batch=0.072\n",
      "9903/67600 (epoch 7), train_loss = 1.243, time/batch=0.087\n",
      "9904/67600 (epoch 7), train_loss = 1.235, time/batch=0.111\n",
      "9905/67600 (epoch 7), train_loss = 1.276, time/batch=0.094\n",
      "9906/67600 (epoch 7), train_loss = 1.234, time/batch=0.147\n",
      "9907/67600 (epoch 7), train_loss = 1.222, time/batch=0.237\n",
      "9908/67600 (epoch 7), train_loss = 1.267, time/batch=0.084\n",
      "9909/67600 (epoch 7), train_loss = 1.296, time/batch=0.093\n",
      "9910/67600 (epoch 7), train_loss = 1.213, time/batch=0.083\n",
      "9911/67600 (epoch 7), train_loss = 1.228, time/batch=0.083\n",
      "9912/67600 (epoch 7), train_loss = 1.202, time/batch=0.072\n",
      "9913/67600 (epoch 7), train_loss = 1.224, time/batch=0.071\n",
      "9914/67600 (epoch 7), train_loss = 1.177, time/batch=0.156\n",
      "9915/67600 (epoch 7), train_loss = 1.288, time/batch=0.087\n",
      "9916/67600 (epoch 7), train_loss = 1.298, time/batch=0.104\n",
      "9917/67600 (epoch 7), train_loss = 1.190, time/batch=0.084\n",
      "9918/67600 (epoch 7), train_loss = 1.175, time/batch=0.068\n",
      "9919/67600 (epoch 7), train_loss = 1.213, time/batch=0.071\n",
      "9920/67600 (epoch 7), train_loss = 1.239, time/batch=0.066\n",
      "9921/67600 (epoch 7), train_loss = 1.253, time/batch=0.067\n",
      "9922/67600 (epoch 7), train_loss = 1.278, time/batch=0.066\n",
      "9923/67600 (epoch 7), train_loss = 1.248, time/batch=0.065\n",
      "9924/67600 (epoch 7), train_loss = 1.267, time/batch=0.067\n",
      "9925/67600 (epoch 7), train_loss = 1.217, time/batch=0.092\n",
      "9926/67600 (epoch 7), train_loss = 1.279, time/batch=0.165\n",
      "9927/67600 (epoch 7), train_loss = 1.252, time/batch=0.080\n",
      "9928/67600 (epoch 7), train_loss = 1.222, time/batch=0.098\n",
      "9929/67600 (epoch 7), train_loss = 1.238, time/batch=0.066\n",
      "9930/67600 (epoch 7), train_loss = 1.237, time/batch=0.068\n",
      "9931/67600 (epoch 7), train_loss = 1.299, time/batch=0.071\n",
      "9932/67600 (epoch 7), train_loss = 1.250, time/batch=0.065\n",
      "9933/67600 (epoch 7), train_loss = 1.218, time/batch=0.073\n",
      "9934/67600 (epoch 7), train_loss = 1.239, time/batch=0.066\n",
      "9935/67600 (epoch 7), train_loss = 1.246, time/batch=0.084\n",
      "9936/67600 (epoch 7), train_loss = 1.213, time/batch=0.070\n",
      "9937/67600 (epoch 7), train_loss = 1.259, time/batch=0.064\n",
      "9938/67600 (epoch 7), train_loss = 1.221, time/batch=0.159\n",
      "9939/67600 (epoch 7), train_loss = 1.191, time/batch=0.104\n",
      "9940/67600 (epoch 7), train_loss = 1.278, time/batch=0.093\n",
      "9941/67600 (epoch 7), train_loss = 1.209, time/batch=0.076\n",
      "9942/67600 (epoch 7), train_loss = 1.229, time/batch=0.064\n",
      "9943/67600 (epoch 7), train_loss = 1.258, time/batch=0.080\n",
      "9944/67600 (epoch 7), train_loss = 1.211, time/batch=0.069\n",
      "9945/67600 (epoch 7), train_loss = 1.245, time/batch=0.063\n",
      "9946/67600 (epoch 7), train_loss = 1.230, time/batch=0.075\n",
      "9947/67600 (epoch 7), train_loss = 1.209, time/batch=0.068\n",
      "9948/67600 (epoch 7), train_loss = 1.264, time/batch=0.066\n",
      "9949/67600 (epoch 7), train_loss = 1.272, time/batch=0.067\n",
      "9950/67600 (epoch 7), train_loss = 1.294, time/batch=0.154\n",
      "9951/67600 (epoch 7), train_loss = 1.260, time/batch=0.121\n",
      "9952/67600 (epoch 7), train_loss = 1.315, time/batch=0.100\n",
      "9953/67600 (epoch 7), train_loss = 1.287, time/batch=0.072\n",
      "9954/67600 (epoch 7), train_loss = 1.215, time/batch=0.066\n",
      "9955/67600 (epoch 7), train_loss = 1.249, time/batch=0.069\n",
      "9956/67600 (epoch 7), train_loss = 1.266, time/batch=0.082\n",
      "9957/67600 (epoch 7), train_loss = 1.225, time/batch=0.066\n",
      "9958/67600 (epoch 7), train_loss = 1.299, time/batch=0.068\n",
      "9959/67600 (epoch 7), train_loss = 1.266, time/batch=0.066\n",
      "9960/67600 (epoch 7), train_loss = 1.233, time/batch=0.064\n",
      "9961/67600 (epoch 7), train_loss = 1.261, time/batch=0.065\n",
      "9962/67600 (epoch 7), train_loss = 1.311, time/batch=0.066\n",
      "9963/67600 (epoch 7), train_loss = 1.250, time/batch=0.196\n",
      "9964/67600 (epoch 7), train_loss = 1.193, time/batch=0.072\n",
      "9965/67600 (epoch 7), train_loss = 1.201, time/batch=0.091\n",
      "9966/67600 (epoch 7), train_loss = 1.232, time/batch=0.066\n",
      "9967/67600 (epoch 7), train_loss = 1.268, time/batch=0.068\n",
      "9968/67600 (epoch 7), train_loss = 1.275, time/batch=0.086\n",
      "9969/67600 (epoch 7), train_loss = 1.287, time/batch=0.077\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9970/67600 (epoch 7), train_loss = 1.273, time/batch=0.083\n",
      "9971/67600 (epoch 7), train_loss = 1.273, time/batch=0.065\n",
      "9972/67600 (epoch 7), train_loss = 1.205, time/batch=0.065\n",
      "9973/67600 (epoch 7), train_loss = 1.236, time/batch=0.085\n",
      "9974/67600 (epoch 7), train_loss = 1.282, time/batch=0.078\n",
      "9975/67600 (epoch 7), train_loss = 1.250, time/batch=0.182\n",
      "9976/67600 (epoch 7), train_loss = 1.267, time/batch=0.082\n",
      "9977/67600 (epoch 7), train_loss = 1.236, time/batch=0.066\n",
      "9978/67600 (epoch 7), train_loss = 1.262, time/batch=0.068\n",
      "9979/67600 (epoch 7), train_loss = 1.293, time/batch=0.080\n",
      "9980/67600 (epoch 7), train_loss = 1.297, time/batch=0.065\n",
      "9981/67600 (epoch 7), train_loss = 1.277, time/batch=0.066\n",
      "9982/67600 (epoch 7), train_loss = 1.270, time/batch=0.074\n",
      "9983/67600 (epoch 7), train_loss = 1.185, time/batch=0.105\n",
      "9984/67600 (epoch 7), train_loss = 1.302, time/batch=0.070\n",
      "9985/67600 (epoch 7), train_loss = 1.308, time/batch=0.075\n",
      "9986/67600 (epoch 7), train_loss = 1.319, time/batch=0.069\n",
      "9987/67600 (epoch 7), train_loss = 1.261, time/batch=0.064\n",
      "9988/67600 (epoch 7), train_loss = 1.249, time/batch=0.063\n",
      "9989/67600 (epoch 7), train_loss = 1.253, time/batch=0.063\n",
      "9990/67600 (epoch 7), train_loss = 1.272, time/batch=0.065\n",
      "9991/67600 (epoch 7), train_loss = 1.230, time/batch=0.067\n",
      "9992/67600 (epoch 7), train_loss = 1.283, time/batch=0.065\n",
      "9993/67600 (epoch 7), train_loss = 1.246, time/batch=0.065\n",
      "9994/67600 (epoch 7), train_loss = 1.305, time/batch=0.233\n",
      "9995/67600 (epoch 7), train_loss = 1.293, time/batch=0.079\n",
      "9996/67600 (epoch 7), train_loss = 1.274, time/batch=0.089\n",
      "9997/67600 (epoch 7), train_loss = 1.228, time/batch=0.068\n",
      "9998/67600 (epoch 7), train_loss = 1.246, time/batch=0.067\n",
      "9999/67600 (epoch 7), train_loss = 1.207, time/batch=0.069\n",
      "10000/67600 (epoch 7), train_loss = 1.234, time/batch=0.076\n",
      "model saved to ./save/model.ckpt\n",
      "10001/67600 (epoch 7), train_loss = 1.255, time/batch=0.108\n",
      "10002/67600 (epoch 7), train_loss = 1.237, time/batch=0.147\n",
      "10003/67600 (epoch 7), train_loss = 1.257, time/batch=0.112\n",
      "10004/67600 (epoch 7), train_loss = 1.267, time/batch=0.067\n",
      "10005/67600 (epoch 7), train_loss = 1.202, time/batch=0.112\n",
      "10006/67600 (epoch 7), train_loss = 1.245, time/batch=0.070\n",
      "10007/67600 (epoch 7), train_loss = 1.216, time/batch=0.085\n",
      "10008/67600 (epoch 7), train_loss = 1.292, time/batch=0.067\n",
      "10009/67600 (epoch 7), train_loss = 1.259, time/batch=0.065\n",
      "10010/67600 (epoch 7), train_loss = 1.232, time/batch=0.063\n",
      "10011/67600 (epoch 7), train_loss = 1.255, time/batch=0.064\n",
      "10012/67600 (epoch 7), train_loss = 1.377, time/batch=0.064\n",
      "10013/67600 (epoch 7), train_loss = 1.283, time/batch=0.174\n",
      "10014/67600 (epoch 7), train_loss = 1.237, time/batch=0.075\n",
      "10015/67600 (epoch 7), train_loss = 1.294, time/batch=0.099\n",
      "10016/67600 (epoch 7), train_loss = 1.233, time/batch=0.065\n",
      "10017/67600 (epoch 7), train_loss = 1.243, time/batch=0.066\n",
      "10018/67600 (epoch 7), train_loss = 1.282, time/batch=0.067\n",
      "10019/67600 (epoch 7), train_loss = 1.234, time/batch=0.065\n",
      "10020/67600 (epoch 7), train_loss = 1.313, time/batch=0.065\n",
      "10021/67600 (epoch 7), train_loss = 1.241, time/batch=0.071\n",
      "10022/67600 (epoch 7), train_loss = 1.226, time/batch=0.064\n",
      "10023/67600 (epoch 7), train_loss = 1.186, time/batch=0.064\n",
      "10024/67600 (epoch 7), train_loss = 1.219, time/batch=0.063\n",
      "10025/67600 (epoch 7), train_loss = 1.239, time/batch=0.065\n",
      "10026/67600 (epoch 7), train_loss = 1.192, time/batch=0.173\n",
      "10027/67600 (epoch 7), train_loss = 1.241, time/batch=0.073\n",
      "10028/67600 (epoch 7), train_loss = 1.208, time/batch=0.104\n",
      "10029/67600 (epoch 7), train_loss = 1.232, time/batch=0.065\n",
      "10030/67600 (epoch 7), train_loss = 1.268, time/batch=0.070\n",
      "10031/67600 (epoch 7), train_loss = 1.277, time/batch=0.066\n",
      "10032/67600 (epoch 7), train_loss = 1.268, time/batch=0.062\n",
      "10033/67600 (epoch 7), train_loss = 1.233, time/batch=0.064\n",
      "10034/67600 (epoch 7), train_loss = 1.213, time/batch=0.065\n",
      "10035/67600 (epoch 7), train_loss = 1.208, time/batch=0.072\n",
      "10036/67600 (epoch 7), train_loss = 1.233, time/batch=0.077\n",
      "10037/67600 (epoch 7), train_loss = 1.252, time/batch=0.078\n",
      "10038/67600 (epoch 7), train_loss = 1.264, time/batch=0.142\n",
      "10039/67600 (epoch 7), train_loss = 1.222, time/batch=0.139\n",
      "10040/67600 (epoch 7), train_loss = 1.272, time/batch=0.086\n",
      "10041/67600 (epoch 7), train_loss = 1.253, time/batch=0.073\n",
      "10042/67600 (epoch 7), train_loss = 1.284, time/batch=0.066\n",
      "10043/67600 (epoch 7), train_loss = 1.243, time/batch=0.065\n",
      "10044/67600 (epoch 7), train_loss = 1.274, time/batch=0.065\n",
      "10045/67600 (epoch 7), train_loss = 1.253, time/batch=0.065\n",
      "10046/67600 (epoch 7), train_loss = 1.210, time/batch=0.072\n",
      "10047/67600 (epoch 7), train_loss = 1.218, time/batch=0.065\n",
      "10048/67600 (epoch 7), train_loss = 1.240, time/batch=0.072\n",
      "10049/67600 (epoch 7), train_loss = 1.306, time/batch=0.066\n",
      "10050/67600 (epoch 7), train_loss = 1.226, time/batch=0.064\n",
      "10051/67600 (epoch 7), train_loss = 1.302, time/batch=0.188\n",
      "10052/67600 (epoch 7), train_loss = 1.220, time/batch=0.064\n",
      "10053/67600 (epoch 7), train_loss = 1.250, time/batch=0.069\n",
      "10054/67600 (epoch 7), train_loss = 1.314, time/batch=0.065\n",
      "10055/67600 (epoch 7), train_loss = 1.219, time/batch=0.070\n",
      "10056/67600 (epoch 7), train_loss = 1.223, time/batch=0.077\n",
      "10057/67600 (epoch 7), train_loss = 1.253, time/batch=0.065\n",
      "10058/67600 (epoch 7), train_loss = 1.201, time/batch=0.079\n",
      "10059/67600 (epoch 7), train_loss = 1.245, time/batch=0.065\n",
      "10060/67600 (epoch 7), train_loss = 1.267, time/batch=0.160\n",
      "10061/67600 (epoch 7), train_loss = 1.211, time/batch=0.073\n",
      "10062/67600 (epoch 7), train_loss = 1.241, time/batch=0.100\n",
      "10063/67600 (epoch 7), train_loss = 1.228, time/batch=0.076\n",
      "10064/67600 (epoch 7), train_loss = 1.283, time/batch=0.066\n",
      "10065/67600 (epoch 7), train_loss = 1.187, time/batch=0.071\n",
      "10066/67600 (epoch 7), train_loss = 1.261, time/batch=0.078\n",
      "10067/67600 (epoch 7), train_loss = 1.239, time/batch=0.066\n",
      "10068/67600 (epoch 7), train_loss = 1.280, time/batch=0.068\n",
      "10069/67600 (epoch 7), train_loss = 1.226, time/batch=0.089\n",
      "10070/67600 (epoch 7), train_loss = 1.300, time/batch=0.065\n",
      "10071/67600 (epoch 7), train_loss = 1.228, time/batch=0.068\n",
      "10072/67600 (epoch 7), train_loss = 1.321, time/batch=0.138\n",
      "10073/67600 (epoch 7), train_loss = 1.246, time/batch=0.091\n",
      "10074/67600 (epoch 7), train_loss = 1.262, time/batch=0.068\n",
      "10075/67600 (epoch 7), train_loss = 1.338, time/batch=0.101\n",
      "10076/67600 (epoch 7), train_loss = 1.245, time/batch=0.073\n",
      "10077/67600 (epoch 7), train_loss = 1.249, time/batch=0.080\n",
      "10078/67600 (epoch 7), train_loss = 1.276, time/batch=0.072\n",
      "10079/67600 (epoch 7), train_loss = 1.311, time/batch=0.066\n",
      "10080/67600 (epoch 7), train_loss = 1.267, time/batch=0.066\n",
      "10081/67600 (epoch 7), train_loss = 1.329, time/batch=0.080\n",
      "10082/67600 (epoch 7), train_loss = 1.246, time/batch=0.083\n",
      "10083/67600 (epoch 7), train_loss = 1.215, time/batch=0.090\n",
      "10084/67600 (epoch 7), train_loss = 1.200, time/batch=0.166\n",
      "10085/67600 (epoch 7), train_loss = 1.252, time/batch=0.071\n",
      "10086/67600 (epoch 7), train_loss = 1.252, time/batch=0.090\n",
      "10087/67600 (epoch 7), train_loss = 1.212, time/batch=0.068\n",
      "10088/67600 (epoch 7), train_loss = 1.251, time/batch=0.069\n",
      "10089/67600 (epoch 7), train_loss = 1.244, time/batch=0.069\n",
      "10090/67600 (epoch 7), train_loss = 1.289, time/batch=0.065\n",
      "10091/67600 (epoch 7), train_loss = 1.292, time/batch=0.068\n",
      "10092/67600 (epoch 7), train_loss = 1.288, time/batch=0.066\n",
      "10093/67600 (epoch 7), train_loss = 1.256, time/batch=0.070\n",
      "10094/67600 (epoch 7), train_loss = 1.291, time/batch=0.065\n",
      "10095/67600 (epoch 7), train_loss = 1.318, time/batch=0.067\n",
      "10096/67600 (epoch 7), train_loss = 1.239, time/batch=0.067\n",
      "10097/67600 (epoch 7), train_loss = 1.315, time/batch=0.145\n",
      "10098/67600 (epoch 7), train_loss = 1.309, time/batch=0.107\n",
      "10099/67600 (epoch 7), train_loss = 1.182, time/batch=0.077\n",
      "10100/67600 (epoch 7), train_loss = 1.330, time/batch=0.068\n",
      "10101/67600 (epoch 7), train_loss = 1.228, time/batch=0.086\n",
      "10102/67600 (epoch 7), train_loss = 1.187, time/batch=0.075\n",
      "10103/67600 (epoch 7), train_loss = 1.181, time/batch=0.083\n",
      "10104/67600 (epoch 7), train_loss = 1.258, time/batch=0.068\n",
      "10105/67600 (epoch 7), train_loss = 1.232, time/batch=0.066\n",
      "10106/67600 (epoch 7), train_loss = 1.287, time/batch=0.066\n",
      "10107/67600 (epoch 7), train_loss = 1.330, time/batch=0.069\n",
      "10108/67600 (epoch 7), train_loss = 1.306, time/batch=0.067\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10109/67600 (epoch 7), train_loss = 1.240, time/batch=0.162\n",
      "10110/67600 (epoch 7), train_loss = 1.279, time/batch=0.116\n",
      "10111/67600 (epoch 7), train_loss = 1.276, time/batch=0.083\n",
      "10112/67600 (epoch 7), train_loss = 1.291, time/batch=0.066\n",
      "10113/67600 (epoch 7), train_loss = 1.267, time/batch=0.066\n",
      "10114/67600 (epoch 7), train_loss = 1.306, time/batch=0.074\n",
      "10115/67600 (epoch 7), train_loss = 1.329, time/batch=0.068\n",
      "10116/67600 (epoch 7), train_loss = 1.250, time/batch=0.065\n",
      "10117/67600 (epoch 7), train_loss = 1.242, time/batch=0.065\n",
      "10118/67600 (epoch 7), train_loss = 1.266, time/batch=0.068\n",
      "10119/67600 (epoch 7), train_loss = 1.257, time/batch=0.067\n",
      "10120/67600 (epoch 7), train_loss = 1.254, time/batch=0.066\n",
      "10121/67600 (epoch 7), train_loss = 1.316, time/batch=0.066\n",
      "10122/67600 (epoch 7), train_loss = 1.282, time/batch=0.243\n",
      "10123/67600 (epoch 7), train_loss = 1.195, time/batch=0.091\n",
      "10124/67600 (epoch 7), train_loss = 1.257, time/batch=0.089\n",
      "10125/67600 (epoch 7), train_loss = 1.244, time/batch=0.068\n",
      "10126/67600 (epoch 7), train_loss = 1.173, time/batch=0.072\n",
      "10127/67600 (epoch 7), train_loss = 1.201, time/batch=0.083\n",
      "10128/67600 (epoch 7), train_loss = 1.288, time/batch=0.070\n",
      "10129/67600 (epoch 7), train_loss = 1.265, time/batch=0.065\n",
      "10130/67600 (epoch 7), train_loss = 1.278, time/batch=0.113\n",
      "10131/67600 (epoch 7), train_loss = 1.249, time/batch=0.074\n",
      "10132/67600 (epoch 7), train_loss = 1.314, time/batch=0.066\n",
      "10133/67600 (epoch 7), train_loss = 1.214, time/batch=0.068\n",
      "10134/67600 (epoch 7), train_loss = 1.156, time/batch=0.069\n",
      "10135/67600 (epoch 7), train_loss = 1.237, time/batch=0.067\n",
      "10136/67600 (epoch 7), train_loss = 1.170, time/batch=0.065\n",
      "10137/67600 (epoch 7), train_loss = 1.313, time/batch=0.065\n",
      "10138/67600 (epoch 7), train_loss = 1.303, time/batch=0.068\n",
      "10139/67600 (epoch 7), train_loss = 1.224, time/batch=0.088\n",
      "10140/67600 (epoch 7), train_loss = 1.266, time/batch=0.236\n",
      "10141/67600 (epoch 7), train_loss = 1.294, time/batch=0.077\n",
      "10142/67600 (epoch 7), train_loss = 1.306, time/batch=0.087\n",
      "10143/67600 (epoch 7), train_loss = 1.243, time/batch=0.077\n",
      "10144/67600 (epoch 7), train_loss = 1.255, time/batch=0.066\n",
      "10145/67600 (epoch 7), train_loss = 1.286, time/batch=0.077\n",
      "10146/67600 (epoch 7), train_loss = 1.276, time/batch=0.071\n",
      "10147/67600 (epoch 7), train_loss = 1.238, time/batch=0.076\n",
      "10148/67600 (epoch 7), train_loss = 1.233, time/batch=0.067\n",
      "10149/67600 (epoch 7), train_loss = 1.307, time/batch=0.072\n",
      "10150/67600 (epoch 7), train_loss = 1.272, time/batch=0.074\n",
      "10151/67600 (epoch 7), train_loss = 1.212, time/batch=0.076\n",
      "10152/67600 (epoch 7), train_loss = 1.259, time/batch=0.232\n",
      "10153/67600 (epoch 7), train_loss = 1.212, time/batch=0.090\n",
      "10154/67600 (epoch 7), train_loss = 1.238, time/batch=0.095\n",
      "10155/67600 (epoch 7), train_loss = 1.244, time/batch=0.080\n",
      "10156/67600 (epoch 7), train_loss = 1.231, time/batch=0.066\n",
      "10157/67600 (epoch 7), train_loss = 1.277, time/batch=0.066\n",
      "10158/67600 (epoch 7), train_loss = 1.262, time/batch=0.064\n",
      "10159/67600 (epoch 7), train_loss = 1.179, time/batch=0.086\n",
      "10160/67600 (epoch 7), train_loss = 1.278, time/batch=0.070\n",
      "10161/67600 (epoch 7), train_loss = 1.291, time/batch=0.069\n",
      "10162/67600 (epoch 7), train_loss = 1.279, time/batch=0.065\n",
      "10163/67600 (epoch 7), train_loss = 1.220, time/batch=0.196\n",
      "10164/67600 (epoch 7), train_loss = 1.263, time/batch=0.076\n",
      "10165/67600 (epoch 7), train_loss = 1.284, time/batch=0.084\n",
      "10166/67600 (epoch 7), train_loss = 1.250, time/batch=0.076\n",
      "10167/67600 (epoch 7), train_loss = 1.199, time/batch=0.073\n",
      "10168/67600 (epoch 7), train_loss = 1.250, time/batch=0.074\n",
      "10169/67600 (epoch 7), train_loss = 1.236, time/batch=0.065\n",
      "10170/67600 (epoch 7), train_loss = 1.230, time/batch=0.079\n",
      "10171/67600 (epoch 7), train_loss = 1.282, time/batch=0.073\n",
      "10172/67600 (epoch 7), train_loss = 1.267, time/batch=0.170\n",
      "10173/67600 (epoch 7), train_loss = 1.209, time/batch=0.067\n",
      "10174/67600 (epoch 7), train_loss = 1.251, time/batch=0.099\n",
      "10175/67600 (epoch 7), train_loss = 1.160, time/batch=0.091\n",
      "10176/67600 (epoch 7), train_loss = 1.255, time/batch=0.070\n",
      "10177/67600 (epoch 7), train_loss = 1.248, time/batch=0.069\n",
      "10178/67600 (epoch 7), train_loss = 1.244, time/batch=0.083\n",
      "10179/67600 (epoch 7), train_loss = 1.226, time/batch=0.075\n",
      "10180/67600 (epoch 7), train_loss = 1.195, time/batch=0.064\n",
      "10181/67600 (epoch 7), train_loss = 1.239, time/batch=0.065\n",
      "10182/67600 (epoch 7), train_loss = 1.218, time/batch=0.067\n",
      "10183/67600 (epoch 7), train_loss = 1.230, time/batch=0.156\n",
      "10184/67600 (epoch 7), train_loss = 1.234, time/batch=0.116\n",
      "10185/67600 (epoch 7), train_loss = 1.271, time/batch=0.111\n",
      "10186/67600 (epoch 7), train_loss = 1.248, time/batch=0.066\n",
      "10187/67600 (epoch 7), train_loss = 1.263, time/batch=0.092\n",
      "10188/67600 (epoch 7), train_loss = 1.252, time/batch=0.069\n",
      "10189/67600 (epoch 7), train_loss = 1.268, time/batch=0.065\n",
      "10190/67600 (epoch 7), train_loss = 1.251, time/batch=0.067\n",
      "10191/67600 (epoch 7), train_loss = 1.260, time/batch=0.065\n",
      "10192/67600 (epoch 7), train_loss = 1.269, time/batch=0.066\n",
      "10193/67600 (epoch 7), train_loss = 1.229, time/batch=0.077\n",
      "10194/67600 (epoch 7), train_loss = 1.260, time/batch=0.065\n",
      "10195/67600 (epoch 7), train_loss = 1.288, time/batch=0.189\n",
      "10196/67600 (epoch 7), train_loss = 1.270, time/batch=0.081\n",
      "10197/67600 (epoch 7), train_loss = 1.249, time/batch=0.093\n",
      "10198/67600 (epoch 7), train_loss = 1.267, time/batch=0.065\n",
      "10199/67600 (epoch 7), train_loss = 1.212, time/batch=0.065\n",
      "10200/67600 (epoch 7), train_loss = 1.309, time/batch=0.066\n",
      "10201/67600 (epoch 7), train_loss = 1.233, time/batch=0.067\n",
      "10202/67600 (epoch 7), train_loss = 1.205, time/batch=0.070\n",
      "10203/67600 (epoch 7), train_loss = 1.276, time/batch=0.066\n",
      "10204/67600 (epoch 7), train_loss = 1.181, time/batch=0.066\n",
      "10205/67600 (epoch 7), train_loss = 1.214, time/batch=0.065\n",
      "10206/67600 (epoch 7), train_loss = 1.188, time/batch=0.067\n",
      "10207/67600 (epoch 7), train_loss = 1.231, time/batch=0.065\n",
      "10208/67600 (epoch 7), train_loss = 1.255, time/batch=0.196\n",
      "10209/67600 (epoch 7), train_loss = 1.261, time/batch=0.065\n",
      "10210/67600 (epoch 7), train_loss = 1.227, time/batch=0.081\n",
      "10211/67600 (epoch 7), train_loss = 1.247, time/batch=0.066\n",
      "10212/67600 (epoch 7), train_loss = 1.269, time/batch=0.067\n",
      "10213/67600 (epoch 7), train_loss = 1.218, time/batch=0.066\n",
      "10214/67600 (epoch 7), train_loss = 1.192, time/batch=0.065\n",
      "10215/67600 (epoch 7), train_loss = 1.210, time/batch=0.067\n",
      "10216/67600 (epoch 7), train_loss = 1.236, time/batch=0.076\n",
      "10217/67600 (epoch 7), train_loss = 1.290, time/batch=0.073\n",
      "10218/67600 (epoch 7), train_loss = 1.234, time/batch=0.080\n",
      "10219/67600 (epoch 7), train_loss = 1.240, time/batch=0.065\n",
      "10220/67600 (epoch 7), train_loss = 1.313, time/batch=0.065\n",
      "10221/67600 (epoch 7), train_loss = 1.248, time/batch=0.192\n",
      "10222/67600 (epoch 7), train_loss = 1.233, time/batch=0.069\n",
      "10223/67600 (epoch 7), train_loss = 1.213, time/batch=0.068\n",
      "10224/67600 (epoch 7), train_loss = 1.233, time/batch=0.067\n",
      "10225/67600 (epoch 7), train_loss = 1.232, time/batch=0.066\n",
      "10226/67600 (epoch 7), train_loss = 1.239, time/batch=0.069\n",
      "10227/67600 (epoch 7), train_loss = 1.283, time/batch=0.067\n",
      "10228/67600 (epoch 7), train_loss = 1.292, time/batch=0.065\n",
      "10229/67600 (epoch 7), train_loss = 1.211, time/batch=0.068\n",
      "10230/67600 (epoch 7), train_loss = 1.256, time/batch=0.173\n",
      "10231/67600 (epoch 7), train_loss = 1.246, time/batch=0.074\n",
      "10232/67600 (epoch 7), train_loss = 1.272, time/batch=0.117\n",
      "10233/67600 (epoch 7), train_loss = 1.279, time/batch=0.067\n",
      "10234/67600 (epoch 7), train_loss = 1.223, time/batch=0.073\n",
      "10235/67600 (epoch 7), train_loss = 1.303, time/batch=0.068\n",
      "10236/67600 (epoch 7), train_loss = 1.268, time/batch=0.071\n",
      "10237/67600 (epoch 7), train_loss = 1.231, time/batch=0.079\n",
      "10238/67600 (epoch 7), train_loss = 1.281, time/batch=0.066\n",
      "10239/67600 (epoch 7), train_loss = 1.321, time/batch=0.069\n",
      "10240/67600 (epoch 7), train_loss = 1.289, time/batch=0.074\n",
      "10241/67600 (epoch 7), train_loss = 1.259, time/batch=0.066\n",
      "10242/67600 (epoch 7), train_loss = 1.241, time/batch=0.174\n",
      "10243/67600 (epoch 7), train_loss = 1.269, time/batch=0.069\n",
      "10244/67600 (epoch 7), train_loss = 1.296, time/batch=0.114\n",
      "10245/67600 (epoch 7), train_loss = 1.248, time/batch=0.067\n",
      "10246/67600 (epoch 7), train_loss = 1.226, time/batch=0.066\n",
      "10247/67600 (epoch 7), train_loss = 1.257, time/batch=0.065\n",
      "10248/67600 (epoch 7), train_loss = 1.240, time/batch=0.066\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10249/67600 (epoch 7), train_loss = 1.282, time/batch=0.065\n",
      "10250/67600 (epoch 7), train_loss = 1.255, time/batch=0.062\n",
      "10251/67600 (epoch 7), train_loss = 1.267, time/batch=0.069\n",
      "10252/67600 (epoch 7), train_loss = 1.268, time/batch=0.062\n",
      "10253/67600 (epoch 7), train_loss = 1.224, time/batch=0.067\n",
      "10254/67600 (epoch 7), train_loss = 1.239, time/batch=0.066\n",
      "10255/67600 (epoch 7), train_loss = 1.250, time/batch=0.168\n",
      "10256/67600 (epoch 7), train_loss = 1.222, time/batch=0.065\n",
      "10257/67600 (epoch 7), train_loss = 1.281, time/batch=0.098\n",
      "10258/67600 (epoch 7), train_loss = 1.241, time/batch=0.074\n",
      "10259/67600 (epoch 7), train_loss = 1.253, time/batch=0.077\n",
      "10260/67600 (epoch 7), train_loss = 1.308, time/batch=0.076\n",
      "10261/67600 (epoch 7), train_loss = 1.267, time/batch=0.070\n",
      "10262/67600 (epoch 7), train_loss = 1.288, time/batch=0.078\n",
      "10263/67600 (epoch 7), train_loss = 1.250, time/batch=0.077\n",
      "10264/67600 (epoch 7), train_loss = 1.258, time/batch=0.067\n",
      "10265/67600 (epoch 7), train_loss = 1.254, time/batch=0.066\n",
      "10266/67600 (epoch 7), train_loss = 1.240, time/batch=0.079\n",
      "10267/67600 (epoch 7), train_loss = 1.257, time/batch=0.189\n",
      "10268/67600 (epoch 7), train_loss = 1.228, time/batch=0.065\n",
      "10269/67600 (epoch 7), train_loss = 1.204, time/batch=0.083\n",
      "10270/67600 (epoch 7), train_loss = 1.265, time/batch=0.078\n",
      "10271/67600 (epoch 7), train_loss = 1.225, time/batch=0.066\n",
      "10272/67600 (epoch 7), train_loss = 1.169, time/batch=0.069\n",
      "10273/67600 (epoch 7), train_loss = 1.270, time/batch=0.066\n",
      "10274/67600 (epoch 7), train_loss = 1.201, time/batch=0.064\n",
      "10275/67600 (epoch 7), train_loss = 1.287, time/batch=0.063\n",
      "10276/67600 (epoch 7), train_loss = 1.269, time/batch=0.062\n",
      "10277/67600 (epoch 7), train_loss = 1.267, time/batch=0.071\n",
      "10278/67600 (epoch 7), train_loss = 1.295, time/batch=0.072\n",
      "10279/67600 (epoch 7), train_loss = 1.199, time/batch=0.064\n",
      "10280/67600 (epoch 7), train_loss = 1.298, time/batch=0.201\n",
      "10281/67600 (epoch 7), train_loss = 1.222, time/batch=0.076\n",
      "10282/67600 (epoch 7), train_loss = 1.219, time/batch=0.065\n",
      "10283/67600 (epoch 7), train_loss = 1.241, time/batch=0.084\n",
      "10284/67600 (epoch 7), train_loss = 1.173, time/batch=0.063\n",
      "10285/67600 (epoch 7), train_loss = 1.287, time/batch=0.064\n",
      "10286/67600 (epoch 7), train_loss = 1.249, time/batch=0.063\n",
      "10287/67600 (epoch 7), train_loss = 1.321, time/batch=0.069\n",
      "10288/67600 (epoch 7), train_loss = 1.261, time/batch=0.093\n",
      "10289/67600 (epoch 7), train_loss = 1.293, time/batch=0.142\n",
      "10290/67600 (epoch 7), train_loss = 1.394, time/batch=0.062\n",
      "10291/67600 (epoch 7), train_loss = 1.216, time/batch=0.099\n",
      "10292/67600 (epoch 7), train_loss = 1.256, time/batch=0.066\n",
      "10293/67600 (epoch 7), train_loss = 1.286, time/batch=0.072\n",
      "10294/67600 (epoch 7), train_loss = 1.337, time/batch=0.086\n",
      "10295/67600 (epoch 7), train_loss = 1.233, time/batch=0.065\n",
      "10296/67600 (epoch 7), train_loss = 1.252, time/batch=0.080\n",
      "10297/67600 (epoch 7), train_loss = 1.259, time/batch=0.066\n",
      "10298/67600 (epoch 7), train_loss = 1.214, time/batch=0.066\n",
      "10299/67600 (epoch 7), train_loss = 1.289, time/batch=0.063\n",
      "10300/67600 (epoch 7), train_loss = 1.142, time/batch=0.078\n",
      "10301/67600 (epoch 7), train_loss = 1.287, time/batch=0.107\n",
      "10302/67600 (epoch 7), train_loss = 1.189, time/batch=0.066\n",
      "10303/67600 (epoch 7), train_loss = 1.242, time/batch=0.065\n",
      "10304/67600 (epoch 7), train_loss = 1.300, time/batch=0.066\n",
      "10305/67600 (epoch 7), train_loss = 1.263, time/batch=0.066\n",
      "10306/67600 (epoch 7), train_loss = 1.254, time/batch=0.070\n",
      "10307/67600 (epoch 7), train_loss = 1.269, time/batch=0.065\n",
      "10308/67600 (epoch 7), train_loss = 1.255, time/batch=0.066\n",
      "10309/67600 (epoch 7), train_loss = 1.236, time/batch=0.069\n",
      "10310/67600 (epoch 7), train_loss = 1.230, time/batch=0.066\n",
      "10311/67600 (epoch 7), train_loss = 1.239, time/batch=0.065\n",
      "10312/67600 (epoch 7), train_loss = 1.268, time/batch=0.239\n",
      "10313/67600 (epoch 7), train_loss = 1.238, time/batch=0.068\n",
      "10314/67600 (epoch 7), train_loss = 1.241, time/batch=0.101\n",
      "10315/67600 (epoch 7), train_loss = 1.328, time/batch=0.070\n",
      "10316/67600 (epoch 7), train_loss = 1.331, time/batch=0.066\n",
      "10317/67600 (epoch 7), train_loss = 1.314, time/batch=0.066\n",
      "10318/67600 (epoch 7), train_loss = 1.241, time/batch=0.065\n",
      "10319/67600 (epoch 7), train_loss = 1.285, time/batch=0.072\n",
      "10320/67600 (epoch 7), train_loss = 1.256, time/batch=0.074\n",
      "10321/67600 (epoch 7), train_loss = 1.261, time/batch=0.077\n",
      "10322/67600 (epoch 7), train_loss = 1.290, time/batch=0.068\n",
      "10323/67600 (epoch 7), train_loss = 1.301, time/batch=0.073\n",
      "10324/67600 (epoch 7), train_loss = 1.263, time/batch=0.209\n",
      "10325/67600 (epoch 7), train_loss = 1.313, time/batch=0.066\n",
      "10326/67600 (epoch 7), train_loss = 1.333, time/batch=0.074\n",
      "10327/67600 (epoch 7), train_loss = 1.285, time/batch=0.084\n",
      "10328/67600 (epoch 7), train_loss = 1.219, time/batch=0.076\n",
      "10329/67600 (epoch 7), train_loss = 1.312, time/batch=0.067\n",
      "10330/67600 (epoch 7), train_loss = 1.292, time/batch=0.066\n",
      "10331/67600 (epoch 7), train_loss = 1.227, time/batch=0.066\n",
      "10332/67600 (epoch 7), train_loss = 1.262, time/batch=0.083\n",
      "10333/67600 (epoch 7), train_loss = 1.253, time/batch=0.078\n",
      "10334/67600 (epoch 7), train_loss = 1.257, time/batch=0.075\n",
      "10335/67600 (epoch 7), train_loss = 1.232, time/batch=0.066\n",
      "10336/67600 (epoch 7), train_loss = 1.289, time/batch=0.227\n",
      "10337/67600 (epoch 7), train_loss = 1.224, time/batch=0.071\n",
      "10338/67600 (epoch 7), train_loss = 1.260, time/batch=0.075\n",
      "10339/67600 (epoch 7), train_loss = 1.309, time/batch=0.068\n",
      "10340/67600 (epoch 7), train_loss = 1.290, time/batch=0.113\n",
      "10341/67600 (epoch 7), train_loss = 1.163, time/batch=0.070\n",
      "10342/67600 (epoch 7), train_loss = 1.250, time/batch=0.082\n",
      "10343/67600 (epoch 7), train_loss = 1.160, time/batch=0.084\n",
      "10344/67600 (epoch 7), train_loss = 1.216, time/batch=0.153\n",
      "10345/67600 (epoch 7), train_loss = 1.229, time/batch=0.065\n",
      "10346/67600 (epoch 7), train_loss = 1.234, time/batch=0.114\n",
      "10347/67600 (epoch 7), train_loss = 1.253, time/batch=0.074\n",
      "10348/67600 (epoch 7), train_loss = 1.225, time/batch=0.065\n",
      "10349/67600 (epoch 7), train_loss = 1.240, time/batch=0.079\n",
      "10350/67600 (epoch 7), train_loss = 1.224, time/batch=0.070\n",
      "10351/67600 (epoch 7), train_loss = 1.186, time/batch=0.077\n",
      "10352/67600 (epoch 7), train_loss = 1.313, time/batch=0.078\n",
      "10353/67600 (epoch 7), train_loss = 1.281, time/batch=0.067\n",
      "10354/67600 (epoch 7), train_loss = 1.308, time/batch=0.065\n",
      "10355/67600 (epoch 7), train_loss = 1.294, time/batch=0.080\n",
      "10356/67600 (epoch 7), train_loss = 1.272, time/batch=0.168\n",
      "10357/67600 (epoch 7), train_loss = 1.232, time/batch=0.067\n",
      "10358/67600 (epoch 7), train_loss = 1.284, time/batch=0.112\n",
      "10359/67600 (epoch 7), train_loss = 1.238, time/batch=0.069\n",
      "10360/67600 (epoch 7), train_loss = 1.252, time/batch=0.067\n",
      "10361/67600 (epoch 7), train_loss = 1.317, time/batch=0.084\n",
      "10362/67600 (epoch 7), train_loss = 1.287, time/batch=0.068\n",
      "10363/67600 (epoch 7), train_loss = 1.290, time/batch=0.091\n",
      "10364/67600 (epoch 7), train_loss = 1.263, time/batch=0.075\n",
      "10365/67600 (epoch 7), train_loss = 1.305, time/batch=0.069\n",
      "10366/67600 (epoch 7), train_loss = 1.305, time/batch=0.077\n",
      "10367/67600 (epoch 7), train_loss = 1.196, time/batch=0.110\n",
      "10368/67600 (epoch 7), train_loss = 1.237, time/batch=0.136\n",
      "10369/67600 (epoch 7), train_loss = 1.284, time/batch=0.103\n",
      "10370/67600 (epoch 7), train_loss = 1.242, time/batch=0.071\n",
      "10371/67600 (epoch 7), train_loss = 1.231, time/batch=0.066\n",
      "10372/67600 (epoch 7), train_loss = 1.304, time/batch=0.065\n",
      "10373/67600 (epoch 7), train_loss = 1.245, time/batch=0.066\n",
      "10374/67600 (epoch 7), train_loss = 1.242, time/batch=0.065\n",
      "10375/67600 (epoch 7), train_loss = 1.286, time/batch=0.067\n",
      "10376/67600 (epoch 7), train_loss = 1.239, time/batch=0.066\n",
      "10377/67600 (epoch 7), train_loss = 1.273, time/batch=0.067\n",
      "10378/67600 (epoch 7), train_loss = 1.299, time/batch=0.068\n",
      "10379/67600 (epoch 7), train_loss = 1.239, time/batch=0.070\n",
      "10380/67600 (epoch 7), train_loss = 1.253, time/batch=0.179\n",
      "10381/67600 (epoch 7), train_loss = 1.243, time/batch=0.085\n",
      "10382/67600 (epoch 7), train_loss = 1.267, time/batch=0.083\n",
      "10383/67600 (epoch 7), train_loss = 1.259, time/batch=0.068\n",
      "10384/67600 (epoch 7), train_loss = 1.275, time/batch=0.073\n",
      "10385/67600 (epoch 7), train_loss = 1.252, time/batch=0.088\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10386/67600 (epoch 7), train_loss = 1.278, time/batch=0.069\n",
      "10387/67600 (epoch 7), train_loss = 1.221, time/batch=0.081\n",
      "10388/67600 (epoch 7), train_loss = 1.211, time/batch=0.095\n",
      "10389/67600 (epoch 7), train_loss = 1.239, time/batch=0.086\n",
      "10390/67600 (epoch 7), train_loss = 1.230, time/batch=0.081\n",
      "10391/67600 (epoch 7), train_loss = 1.254, time/batch=0.174\n",
      "10392/67600 (epoch 7), train_loss = 1.227, time/batch=0.102\n",
      "10393/67600 (epoch 7), train_loss = 1.242, time/batch=0.091\n",
      "10394/67600 (epoch 7), train_loss = 1.208, time/batch=0.088\n",
      "10395/67600 (epoch 7), train_loss = 1.259, time/batch=0.067\n",
      "10396/67600 (epoch 7), train_loss = 1.225, time/batch=0.066\n",
      "10397/67600 (epoch 7), train_loss = 1.204, time/batch=0.062\n",
      "10398/67600 (epoch 7), train_loss = 1.230, time/batch=0.063\n",
      "10399/67600 (epoch 7), train_loss = 1.221, time/batch=0.062\n",
      "10400/67600 (epoch 7), train_loss = 1.281, time/batch=0.158\n",
      "10401/67600 (epoch 7), train_loss = 1.243, time/batch=0.068\n",
      "10402/67600 (epoch 7), train_loss = 1.231, time/batch=0.097\n",
      "10403/67600 (epoch 7), train_loss = 1.229, time/batch=0.066\n",
      "10404/67600 (epoch 7), train_loss = 1.251, time/batch=0.065\n",
      "10405/67600 (epoch 7), train_loss = 1.208, time/batch=0.066\n",
      "10406/67600 (epoch 7), train_loss = 1.184, time/batch=0.069\n",
      "10407/67600 (epoch 7), train_loss = 1.280, time/batch=0.067\n",
      "10408/67600 (epoch 7), train_loss = 1.235, time/batch=0.075\n",
      "10409/67600 (epoch 7), train_loss = 1.267, time/batch=0.066\n",
      "10410/67600 (epoch 7), train_loss = 1.225, time/batch=0.068\n",
      "10411/67600 (epoch 7), train_loss = 1.206, time/batch=0.065\n",
      "10412/67600 (epoch 7), train_loss = 1.259, time/batch=0.064\n",
      "10413/67600 (epoch 7), train_loss = 1.213, time/batch=0.167\n",
      "10414/67600 (epoch 7), train_loss = 1.273, time/batch=0.077\n",
      "10415/67600 (epoch 7), train_loss = 1.214, time/batch=0.096\n",
      "10416/67600 (epoch 7), train_loss = 1.275, time/batch=0.067\n",
      "10417/67600 (epoch 7), train_loss = 1.206, time/batch=0.065\n",
      "10418/67600 (epoch 7), train_loss = 1.182, time/batch=0.080\n",
      "10419/67600 (epoch 7), train_loss = 1.305, time/batch=0.067\n",
      "10420/67600 (epoch 7), train_loss = 1.267, time/batch=0.066\n",
      "10421/67600 (epoch 7), train_loss = 1.271, time/batch=0.067\n",
      "10422/67600 (epoch 7), train_loss = 1.208, time/batch=0.064\n",
      "10423/67600 (epoch 7), train_loss = 1.223, time/batch=0.073\n",
      "10424/67600 (epoch 7), train_loss = 1.213, time/batch=0.077\n",
      "10425/67600 (epoch 7), train_loss = 1.168, time/batch=0.124\n",
      "10426/67600 (epoch 7), train_loss = 1.187, time/batch=0.134\n",
      "10427/67600 (epoch 7), train_loss = 1.170, time/batch=0.093\n",
      "10428/67600 (epoch 7), train_loss = 1.174, time/batch=0.067\n",
      "10429/67600 (epoch 7), train_loss = 1.257, time/batch=0.067\n",
      "10430/67600 (epoch 7), train_loss = 1.252, time/batch=0.075\n",
      "10431/67600 (epoch 7), train_loss = 1.193, time/batch=0.071\n",
      "10432/67600 (epoch 7), train_loss = 1.215, time/batch=0.069\n",
      "10433/67600 (epoch 7), train_loss = 1.211, time/batch=0.066\n",
      "10434/67600 (epoch 7), train_loss = 1.237, time/batch=0.064\n",
      "10435/67600 (epoch 7), train_loss = 1.246, time/batch=0.063\n",
      "10436/67600 (epoch 7), train_loss = 1.194, time/batch=0.066\n",
      "10437/67600 (epoch 7), train_loss = 1.257, time/batch=0.065\n",
      "10438/67600 (epoch 7), train_loss = 1.284, time/batch=0.155\n",
      "10439/67600 (epoch 7), train_loss = 1.182, time/batch=0.115\n",
      "10440/67600 (epoch 7), train_loss = 1.173, time/batch=0.081\n",
      "10441/67600 (epoch 7), train_loss = 1.211, time/batch=0.077\n",
      "10442/67600 (epoch 7), train_loss = 1.254, time/batch=0.067\n",
      "10443/67600 (epoch 7), train_loss = 1.225, time/batch=0.067\n",
      "10444/67600 (epoch 7), train_loss = 1.251, time/batch=0.082\n",
      "10445/67600 (epoch 7), train_loss = 1.202, time/batch=0.066\n",
      "10446/67600 (epoch 7), train_loss = 1.222, time/batch=0.066\n",
      "10447/67600 (epoch 7), train_loss = 1.260, time/batch=0.065\n",
      "10448/67600 (epoch 7), train_loss = 1.216, time/batch=0.066\n",
      "10449/67600 (epoch 7), train_loss = 1.308, time/batch=0.064\n",
      "10450/67600 (epoch 7), train_loss = 1.245, time/batch=0.064\n",
      "10451/67600 (epoch 7), train_loss = 1.311, time/batch=0.210\n",
      "10452/67600 (epoch 7), train_loss = 1.207, time/batch=0.077\n",
      "10453/67600 (epoch 7), train_loss = 1.235, time/batch=0.072\n",
      "10454/67600 (epoch 7), train_loss = 1.260, time/batch=0.067\n",
      "10455/67600 (epoch 7), train_loss = 1.225, time/batch=0.063\n",
      "10456/67600 (epoch 7), train_loss = 1.286, time/batch=0.066\n",
      "10457/67600 (epoch 7), train_loss = 1.241, time/batch=0.065\n",
      "10458/67600 (epoch 7), train_loss = 1.230, time/batch=0.073\n",
      "10459/67600 (epoch 7), train_loss = 1.238, time/batch=0.085\n",
      "10460/67600 (epoch 7), train_loss = 1.247, time/batch=0.150\n",
      "10461/67600 (epoch 7), train_loss = 1.263, time/batch=0.066\n",
      "10462/67600 (epoch 7), train_loss = 1.202, time/batch=0.090\n",
      "10463/67600 (epoch 7), train_loss = 1.219, time/batch=0.082\n",
      "10464/67600 (epoch 7), train_loss = 1.238, time/batch=0.067\n",
      "10465/67600 (epoch 7), train_loss = 1.247, time/batch=0.082\n",
      "10466/67600 (epoch 7), train_loss = 1.222, time/batch=0.066\n",
      "10467/67600 (epoch 7), train_loss = 1.245, time/batch=0.076\n",
      "10468/67600 (epoch 7), train_loss = 1.182, time/batch=0.066\n",
      "10469/67600 (epoch 7), train_loss = 1.257, time/batch=0.065\n",
      "10470/67600 (epoch 7), train_loss = 1.238, time/batch=0.065\n",
      "10471/67600 (epoch 7), train_loss = 1.205, time/batch=0.066\n",
      "10472/67600 (epoch 7), train_loss = 1.240, time/batch=0.106\n",
      "10473/67600 (epoch 7), train_loss = 1.198, time/batch=0.066\n",
      "10474/67600 (epoch 7), train_loss = 1.211, time/batch=0.065\n",
      "10475/67600 (epoch 7), train_loss = 1.212, time/batch=0.067\n",
      "10476/67600 (epoch 7), train_loss = 1.176, time/batch=0.092\n",
      "10477/67600 (epoch 7), train_loss = 1.211, time/batch=0.075\n",
      "10478/67600 (epoch 7), train_loss = 1.217, time/batch=0.073\n",
      "10479/67600 (epoch 7), train_loss = 1.231, time/batch=0.065\n",
      "10480/67600 (epoch 7), train_loss = 1.206, time/batch=0.065\n",
      "10481/67600 (epoch 7), train_loss = 1.262, time/batch=0.067\n",
      "10482/67600 (epoch 7), train_loss = 1.233, time/batch=0.265\n",
      "10483/67600 (epoch 7), train_loss = 1.244, time/batch=0.087\n",
      "10484/67600 (epoch 7), train_loss = 1.225, time/batch=0.089\n",
      "10485/67600 (epoch 7), train_loss = 1.222, time/batch=0.080\n",
      "10486/67600 (epoch 7), train_loss = 1.221, time/batch=0.097\n",
      "10487/67600 (epoch 7), train_loss = 1.223, time/batch=0.066\n",
      "10488/67600 (epoch 7), train_loss = 1.225, time/batch=0.068\n",
      "10489/67600 (epoch 7), train_loss = 1.185, time/batch=0.075\n",
      "10490/67600 (epoch 7), train_loss = 1.267, time/batch=0.066\n",
      "10491/67600 (epoch 7), train_loss = 1.185, time/batch=0.067\n",
      "10492/67600 (epoch 7), train_loss = 1.283, time/batch=0.083\n",
      "10493/67600 (epoch 7), train_loss = 1.248, time/batch=0.081\n",
      "10494/67600 (epoch 7), train_loss = 1.280, time/batch=0.202\n",
      "10495/67600 (epoch 7), train_loss = 1.276, time/batch=0.077\n",
      "10496/67600 (epoch 7), train_loss = 1.240, time/batch=0.090\n",
      "10497/67600 (epoch 7), train_loss = 1.217, time/batch=0.081\n",
      "10498/67600 (epoch 7), train_loss = 1.244, time/batch=0.080\n",
      "10499/67600 (epoch 7), train_loss = 1.210, time/batch=0.070\n",
      "10500/67600 (epoch 7), train_loss = 1.198, time/batch=0.066\n",
      "model saved to ./save/model.ckpt\n",
      "10501/67600 (epoch 7), train_loss = 1.196, time/batch=0.070\n",
      "10502/67600 (epoch 7), train_loss = 1.238, time/batch=0.114\n",
      "10503/67600 (epoch 7), train_loss = 1.217, time/batch=0.072\n",
      "10504/67600 (epoch 7), train_loss = 1.241, time/batch=0.065\n",
      "10505/67600 (epoch 7), train_loss = 1.237, time/batch=0.066\n",
      "10506/67600 (epoch 7), train_loss = 1.275, time/batch=0.069\n",
      "10507/67600 (epoch 7), train_loss = 1.135, time/batch=0.066\n",
      "10508/67600 (epoch 7), train_loss = 1.223, time/batch=0.067\n",
      "10509/67600 (epoch 7), train_loss = 1.223, time/batch=0.086\n",
      "10510/67600 (epoch 7), train_loss = 1.240, time/batch=0.080\n",
      "10511/67600 (epoch 7), train_loss = 1.295, time/batch=0.073\n",
      "10512/67600 (epoch 7), train_loss = 1.270, time/batch=0.167\n",
      "10513/67600 (epoch 7), train_loss = 1.257, time/batch=0.070\n",
      "10514/67600 (epoch 7), train_loss = 1.232, time/batch=0.098\n",
      "10515/67600 (epoch 7), train_loss = 1.206, time/batch=0.068\n",
      "10516/67600 (epoch 7), train_loss = 1.256, time/batch=0.069\n",
      "10517/67600 (epoch 7), train_loss = 1.239, time/batch=0.067\n",
      "10518/67600 (epoch 7), train_loss = 1.259, time/batch=0.065\n",
      "10519/67600 (epoch 7), train_loss = 1.242, time/batch=0.067\n",
      "10520/67600 (epoch 7), train_loss = 1.165, time/batch=0.066\n",
      "10521/67600 (epoch 7), train_loss = 1.281, time/batch=0.074\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10522/67600 (epoch 7), train_loss = 1.312, time/batch=0.079\n",
      "10523/67600 (epoch 7), train_loss = 1.227, time/batch=0.073\n",
      "10524/67600 (epoch 7), train_loss = 1.253, time/batch=0.118\n",
      "10525/67600 (epoch 7), train_loss = 1.262, time/batch=0.145\n",
      "10526/67600 (epoch 7), train_loss = 1.235, time/batch=0.083\n",
      "10527/67600 (epoch 7), train_loss = 1.198, time/batch=0.067\n",
      "10528/67600 (epoch 7), train_loss = 1.241, time/batch=0.070\n",
      "10529/67600 (epoch 7), train_loss = 1.238, time/batch=0.069\n",
      "10530/67600 (epoch 7), train_loss = 1.235, time/batch=0.067\n",
      "10531/67600 (epoch 7), train_loss = 1.274, time/batch=0.065\n",
      "10532/67600 (epoch 7), train_loss = 1.206, time/batch=0.066\n",
      "10533/67600 (epoch 7), train_loss = 1.257, time/batch=0.063\n",
      "10534/67600 (epoch 7), train_loss = 1.281, time/batch=0.065\n",
      "10535/67600 (epoch 7), train_loss = 1.300, time/batch=0.064\n",
      "10536/67600 (epoch 7), train_loss = 1.244, time/batch=0.067\n",
      "10537/67600 (epoch 7), train_loss = 1.228, time/batch=0.097\n",
      "10538/67600 (epoch 7), train_loss = 1.205, time/batch=0.166\n",
      "10539/67600 (epoch 7), train_loss = 1.234, time/batch=0.072\n",
      "10540/67600 (epoch 7), train_loss = 1.288, time/batch=0.065\n",
      "10541/67600 (epoch 7), train_loss = 1.277, time/batch=0.066\n",
      "10542/67600 (epoch 7), train_loss = 1.283, time/batch=0.066\n",
      "10543/67600 (epoch 7), train_loss = 1.276, time/batch=0.070\n",
      "10544/67600 (epoch 7), train_loss = 1.292, time/batch=0.088\n",
      "10545/67600 (epoch 7), train_loss = 1.211, time/batch=0.068\n",
      "10546/67600 (epoch 7), train_loss = 1.271, time/batch=0.099\n",
      "10547/67600 (epoch 7), train_loss = 1.210, time/batch=0.124\n",
      "10548/67600 (epoch 7), train_loss = 1.197, time/batch=0.095\n",
      "10549/67600 (epoch 7), train_loss = 1.320, time/batch=0.094\n",
      "10550/67600 (epoch 7), train_loss = 1.280, time/batch=0.077\n",
      "10551/67600 (epoch 7), train_loss = 1.192, time/batch=0.069\n",
      "10552/67600 (epoch 7), train_loss = 1.224, time/batch=0.068\n",
      "10553/67600 (epoch 7), train_loss = 1.212, time/batch=0.066\n",
      "10554/67600 (epoch 7), train_loss = 1.263, time/batch=0.067\n",
      "10555/67600 (epoch 7), train_loss = 1.226, time/batch=0.067\n",
      "10556/67600 (epoch 7), train_loss = 1.285, time/batch=0.065\n",
      "10557/67600 (epoch 7), train_loss = 1.231, time/batch=0.072\n",
      "10558/67600 (epoch 7), train_loss = 1.235, time/batch=0.068\n",
      "10559/67600 (epoch 7), train_loss = 1.210, time/batch=0.167\n",
      "10560/67600 (epoch 7), train_loss = 1.243, time/batch=0.066\n",
      "10561/67600 (epoch 7), train_loss = 1.239, time/batch=0.097\n",
      "10562/67600 (epoch 7), train_loss = 1.207, time/batch=0.068\n",
      "10563/67600 (epoch 7), train_loss = 1.175, time/batch=0.071\n",
      "10564/67600 (epoch 7), train_loss = 1.241, time/batch=0.076\n",
      "10565/67600 (epoch 7), train_loss = 1.235, time/batch=0.070\n",
      "10566/67600 (epoch 7), train_loss = 1.223, time/batch=0.066\n",
      "10567/67600 (epoch 7), train_loss = 1.198, time/batch=0.084\n",
      "10568/67600 (epoch 7), train_loss = 1.323, time/batch=0.068\n",
      "10569/67600 (epoch 7), train_loss = 1.218, time/batch=0.066\n",
      "10570/67600 (epoch 7), train_loss = 1.229, time/batch=0.067\n",
      "10571/67600 (epoch 7), train_loss = 1.268, time/batch=0.093\n",
      "10572/67600 (epoch 7), train_loss = 1.218, time/batch=0.141\n",
      "10573/67600 (epoch 7), train_loss = 1.250, time/batch=0.072\n",
      "10574/67600 (epoch 7), train_loss = 1.264, time/batch=0.092\n",
      "10575/67600 (epoch 7), train_loss = 1.244, time/batch=0.066\n",
      "10576/67600 (epoch 7), train_loss = 1.290, time/batch=0.068\n",
      "10577/67600 (epoch 7), train_loss = 1.292, time/batch=0.066\n",
      "10578/67600 (epoch 7), train_loss = 1.267, time/batch=0.076\n",
      "10579/67600 (epoch 7), train_loss = 1.337, time/batch=0.067\n",
      "10580/67600 (epoch 7), train_loss = 1.235, time/batch=0.069\n",
      "10581/67600 (epoch 7), train_loss = 1.274, time/batch=0.067\n",
      "10582/67600 (epoch 7), train_loss = 1.242, time/batch=0.087\n",
      "10583/67600 (epoch 7), train_loss = 1.338, time/batch=0.071\n",
      "10584/67600 (epoch 7), train_loss = 1.228, time/batch=0.226\n",
      "10585/67600 (epoch 7), train_loss = 1.275, time/batch=0.105\n",
      "10586/67600 (epoch 7), train_loss = 1.343, time/batch=0.090\n",
      "10587/67600 (epoch 7), train_loss = 1.261, time/batch=0.079\n",
      "10588/67600 (epoch 7), train_loss = 1.242, time/batch=0.074\n",
      "10589/67600 (epoch 7), train_loss = 1.247, time/batch=0.074\n",
      "10590/67600 (epoch 7), train_loss = 1.301, time/batch=0.069\n",
      "10591/67600 (epoch 7), train_loss = 1.243, time/batch=0.071\n",
      "10592/67600 (epoch 7), train_loss = 1.274, time/batch=0.070\n",
      "10593/67600 (epoch 7), train_loss = 1.267, time/batch=0.071\n",
      "10594/67600 (epoch 7), train_loss = 1.258, time/batch=0.073\n",
      "10595/67600 (epoch 7), train_loss = 1.280, time/batch=0.215\n",
      "10596/67600 (epoch 7), train_loss = 1.234, time/batch=0.081\n",
      "10597/67600 (epoch 7), train_loss = 1.286, time/batch=0.093\n",
      "10598/67600 (epoch 7), train_loss = 1.325, time/batch=0.078\n",
      "10599/67600 (epoch 7), train_loss = 1.318, time/batch=0.072\n",
      "10600/67600 (epoch 7), train_loss = 1.286, time/batch=0.068\n",
      "10601/67600 (epoch 7), train_loss = 1.255, time/batch=0.073\n",
      "10602/67600 (epoch 7), train_loss = 1.257, time/batch=0.073\n",
      "10603/67600 (epoch 7), train_loss = 1.299, time/batch=0.081\n",
      "10604/67600 (epoch 7), train_loss = 1.251, time/batch=0.073\n",
      "10605/67600 (epoch 7), train_loss = 1.249, time/batch=0.084\n",
      "10606/67600 (epoch 7), train_loss = 1.280, time/batch=0.237\n",
      "10607/67600 (epoch 7), train_loss = 1.285, time/batch=0.075\n",
      "10608/67600 (epoch 7), train_loss = 1.276, time/batch=0.090\n",
      "10609/67600 (epoch 7), train_loss = 1.221, time/batch=0.079\n",
      "10610/67600 (epoch 7), train_loss = 1.220, time/batch=0.085\n",
      "10611/67600 (epoch 7), train_loss = 1.210, time/batch=0.071\n",
      "10612/67600 (epoch 7), train_loss = 1.215, time/batch=0.085\n",
      "10613/67600 (epoch 7), train_loss = 1.237, time/batch=0.096\n",
      "10614/67600 (epoch 7), train_loss = 1.187, time/batch=0.099\n",
      "10615/67600 (epoch 7), train_loss = 1.278, time/batch=0.094\n",
      "10616/67600 (epoch 7), train_loss = 1.250, time/batch=0.074\n",
      "10617/67600 (epoch 7), train_loss = 1.221, time/batch=0.093\n",
      "10618/67600 (epoch 7), train_loss = 1.254, time/batch=0.071\n",
      "10619/67600 (epoch 7), train_loss = 1.233, time/batch=0.070\n",
      "10620/67600 (epoch 7), train_loss = 1.234, time/batch=0.081\n",
      "10621/67600 (epoch 7), train_loss = 1.182, time/batch=0.076\n",
      "10622/67600 (epoch 7), train_loss = 1.281, time/batch=0.174\n",
      "10623/67600 (epoch 7), train_loss = 1.273, time/batch=0.166\n",
      "10624/67600 (epoch 7), train_loss = 1.204, time/batch=0.089\n",
      "10625/67600 (epoch 7), train_loss = 1.214, time/batch=0.084\n",
      "10626/67600 (epoch 7), train_loss = 1.239, time/batch=0.076\n",
      "10627/67600 (epoch 7), train_loss = 1.196, time/batch=0.072\n",
      "10628/67600 (epoch 7), train_loss = 1.251, time/batch=0.072\n",
      "10629/67600 (epoch 7), train_loss = 1.203, time/batch=0.095\n",
      "10630/67600 (epoch 7), train_loss = 1.215, time/batch=0.087\n",
      "10631/67600 (epoch 7), train_loss = 1.241, time/batch=0.073\n",
      "10632/67600 (epoch 7), train_loss = 1.249, time/batch=0.083\n",
      "10633/67600 (epoch 7), train_loss = 1.175, time/batch=0.193\n",
      "10634/67600 (epoch 7), train_loss = 1.202, time/batch=0.138\n",
      "10635/67600 (epoch 7), train_loss = 1.202, time/batch=0.071\n",
      "10636/67600 (epoch 7), train_loss = 1.233, time/batch=0.084\n",
      "10637/67600 (epoch 7), train_loss = 1.232, time/batch=0.081\n",
      "10638/67600 (epoch 7), train_loss = 1.232, time/batch=0.087\n",
      "10639/67600 (epoch 7), train_loss = 1.231, time/batch=0.083\n",
      "10640/67600 (epoch 7), train_loss = 1.244, time/batch=0.073\n",
      "10641/67600 (epoch 7), train_loss = 1.247, time/batch=0.084\n",
      "10642/67600 (epoch 7), train_loss = 1.271, time/batch=0.073\n",
      "10643/67600 (epoch 7), train_loss = 1.352, time/batch=0.073\n",
      "10644/67600 (epoch 7), train_loss = 1.308, time/batch=0.221\n",
      "10645/67600 (epoch 7), train_loss = 1.258, time/batch=0.082\n",
      "10646/67600 (epoch 7), train_loss = 1.253, time/batch=0.070\n",
      "10647/67600 (epoch 7), train_loss = 1.236, time/batch=0.071\n",
      "10648/67600 (epoch 7), train_loss = 1.265, time/batch=0.073\n",
      "10649/67600 (epoch 7), train_loss = 1.170, time/batch=0.075\n",
      "10650/67600 (epoch 7), train_loss = 1.204, time/batch=0.071\n",
      "10651/67600 (epoch 7), train_loss = 1.288, time/batch=0.074\n",
      "10652/67600 (epoch 7), train_loss = 1.238, time/batch=0.188\n",
      "10653/67600 (epoch 7), train_loss = 1.208, time/batch=0.070\n",
      "10654/67600 (epoch 7), train_loss = 1.242, time/batch=0.104\n",
      "10655/67600 (epoch 7), train_loss = 1.218, time/batch=0.073\n",
      "10656/67600 (epoch 7), train_loss = 1.234, time/batch=0.078\n",
      "10657/67600 (epoch 7), train_loss = 1.235, time/batch=0.082\n",
      "10658/67600 (epoch 7), train_loss = 1.186, time/batch=0.069\n",
      "10659/67600 (epoch 7), train_loss = 1.223, time/batch=0.070\n",
      "10660/67600 (epoch 7), train_loss = 1.255, time/batch=0.076\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10661/67600 (epoch 7), train_loss = 1.266, time/batch=0.073\n",
      "10662/67600 (epoch 7), train_loss = 1.268, time/batch=0.070\n",
      "10663/67600 (epoch 7), train_loss = 1.224, time/batch=0.072\n",
      "10664/67600 (epoch 7), train_loss = 1.254, time/batch=0.191\n",
      "10665/67600 (epoch 7), train_loss = 1.228, time/batch=0.115\n",
      "10666/67600 (epoch 7), train_loss = 1.205, time/batch=0.071\n",
      "10667/67600 (epoch 7), train_loss = 1.210, time/batch=0.072\n",
      "10668/67600 (epoch 7), train_loss = 1.322, time/batch=0.072\n",
      "10669/67600 (epoch 7), train_loss = 1.236, time/batch=0.070\n",
      "10670/67600 (epoch 7), train_loss = 1.201, time/batch=0.074\n",
      "10671/67600 (epoch 7), train_loss = 1.255, time/batch=0.068\n",
      "10672/67600 (epoch 7), train_loss = 1.207, time/batch=0.075\n",
      "10673/67600 (epoch 7), train_loss = 1.203, time/batch=0.072\n",
      "10674/67600 (epoch 7), train_loss = 1.248, time/batch=0.069\n",
      "10675/67600 (epoch 7), train_loss = 1.209, time/batch=0.127\n",
      "10676/67600 (epoch 7), train_loss = 1.198, time/batch=0.144\n",
      "10677/67600 (epoch 7), train_loss = 1.240, time/batch=0.107\n",
      "10678/67600 (epoch 7), train_loss = 1.274, time/batch=0.075\n",
      "10679/67600 (epoch 7), train_loss = 1.223, time/batch=0.074\n",
      "10680/67600 (epoch 7), train_loss = 1.250, time/batch=0.072\n",
      "10681/67600 (epoch 7), train_loss = 1.236, time/batch=0.068\n",
      "10682/67600 (epoch 7), train_loss = 1.231, time/batch=0.076\n",
      "10683/67600 (epoch 7), train_loss = 1.243, time/batch=0.080\n",
      "10684/67600 (epoch 7), train_loss = 1.224, time/batch=0.069\n",
      "10685/67600 (epoch 7), train_loss = 1.221, time/batch=0.071\n",
      "10686/67600 (epoch 7), train_loss = 1.268, time/batch=0.075\n",
      "10687/67600 (epoch 7), train_loss = 1.225, time/batch=0.205\n",
      "10688/67600 (epoch 7), train_loss = 1.272, time/batch=0.109\n",
      "10689/67600 (epoch 7), train_loss = 1.268, time/batch=0.075\n",
      "10690/67600 (epoch 7), train_loss = 1.275, time/batch=0.080\n",
      "10691/67600 (epoch 7), train_loss = 1.246, time/batch=0.071\n",
      "10692/67600 (epoch 7), train_loss = 1.296, time/batch=0.088\n",
      "10693/67600 (epoch 7), train_loss = 1.218, time/batch=0.081\n",
      "10694/67600 (epoch 7), train_loss = 1.252, time/batch=0.070\n",
      "10695/67600 (epoch 7), train_loss = 1.260, time/batch=0.069\n",
      "10696/67600 (epoch 7), train_loss = 1.339, time/batch=0.077\n",
      "10697/67600 (epoch 7), train_loss = 1.296, time/batch=0.087\n",
      "10698/67600 (epoch 7), train_loss = 1.196, time/batch=0.210\n",
      "10699/67600 (epoch 7), train_loss = 1.240, time/batch=0.082\n",
      "10700/67600 (epoch 7), train_loss = 1.233, time/batch=0.070\n",
      "10701/67600 (epoch 7), train_loss = 1.264, time/batch=0.073\n",
      "10702/67600 (epoch 7), train_loss = 1.230, time/batch=0.076\n",
      "10703/67600 (epoch 7), train_loss = 1.222, time/batch=0.069\n",
      "10704/67600 (epoch 7), train_loss = 1.289, time/batch=0.072\n",
      "10705/67600 (epoch 7), train_loss = 1.226, time/batch=0.071\n",
      "10706/67600 (epoch 7), train_loss = 1.237, time/batch=0.180\n",
      "10707/67600 (epoch 7), train_loss = 1.261, time/batch=0.073\n",
      "10708/67600 (epoch 7), train_loss = 1.338, time/batch=0.120\n",
      "10709/67600 (epoch 7), train_loss = 1.255, time/batch=0.072\n",
      "10710/67600 (epoch 7), train_loss = 1.239, time/batch=0.070\n",
      "10711/67600 (epoch 7), train_loss = 1.241, time/batch=0.087\n",
      "10712/67600 (epoch 7), train_loss = 1.265, time/batch=0.078\n",
      "10713/67600 (epoch 7), train_loss = 1.237, time/batch=0.068\n",
      "10714/67600 (epoch 7), train_loss = 1.212, time/batch=0.072\n",
      "10715/67600 (epoch 7), train_loss = 1.304, time/batch=0.092\n",
      "10716/67600 (epoch 7), train_loss = 1.201, time/batch=0.080\n",
      "10717/67600 (epoch 7), train_loss = 1.304, time/batch=0.194\n",
      "10718/67600 (epoch 7), train_loss = 1.261, time/batch=0.071\n",
      "10719/67600 (epoch 7), train_loss = 1.281, time/batch=0.113\n",
      "10720/67600 (epoch 7), train_loss = 1.275, time/batch=0.075\n",
      "10721/67600 (epoch 7), train_loss = 1.270, time/batch=0.077\n",
      "10722/67600 (epoch 7), train_loss = 1.308, time/batch=0.075\n",
      "10723/67600 (epoch 7), train_loss = 1.260, time/batch=0.071\n",
      "10724/67600 (epoch 7), train_loss = 1.261, time/batch=0.071\n",
      "10725/67600 (epoch 7), train_loss = 1.219, time/batch=0.076\n",
      "10726/67600 (epoch 7), train_loss = 1.323, time/batch=0.072\n",
      "10727/67600 (epoch 7), train_loss = 1.316, time/batch=0.069\n",
      "10728/67600 (epoch 7), train_loss = 1.293, time/batch=0.074\n",
      "10729/67600 (epoch 7), train_loss = 1.240, time/batch=0.199\n",
      "10730/67600 (epoch 7), train_loss = 1.310, time/batch=0.103\n",
      "10731/67600 (epoch 7), train_loss = 1.220, time/batch=0.073\n",
      "10732/67600 (epoch 7), train_loss = 1.194, time/batch=0.074\n",
      "10733/67600 (epoch 7), train_loss = 1.251, time/batch=0.072\n",
      "10734/67600 (epoch 7), train_loss = 1.244, time/batch=0.075\n",
      "10735/67600 (epoch 7), train_loss = 1.190, time/batch=0.072\n",
      "10736/67600 (epoch 7), train_loss = 1.251, time/batch=0.070\n",
      "10737/67600 (epoch 7), train_loss = 1.241, time/batch=0.071\n",
      "10738/67600 (epoch 7), train_loss = 1.228, time/batch=0.072\n",
      "10739/67600 (epoch 7), train_loss = 1.278, time/batch=0.085\n",
      "10740/67600 (epoch 7), train_loss = 1.274, time/batch=0.199\n",
      "10741/67600 (epoch 7), train_loss = 1.258, time/batch=0.069\n",
      "10742/67600 (epoch 7), train_loss = 1.188, time/batch=0.094\n",
      "10743/67600 (epoch 7), train_loss = 1.191, time/batch=0.074\n",
      "10744/67600 (epoch 7), train_loss = 1.211, time/batch=0.074\n",
      "10745/67600 (epoch 7), train_loss = 1.250, time/batch=0.073\n",
      "10746/67600 (epoch 7), train_loss = 1.195, time/batch=0.072\n",
      "10747/67600 (epoch 7), train_loss = 1.251, time/batch=0.083\n",
      "10748/67600 (epoch 7), train_loss = 1.272, time/batch=0.068\n",
      "10749/67600 (epoch 7), train_loss = 1.239, time/batch=0.071\n",
      "10750/67600 (epoch 7), train_loss = 1.216, time/batch=0.071\n",
      "10751/67600 (epoch 7), train_loss = 1.294, time/batch=0.073\n",
      "10752/67600 (epoch 7), train_loss = 1.220, time/batch=0.226\n",
      "10753/67600 (epoch 7), train_loss = 1.287, time/batch=0.084\n",
      "10754/67600 (epoch 7), train_loss = 1.310, time/batch=0.067\n",
      "10755/67600 (epoch 7), train_loss = 1.275, time/batch=0.073\n",
      "10756/67600 (epoch 7), train_loss = 1.232, time/batch=0.071\n",
      "10757/67600 (epoch 7), train_loss = 1.234, time/batch=0.073\n",
      "10758/67600 (epoch 7), train_loss = 1.246, time/batch=0.071\n",
      "10759/67600 (epoch 7), train_loss = 1.239, time/batch=0.071\n",
      "10760/67600 (epoch 7), train_loss = 1.252, time/batch=0.069\n",
      "10761/67600 (epoch 7), train_loss = 1.257, time/batch=0.070\n",
      "10762/67600 (epoch 7), train_loss = 1.207, time/batch=0.071\n",
      "10763/67600 (epoch 7), train_loss = 1.269, time/batch=0.111\n",
      "10764/67600 (epoch 7), train_loss = 1.298, time/batch=0.213\n",
      "10765/67600 (epoch 7), train_loss = 1.236, time/batch=0.089\n",
      "10766/67600 (epoch 7), train_loss = 1.213, time/batch=0.082\n",
      "10767/67600 (epoch 7), train_loss = 1.244, time/batch=0.086\n",
      "10768/67600 (epoch 7), train_loss = 1.266, time/batch=0.078\n",
      "10769/67600 (epoch 7), train_loss = 1.196, time/batch=0.070\n",
      "10770/67600 (epoch 7), train_loss = 1.269, time/batch=0.083\n",
      "10771/67600 (epoch 7), train_loss = 1.253, time/batch=0.132\n",
      "10772/67600 (epoch 7), train_loss = 1.259, time/batch=0.077\n",
      "10773/67600 (epoch 7), train_loss = 1.253, time/batch=0.081\n",
      "10774/67600 (epoch 7), train_loss = 1.220, time/batch=0.083\n",
      "10775/67600 (epoch 7), train_loss = 1.237, time/batch=0.073\n",
      "10776/67600 (epoch 7), train_loss = 1.237, time/batch=0.081\n",
      "10777/67600 (epoch 7), train_loss = 1.303, time/batch=0.076\n",
      "10778/67600 (epoch 7), train_loss = 1.307, time/batch=0.083\n",
      "10779/67600 (epoch 7), train_loss = 1.253, time/batch=0.070\n",
      "10780/67600 (epoch 7), train_loss = 1.264, time/batch=0.264\n",
      "10781/67600 (epoch 7), train_loss = 1.291, time/batch=0.099\n",
      "10782/67600 (epoch 7), train_loss = 1.257, time/batch=0.077\n",
      "10783/67600 (epoch 7), train_loss = 1.230, time/batch=0.092\n",
      "10784/67600 (epoch 7), train_loss = 1.252, time/batch=0.078\n",
      "10785/67600 (epoch 7), train_loss = 1.235, time/batch=0.073\n",
      "10786/67600 (epoch 7), train_loss = 1.220, time/batch=0.093\n",
      "10787/67600 (epoch 7), train_loss = 1.246, time/batch=0.092\n",
      "10788/67600 (epoch 7), train_loss = 1.295, time/batch=0.074\n",
      "10789/67600 (epoch 7), train_loss = 1.245, time/batch=0.088\n",
      "10790/67600 (epoch 7), train_loss = 1.257, time/batch=0.233\n",
      "10791/67600 (epoch 7), train_loss = 1.243, time/batch=0.098\n",
      "10792/67600 (epoch 7), train_loss = 1.242, time/batch=0.082\n",
      "10793/67600 (epoch 7), train_loss = 1.271, time/batch=0.086\n",
      "10794/67600 (epoch 7), train_loss = 1.298, time/batch=0.072\n",
      "10795/67600 (epoch 7), train_loss = 1.310, time/batch=0.079\n",
      "10796/67600 (epoch 7), train_loss = 1.243, time/batch=0.074\n",
      "10797/67600 (epoch 7), train_loss = 1.244, time/batch=0.070\n",
      "10798/67600 (epoch 7), train_loss = 1.205, time/batch=0.070\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10799/67600 (epoch 7), train_loss = 1.270, time/batch=0.072\n",
      "10800/67600 (epoch 7), train_loss = 1.282, time/batch=0.071\n",
      "10801/67600 (epoch 7), train_loss = 1.241, time/batch=0.219\n",
      "10802/67600 (epoch 7), train_loss = 1.280, time/batch=0.090\n",
      "10803/67600 (epoch 7), train_loss = 1.244, time/batch=0.083\n",
      "10804/67600 (epoch 7), train_loss = 1.219, time/batch=0.072\n",
      "10805/67600 (epoch 7), train_loss = 1.253, time/batch=0.073\n",
      "10806/67600 (epoch 7), train_loss = 1.268, time/batch=0.083\n",
      "10807/67600 (epoch 7), train_loss = 1.235, time/batch=0.076\n",
      "10808/67600 (epoch 7), train_loss = 1.203, time/batch=0.083\n",
      "10809/67600 (epoch 7), train_loss = 1.249, time/batch=0.189\n",
      "10810/67600 (epoch 7), train_loss = 1.226, time/batch=0.116\n",
      "10811/67600 (epoch 7), train_loss = 1.248, time/batch=0.081\n",
      "10812/67600 (epoch 7), train_loss = 1.307, time/batch=0.076\n",
      "10813/67600 (epoch 7), train_loss = 1.347, time/batch=0.081\n",
      "10814/67600 (epoch 7), train_loss = 1.263, time/batch=0.073\n",
      "10815/67600 (epoch 7), train_loss = 1.270, time/batch=0.071\n",
      "10816/67600 (epoch 8), train_loss = 1.438, time/batch=0.074\n",
      "10817/67600 (epoch 8), train_loss = 1.200, time/batch=0.072\n",
      "10818/67600 (epoch 8), train_loss = 1.283, time/batch=0.081\n",
      "10819/67600 (epoch 8), train_loss = 1.235, time/batch=0.186\n",
      "10820/67600 (epoch 8), train_loss = 1.259, time/batch=0.072\n",
      "10821/67600 (epoch 8), train_loss = 1.288, time/batch=0.119\n",
      "10822/67600 (epoch 8), train_loss = 1.243, time/batch=0.070\n",
      "10823/67600 (epoch 8), train_loss = 1.252, time/batch=0.065\n",
      "10824/67600 (epoch 8), train_loss = 1.269, time/batch=0.080\n",
      "10825/67600 (epoch 8), train_loss = 1.242, time/batch=0.074\n",
      "10826/67600 (epoch 8), train_loss = 1.204, time/batch=0.080\n",
      "10827/67600 (epoch 8), train_loss = 1.228, time/batch=0.078\n",
      "10828/67600 (epoch 8), train_loss = 1.230, time/batch=0.083\n",
      "10829/67600 (epoch 8), train_loss = 1.297, time/batch=0.072\n",
      "10830/67600 (epoch 8), train_loss = 1.265, time/batch=0.221\n",
      "10831/67600 (epoch 8), train_loss = 1.246, time/batch=0.076\n",
      "10832/67600 (epoch 8), train_loss = 1.249, time/batch=0.107\n",
      "10833/67600 (epoch 8), train_loss = 1.265, time/batch=0.085\n",
      "10834/67600 (epoch 8), train_loss = 1.246, time/batch=0.069\n",
      "10835/67600 (epoch 8), train_loss = 1.240, time/batch=0.081\n",
      "10836/67600 (epoch 8), train_loss = 1.244, time/batch=0.074\n",
      "10837/67600 (epoch 8), train_loss = 1.192, time/batch=0.071\n",
      "10838/67600 (epoch 8), train_loss = 1.308, time/batch=0.069\n",
      "10839/67600 (epoch 8), train_loss = 1.290, time/batch=0.071\n",
      "10840/67600 (epoch 8), train_loss = 1.322, time/batch=0.071\n",
      "10841/67600 (epoch 8), train_loss = 1.175, time/batch=0.164\n",
      "10842/67600 (epoch 8), train_loss = 1.268, time/batch=0.112\n",
      "10843/67600 (epoch 8), train_loss = 1.295, time/batch=0.088\n",
      "10844/67600 (epoch 8), train_loss = 1.315, time/batch=0.069\n",
      "10845/67600 (epoch 8), train_loss = 1.246, time/batch=0.072\n",
      "10846/67600 (epoch 8), train_loss = 1.234, time/batch=0.068\n",
      "10847/67600 (epoch 8), train_loss = 1.312, time/batch=0.071\n",
      "10848/67600 (epoch 8), train_loss = 1.242, time/batch=0.076\n",
      "10849/67600 (epoch 8), train_loss = 1.303, time/batch=0.085\n",
      "10850/67600 (epoch 8), train_loss = 1.271, time/batch=0.081\n",
      "10851/67600 (epoch 8), train_loss = 1.255, time/batch=0.074\n",
      "10852/67600 (epoch 8), train_loss = 1.214, time/batch=0.071\n",
      "10853/67600 (epoch 8), train_loss = 1.267, time/batch=0.223\n",
      "10854/67600 (epoch 8), train_loss = 1.262, time/batch=0.087\n",
      "10855/67600 (epoch 8), train_loss = 1.253, time/batch=0.084\n",
      "10856/67600 (epoch 8), train_loss = 1.182, time/batch=0.084\n",
      "10857/67600 (epoch 8), train_loss = 1.281, time/batch=0.072\n",
      "10858/67600 (epoch 8), train_loss = 1.298, time/batch=0.071\n",
      "10859/67600 (epoch 8), train_loss = 1.271, time/batch=0.077\n",
      "10860/67600 (epoch 8), train_loss = 1.291, time/batch=0.070\n",
      "10861/67600 (epoch 8), train_loss = 1.243, time/batch=0.171\n",
      "10862/67600 (epoch 8), train_loss = 1.218, time/batch=0.075\n",
      "10863/67600 (epoch 8), train_loss = 1.263, time/batch=0.106\n",
      "10864/67600 (epoch 8), train_loss = 1.223, time/batch=0.073\n",
      "10865/67600 (epoch 8), train_loss = 1.224, time/batch=0.070\n",
      "10866/67600 (epoch 8), train_loss = 1.309, time/batch=0.093\n",
      "10867/67600 (epoch 8), train_loss = 1.232, time/batch=0.073\n",
      "10868/67600 (epoch 8), train_loss = 1.236, time/batch=0.090\n",
      "10869/67600 (epoch 8), train_loss = 1.331, time/batch=0.072\n",
      "10870/67600 (epoch 8), train_loss = 1.294, time/batch=0.077\n",
      "10871/67600 (epoch 8), train_loss = 1.254, time/batch=0.074\n",
      "10872/67600 (epoch 8), train_loss = 1.261, time/batch=0.186\n",
      "10873/67600 (epoch 8), train_loss = 1.255, time/batch=0.075\n",
      "10874/67600 (epoch 8), train_loss = 1.260, time/batch=0.107\n",
      "10875/67600 (epoch 8), train_loss = 1.263, time/batch=0.071\n",
      "10876/67600 (epoch 8), train_loss = 1.261, time/batch=0.069\n",
      "10877/67600 (epoch 8), train_loss = 1.249, time/batch=0.075\n",
      "10878/67600 (epoch 8), train_loss = 1.288, time/batch=0.105\n",
      "10879/67600 (epoch 8), train_loss = 1.299, time/batch=0.085\n",
      "10880/67600 (epoch 8), train_loss = 1.244, time/batch=0.074\n",
      "10881/67600 (epoch 8), train_loss = 1.231, time/batch=0.073\n",
      "10882/67600 (epoch 8), train_loss = 1.240, time/batch=0.071\n",
      "10883/67600 (epoch 8), train_loss = 1.268, time/batch=0.204\n",
      "10884/67600 (epoch 8), train_loss = 1.282, time/batch=0.073\n",
      "10885/67600 (epoch 8), train_loss = 1.276, time/batch=0.106\n",
      "10886/67600 (epoch 8), train_loss = 1.272, time/batch=0.073\n",
      "10887/67600 (epoch 8), train_loss = 1.274, time/batch=0.069\n",
      "10888/67600 (epoch 8), train_loss = 1.234, time/batch=0.075\n",
      "10889/67600 (epoch 8), train_loss = 1.299, time/batch=0.101\n",
      "10890/67600 (epoch 8), train_loss = 1.249, time/batch=0.102\n",
      "10891/67600 (epoch 8), train_loss = 1.302, time/batch=0.107\n",
      "10892/67600 (epoch 8), train_loss = 1.292, time/batch=0.079\n",
      "10893/67600 (epoch 8), train_loss = 1.381, time/batch=0.222\n",
      "10894/67600 (epoch 8), train_loss = 1.305, time/batch=0.124\n",
      "10895/67600 (epoch 8), train_loss = 1.233, time/batch=0.105\n",
      "10896/67600 (epoch 8), train_loss = 1.214, time/batch=0.071\n",
      "10897/67600 (epoch 8), train_loss = 1.262, time/batch=0.073\n",
      "10898/67600 (epoch 8), train_loss = 1.267, time/batch=0.079\n",
      "10899/67600 (epoch 8), train_loss = 1.251, time/batch=0.071\n",
      "10900/67600 (epoch 8), train_loss = 1.253, time/batch=0.073\n",
      "10901/67600 (epoch 8), train_loss = 1.251, time/batch=0.073\n",
      "10902/67600 (epoch 8), train_loss = 1.193, time/batch=0.076\n",
      "10903/67600 (epoch 8), train_loss = 1.309, time/batch=0.071\n",
      "10904/67600 (epoch 8), train_loss = 1.291, time/batch=0.214\n",
      "10905/67600 (epoch 8), train_loss = 1.289, time/batch=0.085\n",
      "10906/67600 (epoch 8), train_loss = 1.260, time/batch=0.074\n",
      "10907/67600 (epoch 8), train_loss = 1.279, time/batch=0.077\n",
      "10908/67600 (epoch 8), train_loss = 1.209, time/batch=0.072\n",
      "10909/67600 (epoch 8), train_loss = 1.227, time/batch=0.073\n",
      "10910/67600 (epoch 8), train_loss = 1.219, time/batch=0.077\n",
      "10911/67600 (epoch 8), train_loss = 1.163, time/batch=0.082\n",
      "10912/67600 (epoch 8), train_loss = 1.180, time/batch=0.091\n",
      "10913/67600 (epoch 8), train_loss = 1.262, time/batch=0.078\n",
      "10914/67600 (epoch 8), train_loss = 1.244, time/batch=0.075\n",
      "10915/67600 (epoch 8), train_loss = 1.290, time/batch=0.222\n",
      "10916/67600 (epoch 8), train_loss = 1.163, time/batch=0.081\n",
      "10917/67600 (epoch 8), train_loss = 1.238, time/batch=0.073\n",
      "10918/67600 (epoch 8), train_loss = 1.272, time/batch=0.075\n",
      "10919/67600 (epoch 8), train_loss = 1.187, time/batch=0.069\n",
      "10920/67600 (epoch 8), train_loss = 1.219, time/batch=0.073\n",
      "10921/67600 (epoch 8), train_loss = 1.267, time/batch=0.127\n",
      "10922/67600 (epoch 8), train_loss = 1.226, time/batch=0.137\n",
      "10923/67600 (epoch 8), train_loss = 1.264, time/batch=0.090\n",
      "10924/67600 (epoch 8), train_loss = 1.290, time/batch=0.099\n",
      "10925/67600 (epoch 8), train_loss = 1.253, time/batch=0.079\n",
      "10926/67600 (epoch 8), train_loss = 1.221, time/batch=0.091\n",
      "10927/67600 (epoch 8), train_loss = 1.253, time/batch=0.089\n",
      "10928/67600 (epoch 8), train_loss = 1.242, time/batch=0.090\n",
      "10929/67600 (epoch 8), train_loss = 1.280, time/batch=0.378\n",
      "10930/67600 (epoch 8), train_loss = 1.276, time/batch=0.138\n",
      "10931/67600 (epoch 8), train_loss = 1.222, time/batch=0.107\n",
      "10932/67600 (epoch 8), train_loss = 1.207, time/batch=0.083\n",
      "10933/67600 (epoch 8), train_loss = 1.244, time/batch=0.070\n",
      "10934/67600 (epoch 8), train_loss = 1.275, time/batch=0.074\n",
      "10935/67600 (epoch 8), train_loss = 1.268, time/batch=0.069\n",
      "10936/67600 (epoch 8), train_loss = 1.263, time/batch=0.071\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10937/67600 (epoch 8), train_loss = 1.272, time/batch=0.074\n",
      "10938/67600 (epoch 8), train_loss = 1.240, time/batch=0.077\n",
      "10939/67600 (epoch 8), train_loss = 1.220, time/batch=0.238\n",
      "10940/67600 (epoch 8), train_loss = 1.240, time/batch=0.080\n",
      "10941/67600 (epoch 8), train_loss = 1.166, time/batch=0.079\n",
      "10942/67600 (epoch 8), train_loss = 1.245, time/batch=0.084\n",
      "10943/67600 (epoch 8), train_loss = 1.277, time/batch=0.077\n",
      "10944/67600 (epoch 8), train_loss = 1.225, time/batch=0.075\n",
      "10945/67600 (epoch 8), train_loss = 1.239, time/batch=0.075\n",
      "10946/67600 (epoch 8), train_loss = 1.267, time/batch=0.075\n",
      "10947/67600 (epoch 8), train_loss = 1.240, time/batch=0.196\n",
      "10948/67600 (epoch 8), train_loss = 1.294, time/batch=0.103\n",
      "10949/67600 (epoch 8), train_loss = 1.230, time/batch=0.098\n",
      "10950/67600 (epoch 8), train_loss = 1.253, time/batch=0.087\n",
      "10951/67600 (epoch 8), train_loss = 1.259, time/batch=0.096\n",
      "10952/67600 (epoch 8), train_loss = 1.274, time/batch=0.079\n",
      "10953/67600 (epoch 8), train_loss = 1.250, time/batch=0.072\n",
      "10954/67600 (epoch 8), train_loss = 1.258, time/batch=0.074\n",
      "10955/67600 (epoch 8), train_loss = 1.227, time/batch=0.070\n",
      "10956/67600 (epoch 8), train_loss = 1.223, time/batch=0.071\n",
      "10957/67600 (epoch 8), train_loss = 1.203, time/batch=0.096\n",
      "10958/67600 (epoch 8), train_loss = 1.259, time/batch=0.159\n",
      "10959/67600 (epoch 8), train_loss = 1.214, time/batch=0.115\n",
      "10960/67600 (epoch 8), train_loss = 1.298, time/batch=0.079\n",
      "10961/67600 (epoch 8), train_loss = 1.332, time/batch=0.074\n",
      "10962/67600 (epoch 8), train_loss = 1.252, time/batch=0.081\n",
      "10963/67600 (epoch 8), train_loss = 1.243, time/batch=0.095\n",
      "10964/67600 (epoch 8), train_loss = 1.301, time/batch=0.090\n",
      "10965/67600 (epoch 8), train_loss = 1.183, time/batch=0.100\n",
      "10966/67600 (epoch 8), train_loss = 1.262, time/batch=0.085\n",
      "10967/67600 (epoch 8), train_loss = 1.216, time/batch=0.092\n",
      "10968/67600 (epoch 8), train_loss = 1.201, time/batch=0.209\n",
      "10969/67600 (epoch 8), train_loss = 1.243, time/batch=0.106\n",
      "10970/67600 (epoch 8), train_loss = 1.216, time/batch=0.072\n",
      "10971/67600 (epoch 8), train_loss = 1.269, time/batch=0.068\n",
      "10972/67600 (epoch 8), train_loss = 1.278, time/batch=0.068\n",
      "10973/67600 (epoch 8), train_loss = 1.280, time/batch=0.071\n",
      "10974/67600 (epoch 8), train_loss = 1.261, time/batch=0.069\n",
      "10975/67600 (epoch 8), train_loss = 1.233, time/batch=0.070\n",
      "10976/67600 (epoch 8), train_loss = 1.227, time/batch=0.070\n",
      "10977/67600 (epoch 8), train_loss = 1.195, time/batch=0.079\n",
      "10978/67600 (epoch 8), train_loss = 1.252, time/batch=0.080\n",
      "10979/67600 (epoch 8), train_loss = 1.251, time/batch=0.217\n",
      "10980/67600 (epoch 8), train_loss = 1.152, time/batch=0.107\n",
      "10981/67600 (epoch 8), train_loss = 1.239, time/batch=0.086\n",
      "10982/67600 (epoch 8), train_loss = 1.236, time/batch=0.086\n",
      "10983/67600 (epoch 8), train_loss = 1.216, time/batch=0.078\n",
      "10984/67600 (epoch 8), train_loss = 1.260, time/batch=0.074\n",
      "10985/67600 (epoch 8), train_loss = 1.276, time/batch=0.074\n",
      "10986/67600 (epoch 8), train_loss = 1.268, time/batch=0.071\n",
      "10987/67600 (epoch 8), train_loss = 1.211, time/batch=0.071\n",
      "10988/67600 (epoch 8), train_loss = 1.272, time/batch=0.074\n",
      "10989/67600 (epoch 8), train_loss = 1.224, time/batch=0.066\n",
      "10990/67600 (epoch 8), train_loss = 1.221, time/batch=0.204\n",
      "10991/67600 (epoch 8), train_loss = 1.202, time/batch=0.075\n",
      "10992/67600 (epoch 8), train_loss = 1.266, time/batch=0.096\n",
      "10993/67600 (epoch 8), train_loss = 1.296, time/batch=0.078\n",
      "10994/67600 (epoch 8), train_loss = 1.209, time/batch=0.070\n",
      "10995/67600 (epoch 8), train_loss = 1.221, time/batch=0.075\n",
      "10996/67600 (epoch 8), train_loss = 1.187, time/batch=0.077\n",
      "10997/67600 (epoch 8), train_loss = 1.183, time/batch=0.071\n",
      "10998/67600 (epoch 8), train_loss = 1.221, time/batch=0.072\n",
      "10999/67600 (epoch 8), train_loss = 1.328, time/batch=0.088\n",
      "11000/67600 (epoch 8), train_loss = 1.337, time/batch=0.099\n",
      "model saved to ./save/model.ckpt\n",
      "11001/67600 (epoch 8), train_loss = 1.313, time/batch=0.170\n",
      "11002/67600 (epoch 8), train_loss = 1.339, time/batch=0.102\n",
      "11003/67600 (epoch 8), train_loss = 1.242, time/batch=0.108\n",
      "11004/67600 (epoch 8), train_loss = 1.254, time/batch=0.109\n",
      "11005/67600 (epoch 8), train_loss = 1.251, time/batch=0.083\n",
      "11006/67600 (epoch 8), train_loss = 1.319, time/batch=0.074\n",
      "11007/67600 (epoch 8), train_loss = 1.282, time/batch=0.078\n",
      "11008/67600 (epoch 8), train_loss = 1.239, time/batch=0.071\n",
      "11009/67600 (epoch 8), train_loss = 1.280, time/batch=0.075\n",
      "11010/67600 (epoch 8), train_loss = 1.275, time/batch=0.076\n",
      "11011/67600 (epoch 8), train_loss = 1.259, time/batch=0.074\n",
      "11012/67600 (epoch 8), train_loss = 1.241, time/batch=0.258\n",
      "11013/67600 (epoch 8), train_loss = 1.239, time/batch=0.139\n",
      "11014/67600 (epoch 8), train_loss = 1.267, time/batch=0.080\n",
      "11015/67600 (epoch 8), train_loss = 1.220, time/batch=0.077\n",
      "11016/67600 (epoch 8), train_loss = 1.208, time/batch=0.077\n",
      "11017/67600 (epoch 8), train_loss = 1.184, time/batch=0.072\n",
      "11018/67600 (epoch 8), train_loss = 1.310, time/batch=0.068\n",
      "11019/67600 (epoch 8), train_loss = 1.252, time/batch=0.071\n",
      "11020/67600 (epoch 8), train_loss = 1.273, time/batch=0.076\n",
      "11021/67600 (epoch 8), train_loss = 1.191, time/batch=0.272\n",
      "11022/67600 (epoch 8), train_loss = 1.187, time/batch=0.104\n",
      "11023/67600 (epoch 8), train_loss = 1.216, time/batch=0.077\n",
      "11024/67600 (epoch 8), train_loss = 1.264, time/batch=0.070\n",
      "11025/67600 (epoch 8), train_loss = 1.297, time/batch=0.067\n",
      "11026/67600 (epoch 8), train_loss = 1.271, time/batch=0.071\n",
      "11027/67600 (epoch 8), train_loss = 1.325, time/batch=0.072\n",
      "11028/67600 (epoch 8), train_loss = 1.223, time/batch=0.071\n",
      "11029/67600 (epoch 8), train_loss = 1.234, time/batch=0.108\n",
      "11030/67600 (epoch 8), train_loss = 1.243, time/batch=0.162\n",
      "11031/67600 (epoch 8), train_loss = 1.283, time/batch=0.106\n",
      "11032/67600 (epoch 8), train_loss = 1.227, time/batch=0.079\n",
      "11033/67600 (epoch 8), train_loss = 1.239, time/batch=0.078\n",
      "11034/67600 (epoch 8), train_loss = 1.214, time/batch=0.098\n",
      "11035/67600 (epoch 8), train_loss = 1.199, time/batch=0.070\n",
      "11036/67600 (epoch 8), train_loss = 1.305, time/batch=0.081\n",
      "11037/67600 (epoch 8), train_loss = 1.211, time/batch=0.077\n",
      "11038/67600 (epoch 8), train_loss = 1.258, time/batch=0.082\n",
      "11039/67600 (epoch 8), train_loss = 1.248, time/batch=0.076\n",
      "11040/67600 (epoch 8), train_loss = 1.247, time/batch=0.135\n",
      "11041/67600 (epoch 8), train_loss = 1.225, time/batch=0.096\n",
      "11042/67600 (epoch 8), train_loss = 1.286, time/batch=0.089\n",
      "11043/67600 (epoch 8), train_loss = 1.200, time/batch=0.076\n",
      "11044/67600 (epoch 8), train_loss = 1.213, time/batch=0.091\n",
      "11045/67600 (epoch 8), train_loss = 1.217, time/batch=0.086\n",
      "11046/67600 (epoch 8), train_loss = 1.255, time/batch=0.082\n",
      "11047/67600 (epoch 8), train_loss = 1.250, time/batch=0.078\n",
      "11048/67600 (epoch 8), train_loss = 1.185, time/batch=0.069\n",
      "11049/67600 (epoch 8), train_loss = 1.187, time/batch=0.239\n",
      "11050/67600 (epoch 8), train_loss = 1.254, time/batch=0.092\n",
      "11051/67600 (epoch 8), train_loss = 1.242, time/batch=0.072\n",
      "11052/67600 (epoch 8), train_loss = 1.227, time/batch=0.075\n",
      "11053/67600 (epoch 8), train_loss = 1.231, time/batch=0.074\n",
      "11054/67600 (epoch 8), train_loss = 1.293, time/batch=0.073\n",
      "11055/67600 (epoch 8), train_loss = 1.260, time/batch=0.071\n",
      "11056/67600 (epoch 8), train_loss = 1.262, time/batch=0.073\n",
      "11057/67600 (epoch 8), train_loss = 1.198, time/batch=0.079\n",
      "11058/67600 (epoch 8), train_loss = 1.247, time/batch=0.072\n",
      "11059/67600 (epoch 8), train_loss = 1.261, time/batch=0.130\n",
      "11060/67600 (epoch 8), train_loss = 1.196, time/batch=0.253\n",
      "11061/67600 (epoch 8), train_loss = 1.257, time/batch=0.096\n",
      "11062/67600 (epoch 8), train_loss = 1.237, time/batch=0.084\n",
      "11063/67600 (epoch 8), train_loss = 1.245, time/batch=0.092\n",
      "11064/67600 (epoch 8), train_loss = 1.270, time/batch=0.088\n",
      "11065/67600 (epoch 8), train_loss = 1.215, time/batch=0.294\n",
      "11066/67600 (epoch 8), train_loss = 1.211, time/batch=0.085\n",
      "11067/67600 (epoch 8), train_loss = 1.292, time/batch=0.299\n",
      "11068/67600 (epoch 8), train_loss = 1.209, time/batch=0.118\n",
      "11069/67600 (epoch 8), train_loss = 1.251, time/batch=0.122\n",
      "11070/67600 (epoch 8), train_loss = 1.264, time/batch=0.122\n",
      "11071/67600 (epoch 8), train_loss = 1.316, time/batch=0.123\n",
      "11072/67600 (epoch 8), train_loss = 1.287, time/batch=0.228\n",
      "11073/67600 (epoch 8), train_loss = 1.291, time/batch=0.144\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11074/67600 (epoch 8), train_loss = 1.204, time/batch=0.117\n",
      "11075/67600 (epoch 8), train_loss = 1.209, time/batch=0.125\n",
      "11076/67600 (epoch 8), train_loss = 1.231, time/batch=0.123\n",
      "11077/67600 (epoch 8), train_loss = 1.224, time/batch=0.110\n",
      "11078/67600 (epoch 8), train_loss = 1.244, time/batch=0.116\n",
      "11079/67600 (epoch 8), train_loss = 1.254, time/batch=0.235\n",
      "11080/67600 (epoch 8), train_loss = 1.225, time/batch=0.157\n",
      "11081/67600 (epoch 8), train_loss = 1.227, time/batch=0.118\n",
      "11082/67600 (epoch 8), train_loss = 1.209, time/batch=0.139\n",
      "11083/67600 (epoch 8), train_loss = 1.252, time/batch=0.097\n",
      "11084/67600 (epoch 8), train_loss = 1.224, time/batch=0.145\n",
      "11085/67600 (epoch 8), train_loss = 1.211, time/batch=0.132\n",
      "11086/67600 (epoch 8), train_loss = 1.272, time/batch=0.236\n",
      "11087/67600 (epoch 8), train_loss = 1.244, time/batch=0.149\n",
      "11088/67600 (epoch 8), train_loss = 1.250, time/batch=0.116\n",
      "11089/67600 (epoch 8), train_loss = 1.287, time/batch=0.108\n",
      "11090/67600 (epoch 8), train_loss = 1.262, time/batch=0.109\n",
      "11091/67600 (epoch 8), train_loss = 1.239, time/batch=0.125\n",
      "11092/67600 (epoch 8), train_loss = 1.259, time/batch=0.122\n",
      "11093/67600 (epoch 8), train_loss = 1.210, time/batch=0.243\n",
      "11094/67600 (epoch 8), train_loss = 1.210, time/batch=0.135\n",
      "11095/67600 (epoch 8), train_loss = 1.268, time/batch=0.120\n",
      "11096/67600 (epoch 8), train_loss = 1.281, time/batch=0.119\n",
      "11097/67600 (epoch 8), train_loss = 1.221, time/batch=0.116\n",
      "11098/67600 (epoch 8), train_loss = 1.180, time/batch=0.133\n",
      "11099/67600 (epoch 8), train_loss = 1.264, time/batch=0.115\n",
      "11100/67600 (epoch 8), train_loss = 1.212, time/batch=0.258\n",
      "11101/67600 (epoch 8), train_loss = 1.332, time/batch=0.128\n",
      "11102/67600 (epoch 8), train_loss = 1.261, time/batch=0.118\n",
      "11103/67600 (epoch 8), train_loss = 1.238, time/batch=0.115\n",
      "11104/67600 (epoch 8), train_loss = 1.278, time/batch=0.121\n",
      "11105/67600 (epoch 8), train_loss = 1.268, time/batch=0.207\n",
      "11106/67600 (epoch 8), train_loss = 1.266, time/batch=0.164\n",
      "11107/67600 (epoch 8), train_loss = 1.254, time/batch=0.100\n",
      "11108/67600 (epoch 8), train_loss = 1.258, time/batch=0.136\n",
      "11109/67600 (epoch 8), train_loss = 1.251, time/batch=0.122\n",
      "11110/67600 (epoch 8), train_loss = 1.256, time/batch=0.129\n",
      "11111/67600 (epoch 8), train_loss = 1.265, time/batch=0.111\n",
      "11112/67600 (epoch 8), train_loss = 1.255, time/batch=0.187\n",
      "11113/67600 (epoch 8), train_loss = 1.224, time/batch=0.199\n",
      "11114/67600 (epoch 8), train_loss = 1.225, time/batch=0.137\n",
      "11115/67600 (epoch 8), train_loss = 1.281, time/batch=0.122\n",
      "11116/67600 (epoch 8), train_loss = 1.244, time/batch=0.112\n",
      "11117/67600 (epoch 8), train_loss = 1.274, time/batch=0.143\n",
      "11118/67600 (epoch 8), train_loss = 1.239, time/batch=0.105\n",
      "11119/67600 (epoch 8), train_loss = 1.262, time/batch=0.250\n",
      "11120/67600 (epoch 8), train_loss = 1.267, time/batch=0.136\n",
      "11121/67600 (epoch 8), train_loss = 1.278, time/batch=0.131\n",
      "11122/67600 (epoch 8), train_loss = 1.300, time/batch=0.125\n",
      "11123/67600 (epoch 8), train_loss = 1.273, time/batch=0.110\n",
      "11124/67600 (epoch 8), train_loss = 1.282, time/batch=0.131\n",
      "11125/67600 (epoch 8), train_loss = 1.284, time/batch=0.120\n",
      "11126/67600 (epoch 8), train_loss = 1.248, time/batch=0.122\n",
      "11127/67600 (epoch 8), train_loss = 1.208, time/batch=0.245\n",
      "11128/67600 (epoch 8), train_loss = 1.223, time/batch=0.132\n",
      "11129/67600 (epoch 8), train_loss = 1.279, time/batch=0.112\n",
      "11130/67600 (epoch 8), train_loss = 1.249, time/batch=0.130\n",
      "11131/67600 (epoch 8), train_loss = 1.326, time/batch=0.129\n",
      "11132/67600 (epoch 8), train_loss = 1.239, time/batch=0.103\n",
      "11133/67600 (epoch 8), train_loss = 1.278, time/batch=0.138\n",
      "11134/67600 (epoch 8), train_loss = 1.278, time/batch=0.261\n",
      "11135/67600 (epoch 8), train_loss = 1.289, time/batch=0.125\n",
      "11136/67600 (epoch 8), train_loss = 1.303, time/batch=0.120\n",
      "11137/67600 (epoch 8), train_loss = 1.248, time/batch=0.123\n",
      "11138/67600 (epoch 8), train_loss = 1.263, time/batch=0.133\n",
      "11139/67600 (epoch 8), train_loss = 1.219, time/batch=0.113\n",
      "11140/67600 (epoch 8), train_loss = 1.247, time/batch=0.132\n",
      "11141/67600 (epoch 8), train_loss = 1.213, time/batch=0.265\n",
      "11142/67600 (epoch 8), train_loss = 1.215, time/batch=0.115\n",
      "11143/67600 (epoch 8), train_loss = 1.282, time/batch=0.130\n",
      "11144/67600 (epoch 8), train_loss = 1.240, time/batch=0.114\n",
      "11145/67600 (epoch 8), train_loss = 1.258, time/batch=0.149\n",
      "11146/67600 (epoch 8), train_loss = 1.285, time/batch=0.139\n",
      "11147/67600 (epoch 8), train_loss = 1.200, time/batch=0.121\n",
      "11148/67600 (epoch 8), train_loss = 1.253, time/batch=0.146\n",
      "11149/67600 (epoch 8), train_loss = 1.243, time/batch=0.100\n",
      "11150/67600 (epoch 8), train_loss = 1.264, time/batch=0.122\n",
      "11151/67600 (epoch 8), train_loss = 1.285, time/batch=0.143\n",
      "11152/67600 (epoch 8), train_loss = 1.242, time/batch=0.255\n",
      "11153/67600 (epoch 8), train_loss = 1.220, time/batch=0.142\n",
      "11154/67600 (epoch 8), train_loss = 1.257, time/batch=0.119\n",
      "11155/67600 (epoch 8), train_loss = 1.291, time/batch=0.096\n",
      "11156/67600 (epoch 8), train_loss = 1.241, time/batch=0.107\n",
      "11157/67600 (epoch 8), train_loss = 1.227, time/batch=0.126\n",
      "11158/67600 (epoch 8), train_loss = 1.214, time/batch=0.121\n",
      "11159/67600 (epoch 8), train_loss = 1.202, time/batch=0.270\n",
      "11160/67600 (epoch 8), train_loss = 1.294, time/batch=0.120\n",
      "11161/67600 (epoch 8), train_loss = 1.318, time/batch=0.136\n",
      "11162/67600 (epoch 8), train_loss = 1.259, time/batch=0.108\n",
      "11163/67600 (epoch 8), train_loss = 1.252, time/batch=0.118\n",
      "11164/67600 (epoch 8), train_loss = 1.295, time/batch=0.118\n",
      "11165/67600 (epoch 8), train_loss = 1.301, time/batch=0.120\n",
      "11166/67600 (epoch 8), train_loss = 1.209, time/batch=0.262\n",
      "11167/67600 (epoch 8), train_loss = 1.203, time/batch=0.128\n",
      "11168/67600 (epoch 8), train_loss = 1.188, time/batch=0.122\n",
      "11169/67600 (epoch 8), train_loss = 1.215, time/batch=0.127\n",
      "11170/67600 (epoch 8), train_loss = 1.222, time/batch=0.124\n",
      "11171/67600 (epoch 8), train_loss = 1.287, time/batch=0.241\n",
      "11172/67600 (epoch 8), train_loss = 1.227, time/batch=0.155\n",
      "11173/67600 (epoch 8), train_loss = 1.238, time/batch=0.104\n",
      "11174/67600 (epoch 8), train_loss = 1.195, time/batch=0.129\n",
      "11175/67600 (epoch 8), train_loss = 1.330, time/batch=0.120\n",
      "11176/67600 (epoch 8), train_loss = 1.250, time/batch=0.116\n",
      "11177/67600 (epoch 8), train_loss = 1.210, time/batch=0.123\n",
      "11178/67600 (epoch 8), train_loss = 1.215, time/batch=0.202\n",
      "11179/67600 (epoch 8), train_loss = 1.289, time/batch=0.172\n",
      "11180/67600 (epoch 8), train_loss = 1.245, time/batch=0.113\n",
      "11181/67600 (epoch 8), train_loss = 1.231, time/batch=0.121\n",
      "11182/67600 (epoch 8), train_loss = 1.241, time/batch=0.127\n",
      "11183/67600 (epoch 8), train_loss = 1.188, time/batch=0.102\n",
      "11184/67600 (epoch 8), train_loss = 1.244, time/batch=0.132\n",
      "11185/67600 (epoch 8), train_loss = 1.319, time/batch=0.313\n",
      "11186/67600 (epoch 8), train_loss = 1.240, time/batch=0.157\n",
      "11187/67600 (epoch 8), train_loss = 1.245, time/batch=0.161\n",
      "11188/67600 (epoch 8), train_loss = 1.278, time/batch=0.130\n",
      "11189/67600 (epoch 8), train_loss = 1.250, time/batch=0.095\n",
      "11190/67600 (epoch 8), train_loss = 1.306, time/batch=0.124\n",
      "11191/67600 (epoch 8), train_loss = 1.323, time/batch=0.219\n",
      "11192/67600 (epoch 8), train_loss = 1.273, time/batch=0.220\n",
      "11193/67600 (epoch 8), train_loss = 1.255, time/batch=0.147\n",
      "11194/67600 (epoch 8), train_loss = 1.315, time/batch=0.154\n",
      "11195/67600 (epoch 8), train_loss = 1.325, time/batch=0.114\n",
      "11196/67600 (epoch 8), train_loss = 1.280, time/batch=0.246\n",
      "11197/67600 (epoch 8), train_loss = 1.250, time/batch=0.207\n",
      "11198/67600 (epoch 8), train_loss = 1.242, time/batch=0.152\n",
      "11199/67600 (epoch 8), train_loss = 1.278, time/batch=0.116\n",
      "11200/67600 (epoch 8), train_loss = 1.332, time/batch=0.124\n",
      "11201/67600 (epoch 8), train_loss = 1.251, time/batch=0.125\n",
      "11202/67600 (epoch 8), train_loss = 1.238, time/batch=0.115\n",
      "11203/67600 (epoch 8), train_loss = 1.243, time/batch=0.101\n",
      "11204/67600 (epoch 8), train_loss = 1.288, time/batch=0.257\n",
      "11205/67600 (epoch 8), train_loss = 1.263, time/batch=0.153\n",
      "11206/67600 (epoch 8), train_loss = 1.240, time/batch=0.130\n",
      "11207/67600 (epoch 8), train_loss = 1.237, time/batch=0.108\n",
      "11208/67600 (epoch 8), train_loss = 1.235, time/batch=0.115\n",
      "11209/67600 (epoch 8), train_loss = 1.253, time/batch=0.237\n",
      "11210/67600 (epoch 8), train_loss = 1.237, time/batch=0.161\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11211/67600 (epoch 8), train_loss = 1.241, time/batch=0.125\n",
      "11212/67600 (epoch 8), train_loss = 1.299, time/batch=0.116\n",
      "11213/67600 (epoch 8), train_loss = 1.294, time/batch=0.114\n",
      "11214/67600 (epoch 8), train_loss = 1.254, time/batch=0.127\n",
      "11215/67600 (epoch 8), train_loss = 1.236, time/batch=0.128\n",
      "11216/67600 (epoch 8), train_loss = 1.277, time/batch=0.243\n",
      "11217/67600 (epoch 8), train_loss = 1.330, time/batch=0.146\n",
      "11218/67600 (epoch 8), train_loss = 1.309, time/batch=0.111\n",
      "11219/67600 (epoch 8), train_loss = 1.269, time/batch=0.121\n",
      "11220/67600 (epoch 8), train_loss = 1.332, time/batch=0.131\n",
      "11221/67600 (epoch 8), train_loss = 1.293, time/batch=0.126\n",
      "11222/67600 (epoch 8), train_loss = 1.301, time/batch=0.114\n",
      "11223/67600 (epoch 8), train_loss = 1.234, time/batch=0.176\n",
      "11224/67600 (epoch 8), train_loss = 1.285, time/batch=0.204\n",
      "11225/67600 (epoch 8), train_loss = 1.279, time/batch=0.105\n",
      "11226/67600 (epoch 8), train_loss = 1.277, time/batch=0.133\n",
      "11227/67600 (epoch 8), train_loss = 1.216, time/batch=0.136\n",
      "11228/67600 (epoch 8), train_loss = 1.247, time/batch=0.120\n",
      "11229/67600 (epoch 8), train_loss = 1.261, time/batch=0.159\n",
      "11230/67600 (epoch 8), train_loss = 1.239, time/batch=0.246\n",
      "11231/67600 (epoch 8), train_loss = 1.301, time/batch=0.125\n",
      "11232/67600 (epoch 8), train_loss = 1.262, time/batch=0.138\n",
      "11233/67600 (epoch 8), train_loss = 1.291, time/batch=0.109\n",
      "11234/67600 (epoch 8), train_loss = 1.302, time/batch=0.120\n",
      "11235/67600 (epoch 8), train_loss = 1.229, time/batch=0.247\n",
      "11236/67600 (epoch 8), train_loss = 1.171, time/batch=0.135\n",
      "11237/67600 (epoch 8), train_loss = 1.199, time/batch=0.134\n",
      "11238/67600 (epoch 8), train_loss = 1.248, time/batch=0.138\n",
      "11239/67600 (epoch 8), train_loss = 1.202, time/batch=0.107\n",
      "11240/67600 (epoch 8), train_loss = 1.251, time/batch=0.130\n",
      "11241/67600 (epoch 8), train_loss = 1.224, time/batch=0.118\n",
      "11242/67600 (epoch 8), train_loss = 1.235, time/batch=0.159\n",
      "11243/67600 (epoch 8), train_loss = 1.234, time/batch=0.139\n",
      "11244/67600 (epoch 8), train_loss = 1.161, time/batch=0.115\n",
      "11245/67600 (epoch 8), train_loss = 1.224, time/batch=0.120\n",
      "11246/67600 (epoch 8), train_loss = 1.286, time/batch=0.118\n",
      "11247/67600 (epoch 8), train_loss = 1.212, time/batch=0.122\n",
      "11248/67600 (epoch 8), train_loss = 1.275, time/batch=0.317\n",
      "11249/67600 (epoch 8), train_loss = 1.274, time/batch=0.134\n",
      "11250/67600 (epoch 8), train_loss = 1.211, time/batch=0.135\n",
      "11251/67600 (epoch 8), train_loss = 1.314, time/batch=0.116\n",
      "11252/67600 (epoch 8), train_loss = 1.248, time/batch=0.124\n",
      "11253/67600 (epoch 8), train_loss = 1.254, time/batch=0.111\n",
      "11254/67600 (epoch 8), train_loss = 1.269, time/batch=0.112\n",
      "11255/67600 (epoch 8), train_loss = 1.234, time/batch=0.273\n",
      "11256/67600 (epoch 8), train_loss = 1.231, time/batch=0.139\n",
      "11257/67600 (epoch 8), train_loss = 1.270, time/batch=0.104\n",
      "11258/67600 (epoch 8), train_loss = 1.227, time/batch=0.123\n",
      "11259/67600 (epoch 8), train_loss = 1.215, time/batch=0.123\n",
      "11260/67600 (epoch 8), train_loss = 1.261, time/batch=0.118\n",
      "11261/67600 (epoch 8), train_loss = 1.289, time/batch=0.114\n",
      "11262/67600 (epoch 8), train_loss = 1.207, time/batch=0.232\n",
      "11263/67600 (epoch 8), train_loss = 1.220, time/batch=0.156\n",
      "11264/67600 (epoch 8), train_loss = 1.197, time/batch=0.112\n",
      "11265/67600 (epoch 8), train_loss = 1.214, time/batch=0.104\n",
      "11266/67600 (epoch 8), train_loss = 1.172, time/batch=0.126\n",
      "11267/67600 (epoch 8), train_loss = 1.278, time/batch=0.158\n",
      "11268/67600 (epoch 8), train_loss = 1.290, time/batch=0.193\n",
      "11269/67600 (epoch 8), train_loss = 1.187, time/batch=0.149\n",
      "11270/67600 (epoch 8), train_loss = 1.173, time/batch=0.134\n",
      "11271/67600 (epoch 8), train_loss = 1.207, time/batch=0.112\n",
      "11272/67600 (epoch 8), train_loss = 1.232, time/batch=0.119\n",
      "11273/67600 (epoch 8), train_loss = 1.248, time/batch=0.134\n",
      "11274/67600 (epoch 8), train_loss = 1.272, time/batch=0.107\n",
      "11275/67600 (epoch 8), train_loss = 1.245, time/batch=0.229\n",
      "11276/67600 (epoch 8), train_loss = 1.263, time/batch=0.161\n",
      "11277/67600 (epoch 8), train_loss = 1.209, time/batch=0.119\n",
      "11278/67600 (epoch 8), train_loss = 1.269, time/batch=0.128\n",
      "11279/67600 (epoch 8), train_loss = 1.247, time/batch=0.126\n",
      "11280/67600 (epoch 8), train_loss = 1.218, time/batch=0.113\n",
      "11281/67600 (epoch 8), train_loss = 1.234, time/batch=0.117\n",
      "11282/67600 (epoch 8), train_loss = 1.227, time/batch=0.244\n",
      "11283/67600 (epoch 8), train_loss = 1.287, time/batch=0.148\n",
      "11284/67600 (epoch 8), train_loss = 1.243, time/batch=0.125\n",
      "11285/67600 (epoch 8), train_loss = 1.209, time/batch=0.120\n",
      "11286/67600 (epoch 8), train_loss = 1.234, time/batch=0.111\n",
      "11287/67600 (epoch 8), train_loss = 1.235, time/batch=0.119\n",
      "11288/67600 (epoch 8), train_loss = 1.207, time/batch=0.119\n",
      "11289/67600 (epoch 8), train_loss = 1.256, time/batch=0.247\n",
      "11290/67600 (epoch 8), train_loss = 1.215, time/batch=0.139\n",
      "11291/67600 (epoch 8), train_loss = 1.185, time/batch=0.125\n",
      "11292/67600 (epoch 8), train_loss = 1.274, time/batch=0.141\n",
      "11293/67600 (epoch 8), train_loss = 1.201, time/batch=0.122\n",
      "11294/67600 (epoch 8), train_loss = 1.221, time/batch=0.127\n",
      "11295/67600 (epoch 8), train_loss = 1.253, time/batch=0.117\n",
      "11296/67600 (epoch 8), train_loss = 1.207, time/batch=0.262\n",
      "11297/67600 (epoch 8), train_loss = 1.240, time/batch=0.139\n",
      "11298/67600 (epoch 8), train_loss = 1.221, time/batch=0.125\n",
      "11299/67600 (epoch 8), train_loss = 1.201, time/batch=0.133\n",
      "11300/67600 (epoch 8), train_loss = 1.258, time/batch=0.215\n",
      "11301/67600 (epoch 8), train_loss = 1.264, time/batch=0.122\n",
      "11302/67600 (epoch 8), train_loss = 1.285, time/batch=0.152\n",
      "11303/67600 (epoch 8), train_loss = 1.253, time/batch=0.125\n",
      "11304/67600 (epoch 8), train_loss = 1.305, time/batch=0.135\n",
      "11305/67600 (epoch 8), train_loss = 1.280, time/batch=0.115\n",
      "11306/67600 (epoch 8), train_loss = 1.208, time/batch=0.171\n",
      "11307/67600 (epoch 8), train_loss = 1.238, time/batch=0.250\n",
      "11308/67600 (epoch 8), train_loss = 1.260, time/batch=0.143\n",
      "11309/67600 (epoch 8), train_loss = 1.216, time/batch=0.111\n",
      "11310/67600 (epoch 8), train_loss = 1.290, time/batch=0.146\n",
      "11311/67600 (epoch 8), train_loss = 1.258, time/batch=0.108\n",
      "11312/67600 (epoch 8), train_loss = 1.226, time/batch=0.127\n",
      "11313/67600 (epoch 8), train_loss = 1.255, time/batch=0.123\n",
      "11314/67600 (epoch 8), train_loss = 1.303, time/batch=0.242\n",
      "11315/67600 (epoch 8), train_loss = 1.244, time/batch=0.137\n",
      "11316/67600 (epoch 8), train_loss = 1.190, time/batch=0.117\n",
      "11317/67600 (epoch 8), train_loss = 1.193, time/batch=0.132\n",
      "11318/67600 (epoch 8), train_loss = 1.226, time/batch=0.105\n",
      "11319/67600 (epoch 8), train_loss = 1.259, time/batch=0.129\n",
      "11320/67600 (epoch 8), train_loss = 1.270, time/batch=0.111\n",
      "11321/67600 (epoch 8), train_loss = 1.280, time/batch=0.278\n",
      "11322/67600 (epoch 8), train_loss = 1.265, time/batch=0.119\n",
      "11323/67600 (epoch 8), train_loss = 1.269, time/batch=0.137\n",
      "11324/67600 (epoch 8), train_loss = 1.199, time/batch=0.098\n",
      "11325/67600 (epoch 8), train_loss = 1.228, time/batch=0.126\n",
      "11326/67600 (epoch 8), train_loss = 1.273, time/batch=0.106\n",
      "11327/67600 (epoch 8), train_loss = 1.248, time/batch=0.131\n",
      "11328/67600 (epoch 8), train_loss = 1.260, time/batch=0.272\n",
      "11329/67600 (epoch 8), train_loss = 1.229, time/batch=0.122\n",
      "11330/67600 (epoch 8), train_loss = 1.262, time/batch=0.118\n",
      "11331/67600 (epoch 8), train_loss = 1.284, time/batch=0.135\n",
      "11332/67600 (epoch 8), train_loss = 1.292, time/batch=0.104\n",
      "11333/67600 (epoch 8), train_loss = 1.269, time/batch=0.125\n",
      "11334/67600 (epoch 8), train_loss = 1.264, time/batch=0.131\n",
      "11335/67600 (epoch 8), train_loss = 1.182, time/batch=0.269\n",
      "11336/67600 (epoch 8), train_loss = 1.297, time/batch=0.123\n",
      "11337/67600 (epoch 8), train_loss = 1.302, time/batch=0.093\n",
      "11338/67600 (epoch 8), train_loss = 1.309, time/batch=0.120\n",
      "11339/67600 (epoch 8), train_loss = 1.256, time/batch=0.148\n",
      "11340/67600 (epoch 8), train_loss = 1.243, time/batch=0.150\n",
      "11341/67600 (epoch 8), train_loss = 1.246, time/batch=0.131\n",
      "11342/67600 (epoch 8), train_loss = 1.264, time/batch=0.115\n",
      "11343/67600 (epoch 8), train_loss = 1.222, time/batch=0.114\n",
      "11344/67600 (epoch 8), train_loss = 1.276, time/batch=0.126\n",
      "11345/67600 (epoch 8), train_loss = 1.239, time/batch=0.116\n",
      "11346/67600 (epoch 8), train_loss = 1.298, time/batch=0.309\n",
      "11347/67600 (epoch 8), train_loss = 1.282, time/batch=0.125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11348/67600 (epoch 8), train_loss = 1.267, time/batch=0.126\n",
      "11349/67600 (epoch 8), train_loss = 1.222, time/batch=0.114\n",
      "11350/67600 (epoch 8), train_loss = 1.239, time/batch=0.132\n",
      "11351/67600 (epoch 8), train_loss = 1.201, time/batch=0.109\n",
      "11352/67600 (epoch 8), train_loss = 1.229, time/batch=0.130\n",
      "11353/67600 (epoch 8), train_loss = 1.251, time/batch=0.212\n",
      "11354/67600 (epoch 8), train_loss = 1.232, time/batch=0.172\n",
      "11355/67600 (epoch 8), train_loss = 1.251, time/batch=0.143\n",
      "11356/67600 (epoch 8), train_loss = 1.260, time/batch=0.099\n",
      "11357/67600 (epoch 8), train_loss = 1.195, time/batch=0.121\n",
      "11358/67600 (epoch 8), train_loss = 1.235, time/batch=0.098\n",
      "11359/67600 (epoch 8), train_loss = 1.207, time/batch=0.132\n",
      "11360/67600 (epoch 8), train_loss = 1.292, time/batch=0.141\n",
      "11361/67600 (epoch 8), train_loss = 1.250, time/batch=0.256\n",
      "11362/67600 (epoch 8), train_loss = 1.227, time/batch=0.134\n",
      "11363/67600 (epoch 8), train_loss = 1.248, time/batch=0.114\n",
      "11364/67600 (epoch 8), train_loss = 1.367, time/batch=0.119\n",
      "11365/67600 (epoch 8), train_loss = 1.280, time/batch=0.162\n",
      "11366/67600 (epoch 8), train_loss = 1.230, time/batch=0.199\n",
      "11367/67600 (epoch 8), train_loss = 1.287, time/batch=0.166\n",
      "11368/67600 (epoch 8), train_loss = 1.235, time/batch=0.119\n",
      "11369/67600 (epoch 8), train_loss = 1.233, time/batch=0.127\n",
      "11370/67600 (epoch 8), train_loss = 1.280, time/batch=0.116\n",
      "11371/67600 (epoch 8), train_loss = 1.228, time/batch=0.115\n",
      "11372/67600 (epoch 8), train_loss = 1.307, time/batch=0.168\n",
      "11373/67600 (epoch 8), train_loss = 1.234, time/batch=0.226\n",
      "11374/67600 (epoch 8), train_loss = 1.221, time/batch=0.129\n",
      "11375/67600 (epoch 8), train_loss = 1.179, time/batch=0.117\n",
      "11376/67600 (epoch 8), train_loss = 1.212, time/batch=0.108\n",
      "11377/67600 (epoch 8), train_loss = 1.235, time/batch=0.141\n",
      "11378/67600 (epoch 8), train_loss = 1.188, time/batch=0.115\n",
      "11379/67600 (epoch 8), train_loss = 1.232, time/batch=0.201\n",
      "11380/67600 (epoch 8), train_loss = 1.204, time/batch=0.150\n",
      "11381/67600 (epoch 8), train_loss = 1.227, time/batch=0.148\n",
      "11382/67600 (epoch 8), train_loss = 1.260, time/batch=0.119\n",
      "11383/67600 (epoch 8), train_loss = 1.271, time/batch=0.108\n",
      "11384/67600 (epoch 8), train_loss = 1.261, time/batch=0.129\n",
      "11385/67600 (epoch 8), train_loss = 1.225, time/batch=0.116\n",
      "11386/67600 (epoch 8), train_loss = 1.209, time/batch=0.118\n",
      "11387/67600 (epoch 8), train_loss = 1.202, time/batch=0.257\n",
      "11388/67600 (epoch 8), train_loss = 1.229, time/batch=0.133\n",
      "11389/67600 (epoch 8), train_loss = 1.242, time/batch=0.122\n",
      "11390/67600 (epoch 8), train_loss = 1.258, time/batch=0.117\n",
      "11391/67600 (epoch 8), train_loss = 1.216, time/batch=0.120\n",
      "11392/67600 (epoch 8), train_loss = 1.263, time/batch=0.116\n",
      "11393/67600 (epoch 8), train_loss = 1.244, time/batch=0.116\n",
      "11394/67600 (epoch 8), train_loss = 1.277, time/batch=0.268\n",
      "11395/67600 (epoch 8), train_loss = 1.238, time/batch=0.127\n",
      "11396/67600 (epoch 8), train_loss = 1.269, time/batch=0.134\n",
      "11397/67600 (epoch 8), train_loss = 1.247, time/batch=0.097\n",
      "11398/67600 (epoch 8), train_loss = 1.203, time/batch=0.118\n",
      "11399/67600 (epoch 8), train_loss = 1.213, time/batch=0.235\n",
      "11400/67600 (epoch 8), train_loss = 1.238, time/batch=0.142\n",
      "11401/67600 (epoch 8), train_loss = 1.301, time/batch=0.132\n",
      "11402/67600 (epoch 8), train_loss = 1.223, time/batch=0.127\n",
      "11403/67600 (epoch 8), train_loss = 1.300, time/batch=0.127\n",
      "11404/67600 (epoch 8), train_loss = 1.214, time/batch=0.120\n",
      "11405/67600 (epoch 8), train_loss = 1.244, time/batch=0.130\n",
      "11406/67600 (epoch 8), train_loss = 1.306, time/batch=0.215\n",
      "11407/67600 (epoch 8), train_loss = 1.213, time/batch=0.157\n",
      "11408/67600 (epoch 8), train_loss = 1.219, time/batch=0.118\n",
      "11409/67600 (epoch 8), train_loss = 1.250, time/batch=0.118\n",
      "11410/67600 (epoch 8), train_loss = 1.195, time/batch=0.116\n",
      "11411/67600 (epoch 8), train_loss = 1.238, time/batch=0.125\n",
      "11412/67600 (epoch 8), train_loss = 1.260, time/batch=0.125\n",
      "11413/67600 (epoch 8), train_loss = 1.205, time/batch=0.217\n",
      "11414/67600 (epoch 8), train_loss = 1.233, time/batch=0.141\n",
      "11415/67600 (epoch 8), train_loss = 1.226, time/batch=0.123\n",
      "11416/67600 (epoch 8), train_loss = 1.276, time/batch=0.144\n",
      "11417/67600 (epoch 8), train_loss = 1.184, time/batch=0.104\n",
      "11418/67600 (epoch 8), train_loss = 1.254, time/batch=0.122\n",
      "11419/67600 (epoch 8), train_loss = 1.231, time/batch=0.123\n",
      "11420/67600 (epoch 8), train_loss = 1.271, time/batch=0.180\n",
      "11421/67600 (epoch 8), train_loss = 1.217, time/batch=0.214\n",
      "11422/67600 (epoch 8), train_loss = 1.290, time/batch=0.139\n",
      "11423/67600 (epoch 8), train_loss = 1.224, time/batch=0.146\n",
      "11424/67600 (epoch 8), train_loss = 1.313, time/batch=0.140\n",
      "11425/67600 (epoch 8), train_loss = 1.240, time/batch=0.135\n",
      "11426/67600 (epoch 8), train_loss = 1.255, time/batch=0.101\n",
      "11427/67600 (epoch 8), train_loss = 1.335, time/batch=0.301\n",
      "11428/67600 (epoch 8), train_loss = 1.241, time/batch=0.114\n",
      "11429/67600 (epoch 8), train_loss = 1.241, time/batch=0.133\n",
      "11430/67600 (epoch 8), train_loss = 1.272, time/batch=0.122\n",
      "11431/67600 (epoch 8), train_loss = 1.305, time/batch=0.122\n",
      "11432/67600 (epoch 8), train_loss = 1.262, time/batch=0.123\n",
      "11433/67600 (epoch 8), train_loss = 1.327, time/batch=0.101\n",
      "11434/67600 (epoch 8), train_loss = 1.245, time/batch=0.274\n",
      "11435/67600 (epoch 8), train_loss = 1.214, time/batch=0.106\n",
      "11436/67600 (epoch 8), train_loss = 1.196, time/batch=0.119\n",
      "11437/67600 (epoch 8), train_loss = 1.244, time/batch=0.131\n",
      "11438/67600 (epoch 8), train_loss = 1.248, time/batch=0.130\n",
      "11439/67600 (epoch 8), train_loss = 1.206, time/batch=0.151\n",
      "11440/67600 (epoch 8), train_loss = 1.244, time/batch=0.118\n",
      "11441/67600 (epoch 8), train_loss = 1.239, time/batch=0.091\n",
      "11442/67600 (epoch 8), train_loss = 1.283, time/batch=0.144\n",
      "11443/67600 (epoch 8), train_loss = 1.285, time/batch=0.109\n",
      "11444/67600 (epoch 8), train_loss = 1.283, time/batch=0.120\n",
      "11445/67600 (epoch 8), train_loss = 1.248, time/batch=0.288\n",
      "11446/67600 (epoch 8), train_loss = 1.283, time/batch=0.138\n",
      "11447/67600 (epoch 8), train_loss = 1.312, time/batch=0.113\n",
      "11448/67600 (epoch 8), train_loss = 1.231, time/batch=0.125\n",
      "11449/67600 (epoch 8), train_loss = 1.305, time/batch=0.130\n",
      "11450/67600 (epoch 8), train_loss = 1.302, time/batch=0.119\n",
      "11451/67600 (epoch 8), train_loss = 1.176, time/batch=0.126\n",
      "11452/67600 (epoch 8), train_loss = 1.324, time/batch=0.294\n",
      "11453/67600 (epoch 8), train_loss = 1.223, time/batch=0.119\n",
      "11454/67600 (epoch 8), train_loss = 1.178, time/batch=0.118\n",
      "11455/67600 (epoch 8), train_loss = 1.176, time/batch=0.122\n",
      "11456/67600 (epoch 8), train_loss = 1.255, time/batch=0.105\n",
      "11457/67600 (epoch 8), train_loss = 1.227, time/batch=0.117\n",
      "11458/67600 (epoch 8), train_loss = 1.282, time/batch=0.128\n",
      "11459/67600 (epoch 8), train_loss = 1.324, time/batch=0.300\n",
      "11460/67600 (epoch 8), train_loss = 1.307, time/batch=0.125\n",
      "11461/67600 (epoch 8), train_loss = 1.236, time/batch=0.121\n",
      "11462/67600 (epoch 8), train_loss = 1.274, time/batch=0.118\n",
      "11463/67600 (epoch 8), train_loss = 1.269, time/batch=0.134\n",
      "11464/67600 (epoch 8), train_loss = 1.286, time/batch=0.232\n",
      "11465/67600 (epoch 8), train_loss = 1.259, time/batch=0.159\n",
      "11466/67600 (epoch 8), train_loss = 1.301, time/batch=0.122\n",
      "11467/67600 (epoch 8), train_loss = 1.322, time/batch=0.121\n",
      "11468/67600 (epoch 8), train_loss = 1.242, time/batch=0.119\n",
      "11469/67600 (epoch 8), train_loss = 1.236, time/batch=0.112\n",
      "11470/67600 (epoch 8), train_loss = 1.261, time/batch=0.119\n",
      "11471/67600 (epoch 8), train_loss = 1.249, time/batch=0.229\n",
      "11472/67600 (epoch 8), train_loss = 1.248, time/batch=0.149\n",
      "11473/67600 (epoch 8), train_loss = 1.311, time/batch=0.121\n",
      "11474/67600 (epoch 8), train_loss = 1.275, time/batch=0.133\n",
      "11475/67600 (epoch 8), train_loss = 1.188, time/batch=0.123\n",
      "11476/67600 (epoch 8), train_loss = 1.251, time/batch=0.106\n",
      "11477/67600 (epoch 8), train_loss = 1.238, time/batch=0.119\n",
      "11478/67600 (epoch 8), train_loss = 1.167, time/batch=0.253\n",
      "11479/67600 (epoch 8), train_loss = 1.196, time/batch=0.144\n",
      "11480/67600 (epoch 8), train_loss = 1.280, time/batch=0.114\n",
      "11481/67600 (epoch 8), train_loss = 1.258, time/batch=0.121\n",
      "11482/67600 (epoch 8), train_loss = 1.271, time/batch=0.122\n",
      "11483/67600 (epoch 8), train_loss = 1.245, time/batch=0.138\n",
      "11484/67600 (epoch 8), train_loss = 1.306, time/batch=0.114\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11485/67600 (epoch 8), train_loss = 1.208, time/batch=0.273\n",
      "11486/67600 (epoch 8), train_loss = 1.152, time/batch=0.116\n",
      "11487/67600 (epoch 8), train_loss = 1.229, time/batch=0.123\n",
      "11488/67600 (epoch 8), train_loss = 1.167, time/batch=0.137\n",
      "11489/67600 (epoch 8), train_loss = 1.308, time/batch=0.100\n",
      "11490/67600 (epoch 8), train_loss = 1.296, time/batch=0.233\n",
      "11491/67600 (epoch 8), train_loss = 1.218, time/batch=0.141\n",
      "11492/67600 (epoch 8), train_loss = 1.257, time/batch=0.115\n",
      "11493/67600 (epoch 8), train_loss = 1.290, time/batch=0.134\n",
      "11494/67600 (epoch 8), train_loss = 1.300, time/batch=0.117\n",
      "11495/67600 (epoch 8), train_loss = 1.232, time/batch=0.137\n",
      "11496/67600 (epoch 8), train_loss = 1.251, time/batch=0.108\n",
      "11497/67600 (epoch 8), train_loss = 1.280, time/batch=0.107\n",
      "11498/67600 (epoch 8), train_loss = 1.270, time/batch=0.153\n",
      "11499/67600 (epoch 8), train_loss = 1.235, time/batch=0.294\n",
      "11500/67600 (epoch 8), train_loss = 1.225, time/batch=0.100\n",
      "model saved to ./save/model.ckpt\n",
      "11501/67600 (epoch 8), train_loss = 1.305, time/batch=0.085\n",
      "11502/67600 (epoch 8), train_loss = 1.267, time/batch=0.078\n",
      "11503/67600 (epoch 8), train_loss = 1.204, time/batch=0.110\n",
      "11504/67600 (epoch 8), train_loss = 1.250, time/batch=0.135\n",
      "11505/67600 (epoch 8), train_loss = 1.205, time/batch=0.128\n",
      "11506/67600 (epoch 8), train_loss = 1.231, time/batch=0.109\n",
      "11507/67600 (epoch 8), train_loss = 1.235, time/batch=0.209\n",
      "11508/67600 (epoch 8), train_loss = 1.225, time/batch=0.179\n",
      "11509/67600 (epoch 8), train_loss = 1.270, time/batch=0.125\n",
      "11510/67600 (epoch 8), train_loss = 1.255, time/batch=0.113\n",
      "11511/67600 (epoch 8), train_loss = 1.172, time/batch=0.129\n",
      "11512/67600 (epoch 8), train_loss = 1.273, time/batch=0.132\n",
      "11513/67600 (epoch 8), train_loss = 1.280, time/batch=0.114\n",
      "11514/67600 (epoch 8), train_loss = 1.272, time/batch=0.231\n",
      "11515/67600 (epoch 8), train_loss = 1.212, time/batch=0.156\n",
      "11516/67600 (epoch 8), train_loss = 1.256, time/batch=0.127\n",
      "11517/67600 (epoch 8), train_loss = 1.277, time/batch=0.125\n",
      "11518/67600 (epoch 8), train_loss = 1.244, time/batch=0.107\n",
      "11519/67600 (epoch 8), train_loss = 1.193, time/batch=0.162\n",
      "11520/67600 (epoch 8), train_loss = 1.239, time/batch=0.191\n",
      "11521/67600 (epoch 8), train_loss = 1.230, time/batch=0.151\n",
      "11522/67600 (epoch 8), train_loss = 1.223, time/batch=0.143\n",
      "11523/67600 (epoch 8), train_loss = 1.276, time/batch=0.109\n",
      "11524/67600 (epoch 8), train_loss = 1.263, time/batch=0.120\n",
      "11525/67600 (epoch 8), train_loss = 1.205, time/batch=0.126\n",
      "11526/67600 (epoch 8), train_loss = 1.242, time/batch=0.127\n",
      "11527/67600 (epoch 8), train_loss = 1.151, time/batch=0.226\n",
      "11528/67600 (epoch 8), train_loss = 1.249, time/batch=0.152\n",
      "11529/67600 (epoch 8), train_loss = 1.239, time/batch=0.125\n",
      "11530/67600 (epoch 8), train_loss = 1.238, time/batch=0.116\n",
      "11531/67600 (epoch 8), train_loss = 1.221, time/batch=0.131\n",
      "11532/67600 (epoch 8), train_loss = 1.189, time/batch=0.118\n",
      "11533/67600 (epoch 8), train_loss = 1.236, time/batch=0.161\n",
      "11534/67600 (epoch 8), train_loss = 1.212, time/batch=0.208\n",
      "11535/67600 (epoch 8), train_loss = 1.225, time/batch=0.132\n",
      "11536/67600 (epoch 8), train_loss = 1.227, time/batch=0.104\n",
      "11537/67600 (epoch 8), train_loss = 1.267, time/batch=0.122\n",
      "11538/67600 (epoch 8), train_loss = 1.240, time/batch=0.109\n",
      "11539/67600 (epoch 8), train_loss = 1.254, time/batch=0.131\n",
      "11540/67600 (epoch 8), train_loss = 1.250, time/batch=0.123\n",
      "11541/67600 (epoch 8), train_loss = 1.264, time/batch=0.245\n",
      "11542/67600 (epoch 8), train_loss = 1.244, time/batch=0.136\n",
      "11543/67600 (epoch 8), train_loss = 1.257, time/batch=0.123\n",
      "11544/67600 (epoch 8), train_loss = 1.265, time/batch=0.098\n",
      "11545/67600 (epoch 8), train_loss = 1.226, time/batch=0.134\n",
      "11546/67600 (epoch 8), train_loss = 1.255, time/batch=0.118\n",
      "11547/67600 (epoch 8), train_loss = 1.282, time/batch=0.131\n",
      "11548/67600 (epoch 8), train_loss = 1.263, time/batch=0.241\n",
      "11549/67600 (epoch 8), train_loss = 1.248, time/batch=0.125\n",
      "11550/67600 (epoch 8), train_loss = 1.262, time/batch=0.112\n",
      "11551/67600 (epoch 8), train_loss = 1.205, time/batch=0.129\n",
      "11552/67600 (epoch 8), train_loss = 1.304, time/batch=0.135\n",
      "11553/67600 (epoch 8), train_loss = 1.229, time/batch=0.210\n",
      "11554/67600 (epoch 8), train_loss = 1.199, time/batch=0.155\n",
      "11555/67600 (epoch 8), train_loss = 1.267, time/batch=0.128\n",
      "11556/67600 (epoch 8), train_loss = 1.177, time/batch=0.133\n",
      "11557/67600 (epoch 8), train_loss = 1.205, time/batch=0.110\n",
      "11558/67600 (epoch 8), train_loss = 1.180, time/batch=0.115\n",
      "11559/67600 (epoch 8), train_loss = 1.227, time/batch=0.128\n",
      "11560/67600 (epoch 8), train_loss = 1.251, time/batch=0.247\n",
      "11561/67600 (epoch 8), train_loss = 1.254, time/batch=0.150\n",
      "11562/67600 (epoch 8), train_loss = 1.221, time/batch=0.125\n",
      "11563/67600 (epoch 8), train_loss = 1.240, time/batch=0.111\n",
      "11564/67600 (epoch 8), train_loss = 1.260, time/batch=0.118\n",
      "11565/67600 (epoch 8), train_loss = 1.212, time/batch=0.118\n",
      "11566/67600 (epoch 8), train_loss = 1.183, time/batch=0.122\n",
      "11567/67600 (epoch 8), train_loss = 1.208, time/batch=0.236\n",
      "11568/67600 (epoch 8), train_loss = 1.232, time/batch=0.147\n",
      "11569/67600 (epoch 8), train_loss = 1.285, time/batch=0.116\n",
      "11570/67600 (epoch 8), train_loss = 1.227, time/batch=0.129\n",
      "11571/67600 (epoch 8), train_loss = 1.238, time/batch=0.117\n",
      "11572/67600 (epoch 8), train_loss = 1.307, time/batch=0.115\n",
      "11573/67600 (epoch 8), train_loss = 1.244, time/batch=0.129\n",
      "11574/67600 (epoch 8), train_loss = 1.227, time/batch=0.117\n",
      "11575/67600 (epoch 8), train_loss = 1.206, time/batch=0.262\n",
      "11576/67600 (epoch 8), train_loss = 1.229, time/batch=0.119\n",
      "11577/67600 (epoch 8), train_loss = 1.228, time/batch=0.123\n",
      "11578/67600 (epoch 8), train_loss = 1.232, time/batch=0.106\n",
      "11579/67600 (epoch 8), train_loss = 1.275, time/batch=0.128\n",
      "11580/67600 (epoch 8), train_loss = 1.287, time/batch=0.116\n",
      "11581/67600 (epoch 8), train_loss = 1.209, time/batch=0.125\n",
      "11582/67600 (epoch 8), train_loss = 1.249, time/batch=0.272\n",
      "11583/67600 (epoch 8), train_loss = 1.237, time/batch=0.133\n",
      "11584/67600 (epoch 8), train_loss = 1.267, time/batch=0.119\n",
      "11585/67600 (epoch 8), train_loss = 1.272, time/batch=0.121\n",
      "11586/67600 (epoch 8), train_loss = 1.218, time/batch=0.121\n",
      "11587/67600 (epoch 8), train_loss = 1.295, time/batch=0.124\n",
      "11588/67600 (epoch 8), train_loss = 1.260, time/batch=0.172\n",
      "11589/67600 (epoch 8), train_loss = 1.223, time/batch=0.217\n",
      "11590/67600 (epoch 8), train_loss = 1.273, time/batch=0.124\n",
      "11591/67600 (epoch 8), train_loss = 1.318, time/batch=0.123\n",
      "11592/67600 (epoch 8), train_loss = 1.282, time/batch=0.135\n",
      "11593/67600 (epoch 8), train_loss = 1.255, time/batch=0.150\n",
      "11594/67600 (epoch 8), train_loss = 1.236, time/batch=0.119\n",
      "11595/67600 (epoch 8), train_loss = 1.262, time/batch=0.124\n",
      "11596/67600 (epoch 8), train_loss = 1.293, time/batch=0.122\n",
      "11597/67600 (epoch 8), train_loss = 1.242, time/batch=0.115\n",
      "11598/67600 (epoch 8), train_loss = 1.220, time/batch=0.116\n",
      "11599/67600 (epoch 8), train_loss = 1.254, time/batch=0.127\n",
      "11600/67600 (epoch 8), train_loss = 1.231, time/batch=0.270\n",
      "11601/67600 (epoch 8), train_loss = 1.274, time/batch=0.142\n",
      "11602/67600 (epoch 8), train_loss = 1.249, time/batch=0.123\n",
      "11603/67600 (epoch 8), train_loss = 1.259, time/batch=0.125\n",
      "11604/67600 (epoch 8), train_loss = 1.262, time/batch=0.111\n",
      "11605/67600 (epoch 8), train_loss = 1.215, time/batch=0.123\n",
      "11606/67600 (epoch 8), train_loss = 1.237, time/batch=0.134\n",
      "11607/67600 (epoch 8), train_loss = 1.245, time/batch=0.252\n",
      "11608/67600 (epoch 8), train_loss = 1.218, time/batch=0.128\n",
      "11609/67600 (epoch 8), train_loss = 1.273, time/batch=0.113\n",
      "11610/67600 (epoch 8), train_loss = 1.237, time/batch=0.132\n",
      "11611/67600 (epoch 8), train_loss = 1.246, time/batch=0.111\n",
      "11612/67600 (epoch 8), train_loss = 1.304, time/batch=0.113\n",
      "11613/67600 (epoch 8), train_loss = 1.262, time/batch=0.131\n",
      "11614/67600 (epoch 8), train_loss = 1.283, time/batch=0.267\n",
      "11615/67600 (epoch 8), train_loss = 1.243, time/batch=0.121\n",
      "11616/67600 (epoch 8), train_loss = 1.253, time/batch=0.118\n",
      "11617/67600 (epoch 8), train_loss = 1.246, time/batch=0.111\n",
      "11618/67600 (epoch 8), train_loss = 1.230, time/batch=0.142\n",
      "11619/67600 (epoch 8), train_loss = 1.250, time/batch=0.215\n",
      "11620/67600 (epoch 8), train_loss = 1.221, time/batch=0.157\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11621/67600 (epoch 8), train_loss = 1.194, time/batch=0.120\n",
      "11622/67600 (epoch 8), train_loss = 1.260, time/batch=0.126\n",
      "11623/67600 (epoch 8), train_loss = 1.224, time/batch=0.112\n",
      "11624/67600 (epoch 8), train_loss = 1.164, time/batch=0.119\n",
      "11625/67600 (epoch 8), train_loss = 1.263, time/batch=0.124\n",
      "11626/67600 (epoch 8), train_loss = 1.194, time/batch=0.243\n",
      "11627/67600 (epoch 8), train_loss = 1.281, time/batch=0.146\n",
      "11628/67600 (epoch 8), train_loss = 1.261, time/batch=0.120\n",
      "11629/67600 (epoch 8), train_loss = 1.260, time/batch=0.116\n",
      "11630/67600 (epoch 8), train_loss = 1.286, time/batch=0.124\n",
      "11631/67600 (epoch 8), train_loss = 1.194, time/batch=0.107\n",
      "11632/67600 (epoch 8), train_loss = 1.289, time/batch=0.123\n",
      "11633/67600 (epoch 8), train_loss = 1.217, time/batch=0.222\n",
      "11634/67600 (epoch 8), train_loss = 1.213, time/batch=0.131\n",
      "11635/67600 (epoch 8), train_loss = 1.236, time/batch=0.127\n",
      "11636/67600 (epoch 8), train_loss = 1.163, time/batch=0.129\n",
      "11637/67600 (epoch 8), train_loss = 1.280, time/batch=0.116\n",
      "11638/67600 (epoch 8), train_loss = 1.244, time/batch=0.126\n",
      "11639/67600 (epoch 8), train_loss = 1.314, time/batch=0.121\n",
      "11640/67600 (epoch 8), train_loss = 1.257, time/batch=0.113\n",
      "11641/67600 (epoch 8), train_loss = 1.289, time/batch=0.257\n",
      "11642/67600 (epoch 8), train_loss = 1.387, time/batch=0.151\n",
      "11643/67600 (epoch 8), train_loss = 1.216, time/batch=0.104\n",
      "11644/67600 (epoch 8), train_loss = 1.250, time/batch=0.139\n",
      "11645/67600 (epoch 8), train_loss = 1.279, time/batch=0.095\n",
      "11646/67600 (epoch 8), train_loss = 1.327, time/batch=0.121\n",
      "11647/67600 (epoch 8), train_loss = 1.226, time/batch=0.130\n",
      "11648/67600 (epoch 8), train_loss = 1.243, time/batch=0.260\n",
      "11649/67600 (epoch 8), train_loss = 1.250, time/batch=0.116\n",
      "11650/67600 (epoch 8), train_loss = 1.209, time/batch=0.116\n",
      "11651/67600 (epoch 8), train_loss = 1.284, time/batch=0.112\n",
      "11652/67600 (epoch 8), train_loss = 1.141, time/batch=0.128\n",
      "11653/67600 (epoch 8), train_loss = 1.282, time/batch=0.219\n",
      "11654/67600 (epoch 8), train_loss = 1.185, time/batch=0.150\n",
      "11655/67600 (epoch 8), train_loss = 1.240, time/batch=0.123\n",
      "11656/67600 (epoch 8), train_loss = 1.295, time/batch=0.128\n",
      "11657/67600 (epoch 8), train_loss = 1.259, time/batch=0.123\n",
      "11658/67600 (epoch 8), train_loss = 1.249, time/batch=0.130\n",
      "11659/67600 (epoch 8), train_loss = 1.262, time/batch=0.123\n",
      "11660/67600 (epoch 8), train_loss = 1.248, time/batch=0.229\n",
      "11661/67600 (epoch 8), train_loss = 1.231, time/batch=0.146\n",
      "11662/67600 (epoch 8), train_loss = 1.225, time/batch=0.122\n",
      "11663/67600 (epoch 8), train_loss = 1.230, time/batch=0.119\n",
      "11664/67600 (epoch 8), train_loss = 1.260, time/batch=0.115\n",
      "11665/67600 (epoch 8), train_loss = 1.235, time/batch=0.141\n",
      "11666/67600 (epoch 8), train_loss = 1.239, time/batch=0.114\n",
      "11667/67600 (epoch 8), train_loss = 1.324, time/batch=0.241\n",
      "11668/67600 (epoch 8), train_loss = 1.324, time/batch=0.162\n",
      "11669/67600 (epoch 8), train_loss = 1.305, time/batch=0.111\n",
      "11670/67600 (epoch 8), train_loss = 1.238, time/batch=0.109\n",
      "11671/67600 (epoch 8), train_loss = 1.277, time/batch=0.124\n",
      "11672/67600 (epoch 8), train_loss = 1.248, time/batch=0.127\n",
      "11673/67600 (epoch 8), train_loss = 1.260, time/batch=0.106\n",
      "11674/67600 (epoch 8), train_loss = 1.284, time/batch=0.265\n",
      "11675/67600 (epoch 8), train_loss = 1.296, time/batch=0.127\n",
      "11676/67600 (epoch 8), train_loss = 1.256, time/batch=0.119\n",
      "11677/67600 (epoch 8), train_loss = 1.305, time/batch=0.125\n",
      "11678/67600 (epoch 8), train_loss = 1.328, time/batch=0.122\n",
      "11679/67600 (epoch 8), train_loss = 1.277, time/batch=0.127\n",
      "11680/67600 (epoch 8), train_loss = 1.212, time/batch=0.115\n",
      "11681/67600 (epoch 8), train_loss = 1.306, time/batch=0.283\n",
      "11682/67600 (epoch 8), train_loss = 1.288, time/batch=0.120\n",
      "11683/67600 (epoch 8), train_loss = 1.225, time/batch=0.116\n",
      "11684/67600 (epoch 8), train_loss = 1.255, time/batch=0.110\n",
      "11685/67600 (epoch 8), train_loss = 1.246, time/batch=0.122\n",
      "11686/67600 (epoch 8), train_loss = 1.255, time/batch=0.237\n",
      "11687/67600 (epoch 8), train_loss = 1.226, time/batch=0.151\n",
      "11688/67600 (epoch 8), train_loss = 1.283, time/batch=0.103\n",
      "11689/67600 (epoch 8), train_loss = 1.216, time/batch=0.137\n",
      "11690/67600 (epoch 8), train_loss = 1.255, time/batch=0.120\n",
      "11691/67600 (epoch 8), train_loss = 1.302, time/batch=0.113\n",
      "11692/67600 (epoch 8), train_loss = 1.284, time/batch=0.108\n",
      "11693/67600 (epoch 8), train_loss = 1.158, time/batch=0.159\n",
      "11694/67600 (epoch 8), train_loss = 1.246, time/batch=0.116\n",
      "11695/67600 (epoch 8), train_loss = 1.154, time/batch=0.126\n",
      "11696/67600 (epoch 8), train_loss = 1.211, time/batch=0.136\n",
      "11697/67600 (epoch 8), train_loss = 1.222, time/batch=0.123\n",
      "11698/67600 (epoch 8), train_loss = 1.225, time/batch=0.123\n",
      "11699/67600 (epoch 8), train_loss = 1.245, time/batch=0.297\n",
      "11700/67600 (epoch 8), train_loss = 1.219, time/batch=0.134\n",
      "11701/67600 (epoch 8), train_loss = 1.235, time/batch=0.121\n",
      "11702/67600 (epoch 8), train_loss = 1.218, time/batch=0.116\n",
      "11703/67600 (epoch 8), train_loss = 1.182, time/batch=0.130\n",
      "11704/67600 (epoch 8), train_loss = 1.304, time/batch=0.109\n",
      "11705/67600 (epoch 8), train_loss = 1.274, time/batch=0.122\n",
      "11706/67600 (epoch 8), train_loss = 1.302, time/batch=0.128\n",
      "11707/67600 (epoch 8), train_loss = 1.289, time/batch=0.249\n",
      "11708/67600 (epoch 8), train_loss = 1.266, time/batch=0.117\n",
      "11709/67600 (epoch 8), train_loss = 1.226, time/batch=0.130\n",
      "11710/67600 (epoch 8), train_loss = 1.274, time/batch=0.126\n",
      "11711/67600 (epoch 8), train_loss = 1.231, time/batch=0.127\n",
      "11712/67600 (epoch 8), train_loss = 1.246, time/batch=0.113\n",
      "11713/67600 (epoch 8), train_loss = 1.316, time/batch=0.126\n",
      "11714/67600 (epoch 8), train_loss = 1.280, time/batch=0.261\n",
      "11715/67600 (epoch 8), train_loss = 1.286, time/batch=0.112\n",
      "11716/67600 (epoch 8), train_loss = 1.256, time/batch=0.125\n",
      "11717/67600 (epoch 8), train_loss = 1.298, time/batch=0.114\n",
      "11718/67600 (epoch 8), train_loss = 1.300, time/batch=0.132\n",
      "11719/67600 (epoch 8), train_loss = 1.195, time/batch=0.224\n",
      "11720/67600 (epoch 8), train_loss = 1.228, time/batch=0.150\n",
      "11721/67600 (epoch 8), train_loss = 1.279, time/batch=0.124\n",
      "11722/67600 (epoch 8), train_loss = 1.239, time/batch=0.119\n",
      "11723/67600 (epoch 8), train_loss = 1.227, time/batch=0.125\n",
      "11724/67600 (epoch 8), train_loss = 1.300, time/batch=0.117\n",
      "11725/67600 (epoch 8), train_loss = 1.240, time/batch=0.125\n",
      "11726/67600 (epoch 8), train_loss = 1.236, time/batch=0.237\n",
      "11727/67600 (epoch 8), train_loss = 1.274, time/batch=0.146\n",
      "11728/67600 (epoch 8), train_loss = 1.235, time/batch=0.128\n",
      "11729/67600 (epoch 8), train_loss = 1.269, time/batch=0.124\n",
      "11730/67600 (epoch 8), train_loss = 1.291, time/batch=0.118\n",
      "11731/67600 (epoch 8), train_loss = 1.230, time/batch=0.120\n",
      "11732/67600 (epoch 8), train_loss = 1.245, time/batch=0.118\n",
      "11733/67600 (epoch 8), train_loss = 1.239, time/batch=0.251\n",
      "11734/67600 (epoch 8), train_loss = 1.258, time/batch=0.129\n",
      "11735/67600 (epoch 8), train_loss = 1.252, time/batch=0.132\n",
      "11736/67600 (epoch 8), train_loss = 1.269, time/batch=0.113\n",
      "11737/67600 (epoch 8), train_loss = 1.246, time/batch=0.142\n",
      "11738/67600 (epoch 8), train_loss = 1.272, time/batch=0.101\n",
      "11739/67600 (epoch 8), train_loss = 1.215, time/batch=0.141\n",
      "11740/67600 (epoch 8), train_loss = 1.205, time/batch=0.248\n",
      "11741/67600 (epoch 8), train_loss = 1.234, time/batch=0.133\n",
      "11742/67600 (epoch 8), train_loss = 1.222, time/batch=0.141\n",
      "11743/67600 (epoch 8), train_loss = 1.248, time/batch=0.107\n",
      "11744/67600 (epoch 8), train_loss = 1.217, time/batch=0.122\n",
      "11745/67600 (epoch 8), train_loss = 1.236, time/batch=0.112\n",
      "11746/67600 (epoch 8), train_loss = 1.202, time/batch=0.127\n",
      "11747/67600 (epoch 8), train_loss = 1.257, time/batch=0.249\n",
      "11748/67600 (epoch 8), train_loss = 1.224, time/batch=0.116\n",
      "11749/67600 (epoch 8), train_loss = 1.198, time/batch=0.116\n",
      "11750/67600 (epoch 8), train_loss = 1.222, time/batch=0.134\n",
      "11751/67600 (epoch 8), train_loss = 1.216, time/batch=0.114\n",
      "11752/67600 (epoch 8), train_loss = 1.273, time/batch=0.230\n",
      "11753/67600 (epoch 8), train_loss = 1.234, time/batch=0.164\n",
      "11754/67600 (epoch 8), train_loss = 1.228, time/batch=0.121\n",
      "11755/67600 (epoch 8), train_loss = 1.222, time/batch=0.106\n",
      "11756/67600 (epoch 8), train_loss = 1.244, time/batch=0.139\n",
      "11757/67600 (epoch 8), train_loss = 1.205, time/batch=0.112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11758/67600 (epoch 8), train_loss = 1.177, time/batch=0.132\n",
      "11759/67600 (epoch 8), train_loss = 1.275, time/batch=0.218\n",
      "11760/67600 (epoch 8), train_loss = 1.228, time/batch=0.151\n",
      "11761/67600 (epoch 8), train_loss = 1.258, time/batch=0.125\n",
      "11762/67600 (epoch 8), train_loss = 1.218, time/batch=0.107\n",
      "11763/67600 (epoch 8), train_loss = 1.201, time/batch=0.113\n",
      "11764/67600 (epoch 8), train_loss = 1.254, time/batch=0.124\n",
      "11765/67600 (epoch 8), train_loss = 1.204, time/batch=0.123\n",
      "11766/67600 (epoch 8), train_loss = 1.264, time/batch=0.234\n",
      "11767/67600 (epoch 8), train_loss = 1.210, time/batch=0.146\n",
      "11768/67600 (epoch 8), train_loss = 1.267, time/batch=0.129\n",
      "11769/67600 (epoch 8), train_loss = 1.202, time/batch=0.122\n",
      "11770/67600 (epoch 8), train_loss = 1.179, time/batch=0.110\n",
      "11771/67600 (epoch 8), train_loss = 1.298, time/batch=0.115\n",
      "11772/67600 (epoch 8), train_loss = 1.264, time/batch=0.117\n",
      "11773/67600 (epoch 8), train_loss = 1.269, time/batch=0.309\n",
      "11774/67600 (epoch 8), train_loss = 1.201, time/batch=0.132\n",
      "11775/67600 (epoch 8), train_loss = 1.218, time/batch=0.161\n",
      "11776/67600 (epoch 8), train_loss = 1.206, time/batch=0.111\n",
      "11777/67600 (epoch 8), train_loss = 1.163, time/batch=0.133\n",
      "11778/67600 (epoch 8), train_loss = 1.183, time/batch=0.115\n",
      "11779/67600 (epoch 8), train_loss = 1.165, time/batch=0.129\n",
      "11780/67600 (epoch 8), train_loss = 1.169, time/batch=0.275\n",
      "11781/67600 (epoch 8), train_loss = 1.248, time/batch=0.131\n",
      "11782/67600 (epoch 8), train_loss = 1.245, time/batch=0.112\n",
      "11783/67600 (epoch 8), train_loss = 1.186, time/batch=0.126\n",
      "11784/67600 (epoch 8), train_loss = 1.209, time/batch=0.150\n",
      "11785/67600 (epoch 8), train_loss = 1.203, time/batch=0.107\n",
      "11786/67600 (epoch 8), train_loss = 1.231, time/batch=0.125\n",
      "11787/67600 (epoch 8), train_loss = 1.242, time/batch=0.268\n",
      "11788/67600 (epoch 8), train_loss = 1.185, time/batch=0.123\n",
      "11789/67600 (epoch 8), train_loss = 1.252, time/batch=0.122\n",
      "11790/67600 (epoch 8), train_loss = 1.279, time/batch=0.121\n",
      "11791/67600 (epoch 8), train_loss = 1.172, time/batch=0.119\n",
      "11792/67600 (epoch 8), train_loss = 1.170, time/batch=0.160\n",
      "11793/67600 (epoch 8), train_loss = 1.205, time/batch=0.126\n",
      "11794/67600 (epoch 8), train_loss = 1.250, time/batch=0.113\n",
      "11795/67600 (epoch 8), train_loss = 1.220, time/batch=0.110\n",
      "11796/67600 (epoch 8), train_loss = 1.246, time/batch=0.157\n",
      "11797/67600 (epoch 8), train_loss = 1.196, time/batch=0.136\n",
      "11798/67600 (epoch 8), train_loss = 1.217, time/batch=0.318\n",
      "11799/67600 (epoch 8), train_loss = 1.256, time/batch=0.111\n",
      "11800/67600 (epoch 8), train_loss = 1.214, time/batch=0.133\n",
      "11801/67600 (epoch 8), train_loss = 1.302, time/batch=0.124\n",
      "11802/67600 (epoch 8), train_loss = 1.237, time/batch=0.113\n",
      "11803/67600 (epoch 8), train_loss = 1.306, time/batch=0.146\n",
      "11804/67600 (epoch 8), train_loss = 1.200, time/batch=0.205\n",
      "11805/67600 (epoch 8), train_loss = 1.231, time/batch=0.172\n",
      "11806/67600 (epoch 8), train_loss = 1.259, time/batch=0.109\n",
      "11807/67600 (epoch 8), train_loss = 1.221, time/batch=0.136\n",
      "11808/67600 (epoch 8), train_loss = 1.279, time/batch=0.120\n",
      "11809/67600 (epoch 8), train_loss = 1.232, time/batch=0.151\n",
      "11810/67600 (epoch 8), train_loss = 1.219, time/batch=0.166\n",
      "11811/67600 (epoch 8), train_loss = 1.231, time/batch=0.143\n",
      "11812/67600 (epoch 8), train_loss = 1.236, time/batch=0.111\n",
      "11813/67600 (epoch 8), train_loss = 1.256, time/batch=0.156\n",
      "11814/67600 (epoch 8), train_loss = 1.195, time/batch=0.105\n",
      "11815/67600 (epoch 8), train_loss = 1.213, time/batch=0.111\n",
      "11816/67600 (epoch 8), train_loss = 1.228, time/batch=0.110\n",
      "11817/67600 (epoch 8), train_loss = 1.242, time/batch=0.210\n",
      "11818/67600 (epoch 8), train_loss = 1.215, time/batch=0.165\n",
      "11819/67600 (epoch 8), train_loss = 1.236, time/batch=0.120\n",
      "11820/67600 (epoch 8), train_loss = 1.176, time/batch=0.109\n",
      "11821/67600 (epoch 8), train_loss = 1.252, time/batch=0.111\n",
      "11822/67600 (epoch 8), train_loss = 1.232, time/batch=0.130\n",
      "11823/67600 (epoch 8), train_loss = 1.200, time/batch=0.113\n",
      "11824/67600 (epoch 8), train_loss = 1.236, time/batch=0.153\n",
      "11825/67600 (epoch 8), train_loss = 1.191, time/batch=0.173\n",
      "11826/67600 (epoch 8), train_loss = 1.209, time/batch=0.146\n",
      "11827/67600 (epoch 8), train_loss = 1.205, time/batch=0.111\n",
      "11828/67600 (epoch 8), train_loss = 1.168, time/batch=0.114\n",
      "11829/67600 (epoch 8), train_loss = 1.210, time/batch=0.089\n",
      "11830/67600 (epoch 8), train_loss = 1.211, time/batch=0.126\n",
      "11831/67600 (epoch 8), train_loss = 1.225, time/batch=0.113\n",
      "11832/67600 (epoch 8), train_loss = 1.201, time/batch=0.214\n",
      "11833/67600 (epoch 8), train_loss = 1.253, time/batch=0.132\n",
      "11834/67600 (epoch 8), train_loss = 1.226, time/batch=0.115\n",
      "11835/67600 (epoch 8), train_loss = 1.238, time/batch=0.119\n",
      "11836/67600 (epoch 8), train_loss = 1.218, time/batch=0.111\n",
      "11837/67600 (epoch 8), train_loss = 1.218, time/batch=0.110\n",
      "11838/67600 (epoch 8), train_loss = 1.218, time/batch=0.112\n",
      "11839/67600 (epoch 8), train_loss = 1.217, time/batch=0.121\n",
      "11840/67600 (epoch 8), train_loss = 1.218, time/batch=0.237\n",
      "11841/67600 (epoch 8), train_loss = 1.178, time/batch=0.127\n",
      "11842/67600 (epoch 8), train_loss = 1.260, time/batch=0.113\n",
      "11843/67600 (epoch 8), train_loss = 1.178, time/batch=0.112\n",
      "11844/67600 (epoch 8), train_loss = 1.277, time/batch=0.134\n",
      "11845/67600 (epoch 8), train_loss = 1.238, time/batch=0.098\n",
      "11846/67600 (epoch 8), train_loss = 1.273, time/batch=0.119\n",
      "11847/67600 (epoch 8), train_loss = 1.275, time/batch=0.101\n",
      "11848/67600 (epoch 8), train_loss = 1.236, time/batch=0.232\n",
      "11849/67600 (epoch 8), train_loss = 1.211, time/batch=0.137\n",
      "11850/67600 (epoch 8), train_loss = 1.236, time/batch=0.102\n",
      "11851/67600 (epoch 8), train_loss = 1.206, time/batch=0.124\n",
      "11852/67600 (epoch 8), train_loss = 1.196, time/batch=0.105\n",
      "11853/67600 (epoch 8), train_loss = 1.191, time/batch=0.192\n",
      "11854/67600 (epoch 8), train_loss = 1.233, time/batch=0.151\n",
      "11855/67600 (epoch 8), train_loss = 1.219, time/batch=0.117\n",
      "11856/67600 (epoch 8), train_loss = 1.238, time/batch=0.120\n",
      "11857/67600 (epoch 8), train_loss = 1.233, time/batch=0.114\n",
      "11858/67600 (epoch 8), train_loss = 1.264, time/batch=0.114\n",
      "11859/67600 (epoch 8), train_loss = 1.128, time/batch=0.121\n",
      "11860/67600 (epoch 8), train_loss = 1.218, time/batch=0.106\n",
      "11861/67600 (epoch 8), train_loss = 1.218, time/batch=0.209\n",
      "11862/67600 (epoch 8), train_loss = 1.232, time/batch=0.149\n",
      "11863/67600 (epoch 8), train_loss = 1.289, time/batch=0.117\n",
      "11864/67600 (epoch 8), train_loss = 1.263, time/batch=0.105\n",
      "11865/67600 (epoch 8), train_loss = 1.248, time/batch=0.115\n",
      "11866/67600 (epoch 8), train_loss = 1.229, time/batch=0.117\n",
      "11867/67600 (epoch 8), train_loss = 1.202, time/batch=0.111\n",
      "11868/67600 (epoch 8), train_loss = 1.249, time/batch=0.224\n",
      "11869/67600 (epoch 8), train_loss = 1.233, time/batch=0.112\n",
      "11870/67600 (epoch 8), train_loss = 1.251, time/batch=0.144\n",
      "11871/67600 (epoch 8), train_loss = 1.234, time/batch=0.115\n",
      "11872/67600 (epoch 8), train_loss = 1.158, time/batch=0.115\n",
      "11873/67600 (epoch 8), train_loss = 1.275, time/batch=0.107\n",
      "11874/67600 (epoch 8), train_loss = 1.308, time/batch=0.101\n",
      "11875/67600 (epoch 8), train_loss = 1.223, time/batch=0.124\n",
      "11876/67600 (epoch 8), train_loss = 1.248, time/batch=0.219\n",
      "11877/67600 (epoch 8), train_loss = 1.258, time/batch=0.130\n",
      "11878/67600 (epoch 8), train_loss = 1.233, time/batch=0.106\n",
      "11879/67600 (epoch 8), train_loss = 1.195, time/batch=0.107\n",
      "11880/67600 (epoch 8), train_loss = 1.238, time/batch=0.131\n",
      "11881/67600 (epoch 8), train_loss = 1.232, time/batch=0.123\n",
      "11882/67600 (epoch 8), train_loss = 1.231, time/batch=0.119\n",
      "11883/67600 (epoch 8), train_loss = 1.272, time/batch=0.103\n",
      "11884/67600 (epoch 8), train_loss = 1.198, time/batch=0.238\n",
      "11885/67600 (epoch 8), train_loss = 1.248, time/batch=0.140\n",
      "11886/67600 (epoch 8), train_loss = 1.274, time/batch=0.107\n",
      "11887/67600 (epoch 8), train_loss = 1.295, time/batch=0.114\n",
      "11888/67600 (epoch 8), train_loss = 1.238, time/batch=0.107\n",
      "11889/67600 (epoch 8), train_loss = 1.222, time/batch=0.209\n",
      "11890/67600 (epoch 8), train_loss = 1.200, time/batch=0.139\n",
      "11891/67600 (epoch 8), train_loss = 1.228, time/batch=0.125\n",
      "11892/67600 (epoch 8), train_loss = 1.285, time/batch=0.120\n",
      "11893/67600 (epoch 8), train_loss = 1.274, time/batch=0.113\n",
      "11894/67600 (epoch 8), train_loss = 1.280, time/batch=0.118\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11895/67600 (epoch 8), train_loss = 1.271, time/batch=0.098\n",
      "11896/67600 (epoch 8), train_loss = 1.288, time/batch=0.107\n",
      "11897/67600 (epoch 8), train_loss = 1.206, time/batch=0.161\n",
      "11898/67600 (epoch 8), train_loss = 1.265, time/batch=0.109\n",
      "11899/67600 (epoch 8), train_loss = 1.206, time/batch=0.118\n",
      "11900/67600 (epoch 8), train_loss = 1.191, time/batch=0.108\n",
      "11901/67600 (epoch 8), train_loss = 1.312, time/batch=0.117\n",
      "11902/67600 (epoch 8), train_loss = 1.273, time/batch=0.111\n",
      "11903/67600 (epoch 8), train_loss = 1.184, time/batch=0.236\n",
      "11904/67600 (epoch 8), train_loss = 1.218, time/batch=0.158\n",
      "11905/67600 (epoch 8), train_loss = 1.209, time/batch=0.114\n",
      "11906/67600 (epoch 8), train_loss = 1.256, time/batch=0.121\n",
      "11907/67600 (epoch 8), train_loss = 1.221, time/batch=0.111\n",
      "11908/67600 (epoch 8), train_loss = 1.280, time/batch=0.120\n",
      "11909/67600 (epoch 8), train_loss = 1.227, time/batch=0.104\n",
      "11910/67600 (epoch 8), train_loss = 1.233, time/batch=0.122\n",
      "11911/67600 (epoch 8), train_loss = 1.203, time/batch=0.230\n",
      "11912/67600 (epoch 8), train_loss = 1.237, time/batch=0.117\n",
      "11913/67600 (epoch 8), train_loss = 1.234, time/batch=0.117\n",
      "11914/67600 (epoch 8), train_loss = 1.205, time/batch=0.110\n",
      "11915/67600 (epoch 8), train_loss = 1.173, time/batch=0.116\n",
      "11916/67600 (epoch 8), train_loss = 1.239, time/batch=0.133\n",
      "11917/67600 (epoch 8), train_loss = 1.229, time/batch=0.174\n",
      "11918/67600 (epoch 8), train_loss = 1.216, time/batch=0.158\n",
      "11919/67600 (epoch 8), train_loss = 1.190, time/batch=0.103\n",
      "11920/67600 (epoch 8), train_loss = 1.314, time/batch=0.136\n",
      "11921/67600 (epoch 8), train_loss = 1.212, time/batch=0.100\n",
      "11922/67600 (epoch 8), train_loss = 1.224, time/batch=0.117\n",
      "11923/67600 (epoch 8), train_loss = 1.262, time/batch=0.126\n",
      "11924/67600 (epoch 8), train_loss = 1.213, time/batch=0.185\n",
      "11925/67600 (epoch 8), train_loss = 1.243, time/batch=0.134\n",
      "11926/67600 (epoch 8), train_loss = 1.261, time/batch=0.150\n",
      "11927/67600 (epoch 8), train_loss = 1.236, time/batch=0.123\n",
      "11928/67600 (epoch 8), train_loss = 1.286, time/batch=0.103\n",
      "11929/67600 (epoch 8), train_loss = 1.286, time/batch=0.125\n",
      "11930/67600 (epoch 8), train_loss = 1.263, time/batch=0.109\n",
      "11931/67600 (epoch 8), train_loss = 1.331, time/batch=0.116\n",
      "11932/67600 (epoch 8), train_loss = 1.229, time/batch=0.207\n",
      "11933/67600 (epoch 8), train_loss = 1.266, time/batch=0.144\n",
      "11934/67600 (epoch 8), train_loss = 1.238, time/batch=0.114\n",
      "11935/67600 (epoch 8), train_loss = 1.334, time/batch=0.113\n",
      "11936/67600 (epoch 8), train_loss = 1.217, time/batch=0.109\n",
      "11937/67600 (epoch 8), train_loss = 1.275, time/batch=0.109\n",
      "11938/67600 (epoch 8), train_loss = 1.337, time/batch=0.111\n",
      "11939/67600 (epoch 8), train_loss = 1.257, time/batch=0.148\n",
      "11940/67600 (epoch 8), train_loss = 1.235, time/batch=0.191\n",
      "11941/67600 (epoch 8), train_loss = 1.239, time/batch=0.130\n",
      "11942/67600 (epoch 8), train_loss = 1.297, time/batch=0.129\n",
      "11943/67600 (epoch 8), train_loss = 1.237, time/batch=0.102\n",
      "11944/67600 (epoch 8), train_loss = 1.265, time/batch=0.129\n",
      "11945/67600 (epoch 8), train_loss = 1.260, time/batch=0.108\n",
      "11946/67600 (epoch 8), train_loss = 1.254, time/batch=0.118\n",
      "11947/67600 (epoch 8), train_loss = 1.269, time/batch=0.244\n",
      "11948/67600 (epoch 8), train_loss = 1.228, time/batch=0.116\n",
      "11949/67600 (epoch 8), train_loss = 1.283, time/batch=0.104\n",
      "11950/67600 (epoch 8), train_loss = 1.322, time/batch=0.126\n",
      "11951/67600 (epoch 8), train_loss = 1.312, time/batch=0.118\n",
      "11952/67600 (epoch 8), train_loss = 1.284, time/batch=0.113\n",
      "11953/67600 (epoch 8), train_loss = 1.253, time/batch=0.104\n",
      "11954/67600 (epoch 8), train_loss = 1.253, time/batch=0.118\n",
      "11955/67600 (epoch 8), train_loss = 1.294, time/batch=0.232\n",
      "11956/67600 (epoch 8), train_loss = 1.247, time/batch=0.091\n",
      "11957/67600 (epoch 8), train_loss = 1.243, time/batch=0.131\n",
      "11958/67600 (epoch 8), train_loss = 1.276, time/batch=0.106\n",
      "11959/67600 (epoch 8), train_loss = 1.281, time/batch=0.120\n",
      "11960/67600 (epoch 8), train_loss = 1.267, time/batch=0.229\n",
      "11961/67600 (epoch 8), train_loss = 1.216, time/batch=0.159\n",
      "11962/67600 (epoch 8), train_loss = 1.216, time/batch=0.130\n",
      "11963/67600 (epoch 8), train_loss = 1.201, time/batch=0.111\n",
      "11964/67600 (epoch 8), train_loss = 1.209, time/batch=0.131\n",
      "11965/67600 (epoch 8), train_loss = 1.231, time/batch=0.110\n",
      "11966/67600 (epoch 8), train_loss = 1.181, time/batch=0.135\n",
      "11967/67600 (epoch 8), train_loss = 1.273, time/batch=0.219\n",
      "11968/67600 (epoch 8), train_loss = 1.245, time/batch=0.133\n",
      "11969/67600 (epoch 8), train_loss = 1.213, time/batch=0.125\n",
      "11970/67600 (epoch 8), train_loss = 1.247, time/batch=0.124\n",
      "11971/67600 (epoch 8), train_loss = 1.228, time/batch=0.120\n",
      "11972/67600 (epoch 8), train_loss = 1.224, time/batch=0.114\n",
      "11973/67600 (epoch 8), train_loss = 1.177, time/batch=0.114\n",
      "11974/67600 (epoch 8), train_loss = 1.275, time/batch=0.116\n",
      "11975/67600 (epoch 8), train_loss = 1.268, time/batch=0.235\n",
      "11976/67600 (epoch 8), train_loss = 1.198, time/batch=0.165\n",
      "11977/67600 (epoch 8), train_loss = 1.208, time/batch=0.110\n",
      "11978/67600 (epoch 8), train_loss = 1.232, time/batch=0.117\n",
      "11979/67600 (epoch 8), train_loss = 1.190, time/batch=0.115\n",
      "11980/67600 (epoch 8), train_loss = 1.244, time/batch=0.123\n",
      "11981/67600 (epoch 8), train_loss = 1.199, time/batch=0.128\n",
      "11982/67600 (epoch 8), train_loss = 1.209, time/batch=0.236\n",
      "11983/67600 (epoch 8), train_loss = 1.236, time/batch=0.140\n",
      "11984/67600 (epoch 8), train_loss = 1.242, time/batch=0.111\n",
      "11985/67600 (epoch 8), train_loss = 1.168, time/batch=0.128\n",
      "11986/67600 (epoch 8), train_loss = 1.200, time/batch=0.123\n",
      "11987/67600 (epoch 8), train_loss = 1.197, time/batch=0.115\n",
      "11988/67600 (epoch 8), train_loss = 1.227, time/batch=0.118\n",
      "11989/67600 (epoch 8), train_loss = 1.230, time/batch=0.273\n",
      "11990/67600 (epoch 8), train_loss = 1.228, time/batch=0.103\n",
      "11991/67600 (epoch 8), train_loss = 1.226, time/batch=0.151\n",
      "11992/67600 (epoch 8), train_loss = 1.237, time/batch=0.098\n",
      "11993/67600 (epoch 8), train_loss = 1.240, time/batch=0.133\n",
      "11994/67600 (epoch 8), train_loss = 1.264, time/batch=0.212\n",
      "11995/67600 (epoch 8), train_loss = 1.345, time/batch=0.154\n",
      "11996/67600 (epoch 8), train_loss = 1.302, time/batch=0.112\n",
      "11997/67600 (epoch 8), train_loss = 1.253, time/batch=0.122\n",
      "11998/67600 (epoch 8), train_loss = 1.247, time/batch=0.121\n",
      "11999/67600 (epoch 8), train_loss = 1.232, time/batch=0.115\n",
      "12000/67600 (epoch 8), train_loss = 1.259, time/batch=0.132\n",
      "model saved to ./save/model.ckpt\n",
      "12001/67600 (epoch 8), train_loss = 1.164, time/batch=0.071\n",
      "12002/67600 (epoch 8), train_loss = 1.197, time/batch=0.083\n",
      "12003/67600 (epoch 8), train_loss = 1.282, time/batch=0.094\n",
      "12004/67600 (epoch 8), train_loss = 1.232, time/batch=0.225\n",
      "12005/67600 (epoch 8), train_loss = 1.199, time/batch=0.133\n",
      "12006/67600 (epoch 8), train_loss = 1.240, time/batch=0.125\n",
      "12007/67600 (epoch 8), train_loss = 1.213, time/batch=0.152\n",
      "12008/67600 (epoch 8), train_loss = 1.230, time/batch=0.109\n",
      "12009/67600 (epoch 8), train_loss = 1.229, time/batch=0.110\n",
      "12010/67600 (epoch 8), train_loss = 1.184, time/batch=0.114\n",
      "12011/67600 (epoch 8), train_loss = 1.216, time/batch=0.285\n",
      "12012/67600 (epoch 8), train_loss = 1.250, time/batch=0.140\n",
      "12013/67600 (epoch 8), train_loss = 1.257, time/batch=0.120\n",
      "12014/67600 (epoch 8), train_loss = 1.263, time/batch=0.129\n",
      "12015/67600 (epoch 8), train_loss = 1.218, time/batch=0.129\n",
      "12016/67600 (epoch 8), train_loss = 1.251, time/batch=0.145\n",
      "12017/67600 (epoch 8), train_loss = 1.218, time/batch=0.119\n",
      "12018/67600 (epoch 8), train_loss = 1.200, time/batch=0.242\n",
      "12019/67600 (epoch 8), train_loss = 1.204, time/batch=0.132\n",
      "12020/67600 (epoch 8), train_loss = 1.314, time/batch=0.091\n",
      "12021/67600 (epoch 8), train_loss = 1.233, time/batch=0.125\n",
      "12022/67600 (epoch 8), train_loss = 1.199, time/batch=0.118\n",
      "12023/67600 (epoch 8), train_loss = 1.246, time/batch=0.237\n",
      "12024/67600 (epoch 8), train_loss = 1.202, time/batch=0.150\n",
      "12025/67600 (epoch 8), train_loss = 1.197, time/batch=0.125\n",
      "12026/67600 (epoch 8), train_loss = 1.247, time/batch=0.164\n",
      "12027/67600 (epoch 8), train_loss = 1.203, time/batch=0.102\n",
      "12028/67600 (epoch 8), train_loss = 1.195, time/batch=0.115\n",
      "12029/67600 (epoch 8), train_loss = 1.236, time/batch=0.113\n",
      "12030/67600 (epoch 8), train_loss = 1.265, time/batch=0.226\n",
      "12031/67600 (epoch 8), train_loss = 1.219, time/batch=0.153\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12032/67600 (epoch 8), train_loss = 1.243, time/batch=0.108\n",
      "12033/67600 (epoch 8), train_loss = 1.233, time/batch=0.129\n",
      "12034/67600 (epoch 8), train_loss = 1.228, time/batch=0.109\n",
      "12035/67600 (epoch 8), train_loss = 1.238, time/batch=0.124\n",
      "12036/67600 (epoch 8), train_loss = 1.218, time/batch=0.120\n",
      "12037/67600 (epoch 8), train_loss = 1.216, time/batch=0.241\n",
      "12038/67600 (epoch 8), train_loss = 1.263, time/batch=0.149\n",
      "12039/67600 (epoch 8), train_loss = 1.217, time/batch=0.107\n",
      "12040/67600 (epoch 8), train_loss = 1.270, time/batch=0.123\n",
      "12041/67600 (epoch 8), train_loss = 1.265, time/batch=0.141\n",
      "12042/67600 (epoch 8), train_loss = 1.269, time/batch=0.116\n",
      "12043/67600 (epoch 8), train_loss = 1.239, time/batch=0.127\n",
      "12044/67600 (epoch 8), train_loss = 1.288, time/batch=0.191\n",
      "12045/67600 (epoch 8), train_loss = 1.216, time/batch=0.186\n",
      "12046/67600 (epoch 8), train_loss = 1.250, time/batch=0.114\n",
      "12047/67600 (epoch 8), train_loss = 1.253, time/batch=0.122\n",
      "12048/67600 (epoch 8), train_loss = 1.332, time/batch=0.108\n",
      "12049/67600 (epoch 8), train_loss = 1.289, time/batch=0.117\n",
      "12050/67600 (epoch 8), train_loss = 1.192, time/batch=0.122\n",
      "12051/67600 (epoch 8), train_loss = 1.232, time/batch=0.212\n",
      "12052/67600 (epoch 8), train_loss = 1.227, time/batch=0.182\n",
      "12053/67600 (epoch 8), train_loss = 1.259, time/batch=0.116\n",
      "12054/67600 (epoch 8), train_loss = 1.225, time/batch=0.083\n",
      "12055/67600 (epoch 8), train_loss = 1.216, time/batch=0.154\n",
      "12056/67600 (epoch 8), train_loss = 1.282, time/batch=0.114\n",
      "12057/67600 (epoch 8), train_loss = 1.224, time/batch=0.220\n",
      "12058/67600 (epoch 8), train_loss = 1.231, time/batch=0.149\n",
      "12059/67600 (epoch 8), train_loss = 1.260, time/batch=0.115\n",
      "12060/67600 (epoch 8), train_loss = 1.333, time/batch=0.119\n",
      "12061/67600 (epoch 8), train_loss = 1.250, time/batch=0.146\n",
      "12062/67600 (epoch 8), train_loss = 1.232, time/batch=0.135\n",
      "12063/67600 (epoch 8), train_loss = 1.230, time/batch=0.113\n",
      "12064/67600 (epoch 8), train_loss = 1.258, time/batch=0.184\n",
      "12065/67600 (epoch 8), train_loss = 1.229, time/batch=0.110\n",
      "12066/67600 (epoch 8), train_loss = 1.200, time/batch=0.121\n",
      "12067/67600 (epoch 8), train_loss = 1.298, time/batch=0.138\n",
      "12068/67600 (epoch 8), train_loss = 1.198, time/batch=0.126\n",
      "12069/67600 (epoch 8), train_loss = 1.297, time/batch=0.192\n",
      "12070/67600 (epoch 8), train_loss = 1.255, time/batch=0.227\n",
      "12071/67600 (epoch 8), train_loss = 1.273, time/batch=0.172\n",
      "12072/67600 (epoch 8), train_loss = 1.267, time/batch=0.099\n",
      "12073/67600 (epoch 8), train_loss = 1.266, time/batch=0.119\n",
      "12074/67600 (epoch 8), train_loss = 1.307, time/batch=0.121\n",
      "12075/67600 (epoch 8), train_loss = 1.251, time/batch=0.122\n",
      "12076/67600 (epoch 8), train_loss = 1.256, time/batch=0.208\n",
      "12077/67600 (epoch 8), train_loss = 1.214, time/batch=0.170\n",
      "12078/67600 (epoch 8), train_loss = 1.316, time/batch=0.129\n",
      "12079/67600 (epoch 8), train_loss = 1.309, time/batch=0.130\n",
      "12080/67600 (epoch 8), train_loss = 1.284, time/batch=0.097\n",
      "12081/67600 (epoch 8), train_loss = 1.232, time/batch=0.146\n",
      "12082/67600 (epoch 8), train_loss = 1.303, time/batch=0.204\n",
      "12083/67600 (epoch 8), train_loss = 1.212, time/batch=0.136\n",
      "12084/67600 (epoch 8), train_loss = 1.190, time/batch=0.124\n",
      "12085/67600 (epoch 8), train_loss = 1.246, time/batch=0.124\n",
      "12086/67600 (epoch 8), train_loss = 1.240, time/batch=0.135\n",
      "12087/67600 (epoch 8), train_loss = 1.187, time/batch=0.111\n",
      "12088/67600 (epoch 8), train_loss = 1.242, time/batch=0.109\n",
      "12089/67600 (epoch 8), train_loss = 1.234, time/batch=0.225\n",
      "12090/67600 (epoch 8), train_loss = 1.224, time/batch=0.157\n",
      "12091/67600 (epoch 8), train_loss = 1.270, time/batch=0.116\n",
      "12092/67600 (epoch 8), train_loss = 1.269, time/batch=0.126\n",
      "12093/67600 (epoch 8), train_loss = 1.253, time/batch=0.156\n",
      "12094/67600 (epoch 8), train_loss = 1.182, time/batch=0.097\n",
      "12095/67600 (epoch 8), train_loss = 1.188, time/batch=0.122\n",
      "12096/67600 (epoch 8), train_loss = 1.208, time/batch=0.240\n",
      "12097/67600 (epoch 8), train_loss = 1.246, time/batch=0.148\n",
      "12098/67600 (epoch 8), train_loss = 1.189, time/batch=0.117\n",
      "12099/67600 (epoch 8), train_loss = 1.244, time/batch=0.122\n",
      "12100/67600 (epoch 8), train_loss = 1.269, time/batch=0.121\n",
      "12101/67600 (epoch 8), train_loss = 1.232, time/batch=0.117\n",
      "12102/67600 (epoch 8), train_loss = 1.211, time/batch=0.135\n",
      "12103/67600 (epoch 8), train_loss = 1.291, time/batch=0.246\n",
      "12104/67600 (epoch 8), train_loss = 1.217, time/batch=0.138\n",
      "12105/67600 (epoch 8), train_loss = 1.280, time/batch=0.112\n",
      "12106/67600 (epoch 8), train_loss = 1.302, time/batch=0.121\n",
      "12107/67600 (epoch 8), train_loss = 1.267, time/batch=0.121\n",
      "12108/67600 (epoch 8), train_loss = 1.224, time/batch=0.119\n",
      "12109/67600 (epoch 8), train_loss = 1.228, time/batch=0.130\n",
      "12110/67600 (epoch 8), train_loss = 1.239, time/batch=0.265\n",
      "12111/67600 (epoch 8), train_loss = 1.238, time/batch=0.138\n",
      "12112/67600 (epoch 8), train_loss = 1.244, time/batch=0.118\n",
      "12113/67600 (epoch 8), train_loss = 1.256, time/batch=0.125\n",
      "12114/67600 (epoch 8), train_loss = 1.199, time/batch=0.113\n",
      "12115/67600 (epoch 8), train_loss = 1.264, time/batch=0.107\n",
      "12116/67600 (epoch 8), train_loss = 1.292, time/batch=0.129\n",
      "12117/67600 (epoch 8), train_loss = 1.233, time/batch=0.257\n",
      "12118/67600 (epoch 8), train_loss = 1.209, time/batch=0.119\n",
      "12119/67600 (epoch 8), train_loss = 1.238, time/batch=0.126\n",
      "12120/67600 (epoch 8), train_loss = 1.260, time/batch=0.126\n",
      "12121/67600 (epoch 8), train_loss = 1.190, time/batch=0.098\n",
      "12122/67600 (epoch 8), train_loss = 1.266, time/batch=0.236\n",
      "12123/67600 (epoch 8), train_loss = 1.252, time/batch=0.165\n",
      "12124/67600 (epoch 8), train_loss = 1.256, time/batch=0.112\n",
      "12125/67600 (epoch 8), train_loss = 1.245, time/batch=0.110\n",
      "12126/67600 (epoch 8), train_loss = 1.216, time/batch=0.136\n",
      "12127/67600 (epoch 8), train_loss = 1.230, time/batch=0.117\n",
      "12128/67600 (epoch 8), train_loss = 1.233, time/batch=0.116\n",
      "12129/67600 (epoch 8), train_loss = 1.297, time/batch=0.125\n",
      "12130/67600 (epoch 8), train_loss = 1.301, time/batch=0.210\n",
      "12131/67600 (epoch 8), train_loss = 1.251, time/batch=0.153\n",
      "12132/67600 (epoch 8), train_loss = 1.259, time/batch=0.115\n",
      "12133/67600 (epoch 8), train_loss = 1.283, time/batch=0.133\n",
      "12134/67600 (epoch 8), train_loss = 1.251, time/batch=0.139\n",
      "12135/67600 (epoch 8), train_loss = 1.225, time/batch=0.146\n",
      "12136/67600 (epoch 8), train_loss = 1.244, time/batch=0.291\n",
      "12137/67600 (epoch 8), train_loss = 1.232, time/batch=0.145\n",
      "12138/67600 (epoch 8), train_loss = 1.216, time/batch=0.143\n",
      "12139/67600 (epoch 8), train_loss = 1.237, time/batch=0.140\n",
      "12140/67600 (epoch 8), train_loss = 1.289, time/batch=0.122\n",
      "12141/67600 (epoch 8), train_loss = 1.238, time/batch=0.118\n",
      "12142/67600 (epoch 8), train_loss = 1.248, time/batch=0.247\n",
      "12143/67600 (epoch 8), train_loss = 1.235, time/batch=0.116\n",
      "12144/67600 (epoch 8), train_loss = 1.236, time/batch=0.150\n",
      "12145/67600 (epoch 8), train_loss = 1.261, time/batch=0.165\n",
      "12146/67600 (epoch 8), train_loss = 1.293, time/batch=0.109\n",
      "12147/67600 (epoch 8), train_loss = 1.297, time/batch=0.100\n",
      "12148/67600 (epoch 8), train_loss = 1.238, time/batch=0.136\n",
      "12149/67600 (epoch 8), train_loss = 1.235, time/batch=0.317\n",
      "12150/67600 (epoch 8), train_loss = 1.199, time/batch=0.135\n",
      "12151/67600 (epoch 8), train_loss = 1.264, time/batch=0.132\n",
      "12152/67600 (epoch 8), train_loss = 1.275, time/batch=0.130\n",
      "12153/67600 (epoch 8), train_loss = 1.240, time/batch=0.120\n",
      "12154/67600 (epoch 8), train_loss = 1.274, time/batch=0.231\n",
      "12155/67600 (epoch 8), train_loss = 1.238, time/batch=0.165\n",
      "12156/67600 (epoch 8), train_loss = 1.213, time/batch=0.181\n",
      "12157/67600 (epoch 8), train_loss = 1.245, time/batch=0.114\n",
      "12158/67600 (epoch 8), train_loss = 1.258, time/batch=0.152\n",
      "12159/67600 (epoch 8), train_loss = 1.231, time/batch=0.151\n",
      "12160/67600 (epoch 8), train_loss = 1.195, time/batch=0.166\n",
      "12161/67600 (epoch 8), train_loss = 1.242, time/batch=0.133\n",
      "12162/67600 (epoch 8), train_loss = 1.218, time/batch=0.145\n",
      "12163/67600 (epoch 8), train_loss = 1.242, time/batch=0.125\n",
      "12164/67600 (epoch 8), train_loss = 1.305, time/batch=0.123\n",
      "12165/67600 (epoch 8), train_loss = 1.341, time/batch=0.303\n",
      "12166/67600 (epoch 8), train_loss = 1.258, time/batch=0.123\n",
      "12167/67600 (epoch 8), train_loss = 1.262, time/batch=0.131\n",
      "12168/67600 (epoch 9), train_loss = 1.432, time/batch=0.101\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12169/67600 (epoch 9), train_loss = 1.193, time/batch=0.094\n",
      "12170/67600 (epoch 9), train_loss = 1.274, time/batch=0.125\n",
      "12171/67600 (epoch 9), train_loss = 1.231, time/batch=0.124\n",
      "12172/67600 (epoch 9), train_loss = 1.252, time/batch=0.306\n",
      "12173/67600 (epoch 9), train_loss = 1.277, time/batch=0.101\n",
      "12174/67600 (epoch 9), train_loss = 1.238, time/batch=0.147\n",
      "12175/67600 (epoch 9), train_loss = 1.245, time/batch=0.138\n",
      "12176/67600 (epoch 9), train_loss = 1.260, time/batch=0.248\n",
      "12177/67600 (epoch 9), train_loss = 1.234, time/batch=0.170\n",
      "12178/67600 (epoch 9), train_loss = 1.199, time/batch=0.148\n",
      "12179/67600 (epoch 9), train_loss = 1.216, time/batch=0.131\n",
      "12180/67600 (epoch 9), train_loss = 1.225, time/batch=0.133\n",
      "12181/67600 (epoch 9), train_loss = 1.290, time/batch=0.118\n",
      "12182/67600 (epoch 9), train_loss = 1.262, time/batch=0.100\n",
      "12183/67600 (epoch 9), train_loss = 1.243, time/batch=0.252\n",
      "12184/67600 (epoch 9), train_loss = 1.244, time/batch=0.168\n",
      "12185/67600 (epoch 9), train_loss = 1.259, time/batch=0.122\n",
      "12186/67600 (epoch 9), train_loss = 1.236, time/batch=0.121\n",
      "12187/67600 (epoch 9), train_loss = 1.233, time/batch=0.108\n",
      "12188/67600 (epoch 9), train_loss = 1.237, time/batch=0.155\n",
      "12189/67600 (epoch 9), train_loss = 1.182, time/batch=0.116\n",
      "12190/67600 (epoch 9), train_loss = 1.302, time/batch=0.231\n",
      "12191/67600 (epoch 9), train_loss = 1.278, time/batch=0.195\n",
      "12192/67600 (epoch 9), train_loss = 1.312, time/batch=0.123\n",
      "12193/67600 (epoch 9), train_loss = 1.169, time/batch=0.114\n",
      "12194/67600 (epoch 9), train_loss = 1.263, time/batch=0.125\n",
      "12195/67600 (epoch 9), train_loss = 1.287, time/batch=0.120\n",
      "12196/67600 (epoch 9), train_loss = 1.312, time/batch=0.296\n",
      "12197/67600 (epoch 9), train_loss = 1.239, time/batch=0.147\n",
      "12198/67600 (epoch 9), train_loss = 1.225, time/batch=0.109\n",
      "12199/67600 (epoch 9), train_loss = 1.300, time/batch=0.115\n",
      "12200/67600 (epoch 9), train_loss = 1.233, time/batch=0.115\n",
      "12201/67600 (epoch 9), train_loss = 1.299, time/batch=0.149\n",
      "12202/67600 (epoch 9), train_loss = 1.264, time/batch=0.103\n",
      "12203/67600 (epoch 9), train_loss = 1.253, time/batch=0.255\n",
      "12204/67600 (epoch 9), train_loss = 1.210, time/batch=0.130\n",
      "12205/67600 (epoch 9), train_loss = 1.260, time/batch=0.102\n",
      "12206/67600 (epoch 9), train_loss = 1.259, time/batch=0.130\n",
      "12207/67600 (epoch 9), train_loss = 1.246, time/batch=0.113\n",
      "12208/67600 (epoch 9), train_loss = 1.177, time/batch=0.132\n",
      "12209/67600 (epoch 9), train_loss = 1.275, time/batch=0.136\n",
      "12210/67600 (epoch 9), train_loss = 1.292, time/batch=0.275\n",
      "12211/67600 (epoch 9), train_loss = 1.264, time/batch=0.115\n",
      "12212/67600 (epoch 9), train_loss = 1.283, time/batch=0.102\n",
      "12213/67600 (epoch 9), train_loss = 1.237, time/batch=0.072\n",
      "12214/67600 (epoch 9), train_loss = 1.211, time/batch=0.067\n",
      "12215/67600 (epoch 9), train_loss = 1.256, time/batch=0.066\n",
      "12216/67600 (epoch 9), train_loss = 1.215, time/batch=0.065\n",
      "12217/67600 (epoch 9), train_loss = 1.216, time/batch=0.083\n",
      "12218/67600 (epoch 9), train_loss = 1.305, time/batch=0.139\n",
      "12219/67600 (epoch 9), train_loss = 1.223, time/batch=0.071\n",
      "12220/67600 (epoch 9), train_loss = 1.231, time/batch=0.108\n",
      "12221/67600 (epoch 9), train_loss = 1.325, time/batch=0.079\n",
      "12222/67600 (epoch 9), train_loss = 1.286, time/batch=0.109\n",
      "12223/67600 (epoch 9), train_loss = 1.246, time/batch=0.084\n",
      "12224/67600 (epoch 9), train_loss = 1.258, time/batch=0.068\n",
      "12225/67600 (epoch 9), train_loss = 1.248, time/batch=0.087\n",
      "12226/67600 (epoch 9), train_loss = 1.256, time/batch=0.096\n",
      "12227/67600 (epoch 9), train_loss = 1.256, time/batch=0.081\n",
      "12228/67600 (epoch 9), train_loss = 1.255, time/batch=0.129\n",
      "12229/67600 (epoch 9), train_loss = 1.243, time/batch=0.133\n",
      "12230/67600 (epoch 9), train_loss = 1.286, time/batch=0.142\n",
      "12231/67600 (epoch 9), train_loss = 1.294, time/batch=0.069\n",
      "12232/67600 (epoch 9), train_loss = 1.237, time/batch=0.066\n",
      "12233/67600 (epoch 9), train_loss = 1.229, time/batch=0.066\n",
      "12234/67600 (epoch 9), train_loss = 1.234, time/batch=0.103\n",
      "12235/67600 (epoch 9), train_loss = 1.261, time/batch=0.072\n",
      "12236/67600 (epoch 9), train_loss = 1.273, time/batch=0.069\n",
      "12237/67600 (epoch 9), train_loss = 1.271, time/batch=0.072\n",
      "12238/67600 (epoch 9), train_loss = 1.265, time/batch=0.067\n",
      "12239/67600 (epoch 9), train_loss = 1.266, time/batch=0.081\n",
      "12240/67600 (epoch 9), train_loss = 1.226, time/batch=0.208\n",
      "12241/67600 (epoch 9), train_loss = 1.293, time/batch=0.111\n",
      "12242/67600 (epoch 9), train_loss = 1.241, time/batch=0.105\n",
      "12243/67600 (epoch 9), train_loss = 1.295, time/batch=0.069\n",
      "12244/67600 (epoch 9), train_loss = 1.288, time/batch=0.078\n",
      "12245/67600 (epoch 9), train_loss = 1.376, time/batch=0.097\n",
      "12246/67600 (epoch 9), train_loss = 1.298, time/batch=0.068\n",
      "12247/67600 (epoch 9), train_loss = 1.226, time/batch=0.067\n",
      "12248/67600 (epoch 9), train_loss = 1.208, time/batch=0.103\n",
      "12249/67600 (epoch 9), train_loss = 1.259, time/batch=0.073\n",
      "12250/67600 (epoch 9), train_loss = 1.260, time/batch=0.225\n",
      "12251/67600 (epoch 9), train_loss = 1.242, time/batch=0.089\n",
      "12252/67600 (epoch 9), train_loss = 1.248, time/batch=0.067\n",
      "12253/67600 (epoch 9), train_loss = 1.248, time/batch=0.075\n",
      "12254/67600 (epoch 9), train_loss = 1.191, time/batch=0.067\n",
      "12255/67600 (epoch 9), train_loss = 1.308, time/batch=0.066\n",
      "12256/67600 (epoch 9), train_loss = 1.284, time/batch=0.067\n",
      "12257/67600 (epoch 9), train_loss = 1.282, time/batch=0.071\n",
      "12258/67600 (epoch 9), train_loss = 1.253, time/batch=0.067\n",
      "12259/67600 (epoch 9), train_loss = 1.274, time/batch=0.065\n",
      "12260/67600 (epoch 9), train_loss = 1.201, time/batch=0.065\n",
      "12261/67600 (epoch 9), train_loss = 1.221, time/batch=0.066\n",
      "12262/67600 (epoch 9), train_loss = 1.215, time/batch=0.205\n",
      "12263/67600 (epoch 9), train_loss = 1.159, time/batch=0.117\n",
      "12264/67600 (epoch 9), train_loss = 1.174, time/batch=0.073\n",
      "12265/67600 (epoch 9), train_loss = 1.255, time/batch=0.076\n",
      "12266/67600 (epoch 9), train_loss = 1.240, time/batch=0.065\n",
      "12267/67600 (epoch 9), train_loss = 1.284, time/batch=0.086\n",
      "12268/67600 (epoch 9), train_loss = 1.157, time/batch=0.097\n",
      "12269/67600 (epoch 9), train_loss = 1.233, time/batch=0.072\n",
      "12270/67600 (epoch 9), train_loss = 1.268, time/batch=0.065\n",
      "12271/67600 (epoch 9), train_loss = 1.180, time/batch=0.066\n",
      "12272/67600 (epoch 9), train_loss = 1.212, time/batch=0.067\n",
      "12273/67600 (epoch 9), train_loss = 1.265, time/batch=0.255\n",
      "12274/67600 (epoch 9), train_loss = 1.223, time/batch=0.065\n",
      "12275/67600 (epoch 9), train_loss = 1.255, time/batch=0.065\n",
      "12276/67600 (epoch 9), train_loss = 1.287, time/batch=0.065\n",
      "12277/67600 (epoch 9), train_loss = 1.250, time/batch=0.071\n",
      "12278/67600 (epoch 9), train_loss = 1.214, time/batch=0.066\n",
      "12279/67600 (epoch 9), train_loss = 1.249, time/batch=0.066\n",
      "12280/67600 (epoch 9), train_loss = 1.235, time/batch=0.092\n",
      "12281/67600 (epoch 9), train_loss = 1.276, time/batch=0.114\n",
      "12282/67600 (epoch 9), train_loss = 1.272, time/batch=0.067\n",
      "12283/67600 (epoch 9), train_loss = 1.218, time/batch=0.066\n",
      "12284/67600 (epoch 9), train_loss = 1.202, time/batch=0.068\n",
      "12285/67600 (epoch 9), train_loss = 1.240, time/batch=0.117\n",
      "12286/67600 (epoch 9), train_loss = 1.266, time/batch=0.083\n",
      "12287/67600 (epoch 9), train_loss = 1.261, time/batch=0.079\n",
      "12288/67600 (epoch 9), train_loss = 1.259, time/batch=0.083\n",
      "12289/67600 (epoch 9), train_loss = 1.268, time/batch=0.067\n",
      "12290/67600 (epoch 9), train_loss = 1.234, time/batch=0.131\n",
      "12291/67600 (epoch 9), train_loss = 1.214, time/batch=0.157\n",
      "12292/67600 (epoch 9), train_loss = 1.235, time/batch=0.067\n",
      "12293/67600 (epoch 9), train_loss = 1.162, time/batch=0.074\n",
      "12294/67600 (epoch 9), train_loss = 1.240, time/batch=0.067\n",
      "12295/67600 (epoch 9), train_loss = 1.271, time/batch=0.132\n",
      "12296/67600 (epoch 9), train_loss = 1.216, time/batch=0.107\n",
      "12297/67600 (epoch 9), train_loss = 1.233, time/batch=0.083\n",
      "12298/67600 (epoch 9), train_loss = 1.261, time/batch=0.098\n",
      "12299/67600 (epoch 9), train_loss = 1.234, time/batch=0.082\n",
      "12300/67600 (epoch 9), train_loss = 1.286, time/batch=0.081\n",
      "12301/67600 (epoch 9), train_loss = 1.223, time/batch=0.208\n",
      "12302/67600 (epoch 9), train_loss = 1.246, time/batch=0.103\n",
      "12303/67600 (epoch 9), train_loss = 1.253, time/batch=0.095\n",
      "12304/67600 (epoch 9), train_loss = 1.269, time/batch=0.110\n",
      "12305/67600 (epoch 9), train_loss = 1.246, time/batch=0.115\n",
      "12306/67600 (epoch 9), train_loss = 1.251, time/batch=0.069\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12307/67600 (epoch 9), train_loss = 1.220, time/batch=0.069\n",
      "12308/67600 (epoch 9), train_loss = 1.218, time/batch=0.068\n",
      "12309/67600 (epoch 9), train_loss = 1.198, time/batch=0.065\n",
      "12310/67600 (epoch 9), train_loss = 1.253, time/batch=0.066\n",
      "12311/67600 (epoch 9), train_loss = 1.208, time/batch=0.111\n",
      "12312/67600 (epoch 9), train_loss = 1.297, time/batch=0.158\n",
      "12313/67600 (epoch 9), train_loss = 1.332, time/batch=0.075\n",
      "12314/67600 (epoch 9), train_loss = 1.245, time/batch=0.069\n",
      "12315/67600 (epoch 9), train_loss = 1.235, time/batch=0.068\n",
      "12316/67600 (epoch 9), train_loss = 1.295, time/batch=0.066\n",
      "12317/67600 (epoch 9), train_loss = 1.180, time/batch=0.067\n",
      "12318/67600 (epoch 9), train_loss = 1.256, time/batch=0.076\n",
      "12319/67600 (epoch 9), train_loss = 1.207, time/batch=0.070\n",
      "12320/67600 (epoch 9), train_loss = 1.196, time/batch=0.115\n",
      "12321/67600 (epoch 9), train_loss = 1.242, time/batch=0.120\n",
      "12322/67600 (epoch 9), train_loss = 1.211, time/batch=0.088\n",
      "12323/67600 (epoch 9), train_loss = 1.266, time/batch=0.081\n",
      "12324/67600 (epoch 9), train_loss = 1.268, time/batch=0.067\n",
      "12325/67600 (epoch 9), train_loss = 1.275, time/batch=0.066\n",
      "12326/67600 (epoch 9), train_loss = 1.257, time/batch=0.076\n",
      "12327/67600 (epoch 9), train_loss = 1.227, time/batch=0.070\n",
      "12328/67600 (epoch 9), train_loss = 1.217, time/batch=0.069\n",
      "12329/67600 (epoch 9), train_loss = 1.192, time/batch=0.071\n",
      "12330/67600 (epoch 9), train_loss = 1.249, time/batch=0.070\n",
      "12331/67600 (epoch 9), train_loss = 1.239, time/batch=0.067\n",
      "12332/67600 (epoch 9), train_loss = 1.148, time/batch=0.066\n",
      "12333/67600 (epoch 9), train_loss = 1.234, time/batch=0.170\n",
      "12334/67600 (epoch 9), train_loss = 1.230, time/batch=0.069\n",
      "12335/67600 (epoch 9), train_loss = 1.210, time/batch=0.111\n",
      "12336/67600 (epoch 9), train_loss = 1.253, time/batch=0.072\n",
      "12337/67600 (epoch 9), train_loss = 1.269, time/batch=0.068\n",
      "12338/67600 (epoch 9), train_loss = 1.261, time/batch=0.068\n",
      "12339/67600 (epoch 9), train_loss = 1.206, time/batch=0.063\n",
      "12340/67600 (epoch 9), train_loss = 1.267, time/batch=0.064\n",
      "12341/67600 (epoch 9), train_loss = 1.218, time/batch=0.075\n",
      "12342/67600 (epoch 9), train_loss = 1.220, time/batch=0.065\n",
      "12343/67600 (epoch 9), train_loss = 1.193, time/batch=0.067\n",
      "12344/67600 (epoch 9), train_loss = 1.259, time/batch=0.064\n",
      "12345/67600 (epoch 9), train_loss = 1.291, time/batch=0.078\n",
      "12346/67600 (epoch 9), train_loss = 1.202, time/batch=0.175\n",
      "12347/67600 (epoch 9), train_loss = 1.215, time/batch=0.092\n",
      "12348/67600 (epoch 9), train_loss = 1.185, time/batch=0.087\n",
      "12349/67600 (epoch 9), train_loss = 1.178, time/batch=0.090\n",
      "12350/67600 (epoch 9), train_loss = 1.220, time/batch=0.076\n",
      "12351/67600 (epoch 9), train_loss = 1.322, time/batch=0.064\n",
      "12352/67600 (epoch 9), train_loss = 1.331, time/batch=0.067\n",
      "12353/67600 (epoch 9), train_loss = 1.305, time/batch=0.065\n",
      "12354/67600 (epoch 9), train_loss = 1.336, time/batch=0.066\n",
      "12355/67600 (epoch 9), train_loss = 1.237, time/batch=0.083\n",
      "12356/67600 (epoch 9), train_loss = 1.251, time/batch=0.075\n",
      "12357/67600 (epoch 9), train_loss = 1.244, time/batch=0.120\n",
      "12358/67600 (epoch 9), train_loss = 1.310, time/batch=0.130\n",
      "12359/67600 (epoch 9), train_loss = 1.277, time/batch=0.083\n",
      "12360/67600 (epoch 9), train_loss = 1.237, time/batch=0.073\n",
      "12361/67600 (epoch 9), train_loss = 1.275, time/batch=0.079\n",
      "12362/67600 (epoch 9), train_loss = 1.268, time/batch=0.077\n",
      "12363/67600 (epoch 9), train_loss = 1.252, time/batch=0.073\n",
      "12364/67600 (epoch 9), train_loss = 1.235, time/batch=0.066\n",
      "12365/67600 (epoch 9), train_loss = 1.234, time/batch=0.064\n",
      "12366/67600 (epoch 9), train_loss = 1.261, time/batch=0.065\n",
      "12367/67600 (epoch 9), train_loss = 1.215, time/batch=0.065\n",
      "12368/67600 (epoch 9), train_loss = 1.204, time/batch=0.066\n",
      "12369/67600 (epoch 9), train_loss = 1.178, time/batch=0.070\n",
      "12370/67600 (epoch 9), train_loss = 1.303, time/batch=0.200\n",
      "12371/67600 (epoch 9), train_loss = 1.246, time/batch=0.065\n",
      "12372/67600 (epoch 9), train_loss = 1.267, time/batch=0.074\n",
      "12373/67600 (epoch 9), train_loss = 1.185, time/batch=0.065\n",
      "12374/67600 (epoch 9), train_loss = 1.186, time/batch=0.065\n",
      "12375/67600 (epoch 9), train_loss = 1.208, time/batch=0.064\n",
      "12376/67600 (epoch 9), train_loss = 1.258, time/batch=0.063\n",
      "12377/67600 (epoch 9), train_loss = 1.289, time/batch=0.065\n",
      "12378/67600 (epoch 9), train_loss = 1.262, time/batch=0.063\n",
      "12379/67600 (epoch 9), train_loss = 1.318, time/batch=0.116\n",
      "12380/67600 (epoch 9), train_loss = 1.220, time/batch=0.100\n",
      "12381/67600 (epoch 9), train_loss = 1.232, time/batch=0.069\n",
      "12382/67600 (epoch 9), train_loss = 1.239, time/batch=0.096\n",
      "12383/67600 (epoch 9), train_loss = 1.275, time/batch=0.071\n",
      "12384/67600 (epoch 9), train_loss = 1.221, time/batch=0.081\n",
      "12385/67600 (epoch 9), train_loss = 1.228, time/batch=0.073\n",
      "12386/67600 (epoch 9), train_loss = 1.208, time/batch=0.067\n",
      "12387/67600 (epoch 9), train_loss = 1.190, time/batch=0.076\n",
      "12388/67600 (epoch 9), train_loss = 1.298, time/batch=0.066\n",
      "12389/67600 (epoch 9), train_loss = 1.207, time/batch=0.064\n",
      "12390/67600 (epoch 9), train_loss = 1.256, time/batch=0.074\n",
      "12391/67600 (epoch 9), train_loss = 1.242, time/batch=0.077\n",
      "12392/67600 (epoch 9), train_loss = 1.240, time/batch=0.174\n",
      "12393/67600 (epoch 9), train_loss = 1.219, time/batch=0.070\n",
      "12394/67600 (epoch 9), train_loss = 1.283, time/batch=0.126\n",
      "12395/67600 (epoch 9), train_loss = 1.195, time/batch=0.069\n",
      "12396/67600 (epoch 9), train_loss = 1.207, time/batch=0.068\n",
      "12397/67600 (epoch 9), train_loss = 1.214, time/batch=0.070\n",
      "12398/67600 (epoch 9), train_loss = 1.248, time/batch=0.066\n",
      "12399/67600 (epoch 9), train_loss = 1.246, time/batch=0.071\n",
      "12400/67600 (epoch 9), train_loss = 1.178, time/batch=0.068\n",
      "12401/67600 (epoch 9), train_loss = 1.183, time/batch=0.069\n",
      "12402/67600 (epoch 9), train_loss = 1.249, time/batch=0.066\n",
      "12403/67600 (epoch 9), train_loss = 1.239, time/batch=0.081\n",
      "12404/67600 (epoch 9), train_loss = 1.222, time/batch=0.190\n",
      "12405/67600 (epoch 9), train_loss = 1.226, time/batch=0.069\n",
      "12406/67600 (epoch 9), train_loss = 1.287, time/batch=0.100\n",
      "12407/67600 (epoch 9), train_loss = 1.255, time/batch=0.078\n",
      "12408/67600 (epoch 9), train_loss = 1.260, time/batch=0.068\n",
      "12409/67600 (epoch 9), train_loss = 1.191, time/batch=0.076\n",
      "12410/67600 (epoch 9), train_loss = 1.244, time/batch=0.136\n",
      "12411/67600 (epoch 9), train_loss = 1.257, time/batch=0.083\n",
      "12412/67600 (epoch 9), train_loss = 1.188, time/batch=0.072\n",
      "12413/67600 (epoch 9), train_loss = 1.252, time/batch=0.121\n",
      "12414/67600 (epoch 9), train_loss = 1.233, time/batch=0.277\n",
      "12415/67600 (epoch 9), train_loss = 1.242, time/batch=0.091\n",
      "12416/67600 (epoch 9), train_loss = 1.266, time/batch=0.075\n",
      "12417/67600 (epoch 9), train_loss = 1.211, time/batch=0.096\n",
      "12418/67600 (epoch 9), train_loss = 1.206, time/batch=0.086\n",
      "12419/67600 (epoch 9), train_loss = 1.288, time/batch=0.077\n",
      "12420/67600 (epoch 9), train_loss = 1.203, time/batch=0.078\n",
      "12421/67600 (epoch 9), train_loss = 1.245, time/batch=0.086\n",
      "12422/67600 (epoch 9), train_loss = 1.260, time/batch=0.094\n",
      "12423/67600 (epoch 9), train_loss = 1.312, time/batch=0.177\n",
      "12424/67600 (epoch 9), train_loss = 1.282, time/batch=0.168\n",
      "12425/67600 (epoch 9), train_loss = 1.285, time/batch=0.077\n",
      "12426/67600 (epoch 9), train_loss = 1.200, time/batch=0.090\n",
      "12427/67600 (epoch 9), train_loss = 1.202, time/batch=0.096\n",
      "12428/67600 (epoch 9), train_loss = 1.225, time/batch=0.088\n",
      "12429/67600 (epoch 9), train_loss = 1.218, time/batch=0.091\n",
      "12430/67600 (epoch 9), train_loss = 1.238, time/batch=0.097\n",
      "12431/67600 (epoch 9), train_loss = 1.246, time/batch=0.102\n",
      "12432/67600 (epoch 9), train_loss = 1.222, time/batch=0.202\n",
      "12433/67600 (epoch 9), train_loss = 1.221, time/batch=0.160\n",
      "12434/67600 (epoch 9), train_loss = 1.202, time/batch=0.105\n",
      "12435/67600 (epoch 9), train_loss = 1.244, time/batch=0.141\n",
      "12436/67600 (epoch 9), train_loss = 1.221, time/batch=0.117\n",
      "12437/67600 (epoch 9), train_loss = 1.205, time/batch=0.093\n",
      "12438/67600 (epoch 9), train_loss = 1.265, time/batch=0.122\n",
      "12439/67600 (epoch 9), train_loss = 1.238, time/batch=0.069\n",
      "12440/67600 (epoch 9), train_loss = 1.243, time/batch=0.072\n",
      "12441/67600 (epoch 9), train_loss = 1.279, time/batch=0.077\n",
      "12442/67600 (epoch 9), train_loss = 1.258, time/batch=0.080\n",
      "12443/67600 (epoch 9), train_loss = 1.232, time/batch=0.075\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12444/67600 (epoch 9), train_loss = 1.258, time/batch=0.087\n",
      "12445/67600 (epoch 9), train_loss = 1.206, time/batch=0.096\n",
      "12446/67600 (epoch 9), train_loss = 1.207, time/batch=0.083\n",
      "12447/67600 (epoch 9), train_loss = 1.257, time/batch=0.295\n",
      "12448/67600 (epoch 9), train_loss = 1.272, time/batch=0.095\n",
      "12449/67600 (epoch 9), train_loss = 1.212, time/batch=0.074\n",
      "12450/67600 (epoch 9), train_loss = 1.176, time/batch=0.072\n",
      "12451/67600 (epoch 9), train_loss = 1.262, time/batch=0.074\n",
      "12452/67600 (epoch 9), train_loss = 1.203, time/batch=0.074\n",
      "12453/67600 (epoch 9), train_loss = 1.324, time/batch=0.078\n",
      "12454/67600 (epoch 9), train_loss = 1.254, time/batch=0.073\n",
      "12455/67600 (epoch 9), train_loss = 1.234, time/batch=0.074\n",
      "12456/67600 (epoch 9), train_loss = 1.271, time/batch=0.078\n",
      "12457/67600 (epoch 9), train_loss = 1.263, time/batch=0.283\n",
      "12458/67600 (epoch 9), train_loss = 1.258, time/batch=0.090\n",
      "12459/67600 (epoch 9), train_loss = 1.250, time/batch=0.073\n",
      "12460/67600 (epoch 9), train_loss = 1.254, time/batch=0.085\n",
      "12461/67600 (epoch 9), train_loss = 1.245, time/batch=0.082\n",
      "12462/67600 (epoch 9), train_loss = 1.248, time/batch=0.084\n",
      "12463/67600 (epoch 9), train_loss = 1.257, time/batch=0.104\n",
      "12464/67600 (epoch 9), train_loss = 1.246, time/batch=0.079\n",
      "12465/67600 (epoch 9), train_loss = 1.218, time/batch=0.075\n",
      "12466/67600 (epoch 9), train_loss = 1.219, time/batch=0.077\n",
      "12467/67600 (epoch 9), train_loss = 1.279, time/batch=0.251\n",
      "12468/67600 (epoch 9), train_loss = 1.234, time/batch=0.093\n",
      "12469/67600 (epoch 9), train_loss = 1.264, time/batch=0.089\n",
      "12470/67600 (epoch 9), train_loss = 1.230, time/batch=0.099\n",
      "12471/67600 (epoch 9), train_loss = 1.257, time/batch=0.106\n",
      "12472/67600 (epoch 9), train_loss = 1.264, time/batch=0.074\n",
      "12473/67600 (epoch 9), train_loss = 1.272, time/batch=0.076\n",
      "12474/67600 (epoch 9), train_loss = 1.291, time/batch=0.191\n",
      "12475/67600 (epoch 9), train_loss = 1.269, time/batch=0.070\n",
      "12476/67600 (epoch 9), train_loss = 1.276, time/batch=0.141\n",
      "12477/67600 (epoch 9), train_loss = 1.276, time/batch=0.076\n",
      "12478/67600 (epoch 9), train_loss = 1.241, time/batch=0.075\n",
      "12479/67600 (epoch 9), train_loss = 1.202, time/batch=0.073\n",
      "12480/67600 (epoch 9), train_loss = 1.215, time/batch=0.077\n",
      "12481/67600 (epoch 9), train_loss = 1.271, time/batch=0.071\n",
      "12482/67600 (epoch 9), train_loss = 1.244, time/batch=0.078\n",
      "12483/67600 (epoch 9), train_loss = 1.321, time/batch=0.088\n",
      "12484/67600 (epoch 9), train_loss = 1.234, time/batch=0.072\n",
      "12485/67600 (epoch 9), train_loss = 1.271, time/batch=0.188\n",
      "12486/67600 (epoch 9), train_loss = 1.271, time/batch=0.087\n",
      "12487/67600 (epoch 9), train_loss = 1.282, time/batch=0.089\n",
      "12488/67600 (epoch 9), train_loss = 1.298, time/batch=0.071\n",
      "12489/67600 (epoch 9), train_loss = 1.240, time/batch=0.129\n",
      "12490/67600 (epoch 9), train_loss = 1.252, time/batch=0.096\n",
      "12491/67600 (epoch 9), train_loss = 1.217, time/batch=0.090\n",
      "12492/67600 (epoch 9), train_loss = 1.244, time/batch=0.107\n",
      "12493/67600 (epoch 9), train_loss = 1.207, time/batch=0.089\n",
      "12494/67600 (epoch 9), train_loss = 1.204, time/batch=0.172\n",
      "12495/67600 (epoch 9), train_loss = 1.279, time/batch=0.134\n",
      "12496/67600 (epoch 9), train_loss = 1.232, time/batch=0.146\n",
      "12497/67600 (epoch 9), train_loss = 1.253, time/batch=0.123\n",
      "12498/67600 (epoch 9), train_loss = 1.281, time/batch=0.087\n",
      "12499/67600 (epoch 9), train_loss = 1.195, time/batch=0.091\n",
      "12500/67600 (epoch 9), train_loss = 1.246, time/batch=0.092\n",
      "model saved to ./save/model.ckpt\n",
      "12501/67600 (epoch 9), train_loss = 1.236, time/batch=0.213\n",
      "12502/67600 (epoch 9), train_loss = 1.259, time/batch=0.084\n",
      "12503/67600 (epoch 9), train_loss = 1.278, time/batch=0.139\n",
      "12504/67600 (epoch 9), train_loss = 1.234, time/batch=0.069\n",
      "12505/67600 (epoch 9), train_loss = 1.213, time/batch=0.071\n",
      "12506/67600 (epoch 9), train_loss = 1.252, time/batch=0.076\n",
      "12507/67600 (epoch 9), train_loss = 1.284, time/batch=0.074\n",
      "12508/67600 (epoch 9), train_loss = 1.241, time/batch=0.073\n",
      "12509/67600 (epoch 9), train_loss = 1.224, time/batch=0.070\n",
      "12510/67600 (epoch 9), train_loss = 1.208, time/batch=0.073\n",
      "12511/67600 (epoch 9), train_loss = 1.199, time/batch=0.098\n",
      "12512/67600 (epoch 9), train_loss = 1.285, time/batch=0.198\n",
      "12513/67600 (epoch 9), train_loss = 1.311, time/batch=0.106\n",
      "12514/67600 (epoch 9), train_loss = 1.252, time/batch=0.070\n",
      "12515/67600 (epoch 9), train_loss = 1.247, time/batch=0.149\n",
      "12516/67600 (epoch 9), train_loss = 1.291, time/batch=0.084\n",
      "12517/67600 (epoch 9), train_loss = 1.295, time/batch=0.070\n",
      "12518/67600 (epoch 9), train_loss = 1.203, time/batch=0.075\n",
      "12519/67600 (epoch 9), train_loss = 1.195, time/batch=0.074\n",
      "12520/67600 (epoch 9), train_loss = 1.184, time/batch=0.071\n",
      "12521/67600 (epoch 9), train_loss = 1.209, time/batch=0.072\n",
      "12522/67600 (epoch 9), train_loss = 1.216, time/batch=0.226\n",
      "12523/67600 (epoch 9), train_loss = 1.281, time/batch=0.146\n",
      "12524/67600 (epoch 9), train_loss = 1.222, time/batch=0.086\n",
      "12525/67600 (epoch 9), train_loss = 1.235, time/batch=0.111\n",
      "12526/67600 (epoch 9), train_loss = 1.194, time/batch=0.089\n",
      "12527/67600 (epoch 9), train_loss = 1.323, time/batch=0.091\n",
      "12528/67600 (epoch 9), train_loss = 1.245, time/batch=0.081\n",
      "12529/67600 (epoch 9), train_loss = 1.202, time/batch=0.085\n",
      "12530/67600 (epoch 9), train_loss = 1.211, time/batch=0.360\n",
      "12531/67600 (epoch 9), train_loss = 1.284, time/batch=0.100\n",
      "12532/67600 (epoch 9), train_loss = 1.240, time/batch=0.137\n",
      "12533/67600 (epoch 9), train_loss = 1.227, time/batch=0.150\n",
      "12534/67600 (epoch 9), train_loss = 1.236, time/batch=0.110\n",
      "12535/67600 (epoch 9), train_loss = 1.184, time/batch=0.229\n",
      "12536/67600 (epoch 9), train_loss = 1.237, time/batch=0.152\n",
      "12537/67600 (epoch 9), train_loss = 1.314, time/batch=0.133\n",
      "12538/67600 (epoch 9), train_loss = 1.234, time/batch=0.159\n",
      "12539/67600 (epoch 9), train_loss = 1.242, time/batch=0.158\n",
      "12540/67600 (epoch 9), train_loss = 1.272, time/batch=0.119\n",
      "12541/67600 (epoch 9), train_loss = 1.244, time/batch=0.191\n",
      "12542/67600 (epoch 9), train_loss = 1.294, time/batch=0.146\n",
      "12543/67600 (epoch 9), train_loss = 1.319, time/batch=0.136\n",
      "12544/67600 (epoch 9), train_loss = 1.265, time/batch=0.122\n",
      "12545/67600 (epoch 9), train_loss = 1.247, time/batch=0.141\n",
      "12546/67600 (epoch 9), train_loss = 1.309, time/batch=0.236\n",
      "12547/67600 (epoch 9), train_loss = 1.321, time/batch=0.221\n",
      "12548/67600 (epoch 9), train_loss = 1.278, time/batch=0.121\n",
      "12549/67600 (epoch 9), train_loss = 1.240, time/batch=0.110\n",
      "12550/67600 (epoch 9), train_loss = 1.233, time/batch=0.138\n",
      "12551/67600 (epoch 9), train_loss = 1.272, time/batch=0.132\n",
      "12552/67600 (epoch 9), train_loss = 1.326, time/batch=0.120\n",
      "12553/67600 (epoch 9), train_loss = 1.247, time/batch=0.260\n",
      "12554/67600 (epoch 9), train_loss = 1.230, time/batch=0.169\n",
      "12555/67600 (epoch 9), train_loss = 1.235, time/batch=0.112\n",
      "12556/67600 (epoch 9), train_loss = 1.278, time/batch=0.164\n",
      "12557/67600 (epoch 9), train_loss = 1.258, time/batch=0.117\n",
      "12558/67600 (epoch 9), train_loss = 1.236, time/batch=0.139\n",
      "12559/67600 (epoch 9), train_loss = 1.233, time/batch=0.335\n",
      "12560/67600 (epoch 9), train_loss = 1.229, time/batch=0.115\n",
      "12561/67600 (epoch 9), train_loss = 1.250, time/batch=0.145\n",
      "12562/67600 (epoch 9), train_loss = 1.229, time/batch=0.111\n",
      "12563/67600 (epoch 9), train_loss = 1.234, time/batch=0.131\n",
      "12564/67600 (epoch 9), train_loss = 1.294, time/batch=0.257\n",
      "12565/67600 (epoch 9), train_loss = 1.288, time/batch=0.168\n",
      "12566/67600 (epoch 9), train_loss = 1.247, time/batch=0.103\n",
      "12567/67600 (epoch 9), train_loss = 1.230, time/batch=0.156\n",
      "12568/67600 (epoch 9), train_loss = 1.270, time/batch=0.103\n",
      "12569/67600 (epoch 9), train_loss = 1.328, time/batch=0.116\n",
      "12570/67600 (epoch 9), train_loss = 1.299, time/batch=0.302\n",
      "12571/67600 (epoch 9), train_loss = 1.263, time/batch=0.174\n",
      "12572/67600 (epoch 9), train_loss = 1.327, time/batch=0.149\n",
      "12573/67600 (epoch 9), train_loss = 1.288, time/batch=0.128\n",
      "12574/67600 (epoch 9), train_loss = 1.294, time/batch=0.118\n",
      "12575/67600 (epoch 9), train_loss = 1.227, time/batch=0.182\n",
      "12576/67600 (epoch 9), train_loss = 1.276, time/batch=0.175\n",
      "12577/67600 (epoch 9), train_loss = 1.271, time/batch=0.201\n",
      "12578/67600 (epoch 9), train_loss = 1.274, time/batch=0.120\n",
      "12579/67600 (epoch 9), train_loss = 1.210, time/batch=0.123\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12580/67600 (epoch 9), train_loss = 1.243, time/batch=0.140\n",
      "12581/67600 (epoch 9), train_loss = 1.257, time/batch=0.123\n",
      "12582/67600 (epoch 9), train_loss = 1.234, time/batch=0.111\n",
      "12583/67600 (epoch 9), train_loss = 1.293, time/batch=0.225\n",
      "12584/67600 (epoch 9), train_loss = 1.256, time/batch=0.170\n",
      "12585/67600 (epoch 9), train_loss = 1.287, time/batch=0.128\n",
      "12586/67600 (epoch 9), train_loss = 1.300, time/batch=0.125\n",
      "12587/67600 (epoch 9), train_loss = 1.223, time/batch=0.142\n",
      "12588/67600 (epoch 9), train_loss = 1.167, time/batch=0.132\n",
      "12589/67600 (epoch 9), train_loss = 1.195, time/batch=0.114\n",
      "12590/67600 (epoch 9), train_loss = 1.244, time/batch=0.282\n",
      "12591/67600 (epoch 9), train_loss = 1.192, time/batch=0.116\n",
      "12592/67600 (epoch 9), train_loss = 1.246, time/batch=0.118\n",
      "12593/67600 (epoch 9), train_loss = 1.216, time/batch=0.148\n",
      "12594/67600 (epoch 9), train_loss = 1.234, time/batch=0.112\n",
      "12595/67600 (epoch 9), train_loss = 1.229, time/batch=0.226\n",
      "12596/67600 (epoch 9), train_loss = 1.161, time/batch=0.144\n",
      "12597/67600 (epoch 9), train_loss = 1.218, time/batch=0.134\n",
      "12598/67600 (epoch 9), train_loss = 1.280, time/batch=0.124\n",
      "12599/67600 (epoch 9), train_loss = 1.206, time/batch=0.126\n",
      "12600/67600 (epoch 9), train_loss = 1.270, time/batch=0.127\n",
      "12601/67600 (epoch 9), train_loss = 1.273, time/batch=0.141\n",
      "12602/67600 (epoch 9), train_loss = 1.203, time/batch=0.222\n",
      "12603/67600 (epoch 9), train_loss = 1.309, time/batch=0.150\n",
      "12604/67600 (epoch 9), train_loss = 1.240, time/batch=0.112\n",
      "12605/67600 (epoch 9), train_loss = 1.247, time/batch=0.155\n",
      "12606/67600 (epoch 9), train_loss = 1.268, time/batch=0.100\n",
      "12607/67600 (epoch 9), train_loss = 1.228, time/batch=0.131\n",
      "12608/67600 (epoch 9), train_loss = 1.227, time/batch=0.114\n",
      "12609/67600 (epoch 9), train_loss = 1.265, time/batch=0.226\n",
      "12610/67600 (epoch 9), train_loss = 1.222, time/batch=0.155\n",
      "12611/67600 (epoch 9), train_loss = 1.208, time/batch=0.113\n",
      "12612/67600 (epoch 9), train_loss = 1.259, time/batch=0.125\n",
      "12613/67600 (epoch 9), train_loss = 1.284, time/batch=0.121\n",
      "12614/67600 (epoch 9), train_loss = 1.201, time/batch=0.123\n",
      "12615/67600 (epoch 9), train_loss = 1.216, time/batch=0.115\n",
      "12616/67600 (epoch 9), train_loss = 1.189, time/batch=0.266\n",
      "12617/67600 (epoch 9), train_loss = 1.207, time/batch=0.144\n",
      "12618/67600 (epoch 9), train_loss = 1.166, time/batch=0.112\n",
      "12619/67600 (epoch 9), train_loss = 1.268, time/batch=0.119\n",
      "12620/67600 (epoch 9), train_loss = 1.287, time/batch=0.116\n",
      "12621/67600 (epoch 9), train_loss = 1.183, time/batch=0.114\n",
      "12622/67600 (epoch 9), train_loss = 1.168, time/batch=0.123\n",
      "12623/67600 (epoch 9), train_loss = 1.203, time/batch=0.265\n",
      "12624/67600 (epoch 9), train_loss = 1.225, time/batch=0.126\n",
      "12625/67600 (epoch 9), train_loss = 1.245, time/batch=0.126\n",
      "12626/67600 (epoch 9), train_loss = 1.265, time/batch=0.110\n",
      "12627/67600 (epoch 9), train_loss = 1.240, time/batch=0.138\n",
      "12628/67600 (epoch 9), train_loss = 1.255, time/batch=0.111\n",
      "12629/67600 (epoch 9), train_loss = 1.203, time/batch=0.114\n",
      "12630/67600 (epoch 9), train_loss = 1.265, time/batch=0.291\n",
      "12631/67600 (epoch 9), train_loss = 1.245, time/batch=0.122\n",
      "12632/67600 (epoch 9), train_loss = 1.214, time/batch=0.126\n",
      "12633/67600 (epoch 9), train_loss = 1.228, time/batch=0.123\n",
      "12634/67600 (epoch 9), train_loss = 1.220, time/batch=0.128\n",
      "12635/67600 (epoch 9), train_loss = 1.278, time/batch=0.141\n",
      "12636/67600 (epoch 9), train_loss = 1.235, time/batch=0.137\n",
      "12637/67600 (epoch 9), train_loss = 1.204, time/batch=0.099\n",
      "12638/67600 (epoch 9), train_loss = 1.230, time/batch=0.145\n",
      "12639/67600 (epoch 9), train_loss = 1.229, time/batch=0.103\n",
      "12640/67600 (epoch 9), train_loss = 1.202, time/batch=0.121\n",
      "12641/67600 (epoch 9), train_loss = 1.253, time/batch=0.280\n",
      "12642/67600 (epoch 9), train_loss = 1.210, time/batch=0.131\n",
      "12643/67600 (epoch 9), train_loss = 1.180, time/batch=0.138\n",
      "12644/67600 (epoch 9), train_loss = 1.269, time/batch=0.099\n",
      "12645/67600 (epoch 9), train_loss = 1.197, time/batch=0.128\n",
      "12646/67600 (epoch 9), train_loss = 1.217, time/batch=0.128\n",
      "12647/67600 (epoch 9), train_loss = 1.250, time/batch=0.136\n",
      "12648/67600 (epoch 9), train_loss = 1.201, time/batch=0.272\n",
      "12649/67600 (epoch 9), train_loss = 1.235, time/batch=0.168\n",
      "12650/67600 (epoch 9), train_loss = 1.216, time/batch=0.148\n",
      "12651/67600 (epoch 9), train_loss = 1.194, time/batch=0.113\n",
      "12652/67600 (epoch 9), train_loss = 1.253, time/batch=0.151\n",
      "12653/67600 (epoch 9), train_loss = 1.257, time/batch=0.121\n",
      "12654/67600 (epoch 9), train_loss = 1.277, time/batch=0.319\n",
      "12655/67600 (epoch 9), train_loss = 1.245, time/batch=0.152\n",
      "12656/67600 (epoch 9), train_loss = 1.297, time/batch=0.112\n",
      "12657/67600 (epoch 9), train_loss = 1.273, time/batch=0.134\n",
      "12658/67600 (epoch 9), train_loss = 1.201, time/batch=0.144\n",
      "12659/67600 (epoch 9), train_loss = 1.231, time/batch=0.260\n",
      "12660/67600 (epoch 9), train_loss = 1.258, time/batch=0.171\n",
      "12661/67600 (epoch 9), train_loss = 1.210, time/batch=0.142\n",
      "12662/67600 (epoch 9), train_loss = 1.285, time/batch=0.158\n",
      "12663/67600 (epoch 9), train_loss = 1.253, time/batch=0.165\n",
      "12664/67600 (epoch 9), train_loss = 1.223, time/batch=0.256\n",
      "12665/67600 (epoch 9), train_loss = 1.251, time/batch=0.134\n",
      "12666/67600 (epoch 9), train_loss = 1.302, time/batch=0.149\n",
      "12667/67600 (epoch 9), train_loss = 1.242, time/batch=0.126\n",
      "12668/67600 (epoch 9), train_loss = 1.190, time/batch=0.112\n",
      "12669/67600 (epoch 9), train_loss = 1.191, time/batch=0.112\n",
      "12670/67600 (epoch 9), train_loss = 1.220, time/batch=0.132\n",
      "12671/67600 (epoch 9), train_loss = 1.252, time/batch=0.179\n",
      "12672/67600 (epoch 9), train_loss = 1.266, time/batch=0.175\n",
      "12673/67600 (epoch 9), train_loss = 1.278, time/batch=0.118\n",
      "12674/67600 (epoch 9), train_loss = 1.256, time/batch=0.115\n",
      "12675/67600 (epoch 9), train_loss = 1.265, time/batch=0.127\n",
      "12676/67600 (epoch 9), train_loss = 1.195, time/batch=0.122\n",
      "12677/67600 (epoch 9), train_loss = 1.225, time/batch=0.112\n",
      "12678/67600 (epoch 9), train_loss = 1.264, time/batch=0.118\n",
      "12679/67600 (epoch 9), train_loss = 1.246, time/batch=0.256\n",
      "12680/67600 (epoch 9), train_loss = 1.258, time/batch=0.119\n",
      "12681/67600 (epoch 9), train_loss = 1.222, time/batch=0.128\n",
      "12682/67600 (epoch 9), train_loss = 1.258, time/batch=0.132\n",
      "12683/67600 (epoch 9), train_loss = 1.277, time/batch=0.125\n",
      "12684/67600 (epoch 9), train_loss = 1.285, time/batch=0.168\n",
      "12685/67600 (epoch 9), train_loss = 1.265, time/batch=0.267\n",
      "12686/67600 (epoch 9), train_loss = 1.256, time/batch=0.114\n",
      "12687/67600 (epoch 9), train_loss = 1.178, time/batch=0.151\n",
      "12688/67600 (epoch 9), train_loss = 1.291, time/batch=0.109\n",
      "12689/67600 (epoch 9), train_loss = 1.294, time/batch=0.143\n",
      "12690/67600 (epoch 9), train_loss = 1.300, time/batch=0.208\n",
      "12691/67600 (epoch 9), train_loss = 1.251, time/batch=0.140\n",
      "12692/67600 (epoch 9), train_loss = 1.238, time/batch=0.122\n",
      "12693/67600 (epoch 9), train_loss = 1.243, time/batch=0.112\n",
      "12694/67600 (epoch 9), train_loss = 1.259, time/batch=0.149\n",
      "12695/67600 (epoch 9), train_loss = 1.216, time/batch=0.096\n",
      "12696/67600 (epoch 9), train_loss = 1.274, time/batch=0.105\n",
      "12697/67600 (epoch 9), train_loss = 1.232, time/batch=0.115\n",
      "12698/67600 (epoch 9), train_loss = 1.293, time/batch=0.207\n",
      "12699/67600 (epoch 9), train_loss = 1.275, time/batch=0.159\n",
      "12700/67600 (epoch 9), train_loss = 1.262, time/batch=0.102\n",
      "12701/67600 (epoch 9), train_loss = 1.218, time/batch=0.119\n",
      "12702/67600 (epoch 9), train_loss = 1.234, time/batch=0.099\n",
      "12703/67600 (epoch 9), train_loss = 1.196, time/batch=0.112\n",
      "12704/67600 (epoch 9), train_loss = 1.224, time/batch=0.113\n",
      "12705/67600 (epoch 9), train_loss = 1.247, time/batch=0.173\n",
      "12706/67600 (epoch 9), train_loss = 1.232, time/batch=0.168\n",
      "12707/67600 (epoch 9), train_loss = 1.248, time/batch=0.130\n",
      "12708/67600 (epoch 9), train_loss = 1.252, time/batch=0.118\n",
      "12709/67600 (epoch 9), train_loss = 1.192, time/batch=0.107\n",
      "12710/67600 (epoch 9), train_loss = 1.226, time/batch=0.121\n",
      "12711/67600 (epoch 9), train_loss = 1.202, time/batch=0.096\n",
      "12712/67600 (epoch 9), train_loss = 1.288, time/batch=0.124\n",
      "12713/67600 (epoch 9), train_loss = 1.244, time/batch=0.210\n",
      "12714/67600 (epoch 9), train_loss = 1.225, time/batch=0.142\n",
      "12715/67600 (epoch 9), train_loss = 1.239, time/batch=0.135\n",
      "12716/67600 (epoch 9), train_loss = 1.363, time/batch=0.110\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12717/67600 (epoch 9), train_loss = 1.276, time/batch=0.114\n",
      "12718/67600 (epoch 9), train_loss = 1.229, time/batch=0.109\n",
      "12719/67600 (epoch 9), train_loss = 1.283, time/batch=0.111\n",
      "12720/67600 (epoch 9), train_loss = 1.232, time/batch=0.106\n",
      "12721/67600 (epoch 9), train_loss = 1.227, time/batch=0.210\n",
      "12722/67600 (epoch 9), train_loss = 1.278, time/batch=0.138\n",
      "12723/67600 (epoch 9), train_loss = 1.224, time/batch=0.107\n",
      "12724/67600 (epoch 9), train_loss = 1.302, time/batch=0.115\n",
      "12725/67600 (epoch 9), train_loss = 1.227, time/batch=0.110\n",
      "12726/67600 (epoch 9), train_loss = 1.217, time/batch=0.109\n",
      "12727/67600 (epoch 9), train_loss = 1.174, time/batch=0.116\n",
      "12728/67600 (epoch 9), train_loss = 1.207, time/batch=0.098\n",
      "12729/67600 (epoch 9), train_loss = 1.230, time/batch=0.259\n",
      "12730/67600 (epoch 9), train_loss = 1.184, time/batch=0.122\n",
      "12731/67600 (epoch 9), train_loss = 1.226, time/batch=0.104\n",
      "12732/67600 (epoch 9), train_loss = 1.202, time/batch=0.131\n",
      "12733/67600 (epoch 9), train_loss = 1.223, time/batch=0.102\n",
      "12734/67600 (epoch 9), train_loss = 1.250, time/batch=0.183\n",
      "12735/67600 (epoch 9), train_loss = 1.265, time/batch=0.108\n",
      "12736/67600 (epoch 9), train_loss = 1.255, time/batch=0.111\n",
      "12737/67600 (epoch 9), train_loss = 1.221, time/batch=0.121\n",
      "12738/67600 (epoch 9), train_loss = 1.203, time/batch=0.103\n",
      "12739/67600 (epoch 9), train_loss = 1.197, time/batch=0.118\n",
      "12740/67600 (epoch 9), train_loss = 1.223, time/batch=0.254\n",
      "12741/67600 (epoch 9), train_loss = 1.236, time/batch=0.164\n",
      "12742/67600 (epoch 9), train_loss = 1.254, time/batch=0.118\n",
      "12743/67600 (epoch 9), train_loss = 1.210, time/batch=0.112\n",
      "12744/67600 (epoch 9), train_loss = 1.252, time/batch=0.111\n",
      "12745/67600 (epoch 9), train_loss = 1.240, time/batch=0.113\n",
      "12746/67600 (epoch 9), train_loss = 1.267, time/batch=0.110\n",
      "12747/67600 (epoch 9), train_loss = 1.234, time/batch=0.116\n",
      "12748/67600 (epoch 9), train_loss = 1.267, time/batch=0.278\n",
      "12749/67600 (epoch 9), train_loss = 1.241, time/batch=0.125\n",
      "12750/67600 (epoch 9), train_loss = 1.194, time/batch=0.108\n",
      "12751/67600 (epoch 9), train_loss = 1.211, time/batch=0.176\n",
      "12752/67600 (epoch 9), train_loss = 1.234, time/batch=0.192\n",
      "12753/67600 (epoch 9), train_loss = 1.296, time/batch=0.118\n",
      "12754/67600 (epoch 9), train_loss = 1.217, time/batch=0.311\n",
      "12755/67600 (epoch 9), train_loss = 1.297, time/batch=0.104\n",
      "12756/67600 (epoch 9), train_loss = 1.208, time/batch=0.136\n",
      "12757/67600 (epoch 9), train_loss = 1.238, time/batch=0.118\n",
      "12758/67600 (epoch 9), train_loss = 1.298, time/batch=0.108\n",
      "12759/67600 (epoch 9), train_loss = 1.205, time/batch=0.269\n",
      "12760/67600 (epoch 9), train_loss = 1.216, time/batch=0.156\n",
      "12761/67600 (epoch 9), train_loss = 1.246, time/batch=0.132\n",
      "12762/67600 (epoch 9), train_loss = 1.186, time/batch=0.133\n",
      "12763/67600 (epoch 9), train_loss = 1.233, time/batch=0.119\n",
      "12764/67600 (epoch 9), train_loss = 1.253, time/batch=0.126\n",
      "12765/67600 (epoch 9), train_loss = 1.199, time/batch=0.235\n",
      "12766/67600 (epoch 9), train_loss = 1.229, time/batch=0.162\n",
      "12767/67600 (epoch 9), train_loss = 1.226, time/batch=0.141\n",
      "12768/67600 (epoch 9), train_loss = 1.269, time/batch=0.124\n",
      "12769/67600 (epoch 9), train_loss = 1.180, time/batch=0.131\n",
      "12770/67600 (epoch 9), train_loss = 1.246, time/batch=0.126\n",
      "12771/67600 (epoch 9), train_loss = 1.226, time/batch=0.117\n",
      "12772/67600 (epoch 9), train_loss = 1.263, time/batch=0.248\n",
      "12773/67600 (epoch 9), train_loss = 1.212, time/batch=0.141\n",
      "12774/67600 (epoch 9), train_loss = 1.285, time/batch=0.181\n",
      "12775/67600 (epoch 9), train_loss = 1.220, time/batch=0.144\n",
      "12776/67600 (epoch 9), train_loss = 1.303, time/batch=0.142\n",
      "12777/67600 (epoch 9), train_loss = 1.233, time/batch=0.100\n",
      "12778/67600 (epoch 9), train_loss = 1.252, time/batch=0.265\n",
      "12779/67600 (epoch 9), train_loss = 1.329, time/batch=0.148\n",
      "12780/67600 (epoch 9), train_loss = 1.237, time/batch=0.115\n",
      "12781/67600 (epoch 9), train_loss = 1.235, time/batch=0.112\n",
      "12782/67600 (epoch 9), train_loss = 1.267, time/batch=0.125\n",
      "12783/67600 (epoch 9), train_loss = 1.298, time/batch=0.127\n",
      "12784/67600 (epoch 9), train_loss = 1.258, time/batch=0.120\n",
      "12785/67600 (epoch 9), train_loss = 1.321, time/batch=0.300\n",
      "12786/67600 (epoch 9), train_loss = 1.244, time/batch=0.115\n",
      "12787/67600 (epoch 9), train_loss = 1.208, time/batch=0.143\n",
      "12788/67600 (epoch 9), train_loss = 1.191, time/batch=0.125\n",
      "12789/67600 (epoch 9), train_loss = 1.236, time/batch=0.126\n",
      "12790/67600 (epoch 9), train_loss = 1.244, time/batch=0.215\n",
      "12791/67600 (epoch 9), train_loss = 1.200, time/batch=0.182\n",
      "12792/67600 (epoch 9), train_loss = 1.240, time/batch=0.099\n",
      "12793/67600 (epoch 9), train_loss = 1.234, time/batch=0.146\n",
      "12794/67600 (epoch 9), train_loss = 1.279, time/batch=0.137\n",
      "12795/67600 (epoch 9), train_loss = 1.281, time/batch=0.101\n",
      "12796/67600 (epoch 9), train_loss = 1.275, time/batch=0.134\n",
      "12797/67600 (epoch 9), train_loss = 1.242, time/batch=0.238\n",
      "12798/67600 (epoch 9), train_loss = 1.279, time/batch=0.153\n",
      "12799/67600 (epoch 9), train_loss = 1.311, time/batch=0.125\n",
      "12800/67600 (epoch 9), train_loss = 1.224, time/batch=0.113\n",
      "12801/67600 (epoch 9), train_loss = 1.297, time/batch=0.109\n",
      "12802/67600 (epoch 9), train_loss = 1.294, time/batch=0.125\n",
      "12803/67600 (epoch 9), train_loss = 1.169, time/batch=0.106\n",
      "12804/67600 (epoch 9), train_loss = 1.320, time/batch=0.256\n",
      "12805/67600 (epoch 9), train_loss = 1.219, time/batch=0.150\n",
      "12806/67600 (epoch 9), train_loss = 1.173, time/batch=0.136\n",
      "12807/67600 (epoch 9), train_loss = 1.169, time/batch=0.112\n",
      "12808/67600 (epoch 9), train_loss = 1.248, time/batch=0.116\n",
      "12809/67600 (epoch 9), train_loss = 1.222, time/batch=0.132\n",
      "12810/67600 (epoch 9), train_loss = 1.275, time/batch=0.111\n",
      "12811/67600 (epoch 9), train_loss = 1.319, time/batch=0.256\n",
      "12812/67600 (epoch 9), train_loss = 1.298, time/batch=0.121\n",
      "12813/67600 (epoch 9), train_loss = 1.232, time/batch=0.128\n",
      "12814/67600 (epoch 9), train_loss = 1.272, time/batch=0.128\n",
      "12815/67600 (epoch 9), train_loss = 1.263, time/batch=0.100\n",
      "12816/67600 (epoch 9), train_loss = 1.284, time/batch=0.245\n",
      "12817/67600 (epoch 9), train_loss = 1.254, time/batch=0.131\n",
      "12818/67600 (epoch 9), train_loss = 1.296, time/batch=0.111\n",
      "12819/67600 (epoch 9), train_loss = 1.316, time/batch=0.161\n",
      "12820/67600 (epoch 9), train_loss = 1.238, time/batch=0.094\n",
      "12821/67600 (epoch 9), train_loss = 1.231, time/batch=0.132\n",
      "12822/67600 (epoch 9), train_loss = 1.257, time/batch=0.129\n",
      "12823/67600 (epoch 9), train_loss = 1.243, time/batch=0.101\n",
      "12824/67600 (epoch 9), train_loss = 1.243, time/batch=0.122\n",
      "12825/67600 (epoch 9), train_loss = 1.309, time/batch=0.269\n",
      "12826/67600 (epoch 9), train_loss = 1.267, time/batch=0.122\n",
      "12827/67600 (epoch 9), train_loss = 1.182, time/batch=0.122\n",
      "12828/67600 (epoch 9), train_loss = 1.243, time/batch=0.113\n",
      "12829/67600 (epoch 9), train_loss = 1.236, time/batch=0.108\n",
      "12830/67600 (epoch 9), train_loss = 1.160, time/batch=0.173\n",
      "12831/67600 (epoch 9), train_loss = 1.193, time/batch=0.111\n",
      "12832/67600 (epoch 9), train_loss = 1.277, time/batch=0.115\n",
      "12833/67600 (epoch 9), train_loss = 1.251, time/batch=0.123\n",
      "12834/67600 (epoch 9), train_loss = 1.266, time/batch=0.118\n",
      "12835/67600 (epoch 9), train_loss = 1.241, time/batch=0.116\n",
      "12836/67600 (epoch 9), train_loss = 1.297, time/batch=0.308\n",
      "12837/67600 (epoch 9), train_loss = 1.205, time/batch=0.127\n",
      "12838/67600 (epoch 9), train_loss = 1.147, time/batch=0.110\n",
      "12839/67600 (epoch 9), train_loss = 1.223, time/batch=0.133\n",
      "12840/67600 (epoch 9), train_loss = 1.165, time/batch=0.136\n",
      "12841/67600 (epoch 9), train_loss = 1.303, time/batch=0.102\n",
      "12842/67600 (epoch 9), train_loss = 1.291, time/batch=0.141\n",
      "12843/67600 (epoch 9), train_loss = 1.214, time/batch=0.212\n",
      "12844/67600 (epoch 9), train_loss = 1.252, time/batch=0.186\n",
      "12845/67600 (epoch 9), train_loss = 1.282, time/batch=0.129\n",
      "12846/67600 (epoch 9), train_loss = 1.295, time/batch=0.122\n",
      "12847/67600 (epoch 9), train_loss = 1.226, time/batch=0.119\n",
      "12848/67600 (epoch 9), train_loss = 1.249, time/batch=0.116\n",
      "12849/67600 (epoch 9), train_loss = 1.272, time/batch=0.119\n",
      "12850/67600 (epoch 9), train_loss = 1.265, time/batch=0.266\n",
      "12851/67600 (epoch 9), train_loss = 1.236, time/batch=0.108\n",
      "12852/67600 (epoch 9), train_loss = 1.216, time/batch=0.139\n",
      "12853/67600 (epoch 9), train_loss = 1.303, time/batch=0.101\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12854/67600 (epoch 9), train_loss = 1.260, time/batch=0.122\n",
      "12855/67600 (epoch 9), train_loss = 1.199, time/batch=0.107\n",
      "12856/67600 (epoch 9), train_loss = 1.244, time/batch=0.228\n",
      "12857/67600 (epoch 9), train_loss = 1.202, time/batch=0.150\n",
      "12858/67600 (epoch 9), train_loss = 1.228, time/batch=0.113\n",
      "12859/67600 (epoch 9), train_loss = 1.230, time/batch=0.133\n",
      "12860/67600 (epoch 9), train_loss = 1.219, time/batch=0.136\n",
      "12861/67600 (epoch 9), train_loss = 1.265, time/batch=0.102\n",
      "12862/67600 (epoch 9), train_loss = 1.249, time/batch=0.129\n",
      "12863/67600 (epoch 9), train_loss = 1.169, time/batch=0.233\n",
      "12864/67600 (epoch 9), train_loss = 1.270, time/batch=0.144\n",
      "12865/67600 (epoch 9), train_loss = 1.274, time/batch=0.122\n",
      "12866/67600 (epoch 9), train_loss = 1.268, time/batch=0.153\n",
      "12867/67600 (epoch 9), train_loss = 1.202, time/batch=0.096\n",
      "12868/67600 (epoch 9), train_loss = 1.251, time/batch=0.133\n",
      "12869/67600 (epoch 9), train_loss = 1.270, time/batch=0.105\n",
      "12870/67600 (epoch 9), train_loss = 1.238, time/batch=0.249\n",
      "12871/67600 (epoch 9), train_loss = 1.190, time/batch=0.120\n",
      "12872/67600 (epoch 9), train_loss = 1.234, time/batch=0.131\n",
      "12873/67600 (epoch 9), train_loss = 1.222, time/batch=0.125\n",
      "12874/67600 (epoch 9), train_loss = 1.218, time/batch=0.129\n",
      "12875/67600 (epoch 9), train_loss = 1.269, time/batch=0.116\n",
      "12876/67600 (epoch 9), train_loss = 1.258, time/batch=0.120\n",
      "12877/67600 (epoch 9), train_loss = 1.201, time/batch=0.256\n",
      "12878/67600 (epoch 9), train_loss = 1.237, time/batch=0.124\n",
      "12879/67600 (epoch 9), train_loss = 1.147, time/batch=0.127\n",
      "12880/67600 (epoch 9), train_loss = 1.244, time/batch=0.116\n",
      "12881/67600 (epoch 9), train_loss = 1.230, time/batch=0.128\n",
      "12882/67600 (epoch 9), train_loss = 1.232, time/batch=0.134\n",
      "12883/67600 (epoch 9), train_loss = 1.219, time/batch=0.116\n",
      "12884/67600 (epoch 9), train_loss = 1.186, time/batch=0.244\n",
      "12885/67600 (epoch 9), train_loss = 1.233, time/batch=0.130\n",
      "12886/67600 (epoch 9), train_loss = 1.209, time/batch=0.111\n",
      "12887/67600 (epoch 9), train_loss = 1.220, time/batch=0.130\n",
      "12888/67600 (epoch 9), train_loss = 1.222, time/batch=0.123\n",
      "12889/67600 (epoch 9), train_loss = 1.263, time/batch=0.189\n",
      "12890/67600 (epoch 9), train_loss = 1.232, time/batch=0.169\n",
      "12891/67600 (epoch 9), train_loss = 1.250, time/batch=0.134\n",
      "12892/67600 (epoch 9), train_loss = 1.243, time/batch=0.126\n",
      "12893/67600 (epoch 9), train_loss = 1.260, time/batch=0.115\n",
      "12894/67600 (epoch 9), train_loss = 1.238, time/batch=0.112\n",
      "12895/67600 (epoch 9), train_loss = 1.250, time/batch=0.124\n",
      "12896/67600 (epoch 9), train_loss = 1.259, time/batch=0.233\n",
      "12897/67600 (epoch 9), train_loss = 1.220, time/batch=0.125\n",
      "12898/67600 (epoch 9), train_loss = 1.252, time/batch=0.141\n",
      "12899/67600 (epoch 9), train_loss = 1.278, time/batch=0.105\n",
      "12900/67600 (epoch 9), train_loss = 1.255, time/batch=0.143\n",
      "12901/67600 (epoch 9), train_loss = 1.245, time/batch=0.119\n",
      "12902/67600 (epoch 9), train_loss = 1.254, time/batch=0.106\n",
      "12903/67600 (epoch 9), train_loss = 1.200, time/batch=0.082\n",
      "12904/67600 (epoch 9), train_loss = 1.300, time/batch=0.223\n",
      "12905/67600 (epoch 9), train_loss = 1.222, time/batch=0.154\n",
      "12906/67600 (epoch 9), train_loss = 1.191, time/batch=0.111\n",
      "12907/67600 (epoch 9), train_loss = 1.263, time/batch=0.135\n",
      "12908/67600 (epoch 9), train_loss = 1.174, time/batch=0.121\n",
      "12909/67600 (epoch 9), train_loss = 1.199, time/batch=0.131\n",
      "12910/67600 (epoch 9), train_loss = 1.178, time/batch=0.109\n",
      "12911/67600 (epoch 9), train_loss = 1.221, time/batch=0.254\n",
      "12912/67600 (epoch 9), train_loss = 1.249, time/batch=0.107\n",
      "12913/67600 (epoch 9), train_loss = 1.251, time/batch=0.130\n",
      "12914/67600 (epoch 9), train_loss = 1.217, time/batch=0.097\n",
      "12915/67600 (epoch 9), train_loss = 1.235, time/batch=0.140\n",
      "12916/67600 (epoch 9), train_loss = 1.255, time/batch=0.116\n",
      "12917/67600 (epoch 9), train_loss = 1.207, time/batch=0.124\n",
      "12918/67600 (epoch 9), train_loss = 1.178, time/batch=0.250\n",
      "12919/67600 (epoch 9), train_loss = 1.205, time/batch=0.146\n",
      "12920/67600 (epoch 9), train_loss = 1.231, time/batch=0.111\n",
      "12921/67600 (epoch 9), train_loss = 1.281, time/batch=0.133\n",
      "12922/67600 (epoch 9), train_loss = 1.220, time/batch=0.120\n",
      "12923/67600 (epoch 9), train_loss = 1.232, time/batch=0.127\n",
      "12924/67600 (epoch 9), train_loss = 1.304, time/batch=0.112\n",
      "12925/67600 (epoch 9), train_loss = 1.243, time/batch=0.276\n",
      "12926/67600 (epoch 9), train_loss = 1.221, time/batch=0.105\n",
      "12927/67600 (epoch 9), train_loss = 1.202, time/batch=0.130\n",
      "12928/67600 (epoch 9), train_loss = 1.225, time/batch=0.116\n",
      "12929/67600 (epoch 9), train_loss = 1.224, time/batch=0.117\n",
      "12930/67600 (epoch 9), train_loss = 1.229, time/batch=0.177\n",
      "12931/67600 (epoch 9), train_loss = 1.270, time/batch=0.127\n",
      "12932/67600 (epoch 9), train_loss = 1.278, time/batch=0.112\n",
      "12933/67600 (epoch 9), train_loss = 1.204, time/batch=0.127\n",
      "12934/67600 (epoch 9), train_loss = 1.243, time/batch=0.127\n",
      "12935/67600 (epoch 9), train_loss = 1.231, time/batch=0.119\n",
      "12936/67600 (epoch 9), train_loss = 1.261, time/batch=0.300\n",
      "12937/67600 (epoch 9), train_loss = 1.266, time/batch=0.123\n",
      "12938/67600 (epoch 9), train_loss = 1.214, time/batch=0.113\n",
      "12939/67600 (epoch 9), train_loss = 1.286, time/batch=0.120\n",
      "12940/67600 (epoch 9), train_loss = 1.253, time/batch=0.117\n",
      "12941/67600 (epoch 9), train_loss = 1.217, time/batch=0.117\n",
      "12942/67600 (epoch 9), train_loss = 1.268, time/batch=0.107\n",
      "12943/67600 (epoch 9), train_loss = 1.313, time/batch=0.128\n",
      "12944/67600 (epoch 9), train_loss = 1.274, time/batch=0.291\n",
      "12945/67600 (epoch 9), train_loss = 1.254, time/batch=0.105\n",
      "12946/67600 (epoch 9), train_loss = 1.234, time/batch=0.114\n",
      "12947/67600 (epoch 9), train_loss = 1.258, time/batch=0.132\n",
      "12948/67600 (epoch 9), train_loss = 1.293, time/batch=0.115\n",
      "12949/67600 (epoch 9), train_loss = 1.233, time/batch=0.112\n",
      "12950/67600 (epoch 9), train_loss = 1.219, time/batch=0.115\n",
      "12951/67600 (epoch 9), train_loss = 1.252, time/batch=0.250\n",
      "12952/67600 (epoch 9), train_loss = 1.227, time/batch=0.139\n",
      "12953/67600 (epoch 9), train_loss = 1.269, time/batch=0.135\n",
      "12954/67600 (epoch 9), train_loss = 1.242, time/batch=0.112\n",
      "12955/67600 (epoch 9), train_loss = 1.250, time/batch=0.123\n",
      "12956/67600 (epoch 9), train_loss = 1.256, time/batch=0.220\n",
      "12957/67600 (epoch 9), train_loss = 1.207, time/batch=0.165\n",
      "12958/67600 (epoch 9), train_loss = 1.233, time/batch=0.112\n",
      "12959/67600 (epoch 9), train_loss = 1.241, time/batch=0.137\n",
      "12960/67600 (epoch 9), train_loss = 1.215, time/batch=0.100\n",
      "12961/67600 (epoch 9), train_loss = 1.265, time/batch=0.131\n",
      "12962/67600 (epoch 9), train_loss = 1.235, time/batch=0.133\n",
      "12963/67600 (epoch 9), train_loss = 1.244, time/batch=0.218\n",
      "12964/67600 (epoch 9), train_loss = 1.303, time/batch=0.174\n",
      "12965/67600 (epoch 9), train_loss = 1.256, time/batch=0.115\n",
      "12966/67600 (epoch 9), train_loss = 1.282, time/batch=0.108\n",
      "12967/67600 (epoch 9), train_loss = 1.236, time/batch=0.139\n",
      "12968/67600 (epoch 9), train_loss = 1.251, time/batch=0.126\n",
      "12969/67600 (epoch 9), train_loss = 1.241, time/batch=0.125\n",
      "12970/67600 (epoch 9), train_loss = 1.222, time/batch=0.217\n",
      "12971/67600 (epoch 9), train_loss = 1.243, time/batch=0.154\n",
      "12972/67600 (epoch 9), train_loss = 1.217, time/batch=0.118\n",
      "12973/67600 (epoch 9), train_loss = 1.185, time/batch=0.126\n",
      "12974/67600 (epoch 9), train_loss = 1.252, time/batch=0.118\n",
      "12975/67600 (epoch 9), train_loss = 1.222, time/batch=0.111\n",
      "12976/67600 (epoch 9), train_loss = 1.159, time/batch=0.126\n",
      "12977/67600 (epoch 9), train_loss = 1.258, time/batch=0.258\n",
      "12978/67600 (epoch 9), train_loss = 1.191, time/batch=0.130\n",
      "12979/67600 (epoch 9), train_loss = 1.274, time/batch=0.116\n",
      "12980/67600 (epoch 9), train_loss = 1.256, time/batch=0.118\n",
      "12981/67600 (epoch 9), train_loss = 1.253, time/batch=0.122\n",
      "12982/67600 (epoch 9), train_loss = 1.279, time/batch=0.134\n",
      "12983/67600 (epoch 9), train_loss = 1.191, time/batch=0.120\n",
      "12984/67600 (epoch 9), train_loss = 1.281, time/batch=0.246\n",
      "12985/67600 (epoch 9), train_loss = 1.215, time/batch=0.133\n",
      "12986/67600 (epoch 9), train_loss = 1.208, time/batch=0.126\n",
      "12987/67600 (epoch 9), train_loss = 1.231, time/batch=0.098\n",
      "12988/67600 (epoch 9), train_loss = 1.161, time/batch=0.144\n",
      "12989/67600 (epoch 9), train_loss = 1.277, time/batch=0.226\n",
      "12990/67600 (epoch 9), train_loss = 1.242, time/batch=0.136\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12991/67600 (epoch 9), train_loss = 1.308, time/batch=0.134\n",
      "12992/67600 (epoch 9), train_loss = 1.253, time/batch=0.132\n",
      "12993/67600 (epoch 9), train_loss = 1.284, time/batch=0.136\n",
      "12994/67600 (epoch 9), train_loss = 1.379, time/batch=0.089\n",
      "12995/67600 (epoch 9), train_loss = 1.215, time/batch=0.126\n",
      "12996/67600 (epoch 9), train_loss = 1.245, time/batch=0.277\n",
      "12997/67600 (epoch 9), train_loss = 1.274, time/batch=0.164\n",
      "12998/67600 (epoch 9), train_loss = 1.321, time/batch=0.132\n",
      "12999/67600 (epoch 9), train_loss = 1.221, time/batch=0.106\n",
      "13000/67600 (epoch 9), train_loss = 1.235, time/batch=0.142\n",
      "model saved to ./save/model.ckpt\n",
      "13001/67600 (epoch 9), train_loss = 1.241, time/batch=0.071\n",
      "13002/67600 (epoch 9), train_loss = 1.206, time/batch=0.072\n",
      "13003/67600 (epoch 9), train_loss = 1.281, time/batch=0.103\n",
      "13004/67600 (epoch 9), train_loss = 1.134, time/batch=0.115\n",
      "13005/67600 (epoch 9), train_loss = 1.275, time/batch=0.207\n",
      "13006/67600 (epoch 9), train_loss = 1.180, time/batch=0.198\n",
      "13007/67600 (epoch 9), train_loss = 1.235, time/batch=0.120\n",
      "13008/67600 (epoch 9), train_loss = 1.293, time/batch=0.145\n",
      "13009/67600 (epoch 9), train_loss = 1.254, time/batch=0.104\n",
      "13010/67600 (epoch 9), train_loss = 1.248, time/batch=0.114\n",
      "13011/67600 (epoch 9), train_loss = 1.252, time/batch=0.134\n",
      "13012/67600 (epoch 9), train_loss = 1.242, time/batch=0.272\n",
      "13013/67600 (epoch 9), train_loss = 1.226, time/batch=0.125\n",
      "13014/67600 (epoch 9), train_loss = 1.220, time/batch=0.122\n",
      "13015/67600 (epoch 9), train_loss = 1.225, time/batch=0.116\n",
      "13016/67600 (epoch 9), train_loss = 1.255, time/batch=0.118\n",
      "13017/67600 (epoch 9), train_loss = 1.233, time/batch=0.224\n",
      "13018/67600 (epoch 9), train_loss = 1.235, time/batch=0.129\n",
      "13019/67600 (epoch 9), train_loss = 1.317, time/batch=0.164\n",
      "13020/67600 (epoch 9), train_loss = 1.318, time/batch=0.111\n",
      "13021/67600 (epoch 9), train_loss = 1.298, time/batch=0.117\n",
      "13022/67600 (epoch 9), train_loss = 1.236, time/batch=0.105\n",
      "13023/67600 (epoch 9), train_loss = 1.274, time/batch=0.141\n",
      "13024/67600 (epoch 9), train_loss = 1.244, time/batch=0.246\n",
      "13025/67600 (epoch 9), train_loss = 1.258, time/batch=0.134\n",
      "13026/67600 (epoch 9), train_loss = 1.281, time/batch=0.120\n",
      "13027/67600 (epoch 9), train_loss = 1.291, time/batch=0.127\n",
      "13028/67600 (epoch 9), train_loss = 1.251, time/batch=0.124\n",
      "13029/67600 (epoch 9), train_loss = 1.301, time/batch=0.123\n",
      "13030/67600 (epoch 9), train_loss = 1.323, time/batch=0.111\n",
      "13031/67600 (epoch 9), train_loss = 1.272, time/batch=0.220\n",
      "13032/67600 (epoch 9), train_loss = 1.206, time/batch=0.169\n",
      "13033/67600 (epoch 9), train_loss = 1.300, time/batch=0.123\n",
      "13034/67600 (epoch 9), train_loss = 1.284, time/batch=0.135\n",
      "13035/67600 (epoch 9), train_loss = 1.223, time/batch=0.111\n",
      "13036/67600 (epoch 9), train_loss = 1.249, time/batch=0.125\n",
      "13037/67600 (epoch 9), train_loss = 1.238, time/batch=0.128\n",
      "13038/67600 (epoch 9), train_loss = 1.250, time/batch=0.200\n",
      "13039/67600 (epoch 9), train_loss = 1.222, time/batch=0.168\n",
      "13040/67600 (epoch 9), train_loss = 1.282, time/batch=0.130\n",
      "13041/67600 (epoch 9), train_loss = 1.206, time/batch=0.133\n",
      "13042/67600 (epoch 9), train_loss = 1.251, time/batch=0.126\n",
      "13043/67600 (epoch 9), train_loss = 1.298, time/batch=0.122\n",
      "13044/67600 (epoch 9), train_loss = 1.278, time/batch=0.117\n",
      "13045/67600 (epoch 9), train_loss = 1.154, time/batch=0.130\n",
      "13046/67600 (epoch 9), train_loss = 1.243, time/batch=0.245\n",
      "13047/67600 (epoch 9), train_loss = 1.149, time/batch=0.112\n",
      "13048/67600 (epoch 9), train_loss = 1.205, time/batch=0.127\n",
      "13049/67600 (epoch 9), train_loss = 1.216, time/batch=0.126\n",
      "13050/67600 (epoch 9), train_loss = 1.220, time/batch=0.112\n",
      "13051/67600 (epoch 9), train_loss = 1.241, time/batch=0.236\n",
      "13052/67600 (epoch 9), train_loss = 1.218, time/batch=0.156\n",
      "13053/67600 (epoch 9), train_loss = 1.232, time/batch=0.132\n",
      "13054/67600 (epoch 9), train_loss = 1.214, time/batch=0.124\n",
      "13055/67600 (epoch 9), train_loss = 1.181, time/batch=0.122\n",
      "13056/67600 (epoch 9), train_loss = 1.298, time/batch=0.119\n",
      "13057/67600 (epoch 9), train_loss = 1.267, time/batch=0.261\n",
      "13058/67600 (epoch 9), train_loss = 1.296, time/batch=0.108\n",
      "13059/67600 (epoch 9), train_loss = 1.285, time/batch=0.150\n",
      "13060/67600 (epoch 9), train_loss = 1.260, time/batch=0.123\n",
      "13061/67600 (epoch 9), train_loss = 1.221, time/batch=0.144\n",
      "13062/67600 (epoch 9), train_loss = 1.266, time/batch=0.114\n",
      "13063/67600 (epoch 9), train_loss = 1.227, time/batch=0.125\n",
      "13064/67600 (epoch 9), train_loss = 1.241, time/batch=0.281\n",
      "13065/67600 (epoch 9), train_loss = 1.314, time/batch=0.148\n",
      "13066/67600 (epoch 9), train_loss = 1.272, time/batch=0.123\n",
      "13067/67600 (epoch 9), train_loss = 1.282, time/batch=0.133\n",
      "13068/67600 (epoch 9), train_loss = 1.254, time/batch=0.189\n",
      "13069/67600 (epoch 9), train_loss = 1.293, time/batch=0.119\n",
      "13070/67600 (epoch 9), train_loss = 1.293, time/batch=0.116\n",
      "13071/67600 (epoch 9), train_loss = 1.190, time/batch=0.275\n",
      "13072/67600 (epoch 9), train_loss = 1.226, time/batch=0.158\n",
      "13073/67600 (epoch 9), train_loss = 1.277, time/batch=0.130\n",
      "13074/67600 (epoch 9), train_loss = 1.233, time/batch=0.105\n",
      "13075/67600 (epoch 9), train_loss = 1.223, time/batch=0.143\n",
      "13076/67600 (epoch 9), train_loss = 1.297, time/batch=0.185\n",
      "13077/67600 (epoch 9), train_loss = 1.230, time/batch=0.303\n",
      "13078/67600 (epoch 9), train_loss = 1.232, time/batch=0.113\n",
      "13079/67600 (epoch 9), train_loss = 1.265, time/batch=0.141\n",
      "13080/67600 (epoch 9), train_loss = 1.231, time/batch=0.130\n",
      "13081/67600 (epoch 9), train_loss = 1.267, time/batch=0.236\n",
      "13082/67600 (epoch 9), train_loss = 1.284, time/batch=0.183\n",
      "13083/67600 (epoch 9), train_loss = 1.222, time/batch=0.105\n",
      "13084/67600 (epoch 9), train_loss = 1.240, time/batch=0.148\n",
      "13085/67600 (epoch 9), train_loss = 1.232, time/batch=0.148\n",
      "13086/67600 (epoch 9), train_loss = 1.253, time/batch=0.138\n",
      "13087/67600 (epoch 9), train_loss = 1.248, time/batch=0.096\n",
      "13088/67600 (epoch 9), train_loss = 1.265, time/batch=0.178\n",
      "13089/67600 (epoch 9), train_loss = 1.244, time/batch=0.123\n",
      "13090/67600 (epoch 9), train_loss = 1.267, time/batch=0.151\n",
      "13091/67600 (epoch 9), train_loss = 1.207, time/batch=0.123\n",
      "13092/67600 (epoch 9), train_loss = 1.201, time/batch=0.117\n",
      "13093/67600 (epoch 9), train_loss = 1.229, time/batch=0.320\n",
      "13094/67600 (epoch 9), train_loss = 1.219, time/batch=0.149\n",
      "13095/67600 (epoch 9), train_loss = 1.242, time/batch=0.134\n",
      "13096/67600 (epoch 9), train_loss = 1.212, time/batch=0.119\n",
      "13097/67600 (epoch 9), train_loss = 1.231, time/batch=0.103\n",
      "13098/67600 (epoch 9), train_loss = 1.196, time/batch=0.122\n",
      "13099/67600 (epoch 9), train_loss = 1.251, time/batch=0.353\n",
      "13100/67600 (epoch 9), train_loss = 1.220, time/batch=0.141\n",
      "13101/67600 (epoch 9), train_loss = 1.192, time/batch=0.132\n",
      "13102/67600 (epoch 9), train_loss = 1.217, time/batch=0.124\n",
      "13103/67600 (epoch 9), train_loss = 1.210, time/batch=0.133\n",
      "13104/67600 (epoch 9), train_loss = 1.267, time/batch=0.246\n",
      "13105/67600 (epoch 9), train_loss = 1.227, time/batch=0.177\n",
      "13106/67600 (epoch 9), train_loss = 1.222, time/batch=0.122\n",
      "13107/67600 (epoch 9), train_loss = 1.216, time/batch=0.172\n",
      "13108/67600 (epoch 9), train_loss = 1.240, time/batch=0.140\n",
      "13109/67600 (epoch 9), train_loss = 1.203, time/batch=0.121\n",
      "13110/67600 (epoch 9), train_loss = 1.175, time/batch=0.221\n",
      "13111/67600 (epoch 9), train_loss = 1.270, time/batch=0.184\n",
      "13112/67600 (epoch 9), train_loss = 1.226, time/batch=0.138\n",
      "13113/67600 (epoch 9), train_loss = 1.255, time/batch=0.109\n",
      "13114/67600 (epoch 9), train_loss = 1.212, time/batch=0.153\n",
      "13115/67600 (epoch 9), train_loss = 1.195, time/batch=0.101\n",
      "13116/67600 (epoch 9), train_loss = 1.248, time/batch=0.120\n",
      "13117/67600 (epoch 9), train_loss = 1.196, time/batch=0.256\n",
      "13118/67600 (epoch 9), train_loss = 1.259, time/batch=0.158\n",
      "13119/67600 (epoch 9), train_loss = 1.209, time/batch=0.100\n",
      "13120/67600 (epoch 9), train_loss = 1.262, time/batch=0.144\n",
      "13121/67600 (epoch 9), train_loss = 1.198, time/batch=0.117\n",
      "13122/67600 (epoch 9), train_loss = 1.174, time/batch=0.122\n",
      "13123/67600 (epoch 9), train_loss = 1.290, time/batch=0.116\n",
      "13124/67600 (epoch 9), train_loss = 1.258, time/batch=0.264\n",
      "13125/67600 (epoch 9), train_loss = 1.263, time/batch=0.136\n",
      "13126/67600 (epoch 9), train_loss = 1.199, time/batch=0.128\n",
      "13127/67600 (epoch 9), train_loss = 1.213, time/batch=0.124\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13128/67600 (epoch 9), train_loss = 1.202, time/batch=0.134\n",
      "13129/67600 (epoch 9), train_loss = 1.158, time/batch=0.096\n",
      "13130/67600 (epoch 9), train_loss = 1.178, time/batch=0.145\n",
      "13131/67600 (epoch 9), train_loss = 1.160, time/batch=0.253\n",
      "13132/67600 (epoch 9), train_loss = 1.165, time/batch=0.132\n",
      "13133/67600 (epoch 9), train_loss = 1.244, time/batch=0.116\n",
      "13134/67600 (epoch 9), train_loss = 1.241, time/batch=0.118\n",
      "13135/67600 (epoch 9), train_loss = 1.179, time/batch=0.121\n",
      "13136/67600 (epoch 9), train_loss = 1.202, time/batch=0.123\n",
      "13137/67600 (epoch 9), train_loss = 1.196, time/batch=0.113\n",
      "13138/67600 (epoch 9), train_loss = 1.224, time/batch=0.273\n",
      "13139/67600 (epoch 9), train_loss = 1.238, time/batch=0.121\n",
      "13140/67600 (epoch 9), train_loss = 1.178, time/batch=0.115\n",
      "13141/67600 (epoch 9), train_loss = 1.247, time/batch=0.104\n",
      "13142/67600 (epoch 9), train_loss = 1.274, time/batch=0.138\n",
      "13143/67600 (epoch 9), train_loss = 1.164, time/batch=0.214\n",
      "13144/67600 (epoch 9), train_loss = 1.166, time/batch=0.166\n",
      "13145/67600 (epoch 9), train_loss = 1.199, time/batch=0.131\n",
      "13146/67600 (epoch 9), train_loss = 1.243, time/batch=0.134\n",
      "13147/67600 (epoch 9), train_loss = 1.218, time/batch=0.135\n",
      "13148/67600 (epoch 9), train_loss = 1.239, time/batch=0.119\n",
      "13149/67600 (epoch 9), train_loss = 1.191, time/batch=0.133\n",
      "13150/67600 (epoch 9), train_loss = 1.212, time/batch=0.224\n",
      "13151/67600 (epoch 9), train_loss = 1.254, time/batch=0.148\n",
      "13152/67600 (epoch 9), train_loss = 1.209, time/batch=0.126\n",
      "13153/67600 (epoch 9), train_loss = 1.295, time/batch=0.131\n",
      "13154/67600 (epoch 9), train_loss = 1.231, time/batch=0.120\n",
      "13155/67600 (epoch 9), train_loss = 1.301, time/batch=0.117\n",
      "13156/67600 (epoch 9), train_loss = 1.196, time/batch=0.103\n",
      "13157/67600 (epoch 9), train_loss = 1.225, time/batch=0.245\n",
      "13158/67600 (epoch 9), train_loss = 1.254, time/batch=0.117\n",
      "13159/67600 (epoch 9), train_loss = 1.220, time/batch=0.154\n",
      "13160/67600 (epoch 9), train_loss = 1.272, time/batch=0.110\n",
      "13161/67600 (epoch 9), train_loss = 1.224, time/batch=0.121\n",
      "13162/67600 (epoch 9), train_loss = 1.211, time/batch=0.108\n",
      "13163/67600 (epoch 9), train_loss = 1.226, time/batch=0.115\n",
      "13164/67600 (epoch 9), train_loss = 1.228, time/batch=0.251\n",
      "13165/67600 (epoch 9), train_loss = 1.247, time/batch=0.126\n",
      "13166/67600 (epoch 9), train_loss = 1.191, time/batch=0.121\n",
      "13167/67600 (epoch 9), train_loss = 1.209, time/batch=0.110\n",
      "13168/67600 (epoch 9), train_loss = 1.222, time/batch=0.117\n",
      "13169/67600 (epoch 9), train_loss = 1.239, time/batch=0.126\n",
      "13170/67600 (epoch 9), train_loss = 1.210, time/batch=0.116\n",
      "13171/67600 (epoch 9), train_loss = 1.230, time/batch=0.177\n",
      "13172/67600 (epoch 9), train_loss = 1.176, time/batch=0.211\n",
      "13173/67600 (epoch 9), train_loss = 1.245, time/batch=0.123\n",
      "13174/67600 (epoch 9), train_loss = 1.225, time/batch=0.147\n",
      "13175/67600 (epoch 9), train_loss = 1.195, time/batch=0.185\n",
      "13176/67600 (epoch 9), train_loss = 1.230, time/batch=0.231\n",
      "13177/67600 (epoch 9), train_loss = 1.186, time/batch=0.186\n",
      "13178/67600 (epoch 9), train_loss = 1.205, time/batch=0.121\n",
      "13179/67600 (epoch 9), train_loss = 1.199, time/batch=0.118\n",
      "13180/67600 (epoch 9), train_loss = 1.163, time/batch=0.118\n",
      "13181/67600 (epoch 9), train_loss = 1.207, time/batch=0.156\n",
      "13182/67600 (epoch 9), train_loss = 1.205, time/batch=0.145\n",
      "13183/67600 (epoch 9), train_loss = 1.218, time/batch=0.148\n",
      "13184/67600 (epoch 9), train_loss = 1.196, time/batch=0.130\n",
      "13185/67600 (epoch 9), train_loss = 1.246, time/batch=0.114\n",
      "13186/67600 (epoch 9), train_loss = 1.220, time/batch=0.123\n",
      "13187/67600 (epoch 9), train_loss = 1.233, time/batch=0.123\n",
      "13188/67600 (epoch 9), train_loss = 1.210, time/batch=0.321\n",
      "13189/67600 (epoch 9), train_loss = 1.217, time/batch=0.125\n",
      "13190/67600 (epoch 9), train_loss = 1.215, time/batch=0.125\n",
      "13191/67600 (epoch 9), train_loss = 1.215, time/batch=0.127\n",
      "13192/67600 (epoch 9), train_loss = 1.213, time/batch=0.116\n",
      "13193/67600 (epoch 9), train_loss = 1.171, time/batch=0.120\n",
      "13194/67600 (epoch 9), train_loss = 1.258, time/batch=0.127\n",
      "13195/67600 (epoch 9), train_loss = 1.175, time/batch=0.272\n",
      "13196/67600 (epoch 9), train_loss = 1.269, time/batch=0.109\n",
      "13197/67600 (epoch 9), train_loss = 1.233, time/batch=0.132\n",
      "13198/67600 (epoch 9), train_loss = 1.265, time/batch=0.120\n",
      "13199/67600 (epoch 9), train_loss = 1.272, time/batch=0.122\n",
      "13200/67600 (epoch 9), train_loss = 1.234, time/batch=0.132\n",
      "13201/67600 (epoch 9), train_loss = 1.206, time/batch=0.117\n",
      "13202/67600 (epoch 9), train_loss = 1.230, time/batch=0.273\n",
      "13203/67600 (epoch 9), train_loss = 1.203, time/batch=0.102\n",
      "13204/67600 (epoch 9), train_loss = 1.196, time/batch=0.126\n",
      "13205/67600 (epoch 9), train_loss = 1.188, time/batch=0.143\n",
      "13206/67600 (epoch 9), train_loss = 1.231, time/batch=0.129\n",
      "13207/67600 (epoch 9), train_loss = 1.215, time/batch=0.251\n",
      "13208/67600 (epoch 9), train_loss = 1.231, time/batch=0.147\n",
      "13209/67600 (epoch 9), train_loss = 1.227, time/batch=0.133\n",
      "13210/67600 (epoch 9), train_loss = 1.259, time/batch=0.125\n",
      "13211/67600 (epoch 9), train_loss = 1.125, time/batch=0.138\n",
      "13212/67600 (epoch 9), train_loss = 1.215, time/batch=0.125\n",
      "13213/67600 (epoch 9), train_loss = 1.215, time/batch=0.216\n",
      "13214/67600 (epoch 9), train_loss = 1.226, time/batch=0.221\n",
      "13215/67600 (epoch 9), train_loss = 1.285, time/batch=0.113\n",
      "13216/67600 (epoch 9), train_loss = 1.259, time/batch=0.132\n",
      "13217/67600 (epoch 9), train_loss = 1.242, time/batch=0.130\n",
      "13218/67600 (epoch 9), train_loss = 1.226, time/batch=0.132\n",
      "13219/67600 (epoch 9), train_loss = 1.197, time/batch=0.117\n",
      "13220/67600 (epoch 9), train_loss = 1.242, time/batch=0.253\n",
      "13221/67600 (epoch 9), train_loss = 1.229, time/batch=0.147\n",
      "13222/67600 (epoch 9), train_loss = 1.247, time/batch=0.121\n",
      "13223/67600 (epoch 9), train_loss = 1.228, time/batch=0.148\n",
      "13224/67600 (epoch 9), train_loss = 1.152, time/batch=0.130\n",
      "13225/67600 (epoch 9), train_loss = 1.269, time/batch=0.107\n",
      "13226/67600 (epoch 9), train_loss = 1.303, time/batch=0.132\n",
      "13227/67600 (epoch 9), train_loss = 1.219, time/batch=0.322\n",
      "13228/67600 (epoch 9), train_loss = 1.244, time/batch=0.112\n",
      "13229/67600 (epoch 9), train_loss = 1.252, time/batch=0.132\n",
      "13230/67600 (epoch 9), train_loss = 1.232, time/batch=0.118\n",
      "13231/67600 (epoch 9), train_loss = 1.192, time/batch=0.103\n",
      "13232/67600 (epoch 9), train_loss = 1.237, time/batch=0.126\n",
      "13233/67600 (epoch 9), train_loss = 1.230, time/batch=0.107\n",
      "13234/67600 (epoch 9), train_loss = 1.229, time/batch=0.255\n",
      "13235/67600 (epoch 9), train_loss = 1.269, time/batch=0.122\n",
      "13236/67600 (epoch 9), train_loss = 1.194, time/batch=0.120\n",
      "13237/67600 (epoch 9), train_loss = 1.242, time/batch=0.132\n",
      "13238/67600 (epoch 9), train_loss = 1.265, time/batch=0.104\n",
      "13239/67600 (epoch 9), train_loss = 1.287, time/batch=0.230\n",
      "13240/67600 (epoch 9), train_loss = 1.231, time/batch=0.160\n",
      "13241/67600 (epoch 9), train_loss = 1.217, time/batch=0.139\n",
      "13242/67600 (epoch 9), train_loss = 1.196, time/batch=0.119\n",
      "13243/67600 (epoch 9), train_loss = 1.224, time/batch=0.116\n",
      "13244/67600 (epoch 9), train_loss = 1.278, time/batch=0.128\n",
      "13245/67600 (epoch 9), train_loss = 1.271, time/batch=0.106\n",
      "13246/67600 (epoch 9), train_loss = 1.275, time/batch=0.235\n",
      "13247/67600 (epoch 9), train_loss = 1.265, time/batch=0.164\n",
      "13248/67600 (epoch 9), train_loss = 1.282, time/batch=0.121\n",
      "13249/67600 (epoch 9), train_loss = 1.202, time/batch=0.138\n",
      "13250/67600 (epoch 9), train_loss = 1.263, time/batch=0.111\n",
      "13251/67600 (epoch 9), train_loss = 1.201, time/batch=0.133\n",
      "13252/67600 (epoch 9), train_loss = 1.188, time/batch=0.116\n",
      "13253/67600 (epoch 9), train_loss = 1.306, time/batch=0.243\n",
      "13254/67600 (epoch 9), train_loss = 1.268, time/batch=0.164\n",
      "13255/67600 (epoch 9), train_loss = 1.175, time/batch=0.106\n",
      "13256/67600 (epoch 9), train_loss = 1.212, time/batch=0.127\n",
      "13257/67600 (epoch 9), train_loss = 1.202, time/batch=0.120\n",
      "13258/67600 (epoch 9), train_loss = 1.251, time/batch=0.105\n",
      "13259/67600 (epoch 9), train_loss = 1.214, time/batch=0.153\n",
      "13260/67600 (epoch 9), train_loss = 1.274, time/batch=0.236\n",
      "13261/67600 (epoch 9), train_loss = 1.223, time/batch=0.130\n",
      "13262/67600 (epoch 9), train_loss = 1.228, time/batch=0.130\n",
      "13263/67600 (epoch 9), train_loss = 1.197, time/batch=0.114\n",
      "13264/67600 (epoch 9), train_loss = 1.233, time/batch=0.140\n",
      "13265/67600 (epoch 9), train_loss = 1.226, time/batch=0.113\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13266/67600 (epoch 9), train_loss = 1.201, time/batch=0.135\n",
      "13267/67600 (epoch 9), train_loss = 1.169, time/batch=0.253\n",
      "13268/67600 (epoch 9), train_loss = 1.238, time/batch=0.120\n",
      "13269/67600 (epoch 9), train_loss = 1.222, time/batch=0.154\n",
      "13270/67600 (epoch 9), train_loss = 1.212, time/batch=0.132\n",
      "13271/67600 (epoch 9), train_loss = 1.186, time/batch=0.132\n",
      "13272/67600 (epoch 9), train_loss = 1.304, time/batch=0.108\n",
      "13273/67600 (epoch 9), train_loss = 1.208, time/batch=0.177\n",
      "13274/67600 (epoch 9), train_loss = 1.221, time/batch=0.224\n",
      "13275/67600 (epoch 9), train_loss = 1.256, time/batch=0.114\n",
      "13276/67600 (epoch 9), train_loss = 1.207, time/batch=0.129\n",
      "13277/67600 (epoch 9), train_loss = 1.236, time/batch=0.116\n",
      "13278/67600 (epoch 9), train_loss = 1.255, time/batch=0.173\n",
      "13279/67600 (epoch 9), train_loss = 1.228, time/batch=0.125\n",
      "13280/67600 (epoch 9), train_loss = 1.282, time/batch=0.134\n",
      "13281/67600 (epoch 9), train_loss = 1.283, time/batch=0.145\n",
      "13282/67600 (epoch 9), train_loss = 1.258, time/batch=0.113\n",
      "13283/67600 (epoch 9), train_loss = 1.327, time/batch=0.133\n",
      "13284/67600 (epoch 9), train_loss = 1.225, time/batch=0.321\n",
      "13285/67600 (epoch 9), train_loss = 1.258, time/batch=0.158\n",
      "13286/67600 (epoch 9), train_loss = 1.234, time/batch=0.152\n",
      "13287/67600 (epoch 9), train_loss = 1.330, time/batch=0.183\n",
      "13288/67600 (epoch 9), train_loss = 1.211, time/batch=0.121\n",
      "13289/67600 (epoch 9), train_loss = 1.273, time/batch=0.143\n",
      "13290/67600 (epoch 9), train_loss = 1.328, time/batch=0.288\n",
      "13291/67600 (epoch 9), train_loss = 1.254, time/batch=0.112\n",
      "13292/67600 (epoch 9), train_loss = 1.227, time/batch=0.119\n",
      "13293/67600 (epoch 9), train_loss = 1.232, time/batch=0.127\n",
      "13294/67600 (epoch 9), train_loss = 1.293, time/batch=0.133\n",
      "13295/67600 (epoch 9), train_loss = 1.235, time/batch=0.118\n",
      "13296/67600 (epoch 9), train_loss = 1.258, time/batch=0.125\n",
      "13297/67600 (epoch 9), train_loss = 1.253, time/batch=0.282\n",
      "13298/67600 (epoch 9), train_loss = 1.250, time/batch=0.171\n",
      "13299/67600 (epoch 9), train_loss = 1.262, time/batch=0.127\n",
      "13300/67600 (epoch 9), train_loss = 1.224, time/batch=0.133\n",
      "13301/67600 (epoch 9), train_loss = 1.282, time/batch=0.248\n",
      "13302/67600 (epoch 9), train_loss = 1.316, time/batch=0.165\n",
      "13303/67600 (epoch 9), train_loss = 1.306, time/batch=0.111\n",
      "13304/67600 (epoch 9), train_loss = 1.282, time/batch=0.127\n",
      "13305/67600 (epoch 9), train_loss = 1.250, time/batch=0.108\n",
      "13306/67600 (epoch 9), train_loss = 1.248, time/batch=0.131\n",
      "13307/67600 (epoch 9), train_loss = 1.290, time/batch=0.120\n",
      "13308/67600 (epoch 9), train_loss = 1.241, time/batch=0.237\n",
      "13309/67600 (epoch 9), train_loss = 1.236, time/batch=0.160\n",
      "13310/67600 (epoch 9), train_loss = 1.274, time/batch=0.108\n",
      "13311/67600 (epoch 9), train_loss = 1.274, time/batch=0.139\n",
      "13312/67600 (epoch 9), train_loss = 1.260, time/batch=0.110\n",
      "13313/67600 (epoch 9), train_loss = 1.212, time/batch=0.115\n",
      "13314/67600 (epoch 9), train_loss = 1.209, time/batch=0.128\n",
      "13315/67600 (epoch 9), train_loss = 1.197, time/batch=0.437\n",
      "13316/67600 (epoch 9), train_loss = 1.205, time/batch=0.141\n",
      "13317/67600 (epoch 9), train_loss = 1.222, time/batch=0.125\n",
      "13318/67600 (epoch 9), train_loss = 1.175, time/batch=0.152\n",
      "13319/67600 (epoch 9), train_loss = 1.268, time/batch=0.341\n",
      "13320/67600 (epoch 9), train_loss = 1.237, time/batch=0.151\n",
      "13321/67600 (epoch 9), train_loss = 1.210, time/batch=0.124\n",
      "13322/67600 (epoch 9), train_loss = 1.241, time/batch=0.142\n",
      "13323/67600 (epoch 9), train_loss = 1.221, time/batch=0.140\n",
      "13324/67600 (epoch 9), train_loss = 1.218, time/batch=0.128\n",
      "13325/67600 (epoch 9), train_loss = 1.174, time/batch=0.322\n",
      "13326/67600 (epoch 9), train_loss = 1.271, time/batch=0.141\n",
      "13327/67600 (epoch 9), train_loss = 1.266, time/batch=0.108\n",
      "13328/67600 (epoch 9), train_loss = 1.192, time/batch=0.142\n",
      "13329/67600 (epoch 9), train_loss = 1.203, time/batch=0.134\n",
      "13330/67600 (epoch 9), train_loss = 1.224, time/batch=0.263\n",
      "13331/67600 (epoch 9), train_loss = 1.183, time/batch=0.167\n",
      "13332/67600 (epoch 9), train_loss = 1.243, time/batch=0.121\n",
      "13333/67600 (epoch 9), train_loss = 1.195, time/batch=0.128\n",
      "13334/67600 (epoch 9), train_loss = 1.205, time/batch=0.187\n",
      "13335/67600 (epoch 9), train_loss = 1.234, time/batch=0.167\n",
      "13336/67600 (epoch 9), train_loss = 1.239, time/batch=0.233\n",
      "13337/67600 (epoch 9), train_loss = 1.159, time/batch=0.160\n",
      "13338/67600 (epoch 9), train_loss = 1.195, time/batch=0.152\n",
      "13339/67600 (epoch 9), train_loss = 1.196, time/batch=0.116\n",
      "13340/67600 (epoch 9), train_loss = 1.223, time/batch=0.096\n",
      "13341/67600 (epoch 9), train_loss = 1.227, time/batch=0.096\n",
      "13342/67600 (epoch 9), train_loss = 1.221, time/batch=0.101\n",
      "13343/67600 (epoch 9), train_loss = 1.223, time/batch=0.259\n",
      "13344/67600 (epoch 9), train_loss = 1.232, time/batch=0.121\n",
      "13345/67600 (epoch 9), train_loss = 1.232, time/batch=0.112\n",
      "13346/67600 (epoch 9), train_loss = 1.262, time/batch=0.095\n",
      "13347/67600 (epoch 9), train_loss = 1.339, time/batch=0.128\n",
      "13348/67600 (epoch 9), train_loss = 1.295, time/batch=0.113\n",
      "13349/67600 (epoch 9), train_loss = 1.249, time/batch=0.105\n",
      "13350/67600 (epoch 9), train_loss = 1.240, time/batch=0.133\n",
      "13351/67600 (epoch 9), train_loss = 1.228, time/batch=0.245\n",
      "13352/67600 (epoch 9), train_loss = 1.255, time/batch=0.105\n",
      "13353/67600 (epoch 9), train_loss = 1.159, time/batch=0.124\n",
      "13354/67600 (epoch 9), train_loss = 1.190, time/batch=0.111\n",
      "13355/67600 (epoch 9), train_loss = 1.278, time/batch=0.086\n",
      "13356/67600 (epoch 9), train_loss = 1.225, time/batch=0.091\n",
      "13357/67600 (epoch 9), train_loss = 1.195, time/batch=0.092\n",
      "13358/67600 (epoch 9), train_loss = 1.234, time/batch=0.090\n",
      "13359/67600 (epoch 9), train_loss = 1.210, time/batch=0.197\n",
      "13360/67600 (epoch 9), train_loss = 1.225, time/batch=0.207\n",
      "13361/67600 (epoch 9), train_loss = 1.222, time/batch=0.103\n",
      "13362/67600 (epoch 9), train_loss = 1.183, time/batch=0.099\n",
      "13363/67600 (epoch 9), train_loss = 1.209, time/batch=0.088\n",
      "13364/67600 (epoch 9), train_loss = 1.244, time/batch=0.093\n",
      "13365/67600 (epoch 9), train_loss = 1.253, time/batch=0.209\n",
      "13366/67600 (epoch 9), train_loss = 1.260, time/batch=0.188\n",
      "13367/67600 (epoch 9), train_loss = 1.214, time/batch=0.102\n",
      "13368/67600 (epoch 9), train_loss = 1.247, time/batch=0.122\n",
      "13369/67600 (epoch 9), train_loss = 1.209, time/batch=0.095\n",
      "13370/67600 (epoch 9), train_loss = 1.194, time/batch=0.098\n",
      "13371/67600 (epoch 9), train_loss = 1.198, time/batch=0.091\n",
      "13372/67600 (epoch 9), train_loss = 1.308, time/batch=0.094\n",
      "13373/67600 (epoch 9), train_loss = 1.229, time/batch=0.154\n",
      "13374/67600 (epoch 9), train_loss = 1.192, time/batch=0.101\n",
      "13375/67600 (epoch 9), train_loss = 1.243, time/batch=0.104\n",
      "13376/67600 (epoch 9), train_loss = 1.196, time/batch=0.122\n",
      "13377/67600 (epoch 9), train_loss = 1.195, time/batch=0.079\n",
      "13378/67600 (epoch 9), train_loss = 1.246, time/batch=0.071\n",
      "13379/67600 (epoch 9), train_loss = 1.204, time/batch=0.102\n",
      "13380/67600 (epoch 9), train_loss = 1.194, time/batch=0.308\n",
      "13381/67600 (epoch 9), train_loss = 1.233, time/batch=0.104\n",
      "13382/67600 (epoch 9), train_loss = 1.254, time/batch=0.077\n",
      "13383/67600 (epoch 9), train_loss = 1.214, time/batch=0.076\n",
      "13384/67600 (epoch 9), train_loss = 1.240, time/batch=0.078\n",
      "13385/67600 (epoch 9), train_loss = 1.231, time/batch=0.077\n",
      "13386/67600 (epoch 9), train_loss = 1.224, time/batch=0.083\n",
      "13387/67600 (epoch 9), train_loss = 1.230, time/batch=0.079\n",
      "13388/67600 (epoch 9), train_loss = 1.213, time/batch=0.078\n",
      "13389/67600 (epoch 9), train_loss = 1.209, time/batch=0.079\n",
      "13390/67600 (epoch 9), train_loss = 1.255, time/batch=0.094\n",
      "13391/67600 (epoch 9), train_loss = 1.213, time/batch=0.221\n",
      "13392/67600 (epoch 9), train_loss = 1.268, time/batch=0.085\n",
      "13393/67600 (epoch 9), train_loss = 1.259, time/batch=0.078\n",
      "13394/67600 (epoch 9), train_loss = 1.264, time/batch=0.087\n",
      "13395/67600 (epoch 9), train_loss = 1.234, time/batch=0.090\n",
      "13396/67600 (epoch 9), train_loss = 1.279, time/batch=0.087\n",
      "13397/67600 (epoch 9), train_loss = 1.214, time/batch=0.075\n",
      "13398/67600 (epoch 9), train_loss = 1.247, time/batch=0.075\n",
      "13399/67600 (epoch 9), train_loss = 1.246, time/batch=0.073\n",
      "13400/67600 (epoch 9), train_loss = 1.327, time/batch=0.074\n",
      "13401/67600 (epoch 9), train_loss = 1.286, time/batch=0.235\n",
      "13402/67600 (epoch 9), train_loss = 1.188, time/batch=0.089\n",
      "13403/67600 (epoch 9), train_loss = 1.226, time/batch=0.089\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13404/67600 (epoch 9), train_loss = 1.223, time/batch=0.080\n",
      "13405/67600 (epoch 9), train_loss = 1.254, time/batch=0.075\n",
      "13406/67600 (epoch 9), train_loss = 1.218, time/batch=0.079\n",
      "13407/67600 (epoch 9), train_loss = 1.212, time/batch=0.092\n",
      "13408/67600 (epoch 9), train_loss = 1.280, time/batch=0.184\n",
      "13409/67600 (epoch 9), train_loss = 1.221, time/batch=0.088\n",
      "13410/67600 (epoch 9), train_loss = 1.226, time/batch=0.117\n",
      "13411/67600 (epoch 9), train_loss = 1.257, time/batch=0.077\n",
      "13412/67600 (epoch 9), train_loss = 1.327, time/batch=0.079\n",
      "13413/67600 (epoch 9), train_loss = 1.247, time/batch=0.083\n",
      "13414/67600 (epoch 9), train_loss = 1.227, time/batch=0.076\n",
      "13415/67600 (epoch 9), train_loss = 1.222, time/batch=0.083\n",
      "13416/67600 (epoch 9), train_loss = 1.253, time/batch=0.079\n",
      "13417/67600 (epoch 9), train_loss = 1.221, time/batch=0.083\n",
      "13418/67600 (epoch 9), train_loss = 1.193, time/batch=0.090\n",
      "13419/67600 (epoch 9), train_loss = 1.294, time/batch=0.212\n",
      "13420/67600 (epoch 9), train_loss = 1.195, time/batch=0.169\n",
      "13421/67600 (epoch 9), train_loss = 1.290, time/batch=0.076\n",
      "13422/67600 (epoch 9), train_loss = 1.253, time/batch=0.075\n",
      "13423/67600 (epoch 9), train_loss = 1.269, time/batch=0.091\n",
      "13424/67600 (epoch 9), train_loss = 1.264, time/batch=0.080\n",
      "13425/67600 (epoch 9), train_loss = 1.260, time/batch=0.100\n",
      "13426/67600 (epoch 9), train_loss = 1.300, time/batch=0.106\n",
      "13427/67600 (epoch 9), train_loss = 1.241, time/batch=0.076\n",
      "13428/67600 (epoch 9), train_loss = 1.250, time/batch=0.211\n",
      "13429/67600 (epoch 9), train_loss = 1.210, time/batch=0.118\n",
      "13430/67600 (epoch 9), train_loss = 1.309, time/batch=0.089\n",
      "13431/67600 (epoch 9), train_loss = 1.303, time/batch=0.094\n",
      "13432/67600 (epoch 9), train_loss = 1.281, time/batch=0.118\n",
      "13433/67600 (epoch 9), train_loss = 1.231, time/batch=0.074\n",
      "13434/67600 (epoch 9), train_loss = 1.298, time/batch=0.077\n",
      "13435/67600 (epoch 9), train_loss = 1.206, time/batch=0.086\n",
      "13436/67600 (epoch 9), train_loss = 1.183, time/batch=0.086\n",
      "13437/67600 (epoch 9), train_loss = 1.242, time/batch=0.071\n",
      "13438/67600 (epoch 9), train_loss = 1.233, time/batch=0.215\n",
      "13439/67600 (epoch 9), train_loss = 1.183, time/batch=0.113\n",
      "13440/67600 (epoch 9), train_loss = 1.236, time/batch=0.081\n",
      "13441/67600 (epoch 9), train_loss = 1.227, time/batch=0.091\n",
      "13442/67600 (epoch 9), train_loss = 1.219, time/batch=0.080\n",
      "13443/67600 (epoch 9), train_loss = 1.260, time/batch=0.079\n",
      "13444/67600 (epoch 9), train_loss = 1.266, time/batch=0.088\n",
      "13445/67600 (epoch 9), train_loss = 1.252, time/batch=0.085\n",
      "13446/67600 (epoch 9), train_loss = 1.175, time/batch=0.083\n",
      "13447/67600 (epoch 9), train_loss = 1.185, time/batch=0.088\n",
      "13448/67600 (epoch 9), train_loss = 1.205, time/batch=0.240\n",
      "13449/67600 (epoch 9), train_loss = 1.241, time/batch=0.089\n",
      "13450/67600 (epoch 9), train_loss = 1.185, time/batch=0.074\n",
      "13451/67600 (epoch 9), train_loss = 1.239, time/batch=0.076\n",
      "13452/67600 (epoch 9), train_loss = 1.266, time/batch=0.083\n",
      "13453/67600 (epoch 9), train_loss = 1.226, time/batch=0.078\n",
      "13454/67600 (epoch 9), train_loss = 1.208, time/batch=0.084\n",
      "13455/67600 (epoch 9), train_loss = 1.286, time/batch=0.192\n",
      "13456/67600 (epoch 9), train_loss = 1.212, time/batch=0.099\n",
      "13457/67600 (epoch 9), train_loss = 1.272, time/batch=0.110\n",
      "13458/67600 (epoch 9), train_loss = 1.295, time/batch=0.075\n",
      "13459/67600 (epoch 9), train_loss = 1.264, time/batch=0.085\n",
      "13460/67600 (epoch 9), train_loss = 1.219, time/batch=0.074\n",
      "13461/67600 (epoch 9), train_loss = 1.220, time/batch=0.074\n",
      "13462/67600 (epoch 9), train_loss = 1.233, time/batch=0.078\n",
      "13463/67600 (epoch 9), train_loss = 1.235, time/batch=0.080\n",
      "13464/67600 (epoch 9), train_loss = 1.239, time/batch=0.075\n",
      "13465/67600 (epoch 9), train_loss = 1.253, time/batch=0.080\n",
      "13466/67600 (epoch 9), train_loss = 1.192, time/batch=0.208\n",
      "13467/67600 (epoch 9), train_loss = 1.259, time/batch=0.122\n",
      "13468/67600 (epoch 9), train_loss = 1.286, time/batch=0.075\n",
      "13469/67600 (epoch 9), train_loss = 1.232, time/batch=0.074\n",
      "13470/67600 (epoch 9), train_loss = 1.206, time/batch=0.073\n",
      "13471/67600 (epoch 9), train_loss = 1.232, time/batch=0.081\n",
      "13472/67600 (epoch 9), train_loss = 1.256, time/batch=0.084\n",
      "13473/67600 (epoch 9), train_loss = 1.184, time/batch=0.087\n",
      "13474/67600 (epoch 9), train_loss = 1.262, time/batch=0.083\n",
      "13475/67600 (epoch 9), train_loss = 1.247, time/batch=0.079\n",
      "13476/67600 (epoch 9), train_loss = 1.251, time/batch=0.199\n",
      "13477/67600 (epoch 9), train_loss = 1.240, time/batch=0.081\n",
      "13478/67600 (epoch 9), train_loss = 1.212, time/batch=0.112\n",
      "13479/67600 (epoch 9), train_loss = 1.224, time/batch=0.080\n",
      "13480/67600 (epoch 9), train_loss = 1.229, time/batch=0.120\n",
      "13481/67600 (epoch 9), train_loss = 1.296, time/batch=0.107\n",
      "13482/67600 (epoch 9), train_loss = 1.298, time/batch=0.087\n",
      "13483/67600 (epoch 9), train_loss = 1.249, time/batch=0.072\n",
      "13484/67600 (epoch 9), train_loss = 1.255, time/batch=0.071\n",
      "13485/67600 (epoch 9), train_loss = 1.275, time/batch=0.073\n",
      "13486/67600 (epoch 9), train_loss = 1.245, time/batch=0.294\n",
      "13487/67600 (epoch 9), train_loss = 1.219, time/batch=0.108\n",
      "13488/67600 (epoch 9), train_loss = 1.235, time/batch=0.097\n",
      "13489/67600 (epoch 9), train_loss = 1.231, time/batch=0.085\n",
      "13490/67600 (epoch 9), train_loss = 1.213, time/batch=0.084\n",
      "13491/67600 (epoch 9), train_loss = 1.233, time/batch=0.079\n",
      "13492/67600 (epoch 9), train_loss = 1.286, time/batch=0.071\n",
      "13493/67600 (epoch 9), train_loss = 1.231, time/batch=0.073\n",
      "13494/67600 (epoch 9), train_loss = 1.240, time/batch=0.076\n",
      "13495/67600 (epoch 9), train_loss = 1.226, time/batch=0.144\n",
      "13496/67600 (epoch 9), train_loss = 1.231, time/batch=0.234\n",
      "13497/67600 (epoch 9), train_loss = 1.253, time/batch=0.080\n",
      "13498/67600 (epoch 9), train_loss = 1.290, time/batch=0.073\n",
      "13499/67600 (epoch 9), train_loss = 1.289, time/batch=0.073\n",
      "13500/67600 (epoch 9), train_loss = 1.234, time/batch=0.067\n",
      "model saved to ./save/model.ckpt\n",
      "13501/67600 (epoch 9), train_loss = 1.225, time/batch=0.075\n",
      "13502/67600 (epoch 9), train_loss = 1.194, time/batch=0.074\n",
      "13503/67600 (epoch 9), train_loss = 1.261, time/batch=0.087\n",
      "13504/67600 (epoch 9), train_loss = 1.266, time/batch=0.093\n",
      "13505/67600 (epoch 9), train_loss = 1.240, time/batch=0.109\n",
      "13506/67600 (epoch 9), train_loss = 1.266, time/batch=0.219\n",
      "13507/67600 (epoch 9), train_loss = 1.234, time/batch=0.098\n",
      "13508/67600 (epoch 9), train_loss = 1.210, time/batch=0.086\n",
      "13509/67600 (epoch 9), train_loss = 1.238, time/batch=0.089\n",
      "13510/67600 (epoch 9), train_loss = 1.251, time/batch=0.087\n",
      "13511/67600 (epoch 9), train_loss = 1.228, time/batch=0.086\n",
      "13512/67600 (epoch 9), train_loss = 1.189, time/batch=0.089\n",
      "13513/67600 (epoch 9), train_loss = 1.235, time/batch=0.083\n",
      "13514/67600 (epoch 9), train_loss = 1.212, time/batch=0.089\n",
      "13515/67600 (epoch 9), train_loss = 1.237, time/batch=0.191\n",
      "13516/67600 (epoch 9), train_loss = 1.302, time/batch=0.119\n",
      "13517/67600 (epoch 9), train_loss = 1.335, time/batch=0.092\n",
      "13518/67600 (epoch 9), train_loss = 1.254, time/batch=0.092\n",
      "13519/67600 (epoch 9), train_loss = 1.256, time/batch=0.093\n",
      "13520/67600 (epoch 10), train_loss = 1.422, time/batch=0.087\n",
      "13521/67600 (epoch 10), train_loss = 1.188, time/batch=0.127\n",
      "13522/67600 (epoch 10), train_loss = 1.267, time/batch=0.152\n",
      "13523/67600 (epoch 10), train_loss = 1.224, time/batch=0.125\n",
      "13524/67600 (epoch 10), train_loss = 1.246, time/batch=0.088\n",
      "13525/67600 (epoch 10), train_loss = 1.269, time/batch=0.096\n",
      "13526/67600 (epoch 10), train_loss = 1.233, time/batch=0.090\n",
      "13527/67600 (epoch 10), train_loss = 1.239, time/batch=0.089\n",
      "13528/67600 (epoch 10), train_loss = 1.258, time/batch=0.089\n",
      "13529/67600 (epoch 10), train_loss = 1.229, time/batch=0.079\n",
      "13530/67600 (epoch 10), train_loss = 1.196, time/batch=0.083\n",
      "13531/67600 (epoch 10), train_loss = 1.211, time/batch=0.175\n",
      "13532/67600 (epoch 10), train_loss = 1.218, time/batch=0.103\n",
      "13533/67600 (epoch 10), train_loss = 1.285, time/batch=0.125\n",
      "13534/67600 (epoch 10), train_loss = 1.256, time/batch=0.089\n",
      "13535/67600 (epoch 10), train_loss = 1.237, time/batch=0.090\n",
      "13536/67600 (epoch 10), train_loss = 1.237, time/batch=0.091\n",
      "13537/67600 (epoch 10), train_loss = 1.251, time/batch=0.088\n",
      "13538/67600 (epoch 10), train_loss = 1.234, time/batch=0.088\n",
      "13539/67600 (epoch 10), train_loss = 1.228, time/batch=0.089\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13540/67600 (epoch 10), train_loss = 1.234, time/batch=0.088\n",
      "13541/67600 (epoch 10), train_loss = 1.175, time/batch=0.209\n",
      "13542/67600 (epoch 10), train_loss = 1.299, time/batch=0.123\n",
      "13543/67600 (epoch 10), train_loss = 1.268, time/batch=0.087\n",
      "13544/67600 (epoch 10), train_loss = 1.307, time/batch=0.089\n",
      "13545/67600 (epoch 10), train_loss = 1.163, time/batch=0.091\n",
      "13546/67600 (epoch 10), train_loss = 1.256, time/batch=0.091\n",
      "13547/67600 (epoch 10), train_loss = 1.279, time/batch=0.105\n",
      "13548/67600 (epoch 10), train_loss = 1.310, time/batch=0.104\n",
      "13549/67600 (epoch 10), train_loss = 1.230, time/batch=0.102\n",
      "13550/67600 (epoch 10), train_loss = 1.220, time/batch=0.345\n",
      "13551/67600 (epoch 10), train_loss = 1.294, time/batch=0.109\n",
      "13552/67600 (epoch 10), train_loss = 1.225, time/batch=0.096\n",
      "13553/67600 (epoch 10), train_loss = 1.291, time/batch=0.107\n",
      "13554/67600 (epoch 10), train_loss = 1.256, time/batch=0.140\n",
      "13555/67600 (epoch 10), train_loss = 1.247, time/batch=0.116\n",
      "13556/67600 (epoch 10), train_loss = 1.209, time/batch=0.240\n",
      "13557/67600 (epoch 10), train_loss = 1.257, time/batch=0.164\n",
      "13558/67600 (epoch 10), train_loss = 1.259, time/batch=0.120\n",
      "13559/67600 (epoch 10), train_loss = 1.241, time/batch=0.112\n",
      "13560/67600 (epoch 10), train_loss = 1.170, time/batch=0.114\n",
      "13561/67600 (epoch 10), train_loss = 1.270, time/batch=0.273\n",
      "13562/67600 (epoch 10), train_loss = 1.288, time/batch=0.161\n",
      "13563/67600 (epoch 10), train_loss = 1.264, time/batch=0.115\n",
      "13564/67600 (epoch 10), train_loss = 1.277, time/batch=0.101\n",
      "13565/67600 (epoch 10), train_loss = 1.234, time/batch=0.101\n",
      "13566/67600 (epoch 10), train_loss = 1.207, time/batch=0.101\n",
      "13567/67600 (epoch 10), train_loss = 1.251, time/batch=0.113\n",
      "13568/67600 (epoch 10), train_loss = 1.211, time/batch=0.119\n",
      "13569/67600 (epoch 10), train_loss = 1.209, time/batch=0.254\n",
      "13570/67600 (epoch 10), train_loss = 1.297, time/batch=0.131\n",
      "13571/67600 (epoch 10), train_loss = 1.217, time/batch=0.089\n",
      "13572/67600 (epoch 10), train_loss = 1.225, time/batch=0.088\n",
      "13573/67600 (epoch 10), train_loss = 1.319, time/batch=0.089\n",
      "13574/67600 (epoch 10), train_loss = 1.279, time/batch=0.088\n",
      "13575/67600 (epoch 10), train_loss = 1.240, time/batch=0.092\n",
      "13576/67600 (epoch 10), train_loss = 1.250, time/batch=0.110\n",
      "13577/67600 (epoch 10), train_loss = 1.243, time/batch=0.227\n",
      "13578/67600 (epoch 10), train_loss = 1.253, time/batch=0.108\n",
      "13579/67600 (epoch 10), train_loss = 1.249, time/batch=0.116\n",
      "13580/67600 (epoch 10), train_loss = 1.250, time/batch=0.086\n",
      "13581/67600 (epoch 10), train_loss = 1.236, time/batch=0.094\n",
      "13582/67600 (epoch 10), train_loss = 1.283, time/batch=0.089\n",
      "13583/67600 (epoch 10), train_loss = 1.287, time/batch=0.108\n",
      "13584/67600 (epoch 10), train_loss = 1.230, time/batch=0.092\n",
      "13585/67600 (epoch 10), train_loss = 1.226, time/batch=0.090\n",
      "13586/67600 (epoch 10), train_loss = 1.230, time/batch=0.090\n",
      "13587/67600 (epoch 10), train_loss = 1.254, time/batch=0.253\n",
      "13588/67600 (epoch 10), train_loss = 1.267, time/batch=0.103\n",
      "13589/67600 (epoch 10), train_loss = 1.268, time/batch=0.085\n",
      "13590/67600 (epoch 10), train_loss = 1.260, time/batch=0.096\n",
      "13591/67600 (epoch 10), train_loss = 1.264, time/batch=0.102\n",
      "13592/67600 (epoch 10), train_loss = 1.220, time/batch=0.095\n",
      "13593/67600 (epoch 10), train_loss = 1.294, time/batch=0.095\n",
      "13594/67600 (epoch 10), train_loss = 1.233, time/batch=0.090\n",
      "13595/67600 (epoch 10), train_loss = 1.289, time/batch=0.087\n",
      "13596/67600 (epoch 10), train_loss = 1.287, time/batch=0.226\n",
      "13597/67600 (epoch 10), train_loss = 1.371, time/batch=0.092\n",
      "13598/67600 (epoch 10), train_loss = 1.291, time/batch=0.080\n",
      "13599/67600 (epoch 10), train_loss = 1.222, time/batch=0.087\n",
      "13600/67600 (epoch 10), train_loss = 1.203, time/batch=0.089\n",
      "13601/67600 (epoch 10), train_loss = 1.254, time/batch=0.089\n",
      "13602/67600 (epoch 10), train_loss = 1.256, time/batch=0.091\n",
      "13603/67600 (epoch 10), train_loss = 1.237, time/batch=0.092\n",
      "13604/67600 (epoch 10), train_loss = 1.244, time/batch=0.086\n",
      "13605/67600 (epoch 10), train_loss = 1.243, time/batch=0.179\n",
      "13606/67600 (epoch 10), train_loss = 1.185, time/batch=0.153\n",
      "13607/67600 (epoch 10), train_loss = 1.302, time/batch=0.095\n",
      "13608/67600 (epoch 10), train_loss = 1.278, time/batch=0.098\n",
      "13609/67600 (epoch 10), train_loss = 1.277, time/batch=0.089\n",
      "13610/67600 (epoch 10), train_loss = 1.248, time/batch=0.089\n",
      "13611/67600 (epoch 10), train_loss = 1.270, time/batch=0.095\n",
      "13612/67600 (epoch 10), train_loss = 1.196, time/batch=0.135\n",
      "13613/67600 (epoch 10), train_loss = 1.216, time/batch=0.094\n",
      "13614/67600 (epoch 10), train_loss = 1.210, time/batch=0.095\n",
      "13615/67600 (epoch 10), train_loss = 1.156, time/batch=0.097\n",
      "13616/67600 (epoch 10), train_loss = 1.171, time/batch=0.095\n",
      "13617/67600 (epoch 10), train_loss = 1.246, time/batch=0.092\n",
      "13618/67600 (epoch 10), train_loss = 1.233, time/batch=0.098\n",
      "13619/67600 (epoch 10), train_loss = 1.279, time/batch=0.324\n",
      "13620/67600 (epoch 10), train_loss = 1.150, time/batch=0.133\n",
      "13621/67600 (epoch 10), train_loss = 1.231, time/batch=0.093\n",
      "13622/67600 (epoch 10), train_loss = 1.267, time/batch=0.088\n",
      "13623/67600 (epoch 10), train_loss = 1.174, time/batch=0.082\n",
      "13624/67600 (epoch 10), train_loss = 1.205, time/batch=0.090\n",
      "13625/67600 (epoch 10), train_loss = 1.260, time/batch=0.089\n",
      "13626/67600 (epoch 10), train_loss = 1.219, time/batch=0.199\n",
      "13627/67600 (epoch 10), train_loss = 1.251, time/batch=0.107\n",
      "13628/67600 (epoch 10), train_loss = 1.284, time/batch=0.093\n",
      "13629/67600 (epoch 10), train_loss = 1.248, time/batch=0.111\n",
      "13630/67600 (epoch 10), train_loss = 1.209, time/batch=0.130\n",
      "13631/67600 (epoch 10), train_loss = 1.248, time/batch=0.084\n",
      "13632/67600 (epoch 10), train_loss = 1.231, time/batch=0.087\n",
      "13633/67600 (epoch 10), train_loss = 1.270, time/batch=0.086\n",
      "13634/67600 (epoch 10), train_loss = 1.268, time/batch=0.091\n",
      "13635/67600 (epoch 10), train_loss = 1.211, time/batch=0.205\n",
      "13636/67600 (epoch 10), train_loss = 1.199, time/batch=0.122\n",
      "13637/67600 (epoch 10), train_loss = 1.236, time/batch=0.125\n",
      "13638/67600 (epoch 10), train_loss = 1.256, time/batch=0.114\n",
      "13639/67600 (epoch 10), train_loss = 1.258, time/batch=0.085\n",
      "13640/67600 (epoch 10), train_loss = 1.255, time/batch=0.109\n",
      "13641/67600 (epoch 10), train_loss = 1.263, time/batch=0.116\n",
      "13642/67600 (epoch 10), train_loss = 1.228, time/batch=0.092\n",
      "13643/67600 (epoch 10), train_loss = 1.208, time/batch=0.240\n",
      "13644/67600 (epoch 10), train_loss = 1.231, time/batch=0.118\n",
      "13645/67600 (epoch 10), train_loss = 1.156, time/batch=0.128\n",
      "13646/67600 (epoch 10), train_loss = 1.235, time/batch=0.103\n",
      "13647/67600 (epoch 10), train_loss = 1.268, time/batch=0.092\n",
      "13648/67600 (epoch 10), train_loss = 1.210, time/batch=0.085\n",
      "13649/67600 (epoch 10), train_loss = 1.229, time/batch=0.088\n",
      "13650/67600 (epoch 10), train_loss = 1.257, time/batch=0.095\n",
      "13651/67600 (epoch 10), train_loss = 1.231, time/batch=0.090\n",
      "13652/67600 (epoch 10), train_loss = 1.282, time/batch=0.231\n",
      "13653/67600 (epoch 10), train_loss = 1.217, time/batch=0.145\n",
      "13654/67600 (epoch 10), train_loss = 1.242, time/batch=0.088\n",
      "13655/67600 (epoch 10), train_loss = 1.248, time/batch=0.103\n",
      "13656/67600 (epoch 10), train_loss = 1.262, time/batch=0.093\n",
      "13657/67600 (epoch 10), train_loss = 1.245, time/batch=0.095\n",
      "13658/67600 (epoch 10), train_loss = 1.248, time/batch=0.114\n",
      "13659/67600 (epoch 10), train_loss = 1.216, time/batch=0.095\n",
      "13660/67600 (epoch 10), train_loss = 1.218, time/batch=0.180\n",
      "13661/67600 (epoch 10), train_loss = 1.196, time/batch=0.117\n",
      "13662/67600 (epoch 10), train_loss = 1.251, time/batch=0.115\n",
      "13663/67600 (epoch 10), train_loss = 1.204, time/batch=0.086\n",
      "13664/67600 (epoch 10), train_loss = 1.294, time/batch=0.089\n",
      "13665/67600 (epoch 10), train_loss = 1.332, time/batch=0.091\n",
      "13666/67600 (epoch 10), train_loss = 1.244, time/batch=0.090\n",
      "13667/67600 (epoch 10), train_loss = 1.230, time/batch=0.087\n",
      "13668/67600 (epoch 10), train_loss = 1.290, time/batch=0.089\n",
      "13669/67600 (epoch 10), train_loss = 1.177, time/batch=0.088\n",
      "13670/67600 (epoch 10), train_loss = 1.254, time/batch=0.216\n",
      "13671/67600 (epoch 10), train_loss = 1.200, time/batch=0.106\n",
      "13672/67600 (epoch 10), train_loss = 1.191, time/batch=0.086\n",
      "13673/67600 (epoch 10), train_loss = 1.243, time/batch=0.085\n",
      "13674/67600 (epoch 10), train_loss = 1.205, time/batch=0.086\n",
      "13675/67600 (epoch 10), train_loss = 1.258, time/batch=0.085\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13676/67600 (epoch 10), train_loss = 1.260, time/batch=0.083\n",
      "13677/67600 (epoch 10), train_loss = 1.270, time/batch=0.087\n",
      "13678/67600 (epoch 10), train_loss = 1.251, time/batch=0.085\n",
      "13679/67600 (epoch 10), train_loss = 1.222, time/batch=0.089\n",
      "13680/67600 (epoch 10), train_loss = 1.210, time/batch=0.238\n",
      "13681/67600 (epoch 10), train_loss = 1.189, time/batch=0.087\n",
      "13682/67600 (epoch 10), train_loss = 1.246, time/batch=0.083\n",
      "13683/67600 (epoch 10), train_loss = 1.232, time/batch=0.087\n",
      "13684/67600 (epoch 10), train_loss = 1.146, time/batch=0.094\n",
      "13685/67600 (epoch 10), train_loss = 1.233, time/batch=0.088\n",
      "13686/67600 (epoch 10), train_loss = 1.228, time/batch=0.088\n",
      "13687/67600 (epoch 10), train_loss = 1.203, time/batch=0.201\n",
      "13688/67600 (epoch 10), train_loss = 1.246, time/batch=0.124\n",
      "13689/67600 (epoch 10), train_loss = 1.262, time/batch=0.091\n",
      "13690/67600 (epoch 10), train_loss = 1.257, time/batch=0.091\n",
      "13691/67600 (epoch 10), train_loss = 1.203, time/batch=0.096\n",
      "13692/67600 (epoch 10), train_loss = 1.261, time/batch=0.088\n",
      "13693/67600 (epoch 10), train_loss = 1.214, time/batch=0.093\n",
      "13694/67600 (epoch 10), train_loss = 1.220, time/batch=0.086\n",
      "13695/67600 (epoch 10), train_loss = 1.182, time/batch=0.088\n",
      "13696/67600 (epoch 10), train_loss = 1.250, time/batch=0.186\n",
      "13697/67600 (epoch 10), train_loss = 1.283, time/batch=0.093\n",
      "13698/67600 (epoch 10), train_loss = 1.192, time/batch=0.123\n",
      "13699/67600 (epoch 10), train_loss = 1.207, time/batch=0.092\n",
      "13700/67600 (epoch 10), train_loss = 1.181, time/batch=0.089\n",
      "13701/67600 (epoch 10), train_loss = 1.174, time/batch=0.092\n",
      "13702/67600 (epoch 10), train_loss = 1.214, time/batch=0.092\n",
      "13703/67600 (epoch 10), train_loss = 1.319, time/batch=0.099\n",
      "13704/67600 (epoch 10), train_loss = 1.330, time/batch=0.096\n",
      "13705/67600 (epoch 10), train_loss = 1.297, time/batch=0.113\n",
      "13706/67600 (epoch 10), train_loss = 1.332, time/batch=0.188\n",
      "13707/67600 (epoch 10), train_loss = 1.235, time/batch=0.130\n",
      "13708/67600 (epoch 10), train_loss = 1.248, time/batch=0.093\n",
      "13709/67600 (epoch 10), train_loss = 1.238, time/batch=0.087\n",
      "13710/67600 (epoch 10), train_loss = 1.302, time/batch=0.097\n",
      "13711/67600 (epoch 10), train_loss = 1.271, time/batch=0.089\n",
      "13712/67600 (epoch 10), train_loss = 1.231, time/batch=0.078\n",
      "13713/67600 (epoch 10), train_loss = 1.272, time/batch=0.084\n",
      "13714/67600 (epoch 10), train_loss = 1.262, time/batch=0.085\n",
      "13715/67600 (epoch 10), train_loss = 1.246, time/batch=0.187\n",
      "13716/67600 (epoch 10), train_loss = 1.232, time/batch=0.113\n",
      "13717/67600 (epoch 10), train_loss = 1.233, time/batch=0.097\n",
      "13718/67600 (epoch 10), train_loss = 1.259, time/batch=0.086\n",
      "13719/67600 (epoch 10), train_loss = 1.211, time/batch=0.087\n",
      "13720/67600 (epoch 10), train_loss = 1.200, time/batch=0.086\n",
      "13721/67600 (epoch 10), train_loss = 1.173, time/batch=0.088\n",
      "13722/67600 (epoch 10), train_loss = 1.297, time/batch=0.181\n",
      "13723/67600 (epoch 10), train_loss = 1.237, time/batch=0.096\n",
      "13724/67600 (epoch 10), train_loss = 1.261, time/batch=0.108\n",
      "13725/67600 (epoch 10), train_loss = 1.178, time/batch=0.085\n",
      "13726/67600 (epoch 10), train_loss = 1.183, time/batch=0.085\n",
      "13727/67600 (epoch 10), train_loss = 1.202, time/batch=0.118\n",
      "13728/67600 (epoch 10), train_loss = 1.253, time/batch=0.090\n",
      "13729/67600 (epoch 10), train_loss = 1.284, time/batch=0.084\n",
      "13730/67600 (epoch 10), train_loss = 1.256, time/batch=0.091\n",
      "13731/67600 (epoch 10), train_loss = 1.307, time/batch=0.091\n",
      "13732/67600 (epoch 10), train_loss = 1.218, time/batch=0.094\n",
      "13733/67600 (epoch 10), train_loss = 1.227, time/batch=0.087\n",
      "13734/67600 (epoch 10), train_loss = 1.230, time/batch=0.085\n",
      "13735/67600 (epoch 10), train_loss = 1.268, time/batch=0.252\n",
      "13736/67600 (epoch 10), train_loss = 1.214, time/batch=0.094\n",
      "13737/67600 (epoch 10), train_loss = 1.219, time/batch=0.091\n",
      "13738/67600 (epoch 10), train_loss = 1.202, time/batch=0.092\n",
      "13739/67600 (epoch 10), train_loss = 1.180, time/batch=0.088\n",
      "13740/67600 (epoch 10), train_loss = 1.292, time/batch=0.087\n",
      "13741/67600 (epoch 10), train_loss = 1.203, time/batch=0.155\n",
      "13742/67600 (epoch 10), train_loss = 1.252, time/batch=0.094\n",
      "13743/67600 (epoch 10), train_loss = 1.237, time/batch=0.091\n",
      "13744/67600 (epoch 10), train_loss = 1.236, time/batch=0.084\n",
      "13745/67600 (epoch 10), train_loss = 1.214, time/batch=0.086\n",
      "13746/67600 (epoch 10), train_loss = 1.279, time/batch=0.087\n",
      "13747/67600 (epoch 10), train_loss = 1.193, time/batch=0.085\n",
      "13748/67600 (epoch 10), train_loss = 1.202, time/batch=0.083\n",
      "13749/67600 (epoch 10), train_loss = 1.211, time/batch=0.183\n",
      "13750/67600 (epoch 10), train_loss = 1.239, time/batch=0.149\n",
      "13751/67600 (epoch 10), train_loss = 1.240, time/batch=0.120\n",
      "13752/67600 (epoch 10), train_loss = 1.170, time/batch=0.087\n",
      "13753/67600 (epoch 10), train_loss = 1.176, time/batch=0.086\n",
      "13754/67600 (epoch 10), train_loss = 1.245, time/batch=0.085\n",
      "13755/67600 (epoch 10), train_loss = 1.232, time/batch=0.085\n",
      "13756/67600 (epoch 10), train_loss = 1.217, time/batch=0.088\n",
      "13757/67600 (epoch 10), train_loss = 1.220, time/batch=0.090\n",
      "13758/67600 (epoch 10), train_loss = 1.280, time/batch=0.086\n",
      "13759/67600 (epoch 10), train_loss = 1.250, time/batch=0.249\n",
      "13760/67600 (epoch 10), train_loss = 1.258, time/batch=0.095\n",
      "13761/67600 (epoch 10), train_loss = 1.187, time/batch=0.092\n",
      "13762/67600 (epoch 10), train_loss = 1.238, time/batch=0.089\n",
      "13763/67600 (epoch 10), train_loss = 1.249, time/batch=0.094\n",
      "13764/67600 (epoch 10), train_loss = 1.178, time/batch=0.087\n",
      "13765/67600 (epoch 10), train_loss = 1.248, time/batch=0.093\n",
      "13766/67600 (epoch 10), train_loss = 1.227, time/batch=0.259\n",
      "13767/67600 (epoch 10), train_loss = 1.239, time/batch=0.113\n",
      "13768/67600 (epoch 10), train_loss = 1.262, time/batch=0.088\n",
      "13769/67600 (epoch 10), train_loss = 1.211, time/batch=0.104\n",
      "13770/67600 (epoch 10), train_loss = 1.203, time/batch=0.089\n",
      "13771/67600 (epoch 10), train_loss = 1.284, time/batch=0.093\n",
      "13772/67600 (epoch 10), train_loss = 1.200, time/batch=0.092\n",
      "13773/67600 (epoch 10), train_loss = 1.240, time/batch=0.090\n",
      "13774/67600 (epoch 10), train_loss = 1.256, time/batch=0.092\n",
      "13775/67600 (epoch 10), train_loss = 1.308, time/batch=0.190\n",
      "13776/67600 (epoch 10), train_loss = 1.277, time/batch=0.124\n",
      "13777/67600 (epoch 10), train_loss = 1.281, time/batch=0.089\n",
      "13778/67600 (epoch 10), train_loss = 1.196, time/batch=0.085\n",
      "13779/67600 (epoch 10), train_loss = 1.195, time/batch=0.090\n",
      "13780/67600 (epoch 10), train_loss = 1.218, time/batch=0.089\n",
      "13781/67600 (epoch 10), train_loss = 1.211, time/batch=0.093\n",
      "13782/67600 (epoch 10), train_loss = 1.234, time/batch=0.082\n",
      "13783/67600 (epoch 10), train_loss = 1.238, time/batch=0.087\n",
      "13784/67600 (epoch 10), train_loss = 1.218, time/batch=0.187\n",
      "13785/67600 (epoch 10), train_loss = 1.217, time/batch=0.095\n",
      "13786/67600 (epoch 10), train_loss = 1.195, time/batch=0.129\n",
      "13787/67600 (epoch 10), train_loss = 1.239, time/batch=0.088\n",
      "13788/67600 (epoch 10), train_loss = 1.219, time/batch=0.094\n",
      "13789/67600 (epoch 10), train_loss = 1.198, time/batch=0.087\n",
      "13790/67600 (epoch 10), train_loss = 1.260, time/batch=0.090\n",
      "13791/67600 (epoch 10), train_loss = 1.233, time/batch=0.089\n",
      "13792/67600 (epoch 10), train_loss = 1.241, time/batch=0.087\n",
      "13793/67600 (epoch 10), train_loss = 1.274, time/batch=0.083\n",
      "13794/67600 (epoch 10), train_loss = 1.251, time/batch=0.200\n",
      "13795/67600 (epoch 10), train_loss = 1.230, time/batch=0.098\n",
      "13796/67600 (epoch 10), train_loss = 1.252, time/batch=0.104\n",
      "13797/67600 (epoch 10), train_loss = 1.204, time/batch=0.088\n",
      "13798/67600 (epoch 10), train_loss = 1.203, time/batch=0.089\n",
      "13799/67600 (epoch 10), train_loss = 1.251, time/batch=0.090\n",
      "13800/67600 (epoch 10), train_loss = 1.262, time/batch=0.092\n",
      "13801/67600 (epoch 10), train_loss = 1.205, time/batch=0.088\n",
      "13802/67600 (epoch 10), train_loss = 1.172, time/batch=0.090\n",
      "13803/67600 (epoch 10), train_loss = 1.261, time/batch=0.088\n",
      "13804/67600 (epoch 10), train_loss = 1.199, time/batch=0.230\n",
      "13805/67600 (epoch 10), train_loss = 1.315, time/batch=0.101\n",
      "13806/67600 (epoch 10), train_loss = 1.250, time/batch=0.085\n",
      "13807/67600 (epoch 10), train_loss = 1.233, time/batch=0.106\n",
      "13808/67600 (epoch 10), train_loss = 1.266, time/batch=0.090\n",
      "13809/67600 (epoch 10), train_loss = 1.257, time/batch=0.087\n",
      "13810/67600 (epoch 10), train_loss = 1.254, time/batch=0.092\n",
      "13811/67600 (epoch 10), train_loss = 1.245, time/batch=0.087\n",
      "13812/67600 (epoch 10), train_loss = 1.248, time/batch=0.100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13813/67600 (epoch 10), train_loss = 1.241, time/batch=0.236\n",
      "13814/67600 (epoch 10), train_loss = 1.245, time/batch=0.098\n",
      "13815/67600 (epoch 10), train_loss = 1.251, time/batch=0.079\n",
      "13816/67600 (epoch 10), train_loss = 1.242, time/batch=0.085\n",
      "13817/67600 (epoch 10), train_loss = 1.218, time/batch=0.092\n",
      "13818/67600 (epoch 10), train_loss = 1.213, time/batch=0.087\n",
      "13819/67600 (epoch 10), train_loss = 1.275, time/batch=0.257\n",
      "13820/67600 (epoch 10), train_loss = 1.228, time/batch=0.169\n",
      "13821/67600 (epoch 10), train_loss = 1.260, time/batch=0.101\n",
      "13822/67600 (epoch 10), train_loss = 1.223, time/batch=0.107\n",
      "13823/67600 (epoch 10), train_loss = 1.256, time/batch=0.101\n",
      "13824/67600 (epoch 10), train_loss = 1.260, time/batch=0.096\n",
      "13825/67600 (epoch 10), train_loss = 1.270, time/batch=0.111\n",
      "13826/67600 (epoch 10), train_loss = 1.285, time/batch=0.102\n",
      "13827/67600 (epoch 10), train_loss = 1.266, time/batch=0.228\n",
      "13828/67600 (epoch 10), train_loss = 1.270, time/batch=0.135\n",
      "13829/67600 (epoch 10), train_loss = 1.270, time/batch=0.107\n",
      "13830/67600 (epoch 10), train_loss = 1.236, time/batch=0.096\n",
      "13831/67600 (epoch 10), train_loss = 1.197, time/batch=0.099\n",
      "13832/67600 (epoch 10), train_loss = 1.208, time/batch=0.091\n",
      "13833/67600 (epoch 10), train_loss = 1.266, time/batch=0.104\n",
      "13834/67600 (epoch 10), train_loss = 1.239, time/batch=0.103\n",
      "13835/67600 (epoch 10), train_loss = 1.317, time/batch=0.100\n",
      "13836/67600 (epoch 10), train_loss = 1.227, time/batch=0.229\n",
      "13837/67600 (epoch 10), train_loss = 1.262, time/batch=0.128\n",
      "13838/67600 (epoch 10), train_loss = 1.265, time/batch=0.094\n",
      "13839/67600 (epoch 10), train_loss = 1.277, time/batch=0.103\n",
      "13840/67600 (epoch 10), train_loss = 1.294, time/batch=0.101\n",
      "13841/67600 (epoch 10), train_loss = 1.236, time/batch=0.110\n",
      "13842/67600 (epoch 10), train_loss = 1.242, time/batch=0.103\n",
      "13843/67600 (epoch 10), train_loss = 1.214, time/batch=0.099\n",
      "13844/67600 (epoch 10), train_loss = 1.238, time/batch=0.245\n",
      "13845/67600 (epoch 10), train_loss = 1.201, time/batch=0.101\n",
      "13846/67600 (epoch 10), train_loss = 1.197, time/batch=0.082\n",
      "13847/67600 (epoch 10), train_loss = 1.269, time/batch=0.108\n",
      "13848/67600 (epoch 10), train_loss = 1.228, time/batch=0.099\n",
      "13849/67600 (epoch 10), train_loss = 1.246, time/batch=0.099\n",
      "13850/67600 (epoch 10), train_loss = 1.277, time/batch=0.244\n",
      "13851/67600 (epoch 10), train_loss = 1.190, time/batch=0.123\n",
      "13852/67600 (epoch 10), train_loss = 1.240, time/batch=0.103\n",
      "13853/67600 (epoch 10), train_loss = 1.232, time/batch=0.171\n",
      "13854/67600 (epoch 10), train_loss = 1.257, time/batch=0.096\n",
      "13855/67600 (epoch 10), train_loss = 1.272, time/batch=0.090\n",
      "13856/67600 (epoch 10), train_loss = 1.228, time/batch=0.101\n",
      "13857/67600 (epoch 10), train_loss = 1.209, time/batch=0.116\n",
      "13858/67600 (epoch 10), train_loss = 1.245, time/batch=0.099\n",
      "13859/67600 (epoch 10), train_loss = 1.278, time/batch=0.093\n",
      "13860/67600 (epoch 10), train_loss = 1.238, time/batch=0.115\n",
      "13861/67600 (epoch 10), train_loss = 1.219, time/batch=0.235\n",
      "13862/67600 (epoch 10), train_loss = 1.205, time/batch=0.106\n",
      "13863/67600 (epoch 10), train_loss = 1.195, time/batch=0.101\n",
      "13864/67600 (epoch 10), train_loss = 1.282, time/batch=0.097\n",
      "13865/67600 (epoch 10), train_loss = 1.305, time/batch=0.100\n",
      "13866/67600 (epoch 10), train_loss = 1.247, time/batch=0.142\n",
      "13867/67600 (epoch 10), train_loss = 1.242, time/batch=0.096\n",
      "13868/67600 (epoch 10), train_loss = 1.285, time/batch=0.106\n",
      "13869/67600 (epoch 10), train_loss = 1.289, time/batch=0.092\n",
      "13870/67600 (epoch 10), train_loss = 1.198, time/batch=0.089\n",
      "13871/67600 (epoch 10), train_loss = 1.187, time/batch=0.092\n",
      "13872/67600 (epoch 10), train_loss = 1.181, time/batch=0.084\n",
      "13873/67600 (epoch 10), train_loss = 1.200, time/batch=0.090\n",
      "13874/67600 (epoch 10), train_loss = 1.211, time/batch=0.254\n",
      "13875/67600 (epoch 10), train_loss = 1.276, time/batch=0.088\n",
      "13876/67600 (epoch 10), train_loss = 1.216, time/batch=0.101\n",
      "13877/67600 (epoch 10), train_loss = 1.234, time/batch=0.092\n",
      "13878/67600 (epoch 10), train_loss = 1.192, time/batch=0.090\n",
      "13879/67600 (epoch 10), train_loss = 1.318, time/batch=0.090\n",
      "13880/67600 (epoch 10), train_loss = 1.239, time/batch=0.091\n",
      "13881/67600 (epoch 10), train_loss = 1.195, time/batch=0.090\n",
      "13882/67600 (epoch 10), train_loss = 1.205, time/batch=0.085\n",
      "13883/67600 (epoch 10), train_loss = 1.278, time/batch=0.091\n",
      "13884/67600 (epoch 10), train_loss = 1.236, time/batch=0.232\n",
      "13885/67600 (epoch 10), train_loss = 1.223, time/batch=0.100\n",
      "13886/67600 (epoch 10), train_loss = 1.230, time/batch=0.090\n",
      "13887/67600 (epoch 10), train_loss = 1.180, time/batch=0.090\n",
      "13888/67600 (epoch 10), train_loss = 1.230, time/batch=0.096\n",
      "13889/67600 (epoch 10), train_loss = 1.310, time/batch=0.089\n",
      "13890/67600 (epoch 10), train_loss = 1.230, time/batch=0.092\n",
      "13891/67600 (epoch 10), train_loss = 1.237, time/batch=0.097\n",
      "13892/67600 (epoch 10), train_loss = 1.268, time/batch=0.084\n",
      "13893/67600 (epoch 10), train_loss = 1.242, time/batch=0.228\n",
      "13894/67600 (epoch 10), train_loss = 1.287, time/batch=0.094\n",
      "13895/67600 (epoch 10), train_loss = 1.315, time/batch=0.106\n",
      "13896/67600 (epoch 10), train_loss = 1.258, time/batch=0.104\n",
      "13897/67600 (epoch 10), train_loss = 1.238, time/batch=0.113\n",
      "13898/67600 (epoch 10), train_loss = 1.307, time/batch=0.114\n",
      "13899/67600 (epoch 10), train_loss = 1.317, time/batch=0.218\n",
      "13900/67600 (epoch 10), train_loss = 1.273, time/batch=0.130\n",
      "13901/67600 (epoch 10), train_loss = 1.232, time/batch=0.086\n",
      "13902/67600 (epoch 10), train_loss = 1.227, time/batch=0.076\n",
      "13903/67600 (epoch 10), train_loss = 1.269, time/batch=0.087\n",
      "13904/67600 (epoch 10), train_loss = 1.322, time/batch=0.089\n",
      "13905/67600 (epoch 10), train_loss = 1.244, time/batch=0.080\n",
      "13906/67600 (epoch 10), train_loss = 1.225, time/batch=0.080\n",
      "13907/67600 (epoch 10), train_loss = 1.234, time/batch=0.078\n",
      "13908/67600 (epoch 10), train_loss = 1.269, time/batch=0.078\n",
      "13909/67600 (epoch 10), train_loss = 1.256, time/batch=0.236\n",
      "13910/67600 (epoch 10), train_loss = 1.236, time/batch=0.146\n",
      "13911/67600 (epoch 10), train_loss = 1.229, time/batch=0.074\n",
      "13912/67600 (epoch 10), train_loss = 1.223, time/batch=0.074\n",
      "13913/67600 (epoch 10), train_loss = 1.250, time/batch=0.077\n",
      "13914/67600 (epoch 10), train_loss = 1.224, time/batch=0.084\n",
      "13915/67600 (epoch 10), train_loss = 1.230, time/batch=0.076\n",
      "13916/67600 (epoch 10), train_loss = 1.290, time/batch=0.075\n",
      "13917/67600 (epoch 10), train_loss = 1.286, time/batch=0.076\n",
      "13918/67600 (epoch 10), train_loss = 1.241, time/batch=0.098\n",
      "13919/67600 (epoch 10), train_loss = 1.224, time/batch=0.228\n",
      "13920/67600 (epoch 10), train_loss = 1.263, time/batch=0.121\n",
      "13921/67600 (epoch 10), train_loss = 1.327, time/batch=0.072\n",
      "13922/67600 (epoch 10), train_loss = 1.293, time/batch=0.077\n",
      "13923/67600 (epoch 10), train_loss = 1.260, time/batch=0.081\n",
      "13924/67600 (epoch 10), train_loss = 1.323, time/batch=0.078\n",
      "13925/67600 (epoch 10), train_loss = 1.284, time/batch=0.074\n",
      "13926/67600 (epoch 10), train_loss = 1.288, time/batch=0.081\n",
      "13927/67600 (epoch 10), train_loss = 1.221, time/batch=0.075\n",
      "13928/67600 (epoch 10), train_loss = 1.270, time/batch=0.078\n",
      "13929/67600 (epoch 10), train_loss = 1.267, time/batch=0.186\n",
      "13930/67600 (epoch 10), train_loss = 1.271, time/batch=0.109\n",
      "13931/67600 (epoch 10), train_loss = 1.207, time/batch=0.100\n",
      "13932/67600 (epoch 10), train_loss = 1.241, time/batch=0.078\n",
      "13933/67600 (epoch 10), train_loss = 1.252, time/batch=0.077\n",
      "13934/67600 (epoch 10), train_loss = 1.229, time/batch=0.075\n",
      "13935/67600 (epoch 10), train_loss = 1.287, time/batch=0.091\n",
      "13936/67600 (epoch 10), train_loss = 1.248, time/batch=0.127\n",
      "13937/67600 (epoch 10), train_loss = 1.281, time/batch=0.084\n",
      "13938/67600 (epoch 10), train_loss = 1.297, time/batch=0.105\n",
      "13939/67600 (epoch 10), train_loss = 1.221, time/batch=0.210\n",
      "13940/67600 (epoch 10), train_loss = 1.164, time/batch=0.090\n",
      "13941/67600 (epoch 10), train_loss = 1.193, time/batch=0.088\n",
      "13942/67600 (epoch 10), train_loss = 1.238, time/batch=0.076\n",
      "13943/67600 (epoch 10), train_loss = 1.187, time/batch=0.080\n",
      "13944/67600 (epoch 10), train_loss = 1.238, time/batch=0.092\n",
      "13945/67600 (epoch 10), train_loss = 1.210, time/batch=0.087\n",
      "13946/67600 (epoch 10), train_loss = 1.234, time/batch=0.218\n",
      "13947/67600 (epoch 10), train_loss = 1.229, time/batch=0.109\n",
      "13948/67600 (epoch 10), train_loss = 1.160, time/batch=0.088\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13949/67600 (epoch 10), train_loss = 1.212, time/batch=0.081\n",
      "13950/67600 (epoch 10), train_loss = 1.276, time/batch=0.126\n",
      "13951/67600 (epoch 10), train_loss = 1.201, time/batch=0.109\n",
      "13952/67600 (epoch 10), train_loss = 1.267, time/batch=0.092\n",
      "13953/67600 (epoch 10), train_loss = 1.271, time/batch=0.089\n",
      "13954/67600 (epoch 10), train_loss = 1.198, time/batch=0.086\n",
      "13955/67600 (epoch 10), train_loss = 1.303, time/batch=0.229\n",
      "13956/67600 (epoch 10), train_loss = 1.234, time/batch=0.134\n",
      "13957/67600 (epoch 10), train_loss = 1.244, time/batch=0.086\n",
      "13958/67600 (epoch 10), train_loss = 1.263, time/batch=0.078\n",
      "13959/67600 (epoch 10), train_loss = 1.224, time/batch=0.082\n",
      "13960/67600 (epoch 10), train_loss = 1.226, time/batch=0.102\n",
      "13961/67600 (epoch 10), train_loss = 1.260, time/batch=0.120\n",
      "13962/67600 (epoch 10), train_loss = 1.221, time/batch=0.086\n",
      "13963/67600 (epoch 10), train_loss = 1.203, time/batch=0.081\n",
      "13964/67600 (epoch 10), train_loss = 1.252, time/batch=0.203\n",
      "13965/67600 (epoch 10), train_loss = 1.277, time/batch=0.088\n",
      "13966/67600 (epoch 10), train_loss = 1.195, time/batch=0.128\n",
      "13967/67600 (epoch 10), train_loss = 1.212, time/batch=0.091\n",
      "13968/67600 (epoch 10), train_loss = 1.181, time/batch=0.086\n",
      "13969/67600 (epoch 10), train_loss = 1.201, time/batch=0.094\n",
      "13970/67600 (epoch 10), train_loss = 1.159, time/batch=0.106\n",
      "13971/67600 (epoch 10), train_loss = 1.264, time/batch=0.092\n",
      "13972/67600 (epoch 10), train_loss = 1.284, time/batch=0.098\n",
      "13973/67600 (epoch 10), train_loss = 1.181, time/batch=0.265\n",
      "13974/67600 (epoch 10), train_loss = 1.164, time/batch=0.107\n",
      "13975/67600 (epoch 10), train_loss = 1.198, time/batch=0.118\n",
      "13976/67600 (epoch 10), train_loss = 1.220, time/batch=0.093\n",
      "13977/67600 (epoch 10), train_loss = 1.242, time/batch=0.092\n",
      "13978/67600 (epoch 10), train_loss = 1.259, time/batch=0.091\n",
      "13979/67600 (epoch 10), train_loss = 1.235, time/batch=0.087\n",
      "13980/67600 (epoch 10), train_loss = 1.250, time/batch=0.087\n",
      "13981/67600 (epoch 10), train_loss = 1.196, time/batch=0.089\n",
      "13982/67600 (epoch 10), train_loss = 1.266, time/batch=0.233\n",
      "13983/67600 (epoch 10), train_loss = 1.245, time/batch=0.104\n",
      "13984/67600 (epoch 10), train_loss = 1.212, time/batch=0.090\n",
      "13985/67600 (epoch 10), train_loss = 1.225, time/batch=0.154\n",
      "13986/67600 (epoch 10), train_loss = 1.215, time/batch=0.107\n",
      "13987/67600 (epoch 10), train_loss = 1.271, time/batch=0.098\n",
      "13988/67600 (epoch 10), train_loss = 1.232, time/batch=0.107\n",
      "13989/67600 (epoch 10), train_loss = 1.201, time/batch=0.093\n",
      "13990/67600 (epoch 10), train_loss = 1.226, time/batch=0.314\n",
      "13991/67600 (epoch 10), train_loss = 1.225, time/batch=0.091\n",
      "13992/67600 (epoch 10), train_loss = 1.196, time/batch=0.088\n",
      "13993/67600 (epoch 10), train_loss = 1.252, time/batch=0.116\n",
      "13994/67600 (epoch 10), train_loss = 1.206, time/batch=0.123\n",
      "13995/67600 (epoch 10), train_loss = 1.173, time/batch=0.171\n",
      "13996/67600 (epoch 10), train_loss = 1.268, time/batch=0.097\n",
      "13997/67600 (epoch 10), train_loss = 1.192, time/batch=0.094\n",
      "13998/67600 (epoch 10), train_loss = 1.217, time/batch=0.125\n",
      "13999/67600 (epoch 10), train_loss = 1.247, time/batch=0.128\n",
      "14000/67600 (epoch 10), train_loss = 1.195, time/batch=0.126\n",
      "model saved to ./save/model.ckpt\n",
      "14001/67600 (epoch 10), train_loss = 1.229, time/batch=0.072\n",
      "14002/67600 (epoch 10), train_loss = 1.211, time/batch=0.089\n",
      "14003/67600 (epoch 10), train_loss = 1.190, time/batch=0.103\n",
      "14004/67600 (epoch 10), train_loss = 1.248, time/batch=0.126\n",
      "14005/67600 (epoch 10), train_loss = 1.250, time/batch=0.245\n",
      "14006/67600 (epoch 10), train_loss = 1.272, time/batch=0.114\n",
      "14007/67600 (epoch 10), train_loss = 1.243, time/batch=0.120\n",
      "14008/67600 (epoch 10), train_loss = 1.290, time/batch=0.132\n",
      "14009/67600 (epoch 10), train_loss = 1.267, time/batch=0.123\n",
      "14010/67600 (epoch 10), train_loss = 1.197, time/batch=0.228\n",
      "14011/67600 (epoch 10), train_loss = 1.225, time/batch=0.164\n",
      "14012/67600 (epoch 10), train_loss = 1.255, time/batch=0.129\n",
      "14013/67600 (epoch 10), train_loss = 1.204, time/batch=0.117\n",
      "14014/67600 (epoch 10), train_loss = 1.286, time/batch=0.102\n",
      "14015/67600 (epoch 10), train_loss = 1.248, time/batch=0.145\n",
      "14016/67600 (epoch 10), train_loss = 1.220, time/batch=0.235\n",
      "14017/67600 (epoch 10), train_loss = 1.247, time/batch=0.113\n",
      "14018/67600 (epoch 10), train_loss = 1.296, time/batch=0.154\n",
      "14019/67600 (epoch 10), train_loss = 1.239, time/batch=0.113\n",
      "14020/67600 (epoch 10), train_loss = 1.186, time/batch=0.136\n",
      "14021/67600 (epoch 10), train_loss = 1.191, time/batch=0.149\n",
      "14022/67600 (epoch 10), train_loss = 1.213, time/batch=0.117\n",
      "14023/67600 (epoch 10), train_loss = 1.247, time/batch=0.274\n",
      "14024/67600 (epoch 10), train_loss = 1.260, time/batch=0.143\n",
      "14025/67600 (epoch 10), train_loss = 1.277, time/batch=0.131\n",
      "14026/67600 (epoch 10), train_loss = 1.250, time/batch=0.125\n",
      "14027/67600 (epoch 10), train_loss = 1.259, time/batch=0.119\n",
      "14028/67600 (epoch 10), train_loss = 1.192, time/batch=0.114\n",
      "14029/67600 (epoch 10), train_loss = 1.226, time/batch=0.137\n",
      "14030/67600 (epoch 10), train_loss = 1.257, time/batch=0.257\n",
      "14031/67600 (epoch 10), train_loss = 1.244, time/batch=0.169\n",
      "14032/67600 (epoch 10), train_loss = 1.252, time/batch=0.111\n",
      "14033/67600 (epoch 10), train_loss = 1.216, time/batch=0.133\n",
      "14034/67600 (epoch 10), train_loss = 1.252, time/batch=0.124\n",
      "14035/67600 (epoch 10), train_loss = 1.273, time/batch=0.128\n",
      "14036/67600 (epoch 10), train_loss = 1.280, time/batch=0.105\n",
      "14037/67600 (epoch 10), train_loss = 1.261, time/batch=0.285\n",
      "14038/67600 (epoch 10), train_loss = 1.252, time/batch=0.125\n",
      "14039/67600 (epoch 10), train_loss = 1.178, time/batch=0.147\n",
      "14040/67600 (epoch 10), train_loss = 1.283, time/batch=0.123\n",
      "14041/67600 (epoch 10), train_loss = 1.288, time/batch=0.121\n",
      "14042/67600 (epoch 10), train_loss = 1.297, time/batch=0.133\n",
      "14043/67600 (epoch 10), train_loss = 1.247, time/batch=0.281\n",
      "14044/67600 (epoch 10), train_loss = 1.233, time/batch=0.100\n",
      "14045/67600 (epoch 10), train_loss = 1.242, time/batch=0.132\n",
      "14046/67600 (epoch 10), train_loss = 1.255, time/batch=0.117\n",
      "14047/67600 (epoch 10), train_loss = 1.211, time/batch=0.116\n",
      "14048/67600 (epoch 10), train_loss = 1.272, time/batch=0.137\n",
      "14049/67600 (epoch 10), train_loss = 1.233, time/batch=0.156\n",
      "14050/67600 (epoch 10), train_loss = 1.289, time/batch=0.143\n",
      "14051/67600 (epoch 10), train_loss = 1.274, time/batch=0.111\n",
      "14052/67600 (epoch 10), train_loss = 1.258, time/batch=0.123\n",
      "14053/67600 (epoch 10), train_loss = 1.214, time/batch=0.124\n",
      "14054/67600 (epoch 10), train_loss = 1.225, time/batch=0.328\n",
      "14055/67600 (epoch 10), train_loss = 1.190, time/batch=0.155\n",
      "14056/67600 (epoch 10), train_loss = 1.217, time/batch=0.106\n",
      "14057/67600 (epoch 10), train_loss = 1.242, time/batch=0.118\n",
      "14058/67600 (epoch 10), train_loss = 1.230, time/batch=0.165\n",
      "14059/67600 (epoch 10), train_loss = 1.242, time/batch=0.102\n",
      "14060/67600 (epoch 10), train_loss = 1.246, time/batch=0.138\n",
      "14061/67600 (epoch 10), train_loss = 1.188, time/batch=0.272\n",
      "14062/67600 (epoch 10), train_loss = 1.219, time/batch=0.130\n",
      "14063/67600 (epoch 10), train_loss = 1.197, time/batch=0.120\n",
      "14064/67600 (epoch 10), train_loss = 1.284, time/batch=0.134\n",
      "14065/67600 (epoch 10), train_loss = 1.239, time/batch=0.133\n",
      "14066/67600 (epoch 10), train_loss = 1.222, time/batch=0.275\n",
      "14067/67600 (epoch 10), train_loss = 1.235, time/batch=0.109\n",
      "14068/67600 (epoch 10), train_loss = 1.358, time/batch=0.161\n",
      "14069/67600 (epoch 10), train_loss = 1.271, time/batch=0.098\n",
      "14070/67600 (epoch 10), train_loss = 1.223, time/batch=0.132\n",
      "14071/67600 (epoch 10), train_loss = 1.276, time/batch=0.104\n",
      "14072/67600 (epoch 10), train_loss = 1.228, time/batch=0.235\n",
      "14073/67600 (epoch 10), train_loss = 1.224, time/batch=0.185\n",
      "14074/67600 (epoch 10), train_loss = 1.272, time/batch=0.129\n",
      "14075/67600 (epoch 10), train_loss = 1.221, time/batch=0.137\n",
      "14076/67600 (epoch 10), train_loss = 1.298, time/batch=0.118\n",
      "14077/67600 (epoch 10), train_loss = 1.224, time/batch=0.108\n",
      "14078/67600 (epoch 10), train_loss = 1.213, time/batch=0.128\n",
      "14079/67600 (epoch 10), train_loss = 1.171, time/batch=0.221\n",
      "14080/67600 (epoch 10), train_loss = 1.203, time/batch=0.187\n",
      "14081/67600 (epoch 10), train_loss = 1.225, time/batch=0.114\n",
      "14082/67600 (epoch 10), train_loss = 1.180, time/batch=0.124\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14083/67600 (epoch 10), train_loss = 1.223, time/batch=0.109\n",
      "14084/67600 (epoch 10), train_loss = 1.201, time/batch=0.107\n",
      "14085/67600 (epoch 10), train_loss = 1.219, time/batch=0.123\n",
      "14086/67600 (epoch 10), train_loss = 1.243, time/batch=0.189\n",
      "14087/67600 (epoch 10), train_loss = 1.260, time/batch=0.142\n",
      "14088/67600 (epoch 10), train_loss = 1.251, time/batch=0.138\n",
      "14089/67600 (epoch 10), train_loss = 1.217, time/batch=0.104\n",
      "14090/67600 (epoch 10), train_loss = 1.200, time/batch=0.169\n",
      "14091/67600 (epoch 10), train_loss = 1.191, time/batch=0.142\n",
      "14092/67600 (epoch 10), train_loss = 1.217, time/batch=0.123\n",
      "14093/67600 (epoch 10), train_loss = 1.230, time/batch=0.273\n",
      "14094/67600 (epoch 10), train_loss = 1.247, time/batch=0.125\n",
      "14095/67600 (epoch 10), train_loss = 1.205, time/batch=0.130\n",
      "14096/67600 (epoch 10), train_loss = 1.249, time/batch=0.118\n",
      "14097/67600 (epoch 10), train_loss = 1.236, time/batch=0.116\n",
      "14098/67600 (epoch 10), train_loss = 1.262, time/batch=0.107\n",
      "14099/67600 (epoch 10), train_loss = 1.233, time/batch=0.133\n",
      "14100/67600 (epoch 10), train_loss = 1.265, time/batch=0.135\n",
      "14101/67600 (epoch 10), train_loss = 1.238, time/batch=0.208\n",
      "14102/67600 (epoch 10), train_loss = 1.189, time/batch=0.121\n",
      "14103/67600 (epoch 10), train_loss = 1.209, time/batch=0.109\n",
      "14104/67600 (epoch 10), train_loss = 1.233, time/batch=0.109\n",
      "14105/67600 (epoch 10), train_loss = 1.290, time/batch=0.137\n",
      "14106/67600 (epoch 10), train_loss = 1.213, time/batch=0.220\n",
      "14107/67600 (epoch 10), train_loss = 1.292, time/batch=0.150\n",
      "14108/67600 (epoch 10), train_loss = 1.203, time/batch=0.128\n",
      "14109/67600 (epoch 10), train_loss = 1.235, time/batch=0.124\n",
      "14110/67600 (epoch 10), train_loss = 1.291, time/batch=0.134\n",
      "14111/67600 (epoch 10), train_loss = 1.200, time/batch=0.113\n",
      "14112/67600 (epoch 10), train_loss = 1.213, time/batch=0.132\n",
      "14113/67600 (epoch 10), train_loss = 1.241, time/batch=0.231\n",
      "14114/67600 (epoch 10), train_loss = 1.181, time/batch=0.140\n",
      "14115/67600 (epoch 10), train_loss = 1.225, time/batch=0.112\n",
      "14116/67600 (epoch 10), train_loss = 1.247, time/batch=0.123\n",
      "14117/67600 (epoch 10), train_loss = 1.194, time/batch=0.155\n",
      "14118/67600 (epoch 10), train_loss = 1.227, time/batch=0.118\n",
      "14119/67600 (epoch 10), train_loss = 1.220, time/batch=0.151\n",
      "14120/67600 (epoch 10), train_loss = 1.264, time/batch=0.338\n",
      "14121/67600 (epoch 10), train_loss = 1.177, time/batch=0.117\n",
      "14122/67600 (epoch 10), train_loss = 1.239, time/batch=0.148\n",
      "14123/67600 (epoch 10), train_loss = 1.220, time/batch=0.125\n",
      "14124/67600 (epoch 10), train_loss = 1.258, time/batch=0.116\n",
      "14125/67600 (epoch 10), train_loss = 1.208, time/batch=0.134\n",
      "14126/67600 (epoch 10), train_loss = 1.283, time/batch=0.251\n",
      "14127/67600 (epoch 10), train_loss = 1.216, time/batch=0.130\n",
      "14128/67600 (epoch 10), train_loss = 1.298, time/batch=0.110\n",
      "14129/67600 (epoch 10), train_loss = 1.226, time/batch=0.127\n",
      "14130/67600 (epoch 10), train_loss = 1.250, time/batch=0.109\n",
      "14131/67600 (epoch 10), train_loss = 1.322, time/batch=0.130\n",
      "14132/67600 (epoch 10), train_loss = 1.234, time/batch=0.120\n",
      "14133/67600 (epoch 10), train_loss = 1.230, time/batch=0.253\n",
      "14134/67600 (epoch 10), train_loss = 1.262, time/batch=0.137\n",
      "14135/67600 (epoch 10), train_loss = 1.293, time/batch=0.121\n",
      "14136/67600 (epoch 10), train_loss = 1.251, time/batch=0.121\n",
      "14137/67600 (epoch 10), train_loss = 1.315, time/batch=0.123\n",
      "14138/67600 (epoch 10), train_loss = 1.241, time/batch=0.111\n",
      "14139/67600 (epoch 10), train_loss = 1.203, time/batch=0.121\n",
      "14140/67600 (epoch 10), train_loss = 1.188, time/batch=0.264\n",
      "14141/67600 (epoch 10), train_loss = 1.231, time/batch=0.123\n",
      "14142/67600 (epoch 10), train_loss = 1.239, time/batch=0.138\n",
      "14143/67600 (epoch 10), train_loss = 1.197, time/batch=0.125\n",
      "14144/67600 (epoch 10), train_loss = 1.238, time/batch=0.108\n",
      "14145/67600 (epoch 10), train_loss = 1.226, time/batch=0.165\n",
      "14146/67600 (epoch 10), train_loss = 1.273, time/batch=0.109\n",
      "14147/67600 (epoch 10), train_loss = 1.277, time/batch=0.126\n",
      "14148/67600 (epoch 10), train_loss = 1.269, time/batch=0.116\n",
      "14149/67600 (epoch 10), train_loss = 1.236, time/batch=0.126\n",
      "14150/67600 (epoch 10), train_loss = 1.273, time/batch=0.121\n",
      "14151/67600 (epoch 10), train_loss = 1.306, time/batch=0.287\n",
      "14152/67600 (epoch 10), train_loss = 1.216, time/batch=0.133\n",
      "14153/67600 (epoch 10), train_loss = 1.292, time/batch=0.119\n",
      "14154/67600 (epoch 10), train_loss = 1.285, time/batch=0.116\n",
      "14155/67600 (epoch 10), train_loss = 1.162, time/batch=0.135\n",
      "14156/67600 (epoch 10), train_loss = 1.313, time/batch=0.098\n",
      "14157/67600 (epoch 10), train_loss = 1.215, time/batch=0.114\n",
      "14158/67600 (epoch 10), train_loss = 1.170, time/batch=0.273\n",
      "14159/67600 (epoch 10), train_loss = 1.163, time/batch=0.129\n",
      "14160/67600 (epoch 10), train_loss = 1.242, time/batch=0.104\n",
      "14161/67600 (epoch 10), train_loss = 1.217, time/batch=0.110\n",
      "14162/67600 (epoch 10), train_loss = 1.272, time/batch=0.133\n",
      "14163/67600 (epoch 10), train_loss = 1.315, time/batch=0.155\n",
      "14164/67600 (epoch 10), train_loss = 1.293, time/batch=0.225\n",
      "14165/67600 (epoch 10), train_loss = 1.229, time/batch=0.113\n",
      "14166/67600 (epoch 10), train_loss = 1.269, time/batch=0.131\n",
      "14167/67600 (epoch 10), train_loss = 1.257, time/batch=0.127\n",
      "14168/67600 (epoch 10), train_loss = 1.283, time/batch=0.136\n",
      "14169/67600 (epoch 10), train_loss = 1.247, time/batch=0.118\n",
      "14170/67600 (epoch 10), train_loss = 1.289, time/batch=0.115\n",
      "14171/67600 (epoch 10), train_loss = 1.311, time/batch=0.273\n",
      "14172/67600 (epoch 10), train_loss = 1.235, time/batch=0.103\n",
      "14173/67600 (epoch 10), train_loss = 1.227, time/batch=0.141\n",
      "14174/67600 (epoch 10), train_loss = 1.254, time/batch=0.103\n",
      "14175/67600 (epoch 10), train_loss = 1.238, time/batch=0.118\n",
      "14176/67600 (epoch 10), train_loss = 1.238, time/batch=0.116\n",
      "14177/67600 (epoch 10), train_loss = 1.307, time/batch=0.173\n",
      "14178/67600 (epoch 10), train_loss = 1.262, time/batch=0.177\n",
      "14179/67600 (epoch 10), train_loss = 1.179, time/batch=0.167\n",
      "14180/67600 (epoch 10), train_loss = 1.236, time/batch=0.087\n",
      "14181/67600 (epoch 10), train_loss = 1.232, time/batch=0.147\n",
      "14182/67600 (epoch 10), train_loss = 1.155, time/batch=0.107\n",
      "14183/67600 (epoch 10), train_loss = 1.187, time/batch=0.113\n",
      "14184/67600 (epoch 10), train_loss = 1.275, time/batch=0.142\n",
      "14185/67600 (epoch 10), train_loss = 1.247, time/batch=0.224\n",
      "14186/67600 (epoch 10), train_loss = 1.262, time/batch=0.139\n",
      "14187/67600 (epoch 10), train_loss = 1.236, time/batch=0.121\n",
      "14188/67600 (epoch 10), train_loss = 1.293, time/batch=0.131\n",
      "14189/67600 (epoch 10), train_loss = 1.202, time/batch=0.092\n",
      "14190/67600 (epoch 10), train_loss = 1.148, time/batch=0.121\n",
      "14191/67600 (epoch 10), train_loss = 1.216, time/batch=0.125\n",
      "14192/67600 (epoch 10), train_loss = 1.161, time/batch=0.251\n",
      "14193/67600 (epoch 10), train_loss = 1.301, time/batch=0.124\n",
      "14194/67600 (epoch 10), train_loss = 1.286, time/batch=0.109\n",
      "14195/67600 (epoch 10), train_loss = 1.210, time/batch=0.134\n",
      "14196/67600 (epoch 10), train_loss = 1.249, time/batch=0.115\n",
      "14197/67600 (epoch 10), train_loss = 1.276, time/batch=0.119\n",
      "14198/67600 (epoch 10), train_loss = 1.289, time/batch=0.113\n",
      "14199/67600 (epoch 10), train_loss = 1.219, time/batch=0.190\n",
      "14200/67600 (epoch 10), train_loss = 1.245, time/batch=0.187\n",
      "14201/67600 (epoch 10), train_loss = 1.264, time/batch=0.105\n",
      "14202/67600 (epoch 10), train_loss = 1.262, time/batch=0.136\n",
      "14203/67600 (epoch 10), train_loss = 1.232, time/batch=0.109\n",
      "14204/67600 (epoch 10), train_loss = 1.211, time/batch=0.103\n",
      "14205/67600 (epoch 10), train_loss = 1.297, time/batch=0.218\n",
      "14206/67600 (epoch 10), train_loss = 1.252, time/batch=0.170\n",
      "14207/67600 (epoch 10), train_loss = 1.196, time/batch=0.111\n",
      "14208/67600 (epoch 10), train_loss = 1.241, time/batch=0.127\n",
      "14209/67600 (epoch 10), train_loss = 1.196, time/batch=0.134\n",
      "14210/67600 (epoch 10), train_loss = 1.227, time/batch=0.117\n",
      "14211/67600 (epoch 10), train_loss = 1.228, time/batch=0.115\n",
      "14212/67600 (epoch 10), train_loss = 1.215, time/batch=0.226\n",
      "14213/67600 (epoch 10), train_loss = 1.262, time/batch=0.143\n",
      "14214/67600 (epoch 10), train_loss = 1.246, time/batch=0.114\n",
      "14215/67600 (epoch 10), train_loss = 1.164, time/batch=0.121\n",
      "14216/67600 (epoch 10), train_loss = 1.264, time/batch=0.111\n",
      "14217/67600 (epoch 10), train_loss = 1.272, time/batch=0.119\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14218/67600 (epoch 10), train_loss = 1.263, time/batch=0.117\n",
      "14219/67600 (epoch 10), train_loss = 1.196, time/batch=0.241\n",
      "14220/67600 (epoch 10), train_loss = 1.248, time/batch=0.153\n",
      "14221/67600 (epoch 10), train_loss = 1.268, time/batch=0.110\n",
      "14222/67600 (epoch 10), train_loss = 1.233, time/batch=0.123\n",
      "14223/67600 (epoch 10), train_loss = 1.185, time/batch=0.123\n",
      "14224/67600 (epoch 10), train_loss = 1.229, time/batch=0.119\n",
      "14225/67600 (epoch 10), train_loss = 1.217, time/batch=0.122\n",
      "14226/67600 (epoch 10), train_loss = 1.214, time/batch=0.158\n",
      "14227/67600 (epoch 10), train_loss = 1.264, time/batch=0.207\n",
      "14228/67600 (epoch 10), train_loss = 1.252, time/batch=0.124\n",
      "14229/67600 (epoch 10), train_loss = 1.197, time/batch=0.118\n",
      "14230/67600 (epoch 10), train_loss = 1.233, time/batch=0.119\n",
      "14231/67600 (epoch 10), train_loss = 1.143, time/batch=0.105\n",
      "14232/67600 (epoch 10), train_loss = 1.236, time/batch=0.119\n",
      "14233/67600 (epoch 10), train_loss = 1.225, time/batch=0.120\n",
      "14234/67600 (epoch 10), train_loss = 1.225, time/batch=0.261\n",
      "14235/67600 (epoch 10), train_loss = 1.214, time/batch=0.121\n",
      "14236/67600 (epoch 10), train_loss = 1.183, time/batch=0.111\n",
      "14237/67600 (epoch 10), train_loss = 1.229, time/batch=0.121\n",
      "14238/67600 (epoch 10), train_loss = 1.208, time/batch=0.135\n",
      "14239/67600 (epoch 10), train_loss = 1.216, time/batch=0.216\n",
      "14240/67600 (epoch 10), train_loss = 1.221, time/batch=0.143\n",
      "14241/67600 (epoch 10), train_loss = 1.261, time/batch=0.148\n",
      "14242/67600 (epoch 10), train_loss = 1.229, time/batch=0.127\n",
      "14243/67600 (epoch 10), train_loss = 1.247, time/batch=0.113\n",
      "14244/67600 (epoch 10), train_loss = 1.237, time/batch=0.117\n",
      "14245/67600 (epoch 10), train_loss = 1.255, time/batch=0.125\n",
      "14246/67600 (epoch 10), train_loss = 1.235, time/batch=0.135\n",
      "14247/67600 (epoch 10), train_loss = 1.243, time/batch=0.145\n",
      "14248/67600 (epoch 10), train_loss = 1.255, time/batch=0.118\n",
      "14249/67600 (epoch 10), train_loss = 1.218, time/batch=0.114\n",
      "14250/67600 (epoch 10), train_loss = 1.248, time/batch=0.107\n",
      "14251/67600 (epoch 10), train_loss = 1.271, time/batch=0.126\n",
      "14252/67600 (epoch 10), train_loss = 1.248, time/batch=0.315\n",
      "14253/67600 (epoch 10), train_loss = 1.243, time/batch=0.155\n",
      "14254/67600 (epoch 10), train_loss = 1.246, time/batch=0.116\n",
      "14255/67600 (epoch 10), train_loss = 1.195, time/batch=0.115\n",
      "14256/67600 (epoch 10), train_loss = 1.294, time/batch=0.113\n",
      "14257/67600 (epoch 10), train_loss = 1.218, time/batch=0.132\n",
      "14258/67600 (epoch 10), train_loss = 1.185, time/batch=0.131\n",
      "14259/67600 (epoch 10), train_loss = 1.263, time/batch=0.250\n",
      "14260/67600 (epoch 10), train_loss = 1.170, time/batch=0.134\n",
      "14261/67600 (epoch 10), train_loss = 1.195, time/batch=0.131\n",
      "14262/67600 (epoch 10), train_loss = 1.173, time/batch=0.110\n",
      "14263/67600 (epoch 10), train_loss = 1.215, time/batch=0.124\n",
      "14264/67600 (epoch 10), train_loss = 1.248, time/batch=0.109\n",
      "14265/67600 (epoch 10), train_loss = 1.249, time/batch=0.125\n",
      "14266/67600 (epoch 10), train_loss = 1.214, time/batch=0.254\n",
      "14267/67600 (epoch 10), train_loss = 1.231, time/batch=0.119\n",
      "14268/67600 (epoch 10), train_loss = 1.249, time/batch=0.129\n",
      "14269/67600 (epoch 10), train_loss = 1.202, time/batch=0.119\n",
      "14270/67600 (epoch 10), train_loss = 1.170, time/batch=0.115\n",
      "14271/67600 (epoch 10), train_loss = 1.203, time/batch=0.235\n",
      "14272/67600 (epoch 10), train_loss = 1.228, time/batch=0.155\n",
      "14273/67600 (epoch 10), train_loss = 1.280, time/batch=0.125\n",
      "14274/67600 (epoch 10), train_loss = 1.217, time/batch=0.129\n",
      "14275/67600 (epoch 10), train_loss = 1.226, time/batch=0.122\n",
      "14276/67600 (epoch 10), train_loss = 1.296, time/batch=0.107\n",
      "14277/67600 (epoch 10), train_loss = 1.239, time/batch=0.136\n",
      "14278/67600 (epoch 10), train_loss = 1.214, time/batch=0.238\n",
      "14279/67600 (epoch 10), train_loss = 1.198, time/batch=0.147\n",
      "14280/67600 (epoch 10), train_loss = 1.219, time/batch=0.120\n",
      "14281/67600 (epoch 10), train_loss = 1.218, time/batch=0.127\n",
      "14282/67600 (epoch 10), train_loss = 1.226, time/batch=0.114\n",
      "14283/67600 (epoch 10), train_loss = 1.264, time/batch=0.122\n",
      "14284/67600 (epoch 10), train_loss = 1.271, time/batch=0.120\n",
      "14285/67600 (epoch 10), train_loss = 1.200, time/batch=0.251\n",
      "14286/67600 (epoch 10), train_loss = 1.237, time/batch=0.134\n",
      "14287/67600 (epoch 10), train_loss = 1.225, time/batch=0.119\n",
      "14288/67600 (epoch 10), train_loss = 1.255, time/batch=0.123\n",
      "14289/67600 (epoch 10), train_loss = 1.261, time/batch=0.129\n",
      "14290/67600 (epoch 10), train_loss = 1.214, time/batch=0.117\n",
      "14291/67600 (epoch 10), train_loss = 1.277, time/batch=0.121\n",
      "14292/67600 (epoch 10), train_loss = 1.248, time/batch=0.266\n",
      "14293/67600 (epoch 10), train_loss = 1.213, time/batch=0.126\n",
      "14294/67600 (epoch 10), train_loss = 1.262, time/batch=0.151\n",
      "14295/67600 (epoch 10), train_loss = 1.308, time/batch=0.161\n",
      "14296/67600 (epoch 10), train_loss = 1.269, time/batch=0.116\n",
      "14297/67600 (epoch 10), train_loss = 1.252, time/batch=0.115\n",
      "14298/67600 (epoch 10), train_loss = 1.231, time/batch=0.138\n",
      "14299/67600 (epoch 10), train_loss = 1.256, time/batch=0.245\n",
      "14300/67600 (epoch 10), train_loss = 1.293, time/batch=0.135\n",
      "14301/67600 (epoch 10), train_loss = 1.226, time/batch=0.110\n",
      "14302/67600 (epoch 10), train_loss = 1.215, time/batch=0.125\n",
      "14303/67600 (epoch 10), train_loss = 1.246, time/batch=0.107\n",
      "14304/67600 (epoch 10), train_loss = 1.223, time/batch=0.225\n",
      "14305/67600 (epoch 10), train_loss = 1.265, time/batch=0.154\n",
      "14306/67600 (epoch 10), train_loss = 1.236, time/batch=0.116\n",
      "14307/67600 (epoch 10), train_loss = 1.241, time/batch=0.117\n",
      "14308/67600 (epoch 10), train_loss = 1.251, time/batch=0.117\n",
      "14309/67600 (epoch 10), train_loss = 1.201, time/batch=0.123\n",
      "14310/67600 (epoch 10), train_loss = 1.228, time/batch=0.117\n",
      "14311/67600 (epoch 10), train_loss = 1.238, time/batch=0.213\n",
      "14312/67600 (epoch 10), train_loss = 1.209, time/batch=0.107\n",
      "14313/67600 (epoch 10), train_loss = 1.261, time/batch=0.157\n",
      "14314/67600 (epoch 10), train_loss = 1.232, time/batch=0.118\n",
      "14315/67600 (epoch 10), train_loss = 1.241, time/batch=0.109\n",
      "14316/67600 (epoch 10), train_loss = 1.302, time/batch=0.122\n",
      "14317/67600 (epoch 10), train_loss = 1.248, time/batch=0.133\n",
      "14318/67600 (epoch 10), train_loss = 1.280, time/batch=0.137\n",
      "14319/67600 (epoch 10), train_loss = 1.232, time/batch=0.209\n",
      "14320/67600 (epoch 10), train_loss = 1.247, time/batch=0.157\n",
      "14321/67600 (epoch 10), train_loss = 1.236, time/batch=0.115\n",
      "14322/67600 (epoch 10), train_loss = 1.217, time/batch=0.146\n",
      "14323/67600 (epoch 10), train_loss = 1.236, time/batch=0.105\n",
      "14324/67600 (epoch 10), train_loss = 1.210, time/batch=0.127\n",
      "14325/67600 (epoch 10), train_loss = 1.180, time/batch=0.137\n",
      "14326/67600 (epoch 10), train_loss = 1.243, time/batch=0.223\n",
      "14327/67600 (epoch 10), train_loss = 1.217, time/batch=0.144\n",
      "14328/67600 (epoch 10), train_loss = 1.154, time/batch=0.112\n",
      "14329/67600 (epoch 10), train_loss = 1.254, time/batch=0.118\n",
      "14330/67600 (epoch 10), train_loss = 1.187, time/batch=0.116\n",
      "14331/67600 (epoch 10), train_loss = 1.267, time/batch=0.137\n",
      "14332/67600 (epoch 10), train_loss = 1.255, time/batch=0.088\n",
      "14333/67600 (epoch 10), train_loss = 1.247, time/batch=0.266\n",
      "14334/67600 (epoch 10), train_loss = 1.269, time/batch=0.126\n",
      "14335/67600 (epoch 10), train_loss = 1.187, time/batch=0.107\n",
      "14336/67600 (epoch 10), train_loss = 1.277, time/batch=0.125\n",
      "14337/67600 (epoch 10), train_loss = 1.211, time/batch=0.116\n",
      "14338/67600 (epoch 10), train_loss = 1.207, time/batch=0.231\n",
      "14339/67600 (epoch 10), train_loss = 1.230, time/batch=0.124\n",
      "14340/67600 (epoch 10), train_loss = 1.158, time/batch=0.143\n",
      "14341/67600 (epoch 10), train_loss = 1.275, time/batch=0.124\n",
      "14342/67600 (epoch 10), train_loss = 1.237, time/batch=0.130\n",
      "14343/67600 (epoch 10), train_loss = 1.302, time/batch=0.118\n",
      "14344/67600 (epoch 10), train_loss = 1.248, time/batch=0.108\n",
      "14345/67600 (epoch 10), train_loss = 1.278, time/batch=0.175\n",
      "14346/67600 (epoch 10), train_loss = 1.371, time/batch=0.098\n",
      "14347/67600 (epoch 10), train_loss = 1.210, time/batch=0.141\n",
      "14348/67600 (epoch 10), train_loss = 1.238, time/batch=0.118\n",
      "14349/67600 (epoch 10), train_loss = 1.272, time/batch=0.121\n",
      "14350/67600 (epoch 10), train_loss = 1.316, time/batch=0.114\n",
      "14351/67600 (epoch 10), train_loss = 1.216, time/batch=0.273\n",
      "14352/67600 (epoch 10), train_loss = 1.230, time/batch=0.142\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14353/67600 (epoch 10), train_loss = 1.233, time/batch=0.121\n",
      "14354/67600 (epoch 10), train_loss = 1.199, time/batch=0.122\n",
      "14355/67600 (epoch 10), train_loss = 1.277, time/batch=0.132\n",
      "14356/67600 (epoch 10), train_loss = 1.131, time/batch=0.120\n",
      "14357/67600 (epoch 10), train_loss = 1.267, time/batch=0.120\n",
      "14358/67600 (epoch 10), train_loss = 1.172, time/batch=0.188\n",
      "14359/67600 (epoch 10), train_loss = 1.231, time/batch=0.198\n",
      "14360/67600 (epoch 10), train_loss = 1.288, time/batch=0.119\n",
      "14361/67600 (epoch 10), train_loss = 1.250, time/batch=0.124\n",
      "14362/67600 (epoch 10), train_loss = 1.244, time/batch=0.111\n",
      "14363/67600 (epoch 10), train_loss = 1.246, time/batch=0.128\n",
      "14364/67600 (epoch 10), train_loss = 1.236, time/batch=0.115\n",
      "14365/67600 (epoch 10), train_loss = 1.222, time/batch=0.137\n",
      "14366/67600 (epoch 10), train_loss = 1.214, time/batch=0.240\n",
      "14367/67600 (epoch 10), train_loss = 1.220, time/batch=0.123\n",
      "14368/67600 (epoch 10), train_loss = 1.251, time/batch=0.125\n",
      "14369/67600 (epoch 10), train_loss = 1.230, time/batch=0.134\n",
      "14370/67600 (epoch 10), train_loss = 1.232, time/batch=0.199\n",
      "14371/67600 (epoch 10), train_loss = 1.310, time/batch=0.147\n",
      "14372/67600 (epoch 10), train_loss = 1.313, time/batch=0.149\n",
      "14373/67600 (epoch 10), train_loss = 1.291, time/batch=0.136\n",
      "14374/67600 (epoch 10), train_loss = 1.231, time/batch=0.117\n",
      "14375/67600 (epoch 10), train_loss = 1.271, time/batch=0.124\n",
      "14376/67600 (epoch 10), train_loss = 1.238, time/batch=0.131\n",
      "14377/67600 (epoch 10), train_loss = 1.256, time/batch=0.293\n",
      "14378/67600 (epoch 10), train_loss = 1.276, time/batch=0.171\n",
      "14379/67600 (epoch 10), train_loss = 1.287, time/batch=0.094\n",
      "14380/67600 (epoch 10), train_loss = 1.246, time/batch=0.163\n",
      "14381/67600 (epoch 10), train_loss = 1.295, time/batch=0.144\n",
      "14382/67600 (epoch 10), train_loss = 1.317, time/batch=0.114\n",
      "14383/67600 (epoch 10), train_loss = 1.268, time/batch=0.110\n",
      "14384/67600 (epoch 10), train_loss = 1.202, time/batch=0.224\n",
      "14385/67600 (epoch 10), train_loss = 1.296, time/batch=0.166\n",
      "14386/67600 (epoch 10), train_loss = 1.281, time/batch=0.123\n",
      "14387/67600 (epoch 10), train_loss = 1.221, time/batch=0.121\n",
      "14388/67600 (epoch 10), train_loss = 1.242, time/batch=0.125\n",
      "14389/67600 (epoch 10), train_loss = 1.234, time/batch=0.105\n",
      "14390/67600 (epoch 10), train_loss = 1.244, time/batch=0.145\n",
      "14391/67600 (epoch 10), train_loss = 1.216, time/batch=0.251\n",
      "14392/67600 (epoch 10), train_loss = 1.277, time/batch=0.135\n",
      "14393/67600 (epoch 10), train_loss = 1.200, time/batch=0.117\n",
      "14394/67600 (epoch 10), train_loss = 1.246, time/batch=0.116\n",
      "14395/67600 (epoch 10), train_loss = 1.294, time/batch=0.127\n",
      "14396/67600 (epoch 10), train_loss = 1.274, time/batch=0.111\n",
      "14397/67600 (epoch 10), train_loss = 1.150, time/batch=0.115\n",
      "14398/67600 (epoch 10), train_loss = 1.239, time/batch=0.253\n",
      "14399/67600 (epoch 10), train_loss = 1.143, time/batch=0.107\n",
      "14400/67600 (epoch 10), train_loss = 1.201, time/batch=0.135\n",
      "14401/67600 (epoch 10), train_loss = 1.210, time/batch=0.116\n",
      "14402/67600 (epoch 10), train_loss = 1.215, time/batch=0.116\n",
      "14403/67600 (epoch 10), train_loss = 1.239, time/batch=0.230\n",
      "14404/67600 (epoch 10), train_loss = 1.215, time/batch=0.148\n",
      "14405/67600 (epoch 10), train_loss = 1.230, time/batch=0.127\n",
      "14406/67600 (epoch 10), train_loss = 1.208, time/batch=0.132\n",
      "14407/67600 (epoch 10), train_loss = 1.179, time/batch=0.116\n",
      "14408/67600 (epoch 10), train_loss = 1.292, time/batch=0.126\n",
      "14409/67600 (epoch 10), train_loss = 1.263, time/batch=0.107\n",
      "14410/67600 (epoch 10), train_loss = 1.289, time/batch=0.243\n",
      "14411/67600 (epoch 10), train_loss = 1.280, time/batch=0.133\n",
      "14412/67600 (epoch 10), train_loss = 1.255, time/batch=0.126\n",
      "14413/67600 (epoch 10), train_loss = 1.216, time/batch=0.112\n",
      "14414/67600 (epoch 10), train_loss = 1.260, time/batch=0.112\n",
      "14415/67600 (epoch 10), train_loss = 1.223, time/batch=0.134\n",
      "14416/67600 (epoch 10), train_loss = 1.239, time/batch=0.105\n",
      "14417/67600 (epoch 10), train_loss = 1.308, time/batch=0.136\n",
      "14418/67600 (epoch 10), train_loss = 1.265, time/batch=0.193\n",
      "14419/67600 (epoch 10), train_loss = 1.277, time/batch=0.144\n",
      "14420/67600 (epoch 10), train_loss = 1.252, time/batch=0.113\n",
      "14421/67600 (epoch 10), train_loss = 1.288, time/batch=0.103\n",
      "14422/67600 (epoch 10), train_loss = 1.288, time/batch=0.114\n",
      "14423/67600 (epoch 10), train_loss = 1.183, time/batch=0.123\n",
      "14424/67600 (epoch 10), train_loss = 1.222, time/batch=0.111\n",
      "14425/67600 (epoch 10), train_loss = 1.272, time/batch=0.221\n",
      "14426/67600 (epoch 10), train_loss = 1.228, time/batch=0.143\n",
      "14427/67600 (epoch 10), train_loss = 1.217, time/batch=0.118\n",
      "14428/67600 (epoch 10), train_loss = 1.291, time/batch=0.101\n",
      "14429/67600 (epoch 10), train_loss = 1.221, time/batch=0.114\n",
      "14430/67600 (epoch 10), train_loss = 1.228, time/batch=0.129\n",
      "14431/67600 (epoch 10), train_loss = 1.255, time/batch=0.103\n",
      "14432/67600 (epoch 10), train_loss = 1.229, time/batch=0.104\n",
      "14433/67600 (epoch 10), train_loss = 1.262, time/batch=0.238\n",
      "14434/67600 (epoch 10), train_loss = 1.280, time/batch=0.145\n",
      "14435/67600 (epoch 10), train_loss = 1.215, time/batch=0.109\n",
      "14436/67600 (epoch 10), train_loss = 1.234, time/batch=0.102\n",
      "14437/67600 (epoch 10), train_loss = 1.225, time/batch=0.114\n",
      "14438/67600 (epoch 10), train_loss = 1.249, time/batch=0.121\n",
      "14439/67600 (epoch 10), train_loss = 1.241, time/batch=0.111\n",
      "14440/67600 (epoch 10), train_loss = 1.266, time/batch=0.109\n",
      "14441/67600 (epoch 10), train_loss = 1.242, time/batch=0.258\n",
      "14442/67600 (epoch 10), train_loss = 1.262, time/batch=0.113\n",
      "14443/67600 (epoch 10), train_loss = 1.202, time/batch=0.126\n",
      "14444/67600 (epoch 10), train_loss = 1.198, time/batch=0.114\n",
      "14445/67600 (epoch 10), train_loss = 1.224, time/batch=0.110\n",
      "14446/67600 (epoch 10), train_loss = 1.218, time/batch=0.152\n",
      "14447/67600 (epoch 10), train_loss = 1.237, time/batch=0.105\n",
      "14448/67600 (epoch 10), train_loss = 1.210, time/batch=0.126\n",
      "14449/67600 (epoch 10), train_loss = 1.227, time/batch=0.101\n",
      "14450/67600 (epoch 10), train_loss = 1.191, time/batch=0.115\n",
      "14451/67600 (epoch 10), train_loss = 1.246, time/batch=0.114\n",
      "14452/67600 (epoch 10), train_loss = 1.218, time/batch=0.174\n",
      "14453/67600 (epoch 10), train_loss = 1.187, time/batch=0.195\n",
      "14454/67600 (epoch 10), train_loss = 1.213, time/batch=0.121\n",
      "14455/67600 (epoch 10), train_loss = 1.209, time/batch=0.121\n",
      "14456/67600 (epoch 10), train_loss = 1.263, time/batch=0.114\n",
      "14457/67600 (epoch 10), train_loss = 1.225, time/batch=0.110\n",
      "14458/67600 (epoch 10), train_loss = 1.216, time/batch=0.104\n",
      "14459/67600 (epoch 10), train_loss = 1.213, time/batch=0.104\n",
      "14460/67600 (epoch 10), train_loss = 1.235, time/batch=0.188\n",
      "14461/67600 (epoch 10), train_loss = 1.197, time/batch=0.152\n",
      "14462/67600 (epoch 10), train_loss = 1.173, time/batch=0.148\n",
      "14463/67600 (epoch 10), train_loss = 1.263, time/batch=0.110\n",
      "14464/67600 (epoch 10), train_loss = 1.222, time/batch=0.107\n",
      "14465/67600 (epoch 10), train_loss = 1.247, time/batch=0.113\n",
      "14466/67600 (epoch 10), train_loss = 1.210, time/batch=0.106\n",
      "14467/67600 (epoch 10), train_loss = 1.190, time/batch=0.110\n",
      "14468/67600 (epoch 10), train_loss = 1.243, time/batch=0.253\n",
      "14469/67600 (epoch 10), train_loss = 1.190, time/batch=0.120\n",
      "14470/67600 (epoch 10), train_loss = 1.255, time/batch=0.113\n",
      "14471/67600 (epoch 10), train_loss = 1.208, time/batch=0.115\n",
      "14472/67600 (epoch 10), train_loss = 1.258, time/batch=0.100\n",
      "14473/67600 (epoch 10), train_loss = 1.196, time/batch=0.103\n",
      "14474/67600 (epoch 10), train_loss = 1.169, time/batch=0.226\n",
      "14475/67600 (epoch 10), train_loss = 1.284, time/batch=0.139\n",
      "14476/67600 (epoch 10), train_loss = 1.251, time/batch=0.115\n",
      "14477/67600 (epoch 10), train_loss = 1.256, time/batch=0.125\n",
      "14478/67600 (epoch 10), train_loss = 1.196, time/batch=0.108\n",
      "14479/67600 (epoch 10), train_loss = 1.209, time/batch=0.110\n",
      "14480/67600 (epoch 10), train_loss = 1.198, time/batch=0.110\n",
      "14481/67600 (epoch 10), train_loss = 1.154, time/batch=0.144\n",
      "14482/67600 (epoch 10), train_loss = 1.172, time/batch=0.164\n",
      "14483/67600 (epoch 10), train_loss = 1.156, time/batch=0.146\n",
      "14484/67600 (epoch 10), train_loss = 1.160, time/batch=0.109\n",
      "14485/67600 (epoch 10), train_loss = 1.241, time/batch=0.120\n",
      "14486/67600 (epoch 10), train_loss = 1.236, time/batch=0.113\n",
      "14487/67600 (epoch 10), train_loss = 1.175, time/batch=0.112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14488/67600 (epoch 10), train_loss = 1.195, time/batch=0.114\n",
      "14489/67600 (epoch 10), train_loss = 1.188, time/batch=0.179\n",
      "14490/67600 (epoch 10), train_loss = 1.218, time/batch=0.187\n",
      "14491/67600 (epoch 10), train_loss = 1.234, time/batch=0.105\n",
      "14492/67600 (epoch 10), train_loss = 1.175, time/batch=0.116\n",
      "14493/67600 (epoch 10), train_loss = 1.241, time/batch=0.107\n",
      "14494/67600 (epoch 10), train_loss = 1.270, time/batch=0.115\n",
      "14495/67600 (epoch 10), train_loss = 1.159, time/batch=0.115\n",
      "14496/67600 (epoch 10), train_loss = 1.162, time/batch=0.111\n",
      "14497/67600 (epoch 10), train_loss = 1.193, time/batch=0.217\n",
      "14498/67600 (epoch 10), train_loss = 1.238, time/batch=0.136\n",
      "14499/67600 (epoch 10), train_loss = 1.215, time/batch=0.104\n",
      "14500/67600 (epoch 10), train_loss = 1.234, time/batch=0.118\n",
      "model saved to ./save/model.ckpt\n",
      "14501/67600 (epoch 10), train_loss = 1.187, time/batch=0.070\n",
      "14502/67600 (epoch 10), train_loss = 1.208, time/batch=0.079\n",
      "14503/67600 (epoch 10), train_loss = 1.252, time/batch=0.095\n",
      "14504/67600 (epoch 10), train_loss = 1.205, time/batch=0.103\n",
      "14505/67600 (epoch 10), train_loss = 1.291, time/batch=0.109\n",
      "14506/67600 (epoch 10), train_loss = 1.226, time/batch=0.231\n",
      "14507/67600 (epoch 10), train_loss = 1.296, time/batch=0.116\n",
      "14508/67600 (epoch 10), train_loss = 1.190, time/batch=0.108\n",
      "14509/67600 (epoch 10), train_loss = 1.221, time/batch=0.113\n",
      "14510/67600 (epoch 10), train_loss = 1.248, time/batch=0.102\n",
      "14511/67600 (epoch 10), train_loss = 1.215, time/batch=0.191\n",
      "14512/67600 (epoch 10), train_loss = 1.267, time/batch=0.142\n",
      "14513/67600 (epoch 10), train_loss = 1.222, time/batch=0.147\n",
      "14514/67600 (epoch 10), train_loss = 1.207, time/batch=0.109\n",
      "14515/67600 (epoch 10), train_loss = 1.222, time/batch=0.121\n",
      "14516/67600 (epoch 10), train_loss = 1.221, time/batch=0.109\n",
      "14517/67600 (epoch 10), train_loss = 1.240, time/batch=0.117\n",
      "14518/67600 (epoch 10), train_loss = 1.188, time/batch=0.108\n",
      "14519/67600 (epoch 10), train_loss = 1.205, time/batch=0.136\n",
      "14520/67600 (epoch 10), train_loss = 1.219, time/batch=0.117\n",
      "14521/67600 (epoch 10), train_loss = 1.235, time/batch=0.112\n",
      "14522/67600 (epoch 10), train_loss = 1.205, time/batch=0.114\n",
      "14523/67600 (epoch 10), train_loss = 1.225, time/batch=0.135\n",
      "14524/67600 (epoch 10), train_loss = 1.172, time/batch=0.121\n",
      "14525/67600 (epoch 10), train_loss = 1.238, time/batch=0.296\n",
      "14526/67600 (epoch 10), train_loss = 1.222, time/batch=0.125\n",
      "14527/67600 (epoch 10), train_loss = 1.187, time/batch=0.110\n",
      "14528/67600 (epoch 10), train_loss = 1.224, time/batch=0.188\n",
      "14529/67600 (epoch 10), train_loss = 1.180, time/batch=0.095\n",
      "14530/67600 (epoch 10), train_loss = 1.201, time/batch=0.144\n",
      "14531/67600 (epoch 10), train_loss = 1.195, time/batch=0.106\n",
      "14532/67600 (epoch 10), train_loss = 1.158, time/batch=0.259\n",
      "14533/67600 (epoch 10), train_loss = 1.204, time/batch=0.112\n",
      "14534/67600 (epoch 10), train_loss = 1.199, time/batch=0.134\n",
      "14535/67600 (epoch 10), train_loss = 1.214, time/batch=0.113\n",
      "14536/67600 (epoch 10), train_loss = 1.192, time/batch=0.111\n",
      "14537/67600 (epoch 10), train_loss = 1.242, time/batch=0.107\n",
      "14538/67600 (epoch 10), train_loss = 1.217, time/batch=0.111\n",
      "14539/67600 (epoch 10), train_loss = 1.230, time/batch=0.238\n",
      "14540/67600 (epoch 10), train_loss = 1.207, time/batch=0.157\n",
      "14541/67600 (epoch 10), train_loss = 1.215, time/batch=0.152\n",
      "14542/67600 (epoch 10), train_loss = 1.212, time/batch=0.132\n",
      "14543/67600 (epoch 10), train_loss = 1.210, time/batch=0.118\n",
      "14544/67600 (epoch 10), train_loss = 1.207, time/batch=0.230\n",
      "14545/67600 (epoch 10), train_loss = 1.167, time/batch=0.165\n",
      "14546/67600 (epoch 10), train_loss = 1.255, time/batch=0.131\n",
      "14547/67600 (epoch 10), train_loss = 1.171, time/batch=0.138\n",
      "14548/67600 (epoch 10), train_loss = 1.261, time/batch=0.131\n",
      "14549/67600 (epoch 10), train_loss = 1.230, time/batch=0.145\n",
      "14550/67600 (epoch 10), train_loss = 1.258, time/batch=0.119\n",
      "14551/67600 (epoch 10), train_loss = 1.269, time/batch=0.239\n",
      "14552/67600 (epoch 10), train_loss = 1.234, time/batch=0.140\n",
      "14553/67600 (epoch 10), train_loss = 1.201, time/batch=0.132\n",
      "14554/67600 (epoch 10), train_loss = 1.223, time/batch=0.143\n",
      "14555/67600 (epoch 10), train_loss = 1.199, time/batch=0.103\n",
      "14556/67600 (epoch 10), train_loss = 1.194, time/batch=0.164\n",
      "14557/67600 (epoch 10), train_loss = 1.185, time/batch=0.148\n",
      "14558/67600 (epoch 10), train_loss = 1.230, time/batch=0.204\n",
      "14559/67600 (epoch 10), train_loss = 1.211, time/batch=0.132\n",
      "14560/67600 (epoch 10), train_loss = 1.226, time/batch=0.116\n",
      "14561/67600 (epoch 10), train_loss = 1.224, time/batch=0.110\n",
      "14562/67600 (epoch 10), train_loss = 1.256, time/batch=0.124\n",
      "14563/67600 (epoch 10), train_loss = 1.123, time/batch=0.119\n",
      "14564/67600 (epoch 10), train_loss = 1.212, time/batch=0.104\n",
      "14565/67600 (epoch 10), train_loss = 1.214, time/batch=0.257\n",
      "14566/67600 (epoch 10), train_loss = 1.221, time/batch=0.103\n",
      "14567/67600 (epoch 10), train_loss = 1.281, time/batch=0.155\n",
      "14568/67600 (epoch 10), train_loss = 1.256, time/batch=0.095\n",
      "14569/67600 (epoch 10), train_loss = 1.238, time/batch=0.147\n",
      "14570/67600 (epoch 10), train_loss = 1.222, time/batch=0.124\n",
      "14571/67600 (epoch 10), train_loss = 1.194, time/batch=0.111\n",
      "14572/67600 (epoch 10), train_loss = 1.231, time/batch=0.222\n",
      "14573/67600 (epoch 10), train_loss = 1.223, time/batch=0.121\n",
      "14574/67600 (epoch 10), train_loss = 1.243, time/batch=0.105\n",
      "14575/67600 (epoch 10), train_loss = 1.222, time/batch=0.116\n",
      "14576/67600 (epoch 10), train_loss = 1.148, time/batch=0.106\n",
      "14577/67600 (epoch 10), train_loss = 1.261, time/batch=0.122\n",
      "14578/67600 (epoch 10), train_loss = 1.298, time/batch=0.205\n",
      "14579/67600 (epoch 10), train_loss = 1.214, time/batch=0.135\n",
      "14580/67600 (epoch 10), train_loss = 1.241, time/batch=0.115\n",
      "14581/67600 (epoch 10), train_loss = 1.247, time/batch=0.102\n",
      "14582/67600 (epoch 10), train_loss = 1.229, time/batch=0.109\n",
      "14583/67600 (epoch 10), train_loss = 1.189, time/batch=0.111\n",
      "14584/67600 (epoch 10), train_loss = 1.234, time/batch=0.116\n",
      "14585/67600 (epoch 10), train_loss = 1.225, time/batch=0.108\n",
      "14586/67600 (epoch 10), train_loss = 1.224, time/batch=0.225\n",
      "14587/67600 (epoch 10), train_loss = 1.266, time/batch=0.132\n",
      "14588/67600 (epoch 10), train_loss = 1.188, time/batch=0.111\n",
      "14589/67600 (epoch 10), train_loss = 1.238, time/batch=0.117\n",
      "14590/67600 (epoch 10), train_loss = 1.257, time/batch=0.108\n",
      "14591/67600 (epoch 10), train_loss = 1.279, time/batch=0.133\n",
      "14592/67600 (epoch 10), train_loss = 1.229, time/batch=0.108\n",
      "14593/67600 (epoch 10), train_loss = 1.210, time/batch=0.164\n",
      "14594/67600 (epoch 10), train_loss = 1.189, time/batch=0.161\n",
      "14595/67600 (epoch 10), train_loss = 1.220, time/batch=0.133\n",
      "14596/67600 (epoch 10), train_loss = 1.271, time/batch=0.098\n",
      "14597/67600 (epoch 10), train_loss = 1.270, time/batch=0.127\n",
      "14598/67600 (epoch 10), train_loss = 1.270, time/batch=0.114\n",
      "14599/67600 (epoch 10), train_loss = 1.260, time/batch=0.109\n",
      "14600/67600 (epoch 10), train_loss = 1.280, time/batch=0.110\n",
      "14601/67600 (epoch 10), train_loss = 1.196, time/batch=0.244\n",
      "14602/67600 (epoch 10), train_loss = 1.259, time/batch=0.119\n",
      "14603/67600 (epoch 10), train_loss = 1.196, time/batch=0.134\n",
      "14604/67600 (epoch 10), train_loss = 1.186, time/batch=0.109\n",
      "14605/67600 (epoch 10), train_loss = 1.300, time/batch=0.110\n",
      "14606/67600 (epoch 10), train_loss = 1.264, time/batch=0.111\n",
      "14607/67600 (epoch 10), train_loss = 1.169, time/batch=0.113\n",
      "14608/67600 (epoch 10), train_loss = 1.208, time/batch=0.113\n",
      "14609/67600 (epoch 10), train_loss = 1.197, time/batch=0.240\n",
      "14610/67600 (epoch 10), train_loss = 1.246, time/batch=0.129\n",
      "14611/67600 (epoch 10), train_loss = 1.208, time/batch=0.103\n",
      "14612/67600 (epoch 10), train_loss = 1.268, time/batch=0.111\n",
      "14613/67600 (epoch 10), train_loss = 1.219, time/batch=0.111\n",
      "14614/67600 (epoch 10), train_loss = 1.224, time/batch=0.120\n",
      "14615/67600 (epoch 10), train_loss = 1.190, time/batch=0.116\n",
      "14616/67600 (epoch 10), train_loss = 1.230, time/batch=0.139\n",
      "14617/67600 (epoch 10), train_loss = 1.218, time/batch=0.226\n",
      "14618/67600 (epoch 10), train_loss = 1.198, time/batch=0.119\n",
      "14619/67600 (epoch 10), train_loss = 1.164, time/batch=0.115\n",
      "14620/67600 (epoch 10), train_loss = 1.234, time/batch=0.105\n",
      "14621/67600 (epoch 10), train_loss = 1.218, time/batch=0.117\n",
      "14622/67600 (epoch 10), train_loss = 1.208, time/batch=0.158\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14623/67600 (epoch 10), train_loss = 1.184, time/batch=0.106\n",
      "14624/67600 (epoch 10), train_loss = 1.301, time/batch=0.115\n",
      "14625/67600 (epoch 10), train_loss = 1.206, time/batch=0.099\n",
      "14626/67600 (epoch 10), train_loss = 1.215, time/batch=0.116\n",
      "14627/67600 (epoch 10), train_loss = 1.252, time/batch=0.110\n",
      "14628/67600 (epoch 10), train_loss = 1.204, time/batch=0.216\n",
      "14629/67600 (epoch 10), train_loss = 1.232, time/batch=0.158\n",
      "14630/67600 (epoch 10), train_loss = 1.249, time/batch=0.131\n",
      "14631/67600 (epoch 10), train_loss = 1.222, time/batch=0.115\n",
      "14632/67600 (epoch 10), train_loss = 1.278, time/batch=0.103\n",
      "14633/67600 (epoch 10), train_loss = 1.277, time/batch=0.119\n",
      "14634/67600 (epoch 10), train_loss = 1.254, time/batch=0.108\n",
      "14635/67600 (epoch 10), train_loss = 1.322, time/batch=0.103\n",
      "14636/67600 (epoch 10), train_loss = 1.223, time/batch=0.180\n",
      "14637/67600 (epoch 10), train_loss = 1.256, time/batch=0.193\n",
      "14638/67600 (epoch 10), train_loss = 1.229, time/batch=0.108\n",
      "14639/67600 (epoch 10), train_loss = 1.325, time/batch=0.106\n",
      "14640/67600 (epoch 10), train_loss = 1.208, time/batch=0.118\n",
      "14641/67600 (epoch 10), train_loss = 1.268, time/batch=0.114\n",
      "14642/67600 (epoch 10), train_loss = 1.324, time/batch=0.109\n",
      "14643/67600 (epoch 10), train_loss = 1.249, time/batch=0.113\n",
      "14644/67600 (epoch 10), train_loss = 1.221, time/batch=0.236\n",
      "14645/67600 (epoch 10), train_loss = 1.226, time/batch=0.120\n",
      "14646/67600 (epoch 10), train_loss = 1.290, time/batch=0.113\n",
      "14647/67600 (epoch 10), train_loss = 1.233, time/batch=0.116\n",
      "14648/67600 (epoch 10), train_loss = 1.253, time/batch=0.109\n",
      "14649/67600 (epoch 10), train_loss = 1.243, time/batch=0.163\n",
      "14650/67600 (epoch 10), train_loss = 1.245, time/batch=0.171\n",
      "14651/67600 (epoch 10), train_loss = 1.257, time/batch=0.155\n",
      "14652/67600 (epoch 10), train_loss = 1.219, time/batch=0.104\n",
      "14653/67600 (epoch 10), train_loss = 1.281, time/batch=0.116\n",
      "14654/67600 (epoch 10), train_loss = 1.309, time/batch=0.109\n",
      "14655/67600 (epoch 10), train_loss = 1.301, time/batch=0.107\n",
      "14656/67600 (epoch 10), train_loss = 1.276, time/batch=0.111\n",
      "14657/67600 (epoch 10), train_loss = 1.243, time/batch=0.190\n",
      "14658/67600 (epoch 10), train_loss = 1.245, time/batch=0.170\n",
      "14659/67600 (epoch 10), train_loss = 1.288, time/batch=0.113\n",
      "14660/67600 (epoch 10), train_loss = 1.237, time/batch=0.104\n",
      "14661/67600 (epoch 10), train_loss = 1.234, time/batch=0.122\n",
      "14662/67600 (epoch 10), train_loss = 1.274, time/batch=0.105\n",
      "14663/67600 (epoch 10), train_loss = 1.269, time/batch=0.099\n",
      "14664/67600 (epoch 10), train_loss = 1.257, time/batch=0.118\n",
      "14665/67600 (epoch 10), train_loss = 1.211, time/batch=0.229\n",
      "14666/67600 (epoch 10), train_loss = 1.202, time/batch=0.137\n",
      "14667/67600 (epoch 10), train_loss = 1.193, time/batch=0.116\n",
      "14668/67600 (epoch 10), train_loss = 1.203, time/batch=0.133\n",
      "14669/67600 (epoch 10), train_loss = 1.219, time/batch=0.123\n",
      "14670/67600 (epoch 10), train_loss = 1.169, time/batch=0.114\n",
      "14671/67600 (epoch 10), train_loss = 1.261, time/batch=0.107\n",
      "14672/67600 (epoch 10), train_loss = 1.229, time/batch=0.158\n",
      "14673/67600 (epoch 10), train_loss = 1.209, time/batch=0.187\n",
      "14674/67600 (epoch 10), train_loss = 1.234, time/batch=0.122\n",
      "14675/67600 (epoch 10), train_loss = 1.214, time/batch=0.118\n",
      "14676/67600 (epoch 10), train_loss = 1.213, time/batch=0.108\n",
      "14677/67600 (epoch 10), train_loss = 1.171, time/batch=0.101\n",
      "14678/67600 (epoch 10), train_loss = 1.270, time/batch=0.119\n",
      "14679/67600 (epoch 10), train_loss = 1.264, time/batch=0.099\n",
      "14680/67600 (epoch 10), train_loss = 1.190, time/batch=0.212\n",
      "14681/67600 (epoch 10), train_loss = 1.201, time/batch=0.129\n",
      "14682/67600 (epoch 10), train_loss = 1.219, time/batch=0.121\n",
      "14683/67600 (epoch 10), train_loss = 1.180, time/batch=0.115\n",
      "14684/67600 (epoch 10), train_loss = 1.239, time/batch=0.116\n",
      "14685/67600 (epoch 10), train_loss = 1.190, time/batch=0.138\n",
      "14686/67600 (epoch 10), train_loss = 1.201, time/batch=0.206\n",
      "14687/67600 (epoch 10), train_loss = 1.231, time/batch=0.130\n",
      "14688/67600 (epoch 10), train_loss = 1.236, time/batch=0.127\n",
      "14689/67600 (epoch 10), train_loss = 1.155, time/batch=0.107\n",
      "14690/67600 (epoch 10), train_loss = 1.189, time/batch=0.118\n",
      "14691/67600 (epoch 10), train_loss = 1.193, time/batch=0.121\n",
      "14692/67600 (epoch 10), train_loss = 1.219, time/batch=0.112\n",
      "14693/67600 (epoch 10), train_loss = 1.226, time/batch=0.146\n",
      "14694/67600 (epoch 10), train_loss = 1.216, time/batch=0.170\n",
      "14695/67600 (epoch 10), train_loss = 1.222, time/batch=0.140\n",
      "14696/67600 (epoch 10), train_loss = 1.228, time/batch=0.113\n",
      "14697/67600 (epoch 10), train_loss = 1.225, time/batch=0.118\n",
      "14698/67600 (epoch 10), train_loss = 1.263, time/batch=0.129\n",
      "14699/67600 (epoch 10), train_loss = 1.332, time/batch=0.104\n",
      "14700/67600 (epoch 10), train_loss = 1.291, time/batch=0.113\n",
      "14701/67600 (epoch 10), train_loss = 1.250, time/batch=0.185\n",
      "14702/67600 (epoch 10), train_loss = 1.235, time/batch=0.170\n",
      "14703/67600 (epoch 10), train_loss = 1.224, time/batch=0.132\n",
      "14704/67600 (epoch 10), train_loss = 1.251, time/batch=0.103\n",
      "14705/67600 (epoch 10), train_loss = 1.153, time/batch=0.115\n",
      "14706/67600 (epoch 10), train_loss = 1.183, time/batch=0.103\n",
      "14707/67600 (epoch 10), train_loss = 1.278, time/batch=0.111\n",
      "14708/67600 (epoch 10), train_loss = 1.218, time/batch=0.110\n",
      "14709/67600 (epoch 10), train_loss = 1.191, time/batch=0.223\n",
      "14710/67600 (epoch 10), train_loss = 1.230, time/batch=0.127\n",
      "14711/67600 (epoch 10), train_loss = 1.204, time/batch=0.122\n",
      "14712/67600 (epoch 10), train_loss = 1.219, time/batch=0.117\n",
      "14713/67600 (epoch 10), train_loss = 1.219, time/batch=0.103\n",
      "14714/67600 (epoch 10), train_loss = 1.180, time/batch=0.117\n",
      "14715/67600 (epoch 10), train_loss = 1.200, time/batch=0.108\n",
      "14716/67600 (epoch 10), train_loss = 1.243, time/batch=0.144\n",
      "14717/67600 (epoch 10), train_loss = 1.251, time/batch=0.210\n",
      "14718/67600 (epoch 10), train_loss = 1.260, time/batch=0.112\n",
      "14719/67600 (epoch 10), train_loss = 1.211, time/batch=0.119\n",
      "14720/67600 (epoch 10), train_loss = 1.243, time/batch=0.105\n",
      "14721/67600 (epoch 10), train_loss = 1.202, time/batch=0.126\n",
      "14722/67600 (epoch 10), train_loss = 1.189, time/batch=0.104\n",
      "14723/67600 (epoch 10), train_loss = 1.195, time/batch=0.117\n",
      "14724/67600 (epoch 10), train_loss = 1.301, time/batch=0.180\n",
      "14725/67600 (epoch 10), train_loss = 1.224, time/batch=0.178\n",
      "14726/67600 (epoch 10), train_loss = 1.184, time/batch=0.116\n",
      "14727/67600 (epoch 10), train_loss = 1.240, time/batch=0.107\n",
      "14728/67600 (epoch 10), train_loss = 1.192, time/batch=0.117\n",
      "14729/67600 (epoch 10), train_loss = 1.192, time/batch=0.112\n",
      "14730/67600 (epoch 10), train_loss = 1.244, time/batch=0.156\n",
      "14731/67600 (epoch 10), train_loss = 1.202, time/batch=0.111\n",
      "14732/67600 (epoch 10), train_loss = 1.191, time/batch=0.113\n",
      "14733/67600 (epoch 10), train_loss = 1.229, time/batch=0.111\n",
      "14734/67600 (epoch 10), train_loss = 1.247, time/batch=0.104\n",
      "14735/67600 (epoch 10), train_loss = 1.211, time/batch=0.119\n",
      "14736/67600 (epoch 10), train_loss = 1.235, time/batch=0.245\n",
      "14737/67600 (epoch 10), train_loss = 1.229, time/batch=0.131\n",
      "14738/67600 (epoch 10), train_loss = 1.220, time/batch=0.130\n",
      "14739/67600 (epoch 10), train_loss = 1.225, time/batch=0.114\n",
      "14740/67600 (epoch 10), train_loss = 1.210, time/batch=0.119\n",
      "14741/67600 (epoch 10), train_loss = 1.206, time/batch=0.111\n",
      "14742/67600 (epoch 10), train_loss = 1.249, time/batch=0.114\n",
      "14743/67600 (epoch 10), train_loss = 1.209, time/batch=0.103\n",
      "14744/67600 (epoch 10), train_loss = 1.263, time/batch=0.235\n",
      "14745/67600 (epoch 10), train_loss = 1.249, time/batch=0.121\n",
      "14746/67600 (epoch 10), train_loss = 1.261, time/batch=0.111\n",
      "14747/67600 (epoch 10), train_loss = 1.230, time/batch=0.116\n",
      "14748/67600 (epoch 10), train_loss = 1.270, time/batch=0.114\n",
      "14749/67600 (epoch 10), train_loss = 1.210, time/batch=0.110\n",
      "14750/67600 (epoch 10), train_loss = 1.243, time/batch=0.120\n",
      "14751/67600 (epoch 10), train_loss = 1.242, time/batch=0.114\n",
      "14752/67600 (epoch 10), train_loss = 1.323, time/batch=0.245\n",
      "14753/67600 (epoch 10), train_loss = 1.281, time/batch=0.119\n",
      "14754/67600 (epoch 10), train_loss = 1.183, time/batch=0.096\n",
      "14755/67600 (epoch 10), train_loss = 1.221, time/batch=0.118\n",
      "14756/67600 (epoch 10), train_loss = 1.215, time/batch=0.111\n",
      "14757/67600 (epoch 10), train_loss = 1.246, time/batch=0.144\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14758/67600 (epoch 10), train_loss = 1.214, time/batch=0.164\n",
      "14759/67600 (epoch 10), train_loss = 1.205, time/batch=0.148\n",
      "14760/67600 (epoch 10), train_loss = 1.277, time/batch=0.111\n",
      "14761/67600 (epoch 10), train_loss = 1.214, time/batch=0.127\n",
      "14762/67600 (epoch 10), train_loss = 1.221, time/batch=0.098\n",
      "14763/67600 (epoch 10), train_loss = 1.253, time/batch=0.120\n",
      "14764/67600 (epoch 10), train_loss = 1.321, time/batch=0.103\n",
      "14765/67600 (epoch 10), train_loss = 1.241, time/batch=0.205\n",
      "14766/67600 (epoch 10), train_loss = 1.224, time/batch=0.146\n",
      "14767/67600 (epoch 10), train_loss = 1.219, time/batch=0.115\n",
      "14768/67600 (epoch 10), train_loss = 1.248, time/batch=0.113\n",
      "14769/67600 (epoch 10), train_loss = 1.216, time/batch=0.112\n",
      "14770/67600 (epoch 10), train_loss = 1.187, time/batch=0.119\n",
      "14771/67600 (epoch 10), train_loss = 1.291, time/batch=0.102\n",
      "14772/67600 (epoch 10), train_loss = 1.193, time/batch=0.103\n",
      "14773/67600 (epoch 10), train_loss = 1.281, time/batch=0.246\n",
      "14774/67600 (epoch 10), train_loss = 1.251, time/batch=0.130\n",
      "14775/67600 (epoch 10), train_loss = 1.264, time/batch=0.120\n",
      "14776/67600 (epoch 10), train_loss = 1.259, time/batch=0.125\n",
      "14777/67600 (epoch 10), train_loss = 1.252, time/batch=0.108\n",
      "14778/67600 (epoch 10), train_loss = 1.295, time/batch=0.114\n",
      "14779/67600 (epoch 10), train_loss = 1.232, time/batch=0.115\n",
      "14780/67600 (epoch 10), train_loss = 1.244, time/batch=0.161\n",
      "14781/67600 (epoch 10), train_loss = 1.207, time/batch=0.173\n",
      "14782/67600 (epoch 10), train_loss = 1.306, time/batch=0.136\n",
      "14783/67600 (epoch 10), train_loss = 1.297, time/batch=0.116\n",
      "14784/67600 (epoch 10), train_loss = 1.284, time/batch=0.116\n",
      "14785/67600 (epoch 10), train_loss = 1.228, time/batch=0.116\n",
      "14786/67600 (epoch 10), train_loss = 1.290, time/batch=0.097\n",
      "14787/67600 (epoch 10), train_loss = 1.202, time/batch=0.114\n",
      "14788/67600 (epoch 10), train_loss = 1.177, time/batch=0.186\n",
      "14789/67600 (epoch 10), train_loss = 1.240, time/batch=0.159\n",
      "14790/67600 (epoch 10), train_loss = 1.229, time/batch=0.117\n",
      "14791/67600 (epoch 10), train_loss = 1.177, time/batch=0.118\n",
      "14792/67600 (epoch 10), train_loss = 1.233, time/batch=0.104\n",
      "14793/67600 (epoch 10), train_loss = 1.223, time/batch=0.116\n",
      "14794/67600 (epoch 10), train_loss = 1.213, time/batch=0.209\n",
      "14795/67600 (epoch 10), train_loss = 1.252, time/batch=0.137\n",
      "14796/67600 (epoch 10), train_loss = 1.261, time/batch=0.121\n",
      "14797/67600 (epoch 10), train_loss = 1.247, time/batch=0.109\n",
      "14798/67600 (epoch 10), train_loss = 1.169, time/batch=0.127\n",
      "14799/67600 (epoch 10), train_loss = 1.181, time/batch=0.108\n",
      "14800/67600 (epoch 10), train_loss = 1.202, time/batch=0.109\n",
      "14801/67600 (epoch 10), train_loss = 1.233, time/batch=0.130\n",
      "14802/67600 (epoch 10), train_loss = 1.184, time/batch=0.183\n",
      "14803/67600 (epoch 10), train_loss = 1.238, time/batch=0.137\n",
      "14804/67600 (epoch 10), train_loss = 1.264, time/batch=0.110\n",
      "14805/67600 (epoch 10), train_loss = 1.224, time/batch=0.121\n",
      "14806/67600 (epoch 10), train_loss = 1.204, time/batch=0.102\n",
      "14807/67600 (epoch 10), train_loss = 1.281, time/batch=0.112\n",
      "14808/67600 (epoch 10), train_loss = 1.208, time/batch=0.121\n",
      "14809/67600 (epoch 10), train_loss = 1.271, time/batch=0.161\n",
      "14810/67600 (epoch 10), train_loss = 1.292, time/batch=0.162\n",
      "14811/67600 (epoch 10), train_loss = 1.260, time/batch=0.138\n",
      "14812/67600 (epoch 10), train_loss = 1.214, time/batch=0.114\n",
      "14813/67600 (epoch 10), train_loss = 1.214, time/batch=0.105\n",
      "14814/67600 (epoch 10), train_loss = 1.229, time/batch=0.119\n",
      "14815/67600 (epoch 10), train_loss = 1.230, time/batch=0.105\n",
      "14816/67600 (epoch 10), train_loss = 1.235, time/batch=0.119\n",
      "14817/67600 (epoch 10), train_loss = 1.250, time/batch=0.216\n",
      "14818/67600 (epoch 10), train_loss = 1.186, time/batch=0.132\n",
      "14819/67600 (epoch 10), train_loss = 1.254, time/batch=0.104\n",
      "14820/67600 (epoch 10), train_loss = 1.282, time/batch=0.129\n",
      "14821/67600 (epoch 10), train_loss = 1.229, time/batch=0.098\n",
      "14822/67600 (epoch 10), train_loss = 1.201, time/batch=0.116\n",
      "14823/67600 (epoch 10), train_loss = 1.228, time/batch=0.112\n",
      "14824/67600 (epoch 10), train_loss = 1.251, time/batch=0.103\n",
      "14825/67600 (epoch 10), train_loss = 1.177, time/batch=0.251\n",
      "14826/67600 (epoch 10), train_loss = 1.258, time/batch=0.115\n",
      "14827/67600 (epoch 10), train_loss = 1.242, time/batch=0.121\n",
      "14828/67600 (epoch 10), train_loss = 1.246, time/batch=0.111\n",
      "14829/67600 (epoch 10), train_loss = 1.236, time/batch=0.112\n",
      "14830/67600 (epoch 10), train_loss = 1.209, time/batch=0.107\n",
      "14831/67600 (epoch 10), train_loss = 1.221, time/batch=0.107\n",
      "14832/67600 (epoch 10), train_loss = 1.225, time/batch=0.128\n",
      "14833/67600 (epoch 10), train_loss = 1.293, time/batch=0.239\n",
      "14834/67600 (epoch 10), train_loss = 1.294, time/batch=0.118\n",
      "14835/67600 (epoch 10), train_loss = 1.245, time/batch=0.113\n",
      "14836/67600 (epoch 10), train_loss = 1.251, time/batch=0.117\n",
      "14837/67600 (epoch 10), train_loss = 1.269, time/batch=0.114\n",
      "14838/67600 (epoch 10), train_loss = 1.240, time/batch=0.152\n",
      "14839/67600 (epoch 10), train_loss = 1.214, time/batch=0.101\n",
      "14840/67600 (epoch 10), train_loss = 1.227, time/batch=0.113\n",
      "14841/67600 (epoch 10), train_loss = 1.228, time/batch=0.116\n",
      "14842/67600 (epoch 10), train_loss = 1.212, time/batch=0.113\n",
      "14843/67600 (epoch 10), train_loss = 1.232, time/batch=0.114\n",
      "14844/67600 (epoch 10), train_loss = 1.282, time/batch=0.117\n",
      "14845/67600 (epoch 10), train_loss = 1.226, time/batch=0.278\n",
      "14846/67600 (epoch 10), train_loss = 1.236, time/batch=0.131\n",
      "14847/67600 (epoch 10), train_loss = 1.219, time/batch=0.122\n",
      "14848/67600 (epoch 10), train_loss = 1.227, time/batch=0.117\n",
      "14849/67600 (epoch 10), train_loss = 1.247, time/batch=0.114\n",
      "14850/67600 (epoch 10), train_loss = 1.288, time/batch=0.109\n",
      "14851/67600 (epoch 10), train_loss = 1.284, time/batch=0.120\n",
      "14852/67600 (epoch 10), train_loss = 1.230, time/batch=0.228\n",
      "14853/67600 (epoch 10), train_loss = 1.215, time/batch=0.122\n",
      "14854/67600 (epoch 10), train_loss = 1.190, time/batch=0.119\n",
      "14855/67600 (epoch 10), train_loss = 1.257, time/batch=0.109\n",
      "14856/67600 (epoch 10), train_loss = 1.260, time/batch=0.105\n",
      "14857/67600 (epoch 10), train_loss = 1.235, time/batch=0.118\n",
      "14858/67600 (epoch 10), train_loss = 1.259, time/batch=0.117\n",
      "14859/67600 (epoch 10), train_loss = 1.230, time/batch=0.110\n",
      "14860/67600 (epoch 10), train_loss = 1.205, time/batch=0.254\n",
      "14861/67600 (epoch 10), train_loss = 1.234, time/batch=0.117\n",
      "14862/67600 (epoch 10), train_loss = 1.245, time/batch=0.119\n",
      "14863/67600 (epoch 10), train_loss = 1.227, time/batch=0.102\n",
      "14864/67600 (epoch 10), train_loss = 1.183, time/batch=0.118\n",
      "14865/67600 (epoch 10), train_loss = 1.229, time/batch=0.204\n",
      "14866/67600 (epoch 10), train_loss = 1.208, time/batch=0.119\n",
      "14867/67600 (epoch 10), train_loss = 1.232, time/batch=0.139\n",
      "14868/67600 (epoch 10), train_loss = 1.298, time/batch=0.110\n",
      "14869/67600 (epoch 10), train_loss = 1.328, time/batch=0.129\n",
      "14870/67600 (epoch 10), train_loss = 1.247, time/batch=0.116\n",
      "14871/67600 (epoch 10), train_loss = 1.251, time/batch=0.115\n",
      "14872/67600 (epoch 11), train_loss = 1.418, time/batch=0.183\n",
      "14873/67600 (epoch 11), train_loss = 1.182, time/batch=0.117\n",
      "14874/67600 (epoch 11), train_loss = 1.262, time/batch=0.148\n",
      "14875/67600 (epoch 11), train_loss = 1.220, time/batch=0.109\n",
      "14876/67600 (epoch 11), train_loss = 1.239, time/batch=0.109\n",
      "14877/67600 (epoch 11), train_loss = 1.263, time/batch=0.107\n",
      "14878/67600 (epoch 11), train_loss = 1.231, time/batch=0.118\n",
      "14879/67600 (epoch 11), train_loss = 1.236, time/batch=0.109\n",
      "14880/67600 (epoch 11), train_loss = 1.252, time/batch=0.235\n",
      "14881/67600 (epoch 11), train_loss = 1.225, time/batch=0.133\n",
      "14882/67600 (epoch 11), train_loss = 1.194, time/batch=0.106\n",
      "14883/67600 (epoch 11), train_loss = 1.205, time/batch=0.131\n",
      "14884/67600 (epoch 11), train_loss = 1.215, time/batch=0.100\n",
      "14885/67600 (epoch 11), train_loss = 1.282, time/batch=0.124\n",
      "14886/67600 (epoch 11), train_loss = 1.251, time/batch=0.107\n",
      "14887/67600 (epoch 11), train_loss = 1.229, time/batch=0.108\n",
      "14888/67600 (epoch 11), train_loss = 1.232, time/batch=0.232\n",
      "14889/67600 (epoch 11), train_loss = 1.246, time/batch=0.114\n",
      "14890/67600 (epoch 11), train_loss = 1.231, time/batch=0.125\n",
      "14891/67600 (epoch 11), train_loss = 1.226, time/batch=0.110\n",
      "14892/67600 (epoch 11), train_loss = 1.231, time/batch=0.106\n",
      "14893/67600 (epoch 11), train_loss = 1.168, time/batch=0.111\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14894/67600 (epoch 11), train_loss = 1.297, time/batch=0.115\n",
      "14895/67600 (epoch 11), train_loss = 1.262, time/batch=0.109\n",
      "14896/67600 (epoch 11), train_loss = 1.304, time/batch=0.219\n",
      "14897/67600 (epoch 11), train_loss = 1.158, time/batch=0.125\n",
      "14898/67600 (epoch 11), train_loss = 1.252, time/batch=0.107\n",
      "14899/67600 (epoch 11), train_loss = 1.274, time/batch=0.110\n",
      "14900/67600 (epoch 11), train_loss = 1.305, time/batch=0.114\n",
      "14901/67600 (epoch 11), train_loss = 1.224, time/batch=0.185\n",
      "14902/67600 (epoch 11), train_loss = 1.217, time/batch=0.121\n",
      "14903/67600 (epoch 11), train_loss = 1.289, time/batch=0.153\n",
      "14904/67600 (epoch 11), train_loss = 1.216, time/batch=0.107\n",
      "14905/67600 (epoch 11), train_loss = 1.286, time/batch=0.117\n",
      "14906/67600 (epoch 11), train_loss = 1.254, time/batch=0.121\n",
      "14907/67600 (epoch 11), train_loss = 1.243, time/batch=0.113\n",
      "14908/67600 (epoch 11), train_loss = 1.207, time/batch=0.114\n",
      "14909/67600 (epoch 11), train_loss = 1.255, time/batch=0.210\n",
      "14910/67600 (epoch 11), train_loss = 1.256, time/batch=0.144\n",
      "14911/67600 (epoch 11), train_loss = 1.237, time/batch=0.110\n",
      "14912/67600 (epoch 11), train_loss = 1.164, time/batch=0.116\n",
      "14913/67600 (epoch 11), train_loss = 1.265, time/batch=0.111\n",
      "14914/67600 (epoch 11), train_loss = 1.282, time/batch=0.106\n",
      "14915/67600 (epoch 11), train_loss = 1.261, time/batch=0.109\n",
      "14916/67600 (epoch 11), train_loss = 1.273, time/batch=0.116\n",
      "14917/67600 (epoch 11), train_loss = 1.231, time/batch=0.209\n",
      "14918/67600 (epoch 11), train_loss = 1.202, time/batch=0.139\n",
      "14919/67600 (epoch 11), train_loss = 1.247, time/batch=0.128\n",
      "14920/67600 (epoch 11), train_loss = 1.208, time/batch=0.094\n",
      "14921/67600 (epoch 11), train_loss = 1.206, time/batch=0.138\n",
      "14922/67600 (epoch 11), train_loss = 1.291, time/batch=0.106\n",
      "14923/67600 (epoch 11), train_loss = 1.210, time/batch=0.125\n",
      "14924/67600 (epoch 11), train_loss = 1.219, time/batch=0.141\n",
      "14925/67600 (epoch 11), train_loss = 1.314, time/batch=0.226\n",
      "14926/67600 (epoch 11), train_loss = 1.274, time/batch=0.130\n",
      "14927/67600 (epoch 11), train_loss = 1.237, time/batch=0.103\n",
      "14928/67600 (epoch 11), train_loss = 1.248, time/batch=0.105\n",
      "14929/67600 (epoch 11), train_loss = 1.240, time/batch=0.108\n",
      "14930/67600 (epoch 11), train_loss = 1.250, time/batch=0.107\n",
      "14931/67600 (epoch 11), train_loss = 1.243, time/batch=0.110\n",
      "14932/67600 (epoch 11), train_loss = 1.246, time/batch=0.230\n",
      "14933/67600 (epoch 11), train_loss = 1.230, time/batch=0.125\n",
      "14934/67600 (epoch 11), train_loss = 1.279, time/batch=0.118\n",
      "14935/67600 (epoch 11), train_loss = 1.284, time/batch=0.118\n",
      "14936/67600 (epoch 11), train_loss = 1.224, time/batch=0.109\n",
      "14937/67600 (epoch 11), train_loss = 1.222, time/batch=0.111\n",
      "14938/67600 (epoch 11), train_loss = 1.229, time/batch=0.209\n",
      "14939/67600 (epoch 11), train_loss = 1.251, time/batch=0.134\n",
      "14940/67600 (epoch 11), train_loss = 1.263, time/batch=0.116\n",
      "14941/67600 (epoch 11), train_loss = 1.263, time/batch=0.130\n",
      "14942/67600 (epoch 11), train_loss = 1.255, time/batch=0.102\n",
      "14943/67600 (epoch 11), train_loss = 1.260, time/batch=0.117\n",
      "14944/67600 (epoch 11), train_loss = 1.216, time/batch=0.123\n",
      "14945/67600 (epoch 11), train_loss = 1.292, time/batch=0.132\n",
      "14946/67600 (epoch 11), train_loss = 1.227, time/batch=0.114\n",
      "14947/67600 (epoch 11), train_loss = 1.284, time/batch=0.117\n",
      "14948/67600 (epoch 11), train_loss = 1.285, time/batch=0.114\n",
      "14949/67600 (epoch 11), train_loss = 1.365, time/batch=0.117\n",
      "14950/67600 (epoch 11), train_loss = 1.287, time/batch=0.105\n",
      "14951/67600 (epoch 11), train_loss = 1.215, time/batch=0.109\n",
      "14952/67600 (epoch 11), train_loss = 1.200, time/batch=0.262\n",
      "14953/67600 (epoch 11), train_loss = 1.250, time/batch=0.122\n",
      "14954/67600 (epoch 11), train_loss = 1.253, time/batch=0.126\n",
      "14955/67600 (epoch 11), train_loss = 1.231, time/batch=0.105\n",
      "14956/67600 (epoch 11), train_loss = 1.239, time/batch=0.116\n",
      "14957/67600 (epoch 11), train_loss = 1.239, time/batch=0.118\n",
      "14958/67600 (epoch 11), train_loss = 1.181, time/batch=0.116\n",
      "14959/67600 (epoch 11), train_loss = 1.298, time/batch=0.103\n",
      "14960/67600 (epoch 11), train_loss = 1.275, time/batch=0.239\n",
      "14961/67600 (epoch 11), train_loss = 1.271, time/batch=0.137\n",
      "14962/67600 (epoch 11), train_loss = 1.244, time/batch=0.110\n",
      "14963/67600 (epoch 11), train_loss = 1.266, time/batch=0.122\n",
      "14964/67600 (epoch 11), train_loss = 1.191, time/batch=0.109\n",
      "14965/67600 (epoch 11), train_loss = 1.212, time/batch=0.205\n",
      "14966/67600 (epoch 11), train_loss = 1.206, time/batch=0.126\n",
      "14967/67600 (epoch 11), train_loss = 1.153, time/batch=0.135\n",
      "14968/67600 (epoch 11), train_loss = 1.167, time/batch=0.126\n",
      "14969/67600 (epoch 11), train_loss = 1.242, time/batch=0.111\n",
      "14970/67600 (epoch 11), train_loss = 1.228, time/batch=0.111\n",
      "14971/67600 (epoch 11), train_loss = 1.274, time/batch=0.109\n",
      "14972/67600 (epoch 11), train_loss = 1.148, time/batch=0.115\n",
      "14973/67600 (epoch 11), train_loss = 1.226, time/batch=0.207\n",
      "14974/67600 (epoch 11), train_loss = 1.264, time/batch=0.137\n",
      "14975/67600 (epoch 11), train_loss = 1.168, time/batch=0.122\n",
      "14976/67600 (epoch 11), train_loss = 1.202, time/batch=0.117\n",
      "14977/67600 (epoch 11), train_loss = 1.257, time/batch=0.109\n",
      "14978/67600 (epoch 11), train_loss = 1.212, time/batch=0.113\n",
      "14979/67600 (epoch 11), train_loss = 1.248, time/batch=0.111\n",
      "14980/67600 (epoch 11), train_loss = 1.280, time/batch=0.106\n",
      "14981/67600 (epoch 11), train_loss = 1.246, time/batch=0.224\n",
      "14982/67600 (epoch 11), train_loss = 1.204, time/batch=0.127\n",
      "14983/67600 (epoch 11), train_loss = 1.244, time/batch=0.117\n",
      "14984/67600 (epoch 11), train_loss = 1.228, time/batch=0.080\n",
      "14985/67600 (epoch 11), train_loss = 1.265, time/batch=0.128\n",
      "14986/67600 (epoch 11), train_loss = 1.258, time/batch=0.118\n",
      "14987/67600 (epoch 11), train_loss = 1.206, time/batch=0.110\n",
      "14988/67600 (epoch 11), train_loss = 1.197, time/batch=0.126\n",
      "14989/67600 (epoch 11), train_loss = 1.232, time/batch=0.196\n",
      "14990/67600 (epoch 11), train_loss = 1.253, time/batch=0.134\n",
      "14991/67600 (epoch 11), train_loss = 1.253, time/batch=0.115\n",
      "14992/67600 (epoch 11), train_loss = 1.253, time/batch=0.101\n",
      "14993/67600 (epoch 11), train_loss = 1.260, time/batch=0.123\n",
      "14994/67600 (epoch 11), train_loss = 1.224, time/batch=0.111\n",
      "14995/67600 (epoch 11), train_loss = 1.201, time/batch=0.103\n",
      "14996/67600 (epoch 11), train_loss = 1.227, time/batch=0.158\n",
      "14997/67600 (epoch 11), train_loss = 1.152, time/batch=0.216\n",
      "14998/67600 (epoch 11), train_loss = 1.229, time/batch=0.110\n",
      "14999/67600 (epoch 11), train_loss = 1.266, time/batch=0.120\n",
      "15000/67600 (epoch 11), train_loss = 1.206, time/batch=0.104\n",
      "model saved to ./save/model.ckpt\n",
      "15001/67600 (epoch 11), train_loss = 1.224, time/batch=0.119\n",
      "15002/67600 (epoch 11), train_loss = 1.253, time/batch=0.152\n",
      "15003/67600 (epoch 11), train_loss = 1.227, time/batch=0.111\n",
      "15004/67600 (epoch 11), train_loss = 1.282, time/batch=0.116\n",
      "15005/67600 (epoch 11), train_loss = 1.212, time/batch=0.111\n",
      "15006/67600 (epoch 11), train_loss = 1.235, time/batch=0.106\n",
      "15007/67600 (epoch 11), train_loss = 1.243, time/batch=0.161\n",
      "15008/67600 (epoch 11), train_loss = 1.260, time/batch=0.157\n",
      "15009/67600 (epoch 11), train_loss = 1.243, time/batch=0.115\n",
      "15010/67600 (epoch 11), train_loss = 1.242, time/batch=0.123\n",
      "15011/67600 (epoch 11), train_loss = 1.211, time/batch=0.120\n",
      "15012/67600 (epoch 11), train_loss = 1.212, time/batch=0.111\n",
      "15013/67600 (epoch 11), train_loss = 1.193, time/batch=0.114\n",
      "15014/67600 (epoch 11), train_loss = 1.248, time/batch=0.121\n",
      "15015/67600 (epoch 11), train_loss = 1.198, time/batch=0.135\n",
      "15016/67600 (epoch 11), train_loss = 1.287, time/batch=0.101\n",
      "15017/67600 (epoch 11), train_loss = 1.326, time/batch=0.119\n",
      "15018/67600 (epoch 11), train_loss = 1.241, time/batch=0.123\n",
      "15019/67600 (epoch 11), train_loss = 1.226, time/batch=0.114\n",
      "15020/67600 (epoch 11), train_loss = 1.282, time/batch=0.115\n",
      "15021/67600 (epoch 11), train_loss = 1.176, time/batch=0.112\n",
      "15022/67600 (epoch 11), train_loss = 1.253, time/batch=0.274\n",
      "15023/67600 (epoch 11), train_loss = 1.195, time/batch=0.123\n",
      "15024/67600 (epoch 11), train_loss = 1.187, time/batch=0.108\n",
      "15025/67600 (epoch 11), train_loss = 1.241, time/batch=0.112\n",
      "15026/67600 (epoch 11), train_loss = 1.200, time/batch=0.106\n",
      "15027/67600 (epoch 11), train_loss = 1.256, time/batch=0.112\n",
      "15028/67600 (epoch 11), train_loss = 1.252, time/batch=0.088\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15029/67600 (epoch 11), train_loss = 1.269, time/batch=0.112\n",
      "15030/67600 (epoch 11), train_loss = 1.249, time/batch=0.245\n",
      "15031/67600 (epoch 11), train_loss = 1.219, time/batch=0.120\n",
      "15032/67600 (epoch 11), train_loss = 1.205, time/batch=0.105\n",
      "15033/67600 (epoch 11), train_loss = 1.185, time/batch=0.117\n",
      "15034/67600 (epoch 11), train_loss = 1.240, time/batch=0.108\n",
      "15035/67600 (epoch 11), train_loss = 1.229, time/batch=0.116\n",
      "15036/67600 (epoch 11), train_loss = 1.144, time/batch=0.114\n",
      "15037/67600 (epoch 11), train_loss = 1.231, time/batch=0.113\n",
      "15038/67600 (epoch 11), train_loss = 1.222, time/batch=0.233\n",
      "15039/67600 (epoch 11), train_loss = 1.197, time/batch=0.121\n",
      "15040/67600 (epoch 11), train_loss = 1.242, time/batch=0.110\n",
      "15041/67600 (epoch 11), train_loss = 1.255, time/batch=0.118\n",
      "15042/67600 (epoch 11), train_loss = 1.253, time/batch=0.108\n",
      "15043/67600 (epoch 11), train_loss = 1.201, time/batch=0.181\n",
      "15044/67600 (epoch 11), train_loss = 1.259, time/batch=0.178\n",
      "15045/67600 (epoch 11), train_loss = 1.210, time/batch=0.103\n",
      "15046/67600 (epoch 11), train_loss = 1.218, time/batch=0.128\n",
      "15047/67600 (epoch 11), train_loss = 1.176, time/batch=0.136\n",
      "15048/67600 (epoch 11), train_loss = 1.240, time/batch=0.102\n",
      "15049/67600 (epoch 11), train_loss = 1.275, time/batch=0.114\n",
      "15050/67600 (epoch 11), train_loss = 1.187, time/batch=0.121\n",
      "15051/67600 (epoch 11), train_loss = 1.203, time/batch=0.205\n",
      "15052/67600 (epoch 11), train_loss = 1.179, time/batch=0.142\n",
      "15053/67600 (epoch 11), train_loss = 1.169, time/batch=0.112\n",
      "15054/67600 (epoch 11), train_loss = 1.212, time/batch=0.101\n",
      "15055/67600 (epoch 11), train_loss = 1.314, time/batch=0.118\n",
      "15056/67600 (epoch 11), train_loss = 1.327, time/batch=0.098\n",
      "15057/67600 (epoch 11), train_loss = 1.292, time/batch=0.114\n",
      "15058/67600 (epoch 11), train_loss = 1.328, time/batch=0.135\n",
      "15059/67600 (epoch 11), train_loss = 1.230, time/batch=0.212\n",
      "15060/67600 (epoch 11), train_loss = 1.243, time/batch=0.135\n",
      "15061/67600 (epoch 11), train_loss = 1.236, time/batch=0.112\n",
      "15062/67600 (epoch 11), train_loss = 1.299, time/batch=0.112\n",
      "15063/67600 (epoch 11), train_loss = 1.270, time/batch=0.107\n",
      "15064/67600 (epoch 11), train_loss = 1.229, time/batch=0.103\n",
      "15065/67600 (epoch 11), train_loss = 1.267, time/batch=0.109\n",
      "15066/67600 (epoch 11), train_loss = 1.259, time/batch=0.174\n",
      "15067/67600 (epoch 11), train_loss = 1.242, time/batch=0.154\n",
      "15068/67600 (epoch 11), train_loss = 1.226, time/batch=0.135\n",
      "15069/67600 (epoch 11), train_loss = 1.228, time/batch=0.097\n",
      "15070/67600 (epoch 11), train_loss = 1.257, time/batch=0.118\n",
      "15071/67600 (epoch 11), train_loss = 1.204, time/batch=0.108\n",
      "15072/67600 (epoch 11), train_loss = 1.193, time/batch=0.111\n",
      "15073/67600 (epoch 11), train_loss = 1.169, time/batch=0.109\n",
      "15074/67600 (epoch 11), train_loss = 1.292, time/batch=0.164\n",
      "15075/67600 (epoch 11), train_loss = 1.230, time/batch=0.184\n",
      "15076/67600 (epoch 11), train_loss = 1.258, time/batch=0.110\n",
      "15077/67600 (epoch 11), train_loss = 1.175, time/batch=0.110\n",
      "15078/67600 (epoch 11), train_loss = 1.180, time/batch=0.105\n",
      "15079/67600 (epoch 11), train_loss = 1.198, time/batch=0.117\n",
      "15080/67600 (epoch 11), train_loss = 1.249, time/batch=0.192\n",
      "15081/67600 (epoch 11), train_loss = 1.279, time/batch=0.150\n",
      "15082/67600 (epoch 11), train_loss = 1.249, time/batch=0.118\n",
      "15083/67600 (epoch 11), train_loss = 1.301, time/batch=0.115\n",
      "15084/67600 (epoch 11), train_loss = 1.215, time/batch=0.112\n",
      "15085/67600 (epoch 11), train_loss = 1.222, time/batch=0.116\n",
      "15086/67600 (epoch 11), train_loss = 1.225, time/batch=0.106\n",
      "15087/67600 (epoch 11), train_loss = 1.263, time/batch=0.115\n",
      "15088/67600 (epoch 11), train_loss = 1.208, time/batch=0.216\n",
      "15089/67600 (epoch 11), train_loss = 1.213, time/batch=0.145\n",
      "15090/67600 (epoch 11), train_loss = 1.197, time/batch=0.112\n",
      "15091/67600 (epoch 11), train_loss = 1.175, time/batch=0.110\n",
      "15092/67600 (epoch 11), train_loss = 1.285, time/batch=0.107\n",
      "15093/67600 (epoch 11), train_loss = 1.198, time/batch=0.113\n",
      "15094/67600 (epoch 11), train_loss = 1.250, time/batch=0.116\n",
      "15095/67600 (epoch 11), train_loss = 1.234, time/batch=0.133\n",
      "15096/67600 (epoch 11), train_loss = 1.233, time/batch=0.194\n",
      "15097/67600 (epoch 11), train_loss = 1.210, time/batch=0.145\n",
      "15098/67600 (epoch 11), train_loss = 1.274, time/batch=0.110\n",
      "15099/67600 (epoch 11), train_loss = 1.190, time/batch=0.116\n",
      "15100/67600 (epoch 11), train_loss = 1.198, time/batch=0.109\n",
      "15101/67600 (epoch 11), train_loss = 1.209, time/batch=0.111\n",
      "15102/67600 (epoch 11), train_loss = 1.234, time/batch=0.113\n",
      "15103/67600 (epoch 11), train_loss = 1.235, time/batch=0.191\n",
      "15104/67600 (epoch 11), train_loss = 1.166, time/batch=0.135\n",
      "15105/67600 (epoch 11), train_loss = 1.172, time/batch=0.120\n",
      "15106/67600 (epoch 11), train_loss = 1.239, time/batch=0.112\n",
      "15107/67600 (epoch 11), train_loss = 1.225, time/batch=0.111\n",
      "15108/67600 (epoch 11), train_loss = 1.215, time/batch=0.114\n",
      "15109/67600 (epoch 11), train_loss = 1.217, time/batch=0.105\n",
      "15110/67600 (epoch 11), train_loss = 1.276, time/batch=0.112\n",
      "15111/67600 (epoch 11), train_loss = 1.246, time/batch=0.176\n",
      "15112/67600 (epoch 11), train_loss = 1.257, time/batch=0.176\n",
      "15113/67600 (epoch 11), train_loss = 1.184, time/batch=0.130\n",
      "15114/67600 (epoch 11), train_loss = 1.236, time/batch=0.111\n",
      "15115/67600 (epoch 11), train_loss = 1.241, time/batch=0.115\n",
      "15116/67600 (epoch 11), train_loss = 1.172, time/batch=0.114\n",
      "15117/67600 (epoch 11), train_loss = 1.244, time/batch=0.100\n",
      "15118/67600 (epoch 11), train_loss = 1.224, time/batch=0.116\n",
      "15119/67600 (epoch 11), train_loss = 1.235, time/batch=0.248\n",
      "15120/67600 (epoch 11), train_loss = 1.258, time/batch=0.110\n",
      "15121/67600 (epoch 11), train_loss = 1.208, time/batch=0.113\n",
      "15122/67600 (epoch 11), train_loss = 1.198, time/batch=0.114\n",
      "15123/67600 (epoch 11), train_loss = 1.281, time/batch=0.105\n",
      "15124/67600 (epoch 11), train_loss = 1.195, time/batch=0.143\n",
      "15125/67600 (epoch 11), train_loss = 1.235, time/batch=0.125\n",
      "15126/67600 (epoch 11), train_loss = 1.252, time/batch=0.108\n",
      "15127/67600 (epoch 11), train_loss = 1.304, time/batch=0.112\n",
      "15128/67600 (epoch 11), train_loss = 1.272, time/batch=0.115\n",
      "15129/67600 (epoch 11), train_loss = 1.278, time/batch=0.120\n",
      "15130/67600 (epoch 11), train_loss = 1.192, time/batch=0.110\n",
      "15131/67600 (epoch 11), train_loss = 1.190, time/batch=0.304\n",
      "15132/67600 (epoch 11), train_loss = 1.216, time/batch=0.120\n",
      "15133/67600 (epoch 11), train_loss = 1.206, time/batch=0.120\n",
      "15134/67600 (epoch 11), train_loss = 1.228, time/batch=0.119\n",
      "15135/67600 (epoch 11), train_loss = 1.231, time/batch=0.115\n",
      "15136/67600 (epoch 11), train_loss = 1.216, time/batch=0.107\n",
      "15137/67600 (epoch 11), train_loss = 1.211, time/batch=0.104\n",
      "15138/67600 (epoch 11), train_loss = 1.192, time/batch=0.099\n",
      "15139/67600 (epoch 11), train_loss = 1.236, time/batch=0.259\n",
      "15140/67600 (epoch 11), train_loss = 1.216, time/batch=0.114\n",
      "15141/67600 (epoch 11), train_loss = 1.197, time/batch=0.114\n",
      "15142/67600 (epoch 11), train_loss = 1.256, time/batch=0.107\n",
      "15143/67600 (epoch 11), train_loss = 1.227, time/batch=0.120\n",
      "15144/67600 (epoch 11), train_loss = 1.238, time/batch=0.115\n",
      "15145/67600 (epoch 11), train_loss = 1.267, time/batch=0.107\n",
      "15146/67600 (epoch 11), train_loss = 1.245, time/batch=0.156\n",
      "15147/67600 (epoch 11), train_loss = 1.229, time/batch=0.190\n",
      "15148/67600 (epoch 11), train_loss = 1.249, time/batch=0.117\n",
      "15149/67600 (epoch 11), train_loss = 1.202, time/batch=0.131\n",
      "15150/67600 (epoch 11), train_loss = 1.201, time/batch=0.110\n",
      "15151/67600 (epoch 11), train_loss = 1.247, time/batch=0.105\n",
      "15152/67600 (epoch 11), train_loss = 1.255, time/batch=0.204\n",
      "15153/67600 (epoch 11), train_loss = 1.204, time/batch=0.150\n",
      "15154/67600 (epoch 11), train_loss = 1.169, time/batch=0.114\n",
      "15155/67600 (epoch 11), train_loss = 1.258, time/batch=0.114\n",
      "15156/67600 (epoch 11), train_loss = 1.195, time/batch=0.103\n",
      "15157/67600 (epoch 11), train_loss = 1.312, time/batch=0.122\n",
      "15158/67600 (epoch 11), train_loss = 1.248, time/batch=0.106\n",
      "15159/67600 (epoch 11), train_loss = 1.227, time/batch=0.164\n",
      "15160/67600 (epoch 11), train_loss = 1.259, time/batch=0.169\n",
      "15161/67600 (epoch 11), train_loss = 1.254, time/batch=0.153\n",
      "15162/67600 (epoch 11), train_loss = 1.250, time/batch=0.113\n",
      "15163/67600 (epoch 11), train_loss = 1.241, time/batch=0.103\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15164/67600 (epoch 11), train_loss = 1.245, time/batch=0.112\n",
      "15165/67600 (epoch 11), train_loss = 1.236, time/batch=0.113\n",
      "15166/67600 (epoch 11), train_loss = 1.239, time/batch=0.114\n",
      "15167/67600 (epoch 11), train_loss = 1.246, time/batch=0.209\n",
      "15168/67600 (epoch 11), train_loss = 1.242, time/batch=0.118\n",
      "15169/67600 (epoch 11), train_loss = 1.216, time/batch=0.127\n",
      "15170/67600 (epoch 11), train_loss = 1.208, time/batch=0.126\n",
      "15171/67600 (epoch 11), train_loss = 1.271, time/batch=0.105\n",
      "15172/67600 (epoch 11), train_loss = 1.228, time/batch=0.117\n",
      "15173/67600 (epoch 11), train_loss = 1.253, time/batch=0.111\n",
      "15174/67600 (epoch 11), train_loss = 1.220, time/batch=0.110\n",
      "15175/67600 (epoch 11), train_loss = 1.252, time/batch=0.230\n",
      "15176/67600 (epoch 11), train_loss = 1.254, time/batch=0.132\n",
      "15177/67600 (epoch 11), train_loss = 1.270, time/batch=0.117\n",
      "15178/67600 (epoch 11), train_loss = 1.281, time/batch=0.113\n",
      "15179/67600 (epoch 11), train_loss = 1.264, time/batch=0.117\n",
      "15180/67600 (epoch 11), train_loss = 1.265, time/batch=0.108\n",
      "15181/67600 (epoch 11), train_loss = 1.264, time/batch=0.094\n",
      "15182/67600 (epoch 11), train_loss = 1.231, time/batch=0.119\n",
      "15183/67600 (epoch 11), train_loss = 1.194, time/batch=0.230\n",
      "15184/67600 (epoch 11), train_loss = 1.206, time/batch=0.134\n",
      "15185/67600 (epoch 11), train_loss = 1.262, time/batch=0.095\n",
      "15186/67600 (epoch 11), train_loss = 1.235, time/batch=0.123\n",
      "15187/67600 (epoch 11), train_loss = 1.313, time/batch=0.103\n",
      "15188/67600 (epoch 11), train_loss = 1.220, time/batch=0.194\n",
      "15189/67600 (epoch 11), train_loss = 1.254, time/batch=0.128\n",
      "15190/67600 (epoch 11), train_loss = 1.260, time/batch=0.142\n",
      "15191/67600 (epoch 11), train_loss = 1.272, time/batch=0.104\n",
      "15192/67600 (epoch 11), train_loss = 1.288, time/batch=0.113\n",
      "15193/67600 (epoch 11), train_loss = 1.234, time/batch=0.106\n",
      "15194/67600 (epoch 11), train_loss = 1.237, time/batch=0.119\n",
      "15195/67600 (epoch 11), train_loss = 1.210, time/batch=0.107\n",
      "15196/67600 (epoch 11), train_loss = 1.229, time/batch=0.214\n",
      "15197/67600 (epoch 11), train_loss = 1.196, time/batch=0.126\n",
      "15198/67600 (epoch 11), train_loss = 1.191, time/batch=0.128\n",
      "15199/67600 (epoch 11), train_loss = 1.264, time/batch=0.113\n",
      "15200/67600 (epoch 11), train_loss = 1.223, time/batch=0.115\n",
      "15201/67600 (epoch 11), train_loss = 1.240, time/batch=0.114\n",
      "15202/67600 (epoch 11), train_loss = 1.274, time/batch=0.112\n",
      "15203/67600 (epoch 11), train_loss = 1.187, time/batch=0.106\n",
      "15204/67600 (epoch 11), train_loss = 1.240, time/batch=0.206\n",
      "15205/67600 (epoch 11), train_loss = 1.232, time/batch=0.147\n",
      "15206/67600 (epoch 11), train_loss = 1.255, time/batch=0.112\n",
      "15207/67600 (epoch 11), train_loss = 1.265, time/batch=0.112\n",
      "15208/67600 (epoch 11), train_loss = 1.225, time/batch=0.108\n",
      "15209/67600 (epoch 11), train_loss = 1.204, time/batch=0.107\n",
      "15210/67600 (epoch 11), train_loss = 1.238, time/batch=0.119\n",
      "15211/67600 (epoch 11), train_loss = 1.275, time/batch=0.112\n",
      "15212/67600 (epoch 11), train_loss = 1.231, time/batch=0.302\n",
      "15213/67600 (epoch 11), train_loss = 1.214, time/batch=0.127\n",
      "15214/67600 (epoch 11), train_loss = 1.203, time/batch=0.127\n",
      "15215/67600 (epoch 11), train_loss = 1.194, time/batch=0.124\n",
      "15216/67600 (epoch 11), train_loss = 1.280, time/batch=0.131\n",
      "15217/67600 (epoch 11), train_loss = 1.301, time/batch=0.109\n",
      "15218/67600 (epoch 11), train_loss = 1.245, time/batch=0.110\n",
      "15219/67600 (epoch 11), train_loss = 1.239, time/batch=0.252\n",
      "15220/67600 (epoch 11), train_loss = 1.280, time/batch=0.124\n",
      "15221/67600 (epoch 11), train_loss = 1.283, time/batch=0.112\n",
      "15222/67600 (epoch 11), train_loss = 1.197, time/batch=0.112\n",
      "15223/67600 (epoch 11), train_loss = 1.181, time/batch=0.096\n",
      "15224/67600 (epoch 11), train_loss = 1.176, time/batch=0.123\n",
      "15225/67600 (epoch 11), train_loss = 1.195, time/batch=0.103\n",
      "15226/67600 (epoch 11), train_loss = 1.206, time/batch=0.253\n",
      "15227/67600 (epoch 11), train_loss = 1.271, time/batch=0.116\n",
      "15228/67600 (epoch 11), train_loss = 1.212, time/batch=0.107\n",
      "15229/67600 (epoch 11), train_loss = 1.228, time/batch=0.113\n",
      "15230/67600 (epoch 11), train_loss = 1.187, time/batch=0.105\n",
      "15231/67600 (epoch 11), train_loss = 1.310, time/batch=0.114\n",
      "15232/67600 (epoch 11), train_loss = 1.232, time/batch=0.150\n",
      "15233/67600 (epoch 11), train_loss = 1.192, time/batch=0.116\n",
      "15234/67600 (epoch 11), train_loss = 1.200, time/batch=0.116\n",
      "15235/67600 (epoch 11), train_loss = 1.275, time/batch=0.105\n",
      "15236/67600 (epoch 11), train_loss = 1.233, time/batch=0.115\n",
      "15237/67600 (epoch 11), train_loss = 1.219, time/batch=0.118\n",
      "15238/67600 (epoch 11), train_loss = 1.224, time/batch=0.266\n",
      "15239/67600 (epoch 11), train_loss = 1.176, time/batch=0.126\n",
      "15240/67600 (epoch 11), train_loss = 1.225, time/batch=0.117\n",
      "15241/67600 (epoch 11), train_loss = 1.307, time/batch=0.121\n",
      "15242/67600 (epoch 11), train_loss = 1.225, time/batch=0.112\n",
      "15243/67600 (epoch 11), train_loss = 1.231, time/batch=0.113\n",
      "15244/67600 (epoch 11), train_loss = 1.263, time/batch=0.107\n",
      "15245/67600 (epoch 11), train_loss = 1.239, time/batch=0.114\n",
      "15246/67600 (epoch 11), train_loss = 1.281, time/batch=0.252\n",
      "15247/67600 (epoch 11), train_loss = 1.312, time/batch=0.121\n",
      "15248/67600 (epoch 11), train_loss = 1.254, time/batch=0.127\n",
      "15249/67600 (epoch 11), train_loss = 1.232, time/batch=0.120\n",
      "15250/67600 (epoch 11), train_loss = 1.306, time/batch=0.111\n",
      "15251/67600 (epoch 11), train_loss = 1.314, time/batch=0.114\n",
      "15252/67600 (epoch 11), train_loss = 1.269, time/batch=0.115\n",
      "15253/67600 (epoch 11), train_loss = 1.227, time/batch=0.158\n",
      "15254/67600 (epoch 11), train_loss = 1.222, time/batch=0.187\n",
      "15255/67600 (epoch 11), train_loss = 1.267, time/batch=0.123\n",
      "15256/67600 (epoch 11), train_loss = 1.316, time/batch=0.115\n",
      "15257/67600 (epoch 11), train_loss = 1.242, time/batch=0.115\n",
      "15258/67600 (epoch 11), train_loss = 1.222, time/batch=0.114\n",
      "15259/67600 (epoch 11), train_loss = 1.232, time/batch=0.190\n",
      "15260/67600 (epoch 11), train_loss = 1.262, time/batch=0.146\n",
      "15261/67600 (epoch 11), train_loss = 1.253, time/batch=0.118\n",
      "15262/67600 (epoch 11), train_loss = 1.235, time/batch=0.114\n",
      "15263/67600 (epoch 11), train_loss = 1.226, time/batch=0.109\n",
      "15264/67600 (epoch 11), train_loss = 1.217, time/batch=0.114\n",
      "15265/67600 (epoch 11), train_loss = 1.247, time/batch=0.114\n",
      "15266/67600 (epoch 11), train_loss = 1.220, time/batch=0.113\n",
      "15267/67600 (epoch 11), train_loss = 1.225, time/batch=0.219\n",
      "15268/67600 (epoch 11), train_loss = 1.283, time/batch=0.154\n",
      "15269/67600 (epoch 11), train_loss = 1.283, time/batch=0.106\n",
      "15270/67600 (epoch 11), train_loss = 1.238, time/batch=0.109\n",
      "15271/67600 (epoch 11), train_loss = 1.217, time/batch=0.108\n",
      "15272/67600 (epoch 11), train_loss = 1.259, time/batch=0.119\n",
      "15273/67600 (epoch 11), train_loss = 1.324, time/batch=0.108\n",
      "15274/67600 (epoch 11), train_loss = 1.288, time/batch=0.184\n",
      "15275/67600 (epoch 11), train_loss = 1.255, time/batch=0.143\n",
      "15276/67600 (epoch 11), train_loss = 1.317, time/batch=0.157\n",
      "15277/67600 (epoch 11), train_loss = 1.280, time/batch=0.099\n",
      "15278/67600 (epoch 11), train_loss = 1.282, time/batch=0.111\n",
      "15279/67600 (epoch 11), train_loss = 1.212, time/batch=0.109\n",
      "15280/67600 (epoch 11), train_loss = 1.264, time/batch=0.113\n",
      "15281/67600 (epoch 11), train_loss = 1.265, time/batch=0.110\n",
      "15282/67600 (epoch 11), train_loss = 1.269, time/batch=0.212\n",
      "15283/67600 (epoch 11), train_loss = 1.205, time/batch=0.129\n",
      "15284/67600 (epoch 11), train_loss = 1.240, time/batch=0.123\n",
      "15285/67600 (epoch 11), train_loss = 1.249, time/batch=0.109\n",
      "15286/67600 (epoch 11), train_loss = 1.224, time/batch=0.116\n",
      "15287/67600 (epoch 11), train_loss = 1.280, time/batch=0.109\n",
      "15288/67600 (epoch 11), train_loss = 1.241, time/batch=0.110\n",
      "15289/67600 (epoch 11), train_loss = 1.275, time/batch=0.112\n",
      "15290/67600 (epoch 11), train_loss = 1.295, time/batch=0.233\n",
      "15291/67600 (epoch 11), train_loss = 1.217, time/batch=0.118\n",
      "15292/67600 (epoch 11), train_loss = 1.160, time/batch=0.117\n",
      "15293/67600 (epoch 11), train_loss = 1.190, time/batch=0.106\n",
      "15294/67600 (epoch 11), train_loss = 1.232, time/batch=0.122\n",
      "15295/67600 (epoch 11), train_loss = 1.182, time/batch=0.195\n",
      "15296/67600 (epoch 11), train_loss = 1.235, time/batch=0.134\n",
      "15297/67600 (epoch 11), train_loss = 1.205, time/batch=0.131\n",
      "15298/67600 (epoch 11), train_loss = 1.234, time/batch=0.133\n",
      "15299/67600 (epoch 11), train_loss = 1.231, time/batch=0.123\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15300/67600 (epoch 11), train_loss = 1.157, time/batch=0.105\n",
      "15301/67600 (epoch 11), train_loss = 1.204, time/batch=0.113\n",
      "15302/67600 (epoch 11), train_loss = 1.272, time/batch=0.122\n",
      "15303/67600 (epoch 11), train_loss = 1.195, time/batch=0.229\n",
      "15304/67600 (epoch 11), train_loss = 1.264, time/batch=0.129\n",
      "15305/67600 (epoch 11), train_loss = 1.266, time/batch=0.122\n",
      "15306/67600 (epoch 11), train_loss = 1.193, time/batch=0.111\n",
      "15307/67600 (epoch 11), train_loss = 1.300, time/batch=0.110\n",
      "15308/67600 (epoch 11), train_loss = 1.229, time/batch=0.105\n",
      "15309/67600 (epoch 11), train_loss = 1.245, time/batch=0.122\n",
      "15310/67600 (epoch 11), train_loss = 1.256, time/batch=0.111\n",
      "15311/67600 (epoch 11), train_loss = 1.221, time/batch=0.227\n",
      "15312/67600 (epoch 11), train_loss = 1.226, time/batch=0.147\n",
      "15313/67600 (epoch 11), train_loss = 1.254, time/batch=0.104\n",
      "15314/67600 (epoch 11), train_loss = 1.217, time/batch=0.113\n",
      "15315/67600 (epoch 11), train_loss = 1.197, time/batch=0.102\n",
      "15316/67600 (epoch 11), train_loss = 1.249, time/batch=0.108\n",
      "15317/67600 (epoch 11), train_loss = 1.274, time/batch=0.122\n",
      "15318/67600 (epoch 11), train_loss = 1.190, time/batch=0.133\n",
      "15319/67600 (epoch 11), train_loss = 1.207, time/batch=0.196\n",
      "15320/67600 (epoch 11), train_loss = 1.174, time/batch=0.127\n",
      "15321/67600 (epoch 11), train_loss = 1.195, time/batch=0.118\n",
      "15322/67600 (epoch 11), train_loss = 1.152, time/batch=0.114\n",
      "15323/67600 (epoch 11), train_loss = 1.260, time/batch=0.105\n",
      "15324/67600 (epoch 11), train_loss = 1.281, time/batch=0.115\n",
      "15325/67600 (epoch 11), train_loss = 1.177, time/batch=0.115\n",
      "15326/67600 (epoch 11), train_loss = 1.161, time/batch=0.238\n",
      "15327/67600 (epoch 11), train_loss = 1.195, time/batch=0.121\n",
      "15328/67600 (epoch 11), train_loss = 1.219, time/batch=0.108\n",
      "15329/67600 (epoch 11), train_loss = 1.236, time/batch=0.112\n",
      "15330/67600 (epoch 11), train_loss = 1.255, time/batch=0.119\n",
      "15331/67600 (epoch 11), train_loss = 1.230, time/batch=0.114\n",
      "15332/67600 (epoch 11), train_loss = 1.246, time/batch=0.196\n",
      "15333/67600 (epoch 11), train_loss = 1.192, time/batch=0.144\n",
      "15334/67600 (epoch 11), train_loss = 1.262, time/batch=0.128\n",
      "15335/67600 (epoch 11), train_loss = 1.240, time/batch=0.112\n",
      "15336/67600 (epoch 11), train_loss = 1.210, time/batch=0.120\n",
      "15337/67600 (epoch 11), train_loss = 1.223, time/batch=0.107\n",
      "15338/67600 (epoch 11), train_loss = 1.210, time/batch=0.123\n",
      "15339/67600 (epoch 11), train_loss = 1.266, time/batch=0.152\n",
      "15340/67600 (epoch 11), train_loss = 1.230, time/batch=0.105\n",
      "15341/67600 (epoch 11), train_loss = 1.196, time/batch=0.128\n",
      "15342/67600 (epoch 11), train_loss = 1.221, time/batch=0.111\n",
      "15343/67600 (epoch 11), train_loss = 1.222, time/batch=0.113\n",
      "15344/67600 (epoch 11), train_loss = 1.191, time/batch=0.107\n",
      "15345/67600 (epoch 11), train_loss = 1.247, time/batch=0.108\n",
      "15346/67600 (epoch 11), train_loss = 1.197, time/batch=0.251\n",
      "15347/67600 (epoch 11), train_loss = 1.170, time/batch=0.132\n",
      "15348/67600 (epoch 11), train_loss = 1.264, time/batch=0.114\n",
      "15349/67600 (epoch 11), train_loss = 1.189, time/batch=0.122\n",
      "15350/67600 (epoch 11), train_loss = 1.217, time/batch=0.104\n",
      "15351/67600 (epoch 11), train_loss = 1.244, time/batch=0.111\n",
      "15352/67600 (epoch 11), train_loss = 1.189, time/batch=0.109\n",
      "15353/67600 (epoch 11), train_loss = 1.226, time/batch=0.124\n",
      "15354/67600 (epoch 11), train_loss = 1.206, time/batch=0.232\n",
      "15355/67600 (epoch 11), train_loss = 1.187, time/batch=0.121\n",
      "15356/67600 (epoch 11), train_loss = 1.242, time/batch=0.116\n",
      "15357/67600 (epoch 11), train_loss = 1.244, time/batch=0.108\n",
      "15358/67600 (epoch 11), train_loss = 1.269, time/batch=0.112\n",
      "15359/67600 (epoch 11), train_loss = 1.242, time/batch=0.108\n",
      "15360/67600 (epoch 11), train_loss = 1.284, time/batch=0.112\n",
      "15361/67600 (epoch 11), train_loss = 1.263, time/batch=0.131\n",
      "15362/67600 (epoch 11), train_loss = 1.192, time/batch=0.217\n",
      "15363/67600 (epoch 11), train_loss = 1.226, time/batch=0.120\n",
      "15364/67600 (epoch 11), train_loss = 1.252, time/batch=0.108\n",
      "15365/67600 (epoch 11), train_loss = 1.199, time/batch=0.116\n",
      "15366/67600 (epoch 11), train_loss = 1.284, time/batch=0.114\n",
      "15367/67600 (epoch 11), train_loss = 1.244, time/batch=0.198\n",
      "15368/67600 (epoch 11), train_loss = 1.215, time/batch=0.146\n",
      "15369/67600 (epoch 11), train_loss = 1.243, time/batch=0.123\n",
      "15370/67600 (epoch 11), train_loss = 1.291, time/batch=0.115\n",
      "15371/67600 (epoch 11), train_loss = 1.235, time/batch=0.107\n",
      "15372/67600 (epoch 11), train_loss = 1.180, time/batch=0.120\n",
      "15373/67600 (epoch 11), train_loss = 1.187, time/batch=0.103\n",
      "15374/67600 (epoch 11), train_loss = 1.207, time/batch=0.140\n",
      "15375/67600 (epoch 11), train_loss = 1.244, time/batch=0.215\n",
      "15376/67600 (epoch 11), train_loss = 1.255, time/batch=0.122\n",
      "15377/67600 (epoch 11), train_loss = 1.273, time/batch=0.122\n",
      "15378/67600 (epoch 11), train_loss = 1.247, time/batch=0.112\n",
      "15379/67600 (epoch 11), train_loss = 1.252, time/batch=0.109\n",
      "15380/67600 (epoch 11), train_loss = 1.188, time/batch=0.116\n",
      "15381/67600 (epoch 11), train_loss = 1.223, time/batch=0.115\n",
      "15382/67600 (epoch 11), train_loss = 1.250, time/batch=0.171\n",
      "15383/67600 (epoch 11), train_loss = 1.238, time/batch=0.158\n",
      "15384/67600 (epoch 11), train_loss = 1.246, time/batch=0.135\n",
      "15385/67600 (epoch 11), train_loss = 1.214, time/batch=0.097\n",
      "15386/67600 (epoch 11), train_loss = 1.248, time/batch=0.129\n",
      "15387/67600 (epoch 11), train_loss = 1.268, time/batch=0.107\n",
      "15388/67600 (epoch 11), train_loss = 1.274, time/batch=0.117\n",
      "15389/67600 (epoch 11), train_loss = 1.257, time/batch=0.111\n",
      "15390/67600 (epoch 11), train_loss = 1.248, time/batch=0.216\n",
      "15391/67600 (epoch 11), train_loss = 1.175, time/batch=0.125\n",
      "15392/67600 (epoch 11), train_loss = 1.280, time/batch=0.115\n",
      "15393/67600 (epoch 11), train_loss = 1.283, time/batch=0.119\n",
      "15394/67600 (epoch 11), train_loss = 1.295, time/batch=0.108\n",
      "15395/67600 (epoch 11), train_loss = 1.245, time/batch=0.116\n",
      "15396/67600 (epoch 11), train_loss = 1.230, time/batch=0.110\n",
      "15397/67600 (epoch 11), train_loss = 1.241, time/batch=0.103\n",
      "15398/67600 (epoch 11), train_loss = 1.253, time/batch=0.233\n",
      "15399/67600 (epoch 11), train_loss = 1.209, time/batch=0.109\n",
      "15400/67600 (epoch 11), train_loss = 1.269, time/batch=0.115\n",
      "15401/67600 (epoch 11), train_loss = 1.231, time/batch=0.116\n",
      "15402/67600 (epoch 11), train_loss = 1.286, time/batch=0.119\n",
      "15403/67600 (epoch 11), train_loss = 1.271, time/batch=0.103\n",
      "15404/67600 (epoch 11), train_loss = 1.253, time/batch=0.209\n",
      "15405/67600 (epoch 11), train_loss = 1.211, time/batch=0.152\n",
      "15406/67600 (epoch 11), train_loss = 1.219, time/batch=0.099\n",
      "15407/67600 (epoch 11), train_loss = 1.184, time/batch=0.127\n",
      "15408/67600 (epoch 11), train_loss = 1.207, time/batch=0.103\n",
      "15409/67600 (epoch 11), train_loss = 1.238, time/batch=0.113\n",
      "15410/67600 (epoch 11), train_loss = 1.228, time/batch=0.116\n",
      "15411/67600 (epoch 11), train_loss = 1.236, time/batch=0.135\n",
      "15412/67600 (epoch 11), train_loss = 1.240, time/batch=0.172\n",
      "15413/67600 (epoch 11), train_loss = 1.183, time/batch=0.150\n",
      "15414/67600 (epoch 11), train_loss = 1.215, time/batch=0.113\n",
      "15415/67600 (epoch 11), train_loss = 1.194, time/batch=0.106\n",
      "15416/67600 (epoch 11), train_loss = 1.277, time/batch=0.115\n",
      "15417/67600 (epoch 11), train_loss = 1.233, time/batch=0.109\n",
      "15418/67600 (epoch 11), train_loss = 1.219, time/batch=0.116\n",
      "15419/67600 (epoch 11), train_loss = 1.235, time/batch=0.131\n",
      "15420/67600 (epoch 11), train_loss = 1.353, time/batch=0.189\n",
      "15421/67600 (epoch 11), train_loss = 1.265, time/batch=0.140\n",
      "15422/67600 (epoch 11), train_loss = 1.220, time/batch=0.110\n",
      "15423/67600 (epoch 11), train_loss = 1.272, time/batch=0.114\n",
      "15424/67600 (epoch 11), train_loss = 1.224, time/batch=0.117\n",
      "15425/67600 (epoch 11), train_loss = 1.219, time/batch=0.109\n",
      "15426/67600 (epoch 11), train_loss = 1.267, time/batch=0.103\n",
      "15427/67600 (epoch 11), train_loss = 1.216, time/batch=0.207\n",
      "15428/67600 (epoch 11), train_loss = 1.293, time/batch=0.153\n",
      "15429/67600 (epoch 11), train_loss = 1.223, time/batch=0.109\n",
      "15430/67600 (epoch 11), train_loss = 1.211, time/batch=0.098\n",
      "15431/67600 (epoch 11), train_loss = 1.170, time/batch=0.123\n",
      "15432/67600 (epoch 11), train_loss = 1.200, time/batch=0.113\n",
      "15433/67600 (epoch 11), train_loss = 1.223, time/batch=0.106\n",
      "15434/67600 (epoch 11), train_loss = 1.175, time/batch=0.111\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15435/67600 (epoch 11), train_loss = 1.217, time/batch=0.255\n",
      "15436/67600 (epoch 11), train_loss = 1.196, time/batch=0.093\n",
      "15437/67600 (epoch 11), train_loss = 1.218, time/batch=0.114\n",
      "15438/67600 (epoch 11), train_loss = 1.237, time/batch=0.121\n",
      "15439/67600 (epoch 11), train_loss = 1.253, time/batch=0.109\n",
      "15440/67600 (epoch 11), train_loss = 1.249, time/batch=0.110\n",
      "15441/67600 (epoch 11), train_loss = 1.215, time/batch=0.212\n",
      "15442/67600 (epoch 11), train_loss = 1.195, time/batch=0.142\n",
      "15443/67600 (epoch 11), train_loss = 1.187, time/batch=0.114\n",
      "15444/67600 (epoch 11), train_loss = 1.211, time/batch=0.114\n",
      "15445/67600 (epoch 11), train_loss = 1.223, time/batch=0.108\n",
      "15446/67600 (epoch 11), train_loss = 1.241, time/batch=0.126\n",
      "15447/67600 (epoch 11), train_loss = 1.200, time/batch=0.109\n",
      "15448/67600 (epoch 11), train_loss = 1.246, time/batch=0.134\n",
      "15449/67600 (epoch 11), train_loss = 1.233, time/batch=0.120\n",
      "15450/67600 (epoch 11), train_loss = 1.257, time/batch=0.106\n",
      "15451/67600 (epoch 11), train_loss = 1.231, time/batch=0.125\n",
      "15452/67600 (epoch 11), train_loss = 1.263, time/batch=0.108\n",
      "15453/67600 (epoch 11), train_loss = 1.234, time/batch=0.104\n",
      "15454/67600 (epoch 11), train_loss = 1.183, time/batch=0.111\n",
      "15455/67600 (epoch 11), train_loss = 1.202, time/batch=0.291\n",
      "15456/67600 (epoch 11), train_loss = 1.230, time/batch=0.124\n",
      "15457/67600 (epoch 11), train_loss = 1.288, time/batch=0.118\n",
      "15458/67600 (epoch 11), train_loss = 1.210, time/batch=0.122\n",
      "15459/67600 (epoch 11), train_loss = 1.287, time/batch=0.118\n",
      "15460/67600 (epoch 11), train_loss = 1.201, time/batch=0.120\n",
      "15461/67600 (epoch 11), train_loss = 1.230, time/batch=0.106\n",
      "15462/67600 (epoch 11), train_loss = 1.288, time/batch=0.167\n",
      "15463/67600 (epoch 11), train_loss = 1.196, time/batch=0.185\n",
      "15464/67600 (epoch 11), train_loss = 1.208, time/batch=0.132\n",
      "15465/67600 (epoch 11), train_loss = 1.236, time/batch=0.110\n",
      "15466/67600 (epoch 11), train_loss = 1.178, time/batch=0.104\n",
      "15467/67600 (epoch 11), train_loss = 1.223, time/batch=0.111\n",
      "15468/67600 (epoch 11), train_loss = 1.242, time/batch=0.118\n",
      "15469/67600 (epoch 11), train_loss = 1.191, time/batch=0.105\n",
      "15470/67600 (epoch 11), train_loss = 1.226, time/batch=0.244\n",
      "15471/67600 (epoch 11), train_loss = 1.214, time/batch=0.135\n",
      "15472/67600 (epoch 11), train_loss = 1.260, time/batch=0.119\n",
      "15473/67600 (epoch 11), train_loss = 1.175, time/batch=0.105\n",
      "15474/67600 (epoch 11), train_loss = 1.234, time/batch=0.106\n",
      "15475/67600 (epoch 11), train_loss = 1.216, time/batch=0.131\n",
      "15476/67600 (epoch 11), train_loss = 1.254, time/batch=0.187\n",
      "15477/67600 (epoch 11), train_loss = 1.203, time/batch=0.149\n",
      "15478/67600 (epoch 11), train_loss = 1.281, time/batch=0.108\n",
      "15479/67600 (epoch 11), train_loss = 1.213, time/batch=0.117\n",
      "15480/67600 (epoch 11), train_loss = 1.294, time/batch=0.112\n",
      "15481/67600 (epoch 11), train_loss = 1.221, time/batch=0.117\n",
      "15482/67600 (epoch 11), train_loss = 1.247, time/batch=0.107\n",
      "15483/67600 (epoch 11), train_loss = 1.319, time/batch=0.223\n",
      "15484/67600 (epoch 11), train_loss = 1.231, time/batch=0.102\n",
      "15485/67600 (epoch 11), train_loss = 1.225, time/batch=0.131\n",
      "15486/67600 (epoch 11), train_loss = 1.259, time/batch=0.140\n",
      "15487/67600 (epoch 11), train_loss = 1.289, time/batch=0.102\n",
      "15488/67600 (epoch 11), train_loss = 1.246, time/batch=0.108\n",
      "15489/67600 (epoch 11), train_loss = 1.309, time/batch=0.115\n",
      "15490/67600 (epoch 11), train_loss = 1.237, time/batch=0.108\n",
      "15491/67600 (epoch 11), train_loss = 1.198, time/batch=0.219\n",
      "15492/67600 (epoch 11), train_loss = 1.186, time/batch=0.131\n",
      "15493/67600 (epoch 11), train_loss = 1.225, time/batch=0.117\n",
      "15494/67600 (epoch 11), train_loss = 1.237, time/batch=0.114\n",
      "15495/67600 (epoch 11), train_loss = 1.196, time/batch=0.106\n",
      "15496/67600 (epoch 11), train_loss = 1.234, time/batch=0.110\n",
      "15497/67600 (epoch 11), train_loss = 1.218, time/batch=0.116\n",
      "15498/67600 (epoch 11), train_loss = 1.267, time/batch=0.112\n",
      "15499/67600 (epoch 11), train_loss = 1.272, time/batch=0.220\n",
      "15500/67600 (epoch 11), train_loss = 1.264, time/batch=0.150\n",
      "model saved to ./save/model.ckpt\n",
      "15501/67600 (epoch 11), train_loss = 1.230, time/batch=0.094\n",
      "15502/67600 (epoch 11), train_loss = 1.270, time/batch=0.079\n",
      "15503/67600 (epoch 11), train_loss = 1.302, time/batch=0.092\n",
      "15504/67600 (epoch 11), train_loss = 1.212, time/batch=0.119\n",
      "15505/67600 (epoch 11), train_loss = 1.288, time/batch=0.133\n",
      "15506/67600 (epoch 11), train_loss = 1.278, time/batch=0.108\n",
      "15507/67600 (epoch 11), train_loss = 1.156, time/batch=0.101\n",
      "15508/67600 (epoch 11), train_loss = 1.310, time/batch=0.173\n",
      "15509/67600 (epoch 11), train_loss = 1.213, time/batch=0.153\n",
      "15510/67600 (epoch 11), train_loss = 1.167, time/batch=0.129\n",
      "15511/67600 (epoch 11), train_loss = 1.161, time/batch=0.110\n",
      "15512/67600 (epoch 11), train_loss = 1.238, time/batch=0.133\n",
      "15513/67600 (epoch 11), train_loss = 1.213, time/batch=0.103\n",
      "15514/67600 (epoch 11), train_loss = 1.267, time/batch=0.224\n",
      "15515/67600 (epoch 11), train_loss = 1.314, time/batch=0.150\n",
      "15516/67600 (epoch 11), train_loss = 1.290, time/batch=0.116\n",
      "15517/67600 (epoch 11), train_loss = 1.229, time/batch=0.110\n",
      "15518/67600 (epoch 11), train_loss = 1.267, time/batch=0.127\n",
      "15519/67600 (epoch 11), train_loss = 1.254, time/batch=0.117\n",
      "15520/67600 (epoch 11), train_loss = 1.279, time/batch=0.102\n",
      "15521/67600 (epoch 11), train_loss = 1.242, time/batch=0.157\n",
      "15522/67600 (epoch 11), train_loss = 1.285, time/batch=0.117\n",
      "15523/67600 (epoch 11), train_loss = 1.309, time/batch=0.114\n",
      "15524/67600 (epoch 11), train_loss = 1.232, time/batch=0.107\n",
      "15525/67600 (epoch 11), train_loss = 1.224, time/batch=0.106\n",
      "15526/67600 (epoch 11), train_loss = 1.250, time/batch=0.116\n",
      "15527/67600 (epoch 11), train_loss = 1.231, time/batch=0.110\n",
      "15528/67600 (epoch 11), train_loss = 1.231, time/batch=0.249\n",
      "15529/67600 (epoch 11), train_loss = 1.304, time/batch=0.143\n",
      "15530/67600 (epoch 11), train_loss = 1.257, time/batch=0.111\n",
      "15531/67600 (epoch 11), train_loss = 1.177, time/batch=0.105\n",
      "15532/67600 (epoch 11), train_loss = 1.230, time/batch=0.120\n",
      "15533/67600 (epoch 11), train_loss = 1.226, time/batch=0.110\n",
      "15534/67600 (epoch 11), train_loss = 1.149, time/batch=0.103\n",
      "15535/67600 (epoch 11), train_loss = 1.181, time/batch=0.105\n",
      "15536/67600 (epoch 11), train_loss = 1.271, time/batch=0.245\n",
      "15537/67600 (epoch 11), train_loss = 1.245, time/batch=0.119\n",
      "15538/67600 (epoch 11), train_loss = 1.256, time/batch=0.118\n",
      "15539/67600 (epoch 11), train_loss = 1.231, time/batch=0.106\n",
      "15540/67600 (epoch 11), train_loss = 1.290, time/batch=0.112\n",
      "15541/67600 (epoch 11), train_loss = 1.199, time/batch=0.103\n",
      "15542/67600 (epoch 11), train_loss = 1.148, time/batch=0.115\n",
      "15543/67600 (epoch 11), train_loss = 1.208, time/batch=0.102\n",
      "15544/67600 (epoch 11), train_loss = 1.156, time/batch=0.245\n",
      "15545/67600 (epoch 11), train_loss = 1.296, time/batch=0.123\n",
      "15546/67600 (epoch 11), train_loss = 1.282, time/batch=0.113\n",
      "15547/67600 (epoch 11), train_loss = 1.206, time/batch=0.126\n",
      "15548/67600 (epoch 11), train_loss = 1.243, time/batch=0.100\n",
      "15549/67600 (epoch 11), train_loss = 1.271, time/batch=0.228\n",
      "15550/67600 (epoch 11), train_loss = 1.282, time/batch=0.145\n",
      "15551/67600 (epoch 11), train_loss = 1.215, time/batch=0.111\n",
      "15552/67600 (epoch 11), train_loss = 1.240, time/batch=0.132\n",
      "15553/67600 (epoch 11), train_loss = 1.259, time/batch=0.140\n",
      "15554/67600 (epoch 11), train_loss = 1.259, time/batch=0.110\n",
      "15555/67600 (epoch 11), train_loss = 1.228, time/batch=0.117\n",
      "15556/67600 (epoch 11), train_loss = 1.209, time/batch=0.157\n",
      "15557/67600 (epoch 11), train_loss = 1.292, time/batch=0.146\n",
      "15558/67600 (epoch 11), train_loss = 1.250, time/batch=0.159\n",
      "15559/67600 (epoch 11), train_loss = 1.191, time/batch=0.124\n",
      "15560/67600 (epoch 11), train_loss = 1.238, time/batch=0.109\n",
      "15561/67600 (epoch 11), train_loss = 1.189, time/batch=0.107\n",
      "15562/67600 (epoch 11), train_loss = 1.228, time/batch=0.116\n",
      "15563/67600 (epoch 11), train_loss = 1.224, time/batch=0.122\n",
      "15564/67600 (epoch 11), train_loss = 1.211, time/batch=0.206\n",
      "15565/67600 (epoch 11), train_loss = 1.263, time/batch=0.137\n",
      "15566/67600 (epoch 11), train_loss = 1.243, time/batch=0.136\n",
      "15567/67600 (epoch 11), train_loss = 1.160, time/batch=0.110\n",
      "15568/67600 (epoch 11), train_loss = 1.254, time/batch=0.134\n",
      "15569/67600 (epoch 11), train_loss = 1.270, time/batch=0.113\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15570/67600 (epoch 11), train_loss = 1.260, time/batch=0.109\n",
      "15571/67600 (epoch 11), train_loss = 1.191, time/batch=0.123\n",
      "15572/67600 (epoch 11), train_loss = 1.244, time/batch=0.211\n",
      "15573/67600 (epoch 11), train_loss = 1.268, time/batch=0.138\n",
      "15574/67600 (epoch 11), train_loss = 1.227, time/batch=0.096\n",
      "15575/67600 (epoch 11), train_loss = 1.182, time/batch=0.120\n",
      "15576/67600 (epoch 11), train_loss = 1.226, time/batch=0.111\n",
      "15577/67600 (epoch 11), train_loss = 1.215, time/batch=0.110\n",
      "15578/67600 (epoch 11), train_loss = 1.212, time/batch=0.109\n",
      "15579/67600 (epoch 11), train_loss = 1.260, time/batch=0.170\n",
      "15580/67600 (epoch 11), train_loss = 1.248, time/batch=0.177\n",
      "15581/67600 (epoch 11), train_loss = 1.197, time/batch=0.110\n",
      "15582/67600 (epoch 11), train_loss = 1.231, time/batch=0.104\n",
      "15583/67600 (epoch 11), train_loss = 1.138, time/batch=0.113\n",
      "15584/67600 (epoch 11), train_loss = 1.231, time/batch=0.104\n",
      "15585/67600 (epoch 11), train_loss = 1.219, time/batch=0.198\n",
      "15586/67600 (epoch 11), train_loss = 1.220, time/batch=0.146\n",
      "15587/67600 (epoch 11), train_loss = 1.207, time/batch=0.108\n",
      "15588/67600 (epoch 11), train_loss = 1.181, time/batch=0.127\n",
      "15589/67600 (epoch 11), train_loss = 1.226, time/batch=0.121\n",
      "15590/67600 (epoch 11), train_loss = 1.206, time/batch=0.104\n",
      "15591/67600 (epoch 11), train_loss = 1.211, time/batch=0.105\n",
      "15592/67600 (epoch 11), train_loss = 1.220, time/batch=0.085\n",
      "15593/67600 (epoch 11), train_loss = 1.255, time/batch=0.217\n",
      "15594/67600 (epoch 11), train_loss = 1.226, time/batch=0.138\n",
      "15595/67600 (epoch 11), train_loss = 1.242, time/batch=0.105\n",
      "15596/67600 (epoch 11), train_loss = 1.233, time/batch=0.115\n",
      "15597/67600 (epoch 11), train_loss = 1.250, time/batch=0.125\n",
      "15598/67600 (epoch 11), train_loss = 1.234, time/batch=0.109\n",
      "15599/67600 (epoch 11), train_loss = 1.237, time/batch=0.111\n",
      "15600/67600 (epoch 11), train_loss = 1.252, time/batch=0.113\n",
      "15601/67600 (epoch 11), train_loss = 1.218, time/batch=0.224\n",
      "15602/67600 (epoch 11), train_loss = 1.246, time/batch=0.144\n",
      "15603/67600 (epoch 11), train_loss = 1.265, time/batch=0.112\n",
      "15604/67600 (epoch 11), train_loss = 1.245, time/batch=0.120\n",
      "15605/67600 (epoch 11), train_loss = 1.239, time/batch=0.118\n",
      "15606/67600 (epoch 11), train_loss = 1.241, time/batch=0.107\n",
      "15607/67600 (epoch 11), train_loss = 1.189, time/batch=0.103\n",
      "15608/67600 (epoch 11), train_loss = 1.289, time/batch=0.181\n",
      "15609/67600 (epoch 11), train_loss = 1.216, time/batch=0.166\n",
      "15610/67600 (epoch 11), train_loss = 1.182, time/batch=0.120\n",
      "15611/67600 (epoch 11), train_loss = 1.261, time/batch=0.104\n",
      "15612/67600 (epoch 11), train_loss = 1.167, time/batch=0.121\n",
      "15613/67600 (epoch 11), train_loss = 1.190, time/batch=0.106\n",
      "15614/67600 (epoch 11), train_loss = 1.170, time/batch=0.112\n",
      "15615/67600 (epoch 11), train_loss = 1.213, time/batch=0.118\n",
      "15616/67600 (epoch 11), train_loss = 1.245, time/batch=0.174\n",
      "15617/67600 (epoch 11), train_loss = 1.246, time/batch=0.177\n",
      "15618/67600 (epoch 11), train_loss = 1.213, time/batch=0.115\n",
      "15619/67600 (epoch 11), train_loss = 1.226, time/batch=0.112\n",
      "15620/67600 (epoch 11), train_loss = 1.244, time/batch=0.106\n",
      "15621/67600 (epoch 11), train_loss = 1.199, time/batch=0.116\n",
      "15622/67600 (epoch 11), train_loss = 1.164, time/batch=0.196\n",
      "15623/67600 (epoch 11), train_loss = 1.199, time/batch=0.133\n",
      "15624/67600 (epoch 11), train_loss = 1.224, time/batch=0.119\n",
      "15625/67600 (epoch 11), train_loss = 1.274, time/batch=0.118\n",
      "15626/67600 (epoch 11), train_loss = 1.214, time/batch=0.124\n",
      "15627/67600 (epoch 11), train_loss = 1.226, time/batch=0.120\n",
      "15628/67600 (epoch 11), train_loss = 1.291, time/batch=0.110\n",
      "15629/67600 (epoch 11), train_loss = 1.235, time/batch=0.132\n",
      "15630/67600 (epoch 11), train_loss = 1.206, time/batch=0.139\n",
      "15631/67600 (epoch 11), train_loss = 1.195, time/batch=0.113\n",
      "15632/67600 (epoch 11), train_loss = 1.215, time/batch=0.117\n",
      "15633/67600 (epoch 11), train_loss = 1.214, time/batch=0.110\n",
      "15634/67600 (epoch 11), train_loss = 1.220, time/batch=0.107\n",
      "15635/67600 (epoch 11), train_loss = 1.260, time/batch=0.109\n",
      "15636/67600 (epoch 11), train_loss = 1.272, time/batch=0.259\n",
      "15637/67600 (epoch 11), train_loss = 1.194, time/batch=0.123\n",
      "15638/67600 (epoch 11), train_loss = 1.234, time/batch=0.116\n",
      "15639/67600 (epoch 11), train_loss = 1.220, time/batch=0.111\n",
      "15640/67600 (epoch 11), train_loss = 1.250, time/batch=0.112\n",
      "15641/67600 (epoch 11), train_loss = 1.256, time/batch=0.101\n",
      "15642/67600 (epoch 11), train_loss = 1.213, time/batch=0.110\n",
      "15643/67600 (epoch 11), train_loss = 1.272, time/batch=0.121\n",
      "15644/67600 (epoch 11), train_loss = 1.245, time/batch=0.253\n",
      "15645/67600 (epoch 11), train_loss = 1.210, time/batch=0.120\n",
      "15646/67600 (epoch 11), train_loss = 1.257, time/batch=0.114\n",
      "15647/67600 (epoch 11), train_loss = 1.301, time/batch=0.101\n",
      "15648/67600 (epoch 11), train_loss = 1.266, time/batch=0.105\n",
      "15649/67600 (epoch 11), train_loss = 1.249, time/batch=0.121\n",
      "15650/67600 (epoch 11), train_loss = 1.229, time/batch=0.117\n",
      "15651/67600 (epoch 11), train_loss = 1.252, time/batch=0.106\n",
      "15652/67600 (epoch 11), train_loss = 1.292, time/batch=0.230\n",
      "15653/67600 (epoch 11), train_loss = 1.223, time/batch=0.115\n",
      "15654/67600 (epoch 11), train_loss = 1.214, time/batch=0.098\n",
      "15655/67600 (epoch 11), train_loss = 1.239, time/batch=0.126\n",
      "15656/67600 (epoch 11), train_loss = 1.217, time/batch=0.112\n",
      "15657/67600 (epoch 11), train_loss = 1.260, time/batch=0.161\n",
      "15658/67600 (epoch 11), train_loss = 1.231, time/batch=0.201\n",
      "15659/67600 (epoch 11), train_loss = 1.236, time/batch=0.114\n",
      "15660/67600 (epoch 11), train_loss = 1.248, time/batch=0.123\n",
      "15661/67600 (epoch 11), train_loss = 1.195, time/batch=0.107\n",
      "15662/67600 (epoch 11), train_loss = 1.227, time/batch=0.112\n",
      "15663/67600 (epoch 11), train_loss = 1.233, time/batch=0.111\n",
      "15664/67600 (epoch 11), train_loss = 1.203, time/batch=0.111\n",
      "15665/67600 (epoch 11), train_loss = 1.257, time/batch=0.213\n",
      "15666/67600 (epoch 11), train_loss = 1.231, time/batch=0.142\n",
      "15667/67600 (epoch 11), train_loss = 1.237, time/batch=0.106\n",
      "15668/67600 (epoch 11), train_loss = 1.301, time/batch=0.107\n",
      "15669/67600 (epoch 11), train_loss = 1.242, time/batch=0.115\n",
      "15670/67600 (epoch 11), train_loss = 1.277, time/batch=0.109\n",
      "15671/67600 (epoch 11), train_loss = 1.229, time/batch=0.111\n",
      "15672/67600 (epoch 11), train_loss = 1.241, time/batch=0.120\n",
      "15673/67600 (epoch 11), train_loss = 1.231, time/batch=0.224\n",
      "15674/67600 (epoch 11), train_loss = 1.208, time/batch=0.148\n",
      "15675/67600 (epoch 11), train_loss = 1.228, time/batch=0.106\n",
      "15676/67600 (epoch 11), train_loss = 1.209, time/batch=0.108\n",
      "15677/67600 (epoch 11), train_loss = 1.178, time/batch=0.124\n",
      "15678/67600 (epoch 11), train_loss = 1.235, time/batch=0.103\n",
      "15679/67600 (epoch 11), train_loss = 1.214, time/batch=0.109\n",
      "15680/67600 (epoch 11), train_loss = 1.150, time/batch=0.136\n",
      "15681/67600 (epoch 11), train_loss = 1.251, time/batch=0.186\n",
      "15682/67600 (epoch 11), train_loss = 1.185, time/batch=0.147\n",
      "15683/67600 (epoch 11), train_loss = 1.265, time/batch=0.110\n",
      "15684/67600 (epoch 11), train_loss = 1.251, time/batch=0.106\n",
      "15685/67600 (epoch 11), train_loss = 1.240, time/batch=0.110\n",
      "15686/67600 (epoch 11), train_loss = 1.264, time/batch=0.109\n",
      "15687/67600 (epoch 11), train_loss = 1.182, time/batch=0.119\n",
      "15688/67600 (epoch 11), train_loss = 1.272, time/batch=0.173\n",
      "15689/67600 (epoch 11), train_loss = 1.207, time/batch=0.167\n",
      "15690/67600 (epoch 11), train_loss = 1.205, time/batch=0.107\n",
      "15691/67600 (epoch 11), train_loss = 1.228, time/batch=0.114\n",
      "15692/67600 (epoch 11), train_loss = 1.156, time/batch=0.121\n",
      "15693/67600 (epoch 11), train_loss = 1.270, time/batch=0.107\n",
      "15694/67600 (epoch 11), train_loss = 1.233, time/batch=0.191\n",
      "15695/67600 (epoch 11), train_loss = 1.299, time/batch=0.137\n",
      "15696/67600 (epoch 11), train_loss = 1.245, time/batch=0.129\n",
      "15697/67600 (epoch 11), train_loss = 1.274, time/batch=0.116\n",
      "15698/67600 (epoch 11), train_loss = 1.368, time/batch=0.101\n",
      "15699/67600 (epoch 11), train_loss = 1.205, time/batch=0.126\n",
      "15700/67600 (epoch 11), train_loss = 1.232, time/batch=0.116\n",
      "15701/67600 (epoch 11), train_loss = 1.266, time/batch=0.115\n",
      "15702/67600 (epoch 11), train_loss = 1.312, time/batch=0.199\n",
      "15703/67600 (epoch 11), train_loss = 1.215, time/batch=0.133\n",
      "15704/67600 (epoch 11), train_loss = 1.227, time/batch=0.102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15705/67600 (epoch 11), train_loss = 1.228, time/batch=0.110\n",
      "15706/67600 (epoch 11), train_loss = 1.197, time/batch=0.115\n",
      "15707/67600 (epoch 11), train_loss = 1.274, time/batch=0.119\n",
      "15708/67600 (epoch 11), train_loss = 1.127, time/batch=0.120\n",
      "15709/67600 (epoch 11), train_loss = 1.263, time/batch=0.135\n",
      "15710/67600 (epoch 11), train_loss = 1.167, time/batch=0.199\n",
      "15711/67600 (epoch 11), train_loss = 1.229, time/batch=0.135\n",
      "15712/67600 (epoch 11), train_loss = 1.283, time/batch=0.119\n",
      "15713/67600 (epoch 11), train_loss = 1.245, time/batch=0.106\n",
      "15714/67600 (epoch 11), train_loss = 1.242, time/batch=0.112\n",
      "15715/67600 (epoch 11), train_loss = 1.243, time/batch=0.104\n",
      "15716/67600 (epoch 11), train_loss = 1.231, time/batch=0.116\n",
      "15717/67600 (epoch 11), train_loss = 1.217, time/batch=0.112\n",
      "15718/67600 (epoch 11), train_loss = 1.207, time/batch=0.204\n",
      "15719/67600 (epoch 11), train_loss = 1.214, time/batch=0.125\n",
      "15720/67600 (epoch 11), train_loss = 1.247, time/batch=0.119\n",
      "15721/67600 (epoch 11), train_loss = 1.227, time/batch=0.113\n",
      "15722/67600 (epoch 11), train_loss = 1.230, time/batch=0.108\n",
      "15723/67600 (epoch 11), train_loss = 1.307, time/batch=0.121\n",
      "15724/67600 (epoch 11), train_loss = 1.310, time/batch=0.104\n",
      "15725/67600 (epoch 11), train_loss = 1.285, time/batch=0.162\n",
      "15726/67600 (epoch 11), train_loss = 1.226, time/batch=0.179\n",
      "15727/67600 (epoch 11), train_loss = 1.267, time/batch=0.111\n",
      "15728/67600 (epoch 11), train_loss = 1.232, time/batch=0.130\n",
      "15729/67600 (epoch 11), train_loss = 1.252, time/batch=0.107\n",
      "15730/67600 (epoch 11), train_loss = 1.268, time/batch=0.121\n",
      "15731/67600 (epoch 11), train_loss = 1.285, time/batch=0.113\n",
      "15732/67600 (epoch 11), train_loss = 1.239, time/batch=0.112\n",
      "15733/67600 (epoch 11), train_loss = 1.288, time/batch=0.233\n",
      "15734/67600 (epoch 11), train_loss = 1.310, time/batch=0.116\n",
      "15735/67600 (epoch 11), train_loss = 1.263, time/batch=0.122\n",
      "15736/67600 (epoch 11), train_loss = 1.199, time/batch=0.110\n",
      "15737/67600 (epoch 11), train_loss = 1.294, time/batch=0.121\n",
      "15738/67600 (epoch 11), train_loss = 1.277, time/batch=0.110\n",
      "15739/67600 (epoch 11), train_loss = 1.216, time/batch=0.147\n",
      "15740/67600 (epoch 11), train_loss = 1.238, time/batch=0.107\n",
      "15741/67600 (epoch 11), train_loss = 1.229, time/batch=0.107\n",
      "15742/67600 (epoch 11), train_loss = 1.239, time/batch=0.117\n",
      "15743/67600 (epoch 11), train_loss = 1.211, time/batch=0.105\n",
      "15744/67600 (epoch 11), train_loss = 1.273, time/batch=0.112\n",
      "15745/67600 (epoch 11), train_loss = 1.196, time/batch=0.277\n",
      "15746/67600 (epoch 11), train_loss = 1.241, time/batch=0.115\n",
      "15747/67600 (epoch 11), train_loss = 1.292, time/batch=0.124\n",
      "15748/67600 (epoch 11), train_loss = 1.272, time/batch=0.108\n",
      "15749/67600 (epoch 11), train_loss = 1.146, time/batch=0.132\n",
      "15750/67600 (epoch 11), train_loss = 1.235, time/batch=0.107\n",
      "15751/67600 (epoch 11), train_loss = 1.138, time/batch=0.117\n",
      "15752/67600 (epoch 11), train_loss = 1.195, time/batch=0.106\n",
      "15753/67600 (epoch 11), train_loss = 1.206, time/batch=0.239\n",
      "15754/67600 (epoch 11), train_loss = 1.211, time/batch=0.122\n",
      "15755/67600 (epoch 11), train_loss = 1.235, time/batch=0.123\n",
      "15756/67600 (epoch 11), train_loss = 1.208, time/batch=0.102\n",
      "15757/67600 (epoch 11), train_loss = 1.227, time/batch=0.118\n",
      "15758/67600 (epoch 11), train_loss = 1.204, time/batch=0.116\n",
      "15759/67600 (epoch 11), train_loss = 1.176, time/batch=0.111\n",
      "15760/67600 (epoch 11), train_loss = 1.288, time/batch=0.115\n",
      "15761/67600 (epoch 11), train_loss = 1.262, time/batch=0.235\n",
      "15762/67600 (epoch 11), train_loss = 1.285, time/batch=0.119\n",
      "15763/67600 (epoch 11), train_loss = 1.277, time/batch=0.111\n",
      "15764/67600 (epoch 11), train_loss = 1.251, time/batch=0.101\n",
      "15765/67600 (epoch 11), train_loss = 1.213, time/batch=0.119\n",
      "15766/67600 (epoch 11), train_loss = 1.253, time/batch=0.198\n",
      "15767/67600 (epoch 11), train_loss = 1.218, time/batch=0.124\n",
      "15768/67600 (epoch 11), train_loss = 1.237, time/batch=0.134\n",
      "15769/67600 (epoch 11), train_loss = 1.302, time/batch=0.117\n",
      "15770/67600 (epoch 11), train_loss = 1.261, time/batch=0.120\n",
      "15771/67600 (epoch 11), train_loss = 1.274, time/batch=0.121\n",
      "15772/67600 (epoch 11), train_loss = 1.249, time/batch=0.103\n",
      "15773/67600 (epoch 11), train_loss = 1.284, time/batch=0.112\n",
      "15774/67600 (epoch 11), train_loss = 1.284, time/batch=0.221\n",
      "15775/67600 (epoch 11), train_loss = 1.177, time/batch=0.144\n",
      "15776/67600 (epoch 11), train_loss = 1.219, time/batch=0.118\n",
      "15777/67600 (epoch 11), train_loss = 1.267, time/batch=0.120\n",
      "15778/67600 (epoch 11), train_loss = 1.224, time/batch=0.106\n",
      "15779/67600 (epoch 11), train_loss = 1.211, time/batch=0.108\n",
      "15780/67600 (epoch 11), train_loss = 1.284, time/batch=0.118\n",
      "15781/67600 (epoch 11), train_loss = 1.215, time/batch=0.107\n",
      "15782/67600 (epoch 11), train_loss = 1.225, time/batch=0.215\n",
      "15783/67600 (epoch 11), train_loss = 1.250, time/batch=0.132\n",
      "15784/67600 (epoch 11), train_loss = 1.229, time/batch=0.091\n",
      "15785/67600 (epoch 11), train_loss = 1.261, time/batch=0.126\n",
      "15786/67600 (epoch 11), train_loss = 1.280, time/batch=0.113\n",
      "15787/67600 (epoch 11), train_loss = 1.206, time/batch=0.120\n",
      "15788/67600 (epoch 11), train_loss = 1.231, time/batch=0.107\n",
      "15789/67600 (epoch 11), train_loss = 1.220, time/batch=0.174\n",
      "15790/67600 (epoch 11), train_loss = 1.243, time/batch=0.179\n",
      "15791/67600 (epoch 11), train_loss = 1.236, time/batch=0.119\n",
      "15792/67600 (epoch 11), train_loss = 1.264, time/batch=0.084\n",
      "15793/67600 (epoch 11), train_loss = 1.240, time/batch=0.126\n",
      "15794/67600 (epoch 11), train_loss = 1.255, time/batch=0.113\n",
      "15795/67600 (epoch 11), train_loss = 1.198, time/batch=0.115\n",
      "15796/67600 (epoch 11), train_loss = 1.196, time/batch=0.112\n",
      "15797/67600 (epoch 11), train_loss = 1.218, time/batch=0.244\n",
      "15798/67600 (epoch 11), train_loss = 1.215, time/batch=0.107\n",
      "15799/67600 (epoch 11), train_loss = 1.232, time/batch=0.115\n",
      "15800/67600 (epoch 11), train_loss = 1.208, time/batch=0.121\n",
      "15801/67600 (epoch 11), train_loss = 1.225, time/batch=0.111\n",
      "15802/67600 (epoch 11), train_loss = 1.185, time/batch=0.125\n",
      "15803/67600 (epoch 11), train_loss = 1.240, time/batch=0.189\n",
      "15804/67600 (epoch 11), train_loss = 1.215, time/batch=0.131\n",
      "15805/67600 (epoch 11), train_loss = 1.185, time/batch=0.118\n",
      "15806/67600 (epoch 11), train_loss = 1.210, time/batch=0.108\n",
      "15807/67600 (epoch 11), train_loss = 1.205, time/batch=0.117\n",
      "15808/67600 (epoch 11), train_loss = 1.260, time/batch=0.120\n",
      "15809/67600 (epoch 11), train_loss = 1.221, time/batch=0.108\n",
      "15810/67600 (epoch 11), train_loss = 1.212, time/batch=0.112\n",
      "15811/67600 (epoch 11), train_loss = 1.208, time/batch=0.215\n",
      "15812/67600 (epoch 11), train_loss = 1.233, time/batch=0.132\n",
      "15813/67600 (epoch 11), train_loss = 1.194, time/batch=0.120\n",
      "15814/67600 (epoch 11), train_loss = 1.171, time/batch=0.107\n",
      "15815/67600 (epoch 11), train_loss = 1.258, time/batch=0.119\n",
      "15816/67600 (epoch 11), train_loss = 1.217, time/batch=0.099\n",
      "15817/67600 (epoch 11), train_loss = 1.240, time/batch=0.105\n",
      "15818/67600 (epoch 11), train_loss = 1.205, time/batch=0.136\n",
      "15819/67600 (epoch 11), train_loss = 1.184, time/batch=0.207\n",
      "15820/67600 (epoch 11), train_loss = 1.239, time/batch=0.132\n",
      "15821/67600 (epoch 11), train_loss = 1.186, time/batch=0.123\n",
      "15822/67600 (epoch 11), train_loss = 1.251, time/batch=0.106\n",
      "15823/67600 (epoch 11), train_loss = 1.205, time/batch=0.106\n",
      "15824/67600 (epoch 11), train_loss = 1.254, time/batch=0.116\n",
      "15825/67600 (epoch 11), train_loss = 1.196, time/batch=0.117\n",
      "15826/67600 (epoch 11), train_loss = 1.164, time/batch=0.191\n",
      "15827/67600 (epoch 11), train_loss = 1.279, time/batch=0.153\n",
      "15828/67600 (epoch 11), train_loss = 1.248, time/batch=0.120\n",
      "15829/67600 (epoch 11), train_loss = 1.249, time/batch=0.119\n",
      "15830/67600 (epoch 11), train_loss = 1.194, time/batch=0.106\n",
      "15831/67600 (epoch 11), train_loss = 1.205, time/batch=0.107\n",
      "15832/67600 (epoch 11), train_loss = 1.194, time/batch=0.115\n",
      "15833/67600 (epoch 11), train_loss = 1.150, time/batch=0.119\n",
      "15834/67600 (epoch 11), train_loss = 1.164, time/batch=0.240\n",
      "15835/67600 (epoch 11), train_loss = 1.156, time/batch=0.131\n",
      "15836/67600 (epoch 11), train_loss = 1.156, time/batch=0.117\n",
      "15837/67600 (epoch 11), train_loss = 1.239, time/batch=0.103\n",
      "15838/67600 (epoch 11), train_loss = 1.231, time/batch=0.106\n",
      "15839/67600 (epoch 11), train_loss = 1.174, time/batch=0.137\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15840/67600 (epoch 11), train_loss = 1.188, time/batch=0.171\n",
      "15841/67600 (epoch 11), train_loss = 1.185, time/batch=0.139\n",
      "15842/67600 (epoch 11), train_loss = 1.218, time/batch=0.120\n",
      "15843/67600 (epoch 11), train_loss = 1.233, time/batch=0.111\n",
      "15844/67600 (epoch 11), train_loss = 1.172, time/batch=0.109\n",
      "15845/67600 (epoch 11), train_loss = 1.235, time/batch=0.118\n",
      "15846/67600 (epoch 11), train_loss = 1.265, time/batch=0.108\n",
      "15847/67600 (epoch 11), train_loss = 1.156, time/batch=0.156\n",
      "15848/67600 (epoch 11), train_loss = 1.158, time/batch=0.111\n",
      "15849/67600 (epoch 11), train_loss = 1.187, time/batch=0.114\n",
      "15850/67600 (epoch 11), train_loss = 1.235, time/batch=0.108\n",
      "15851/67600 (epoch 11), train_loss = 1.211, time/batch=0.109\n",
      "15852/67600 (epoch 11), train_loss = 1.228, time/batch=0.117\n",
      "15853/67600 (epoch 11), train_loss = 1.184, time/batch=0.107\n",
      "15854/67600 (epoch 11), train_loss = 1.207, time/batch=0.273\n",
      "15855/67600 (epoch 11), train_loss = 1.252, time/batch=0.125\n",
      "15856/67600 (epoch 11), train_loss = 1.199, time/batch=0.116\n",
      "15857/67600 (epoch 11), train_loss = 1.285, time/batch=0.105\n",
      "15858/67600 (epoch 11), train_loss = 1.223, time/batch=0.120\n",
      "15859/67600 (epoch 11), train_loss = 1.291, time/batch=0.108\n",
      "15860/67600 (epoch 11), train_loss = 1.184, time/batch=0.118\n",
      "15861/67600 (epoch 11), train_loss = 1.217, time/batch=0.111\n",
      "15862/67600 (epoch 11), train_loss = 1.244, time/batch=0.245\n",
      "15863/67600 (epoch 11), train_loss = 1.210, time/batch=0.117\n",
      "15864/67600 (epoch 11), train_loss = 1.262, time/batch=0.119\n",
      "15865/67600 (epoch 11), train_loss = 1.219, time/batch=0.107\n",
      "15866/67600 (epoch 11), train_loss = 1.203, time/batch=0.106\n",
      "15867/67600 (epoch 11), train_loss = 1.220, time/batch=0.118\n",
      "15868/67600 (epoch 11), train_loss = 1.215, time/batch=0.117\n",
      "15869/67600 (epoch 11), train_loss = 1.235, time/batch=0.182\n",
      "15870/67600 (epoch 11), train_loss = 1.187, time/batch=0.159\n",
      "15871/67600 (epoch 11), train_loss = 1.202, time/batch=0.126\n",
      "15872/67600 (epoch 11), train_loss = 1.218, time/batch=0.107\n",
      "15873/67600 (epoch 11), train_loss = 1.231, time/batch=0.112\n",
      "15874/67600 (epoch 11), train_loss = 1.201, time/batch=0.111\n",
      "15875/67600 (epoch 11), train_loss = 1.218, time/batch=0.199\n",
      "15876/67600 (epoch 11), train_loss = 1.169, time/batch=0.147\n",
      "15877/67600 (epoch 11), train_loss = 1.235, time/batch=0.113\n",
      "15878/67600 (epoch 11), train_loss = 1.218, time/batch=0.118\n",
      "15879/67600 (epoch 11), train_loss = 1.183, time/batch=0.122\n",
      "15880/67600 (epoch 11), train_loss = 1.221, time/batch=0.105\n",
      "15881/67600 (epoch 11), train_loss = 1.175, time/batch=0.103\n",
      "15882/67600 (epoch 11), train_loss = 1.199, time/batch=0.131\n",
      "15883/67600 (epoch 11), train_loss = 1.194, time/batch=0.202\n",
      "15884/67600 (epoch 11), train_loss = 1.154, time/batch=0.142\n",
      "15885/67600 (epoch 11), train_loss = 1.202, time/batch=0.127\n",
      "15886/67600 (epoch 11), train_loss = 1.193, time/batch=0.101\n",
      "15887/67600 (epoch 11), train_loss = 1.213, time/batch=0.109\n",
      "15888/67600 (epoch 11), train_loss = 1.188, time/batch=0.111\n",
      "15889/67600 (epoch 11), train_loss = 1.239, time/batch=0.105\n",
      "15890/67600 (epoch 11), train_loss = 1.213, time/batch=0.217\n",
      "15891/67600 (epoch 11), train_loss = 1.228, time/batch=0.119\n",
      "15892/67600 (epoch 11), train_loss = 1.203, time/batch=0.164\n",
      "15893/67600 (epoch 11), train_loss = 1.211, time/batch=0.107\n",
      "15894/67600 (epoch 11), train_loss = 1.208, time/batch=0.120\n",
      "15895/67600 (epoch 11), train_loss = 1.204, time/batch=0.110\n",
      "15896/67600 (epoch 11), train_loss = 1.203, time/batch=0.110\n",
      "15897/67600 (epoch 11), train_loss = 1.165, time/batch=0.114\n",
      "15898/67600 (epoch 11), train_loss = 1.250, time/batch=0.233\n",
      "15899/67600 (epoch 11), train_loss = 1.167, time/batch=0.131\n",
      "15900/67600 (epoch 11), train_loss = 1.258, time/batch=0.122\n",
      "15901/67600 (epoch 11), train_loss = 1.227, time/batch=0.097\n",
      "15902/67600 (epoch 11), train_loss = 1.253, time/batch=0.129\n",
      "15903/67600 (epoch 11), train_loss = 1.265, time/batch=0.113\n",
      "15904/67600 (epoch 11), train_loss = 1.234, time/batch=0.115\n",
      "15905/67600 (epoch 11), train_loss = 1.198, time/batch=0.131\n",
      "15906/67600 (epoch 11), train_loss = 1.219, time/batch=0.212\n",
      "15907/67600 (epoch 11), train_loss = 1.196, time/batch=0.118\n",
      "15908/67600 (epoch 11), train_loss = 1.192, time/batch=0.112\n",
      "15909/67600 (epoch 11), train_loss = 1.185, time/batch=0.125\n",
      "15910/67600 (epoch 11), train_loss = 1.226, time/batch=0.105\n",
      "15911/67600 (epoch 11), train_loss = 1.207, time/batch=0.199\n",
      "15912/67600 (epoch 11), train_loss = 1.223, time/batch=0.131\n",
      "15913/67600 (epoch 11), train_loss = 1.223, time/batch=0.121\n",
      "15914/67600 (epoch 11), train_loss = 1.253, time/batch=0.112\n",
      "15915/67600 (epoch 11), train_loss = 1.120, time/batch=0.115\n",
      "15916/67600 (epoch 11), train_loss = 1.208, time/batch=0.113\n",
      "15917/67600 (epoch 11), train_loss = 1.214, time/batch=0.121\n",
      "15918/67600 (epoch 11), train_loss = 1.219, time/batch=0.116\n",
      "15919/67600 (epoch 11), train_loss = 1.277, time/batch=0.196\n",
      "15920/67600 (epoch 11), train_loss = 1.251, time/batch=0.151\n",
      "15921/67600 (epoch 11), train_loss = 1.237, time/batch=0.125\n",
      "15922/67600 (epoch 11), train_loss = 1.220, time/batch=0.105\n",
      "15923/67600 (epoch 11), train_loss = 1.189, time/batch=0.108\n",
      "15924/67600 (epoch 11), train_loss = 1.222, time/batch=0.110\n",
      "15925/67600 (epoch 11), train_loss = 1.217, time/batch=0.116\n",
      "15926/67600 (epoch 11), train_loss = 1.241, time/batch=0.112\n",
      "15927/67600 (epoch 11), train_loss = 1.216, time/batch=0.224\n",
      "15928/67600 (epoch 11), train_loss = 1.148, time/batch=0.133\n",
      "15929/67600 (epoch 11), train_loss = 1.259, time/batch=0.124\n",
      "15930/67600 (epoch 11), train_loss = 1.292, time/batch=0.111\n",
      "15931/67600 (epoch 11), train_loss = 1.212, time/batch=0.117\n",
      "15932/67600 (epoch 11), train_loss = 1.238, time/batch=0.117\n",
      "15933/67600 (epoch 11), train_loss = 1.243, time/batch=0.112\n",
      "15934/67600 (epoch 11), train_loss = 1.224, time/batch=0.209\n",
      "15935/67600 (epoch 11), train_loss = 1.186, time/batch=0.138\n",
      "15936/67600 (epoch 11), train_loss = 1.229, time/batch=0.120\n",
      "15937/67600 (epoch 11), train_loss = 1.219, time/batch=0.110\n",
      "15938/67600 (epoch 11), train_loss = 1.220, time/batch=0.114\n",
      "15939/67600 (epoch 11), train_loss = 1.261, time/batch=0.108\n",
      "15940/67600 (epoch 11), train_loss = 1.184, time/batch=0.114\n",
      "15941/67600 (epoch 11), train_loss = 1.233, time/batch=0.120\n",
      "15942/67600 (epoch 11), train_loss = 1.253, time/batch=0.225\n",
      "15943/67600 (epoch 11), train_loss = 1.273, time/batch=0.133\n",
      "15944/67600 (epoch 11), train_loss = 1.226, time/batch=0.112\n",
      "15945/67600 (epoch 11), train_loss = 1.204, time/batch=0.109\n",
      "15946/67600 (epoch 11), train_loss = 1.180, time/batch=0.114\n",
      "15947/67600 (epoch 11), train_loss = 1.217, time/batch=0.100\n",
      "15948/67600 (epoch 11), train_loss = 1.268, time/batch=0.213\n",
      "15949/67600 (epoch 11), train_loss = 1.269, time/batch=0.162\n",
      "15950/67600 (epoch 11), train_loss = 1.268, time/batch=0.109\n",
      "15951/67600 (epoch 11), train_loss = 1.257, time/batch=0.120\n",
      "15952/67600 (epoch 11), train_loss = 1.276, time/batch=0.099\n",
      "15953/67600 (epoch 11), train_loss = 1.191, time/batch=0.124\n",
      "15954/67600 (epoch 11), train_loss = 1.256, time/batch=0.119\n",
      "15955/67600 (epoch 11), train_loss = 1.192, time/batch=0.139\n",
      "15956/67600 (epoch 11), train_loss = 1.185, time/batch=0.110\n",
      "15957/67600 (epoch 11), train_loss = 1.293, time/batch=0.116\n",
      "15958/67600 (epoch 11), train_loss = 1.258, time/batch=0.108\n",
      "15959/67600 (epoch 11), train_loss = 1.162, time/batch=0.112\n",
      "15960/67600 (epoch 11), train_loss = 1.204, time/batch=0.108\n",
      "15961/67600 (epoch 11), train_loss = 1.193, time/batch=0.109\n",
      "15962/67600 (epoch 11), train_loss = 1.242, time/batch=0.275\n",
      "15963/67600 (epoch 11), train_loss = 1.202, time/batch=0.124\n",
      "15964/67600 (epoch 11), train_loss = 1.265, time/batch=0.103\n",
      "15965/67600 (epoch 11), train_loss = 1.215, time/batch=0.120\n",
      "15966/67600 (epoch 11), train_loss = 1.220, time/batch=0.114\n",
      "15967/67600 (epoch 11), train_loss = 1.188, time/batch=0.120\n",
      "15968/67600 (epoch 11), train_loss = 1.228, time/batch=0.105\n",
      "15969/67600 (epoch 11), train_loss = 1.213, time/batch=0.124\n",
      "15970/67600 (epoch 11), train_loss = 1.193, time/batch=0.234\n",
      "15971/67600 (epoch 11), train_loss = 1.158, time/batch=0.112\n",
      "15972/67600 (epoch 11), train_loss = 1.230, time/batch=0.118\n",
      "15973/67600 (epoch 11), train_loss = 1.211, time/batch=0.102\n",
      "15974/67600 (epoch 11), train_loss = 1.203, time/batch=0.119\n",
      "15975/67600 (epoch 11), train_loss = 1.180, time/batch=0.105\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15976/67600 (epoch 11), train_loss = 1.296, time/batch=0.107\n",
      "15977/67600 (epoch 11), train_loss = 1.203, time/batch=0.228\n",
      "15978/67600 (epoch 11), train_loss = 1.210, time/batch=0.119\n",
      "15979/67600 (epoch 11), train_loss = 1.249, time/batch=0.141\n",
      "15980/67600 (epoch 11), train_loss = 1.202, time/batch=0.119\n",
      "15981/67600 (epoch 11), train_loss = 1.230, time/batch=0.109\n",
      "15982/67600 (epoch 11), train_loss = 1.246, time/batch=0.101\n",
      "15983/67600 (epoch 11), train_loss = 1.218, time/batch=0.208\n",
      "15984/67600 (epoch 11), train_loss = 1.277, time/batch=0.139\n",
      "15985/67600 (epoch 11), train_loss = 1.274, time/batch=0.125\n",
      "15986/67600 (epoch 11), train_loss = 1.250, time/batch=0.121\n",
      "15987/67600 (epoch 11), train_loss = 1.320, time/batch=0.110\n",
      "15988/67600 (epoch 11), train_loss = 1.222, time/batch=0.115\n",
      "15989/67600 (epoch 11), train_loss = 1.254, time/batch=0.120\n",
      "15990/67600 (epoch 11), train_loss = 1.225, time/batch=0.168\n",
      "15991/67600 (epoch 11), train_loss = 1.322, time/batch=0.162\n",
      "15992/67600 (epoch 11), train_loss = 1.207, time/batch=0.137\n",
      "15993/67600 (epoch 11), train_loss = 1.263, time/batch=0.113\n",
      "15994/67600 (epoch 11), train_loss = 1.323, time/batch=0.104\n",
      "15995/67600 (epoch 11), train_loss = 1.246, time/batch=0.117\n",
      "15996/67600 (epoch 11), train_loss = 1.217, time/batch=0.105\n",
      "15997/67600 (epoch 11), train_loss = 1.219, time/batch=0.102\n",
      "15998/67600 (epoch 11), train_loss = 1.285, time/batch=0.184\n",
      "15999/67600 (epoch 11), train_loss = 1.233, time/batch=0.143\n",
      "16000/67600 (epoch 11), train_loss = 1.248, time/batch=0.128\n",
      "model saved to ./save/model.ckpt\n",
      "16001/67600 (epoch 11), train_loss = 1.238, time/batch=0.068\n",
      "16002/67600 (epoch 11), train_loss = 1.245, time/batch=0.070\n",
      "16003/67600 (epoch 11), train_loss = 1.252, time/batch=0.198\n",
      "16004/67600 (epoch 11), train_loss = 1.214, time/batch=0.125\n",
      "16005/67600 (epoch 11), train_loss = 1.278, time/batch=0.115\n",
      "16006/67600 (epoch 11), train_loss = 1.303, time/batch=0.121\n",
      "16007/67600 (epoch 11), train_loss = 1.298, time/batch=0.109\n",
      "16008/67600 (epoch 11), train_loss = 1.270, time/batch=0.114\n",
      "16009/67600 (epoch 11), train_loss = 1.237, time/batch=0.114\n",
      "16010/67600 (epoch 11), train_loss = 1.241, time/batch=0.104\n",
      "16011/67600 (epoch 11), train_loss = 1.286, time/batch=0.211\n",
      "16012/67600 (epoch 11), train_loss = 1.233, time/batch=0.119\n",
      "16013/67600 (epoch 11), train_loss = 1.230, time/batch=0.116\n",
      "16014/67600 (epoch 11), train_loss = 1.270, time/batch=0.132\n",
      "16015/67600 (epoch 11), train_loss = 1.266, time/batch=0.106\n",
      "16016/67600 (epoch 11), train_loss = 1.254, time/batch=0.214\n",
      "16017/67600 (epoch 11), train_loss = 1.209, time/batch=0.107\n",
      "16018/67600 (epoch 11), train_loss = 1.196, time/batch=0.138\n",
      "16019/67600 (epoch 11), train_loss = 1.188, time/batch=0.112\n",
      "16020/67600 (epoch 11), train_loss = 1.201, time/batch=0.115\n",
      "16021/67600 (epoch 11), train_loss = 1.218, time/batch=0.097\n",
      "16022/67600 (epoch 11), train_loss = 1.164, time/batch=0.125\n",
      "16023/67600 (epoch 11), train_loss = 1.258, time/batch=0.103\n",
      "16024/67600 (epoch 11), train_loss = 1.225, time/batch=0.156\n",
      "16025/67600 (epoch 11), train_loss = 1.203, time/batch=0.124\n",
      "16026/67600 (epoch 11), train_loss = 1.230, time/batch=0.105\n",
      "16027/67600 (epoch 11), train_loss = 1.209, time/batch=0.116\n",
      "16028/67600 (epoch 11), train_loss = 1.210, time/batch=0.104\n",
      "16029/67600 (epoch 11), train_loss = 1.168, time/batch=0.097\n",
      "16030/67600 (epoch 11), train_loss = 1.270, time/batch=0.101\n",
      "16031/67600 (epoch 11), train_loss = 1.262, time/batch=0.300\n",
      "16032/67600 (epoch 11), train_loss = 1.187, time/batch=0.127\n",
      "16033/67600 (epoch 11), train_loss = 1.199, time/batch=0.122\n",
      "16034/67600 (epoch 11), train_loss = 1.214, time/batch=0.106\n",
      "16035/67600 (epoch 11), train_loss = 1.175, time/batch=0.108\n",
      "16036/67600 (epoch 11), train_loss = 1.233, time/batch=0.113\n",
      "16037/67600 (epoch 11), train_loss = 1.185, time/batch=0.112\n",
      "16038/67600 (epoch 11), train_loss = 1.199, time/batch=0.130\n",
      "16039/67600 (epoch 11), train_loss = 1.229, time/batch=0.222\n",
      "16040/67600 (epoch 11), train_loss = 1.236, time/batch=0.111\n",
      "16041/67600 (epoch 11), train_loss = 1.153, time/batch=0.121\n",
      "16042/67600 (epoch 11), train_loss = 1.185, time/batch=0.119\n",
      "16043/67600 (epoch 11), train_loss = 1.187, time/batch=0.111\n",
      "16044/67600 (epoch 11), train_loss = 1.215, time/batch=0.113\n",
      "16045/67600 (epoch 11), train_loss = 1.225, time/batch=0.101\n",
      "16046/67600 (epoch 11), train_loss = 1.212, time/batch=0.223\n",
      "16047/67600 (epoch 11), train_loss = 1.221, time/batch=0.127\n",
      "16048/67600 (epoch 11), train_loss = 1.226, time/batch=0.109\n",
      "16049/67600 (epoch 11), train_loss = 1.218, time/batch=0.123\n",
      "16050/67600 (epoch 11), train_loss = 1.261, time/batch=0.107\n",
      "16051/67600 (epoch 11), train_loss = 1.324, time/batch=0.110\n",
      "16052/67600 (epoch 11), train_loss = 1.285, time/batch=0.210\n",
      "16053/67600 (epoch 11), train_loss = 1.246, time/batch=0.139\n",
      "16054/67600 (epoch 11), train_loss = 1.231, time/batch=0.112\n",
      "16055/67600 (epoch 11), train_loss = 1.221, time/batch=0.128\n",
      "16056/67600 (epoch 11), train_loss = 1.246, time/batch=0.118\n",
      "16057/67600 (epoch 11), train_loss = 1.149, time/batch=0.091\n",
      "16058/67600 (epoch 11), train_loss = 1.178, time/batch=0.122\n",
      "16059/67600 (epoch 11), train_loss = 1.274, time/batch=0.242\n",
      "16060/67600 (epoch 11), train_loss = 1.216, time/batch=0.142\n",
      "16061/67600 (epoch 11), train_loss = 1.187, time/batch=0.132\n",
      "16062/67600 (epoch 11), train_loss = 1.227, time/batch=0.131\n",
      "16063/67600 (epoch 11), train_loss = 1.201, time/batch=0.122\n",
      "16064/67600 (epoch 11), train_loss = 1.215, time/batch=0.107\n",
      "16065/67600 (epoch 11), train_loss = 1.218, time/batch=0.121\n",
      "16066/67600 (epoch 11), train_loss = 1.177, time/batch=0.130\n",
      "16067/67600 (epoch 11), train_loss = 1.195, time/batch=0.199\n",
      "16068/67600 (epoch 11), train_loss = 1.240, time/batch=0.134\n",
      "16069/67600 (epoch 11), train_loss = 1.248, time/batch=0.123\n",
      "16070/67600 (epoch 11), train_loss = 1.260, time/batch=0.108\n",
      "16071/67600 (epoch 11), train_loss = 1.209, time/batch=0.117\n",
      "16072/67600 (epoch 11), train_loss = 1.240, time/batch=0.104\n",
      "16073/67600 (epoch 11), train_loss = 1.200, time/batch=0.112\n",
      "16074/67600 (epoch 11), train_loss = 1.186, time/batch=0.215\n",
      "16075/67600 (epoch 11), train_loss = 1.193, time/batch=0.138\n",
      "16076/67600 (epoch 11), train_loss = 1.296, time/batch=0.115\n",
      "16077/67600 (epoch 11), train_loss = 1.218, time/batch=0.119\n",
      "16078/67600 (epoch 11), train_loss = 1.180, time/batch=0.112\n",
      "16079/67600 (epoch 11), train_loss = 1.232, time/batch=0.136\n",
      "16080/67600 (epoch 11), train_loss = 1.184, time/batch=0.105\n",
      "16081/67600 (epoch 11), train_loss = 1.188, time/batch=0.112\n",
      "16082/67600 (epoch 11), train_loss = 1.243, time/batch=0.240\n",
      "16083/67600 (epoch 11), train_loss = 1.198, time/batch=0.124\n",
      "16084/67600 (epoch 11), train_loss = 1.189, time/batch=0.129\n",
      "16085/67600 (epoch 11), train_loss = 1.225, time/batch=0.101\n",
      "16086/67600 (epoch 11), train_loss = 1.242, time/batch=0.123\n",
      "16087/67600 (epoch 11), train_loss = 1.211, time/batch=0.199\n",
      "16088/67600 (epoch 11), train_loss = 1.232, time/batch=0.114\n",
      "16089/67600 (epoch 11), train_loss = 1.230, time/batch=0.134\n",
      "16090/67600 (epoch 11), train_loss = 1.217, time/batch=0.114\n",
      "16091/67600 (epoch 11), train_loss = 1.218, time/batch=0.118\n",
      "16092/67600 (epoch 11), train_loss = 1.206, time/batch=0.104\n",
      "16093/67600 (epoch 11), train_loss = 1.202, time/batch=0.119\n",
      "16094/67600 (epoch 11), train_loss = 1.246, time/batch=0.112\n",
      "16095/67600 (epoch 11), train_loss = 1.207, time/batch=0.206\n",
      "16096/67600 (epoch 11), train_loss = 1.260, time/batch=0.143\n",
      "16097/67600 (epoch 11), train_loss = 1.241, time/batch=0.134\n",
      "16098/67600 (epoch 11), train_loss = 1.255, time/batch=0.103\n",
      "16099/67600 (epoch 11), train_loss = 1.226, time/batch=0.105\n",
      "16100/67600 (epoch 11), train_loss = 1.261, time/batch=0.123\n",
      "16101/67600 (epoch 11), train_loss = 1.206, time/batch=0.104\n",
      "16102/67600 (epoch 11), train_loss = 1.239, time/batch=0.114\n",
      "16103/67600 (epoch 11), train_loss = 1.238, time/batch=0.223\n",
      "16104/67600 (epoch 11), train_loss = 1.320, time/batch=0.133\n",
      "16105/67600 (epoch 11), train_loss = 1.276, time/batch=0.109\n",
      "16106/67600 (epoch 11), train_loss = 1.182, time/batch=0.113\n",
      "16107/67600 (epoch 11), train_loss = 1.217, time/batch=0.113\n",
      "16108/67600 (epoch 11), train_loss = 1.207, time/batch=0.113\n",
      "16109/67600 (epoch 11), train_loss = 1.243, time/batch=0.115\n",
      "16110/67600 (epoch 11), train_loss = 1.214, time/batch=0.117\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16111/67600 (epoch 11), train_loss = 1.200, time/batch=0.207\n",
      "16112/67600 (epoch 11), train_loss = 1.274, time/batch=0.124\n",
      "16113/67600 (epoch 11), train_loss = 1.207, time/batch=0.106\n",
      "16114/67600 (epoch 11), train_loss = 1.218, time/batch=0.101\n",
      "16115/67600 (epoch 11), train_loss = 1.250, time/batch=0.122\n",
      "16116/67600 (epoch 11), train_loss = 1.315, time/batch=0.189\n",
      "16117/67600 (epoch 11), train_loss = 1.237, time/batch=0.136\n",
      "16118/67600 (epoch 11), train_loss = 1.222, time/batch=0.151\n",
      "16119/67600 (epoch 11), train_loss = 1.217, time/batch=0.113\n",
      "16120/67600 (epoch 11), train_loss = 1.247, time/batch=0.125\n",
      "16121/67600 (epoch 11), train_loss = 1.212, time/batch=0.117\n",
      "16122/67600 (epoch 11), train_loss = 1.184, time/batch=0.112\n",
      "16123/67600 (epoch 11), train_loss = 1.286, time/batch=0.111\n",
      "16124/67600 (epoch 11), train_loss = 1.191, time/batch=0.212\n",
      "16125/67600 (epoch 11), train_loss = 1.275, time/batch=0.140\n",
      "16126/67600 (epoch 11), train_loss = 1.251, time/batch=0.096\n",
      "16127/67600 (epoch 11), train_loss = 1.262, time/batch=0.123\n",
      "16128/67600 (epoch 11), train_loss = 1.256, time/batch=0.118\n",
      "16129/67600 (epoch 11), train_loss = 1.251, time/batch=0.116\n",
      "16130/67600 (epoch 11), train_loss = 1.293, time/batch=0.113\n",
      "16131/67600 (epoch 11), train_loss = 1.226, time/batch=0.114\n",
      "16132/67600 (epoch 11), train_loss = 1.242, time/batch=0.134\n",
      "16133/67600 (epoch 11), train_loss = 1.204, time/batch=0.119\n",
      "16134/67600 (epoch 11), train_loss = 1.303, time/batch=0.109\n",
      "16135/67600 (epoch 11), train_loss = 1.290, time/batch=0.115\n",
      "16136/67600 (epoch 11), train_loss = 1.285, time/batch=0.112\n",
      "16137/67600 (epoch 11), train_loss = 1.225, time/batch=0.125\n",
      "16138/67600 (epoch 11), train_loss = 1.285, time/batch=0.244\n",
      "16139/67600 (epoch 11), train_loss = 1.199, time/batch=0.148\n",
      "16140/67600 (epoch 11), train_loss = 1.175, time/batch=0.100\n",
      "16141/67600 (epoch 11), train_loss = 1.234, time/batch=0.107\n",
      "16142/67600 (epoch 11), train_loss = 1.229, time/batch=0.106\n",
      "16143/67600 (epoch 11), train_loss = 1.172, time/batch=0.110\n",
      "16144/67600 (epoch 11), train_loss = 1.229, time/batch=0.121\n",
      "16145/67600 (epoch 11), train_loss = 1.218, time/batch=0.116\n",
      "16146/67600 (epoch 11), train_loss = 1.207, time/batch=0.234\n",
      "16147/67600 (epoch 11), train_loss = 1.246, time/batch=0.120\n",
      "16148/67600 (epoch 11), train_loss = 1.257, time/batch=0.123\n",
      "16149/67600 (epoch 11), train_loss = 1.241, time/batch=0.104\n",
      "16150/67600 (epoch 11), train_loss = 1.166, time/batch=0.107\n",
      "16151/67600 (epoch 11), train_loss = 1.180, time/batch=0.112\n",
      "16152/67600 (epoch 11), train_loss = 1.199, time/batch=0.115\n",
      "16153/67600 (epoch 11), train_loss = 1.224, time/batch=0.111\n",
      "16154/67600 (epoch 11), train_loss = 1.183, time/batch=0.240\n",
      "16155/67600 (epoch 11), train_loss = 1.239, time/batch=0.115\n",
      "16156/67600 (epoch 11), train_loss = 1.262, time/batch=0.113\n",
      "16157/67600 (epoch 11), train_loss = 1.221, time/batch=0.109\n",
      "16158/67600 (epoch 11), train_loss = 1.203, time/batch=0.116\n",
      "16159/67600 (epoch 11), train_loss = 1.279, time/batch=0.136\n",
      "16160/67600 (epoch 11), train_loss = 1.203, time/batch=0.187\n",
      "16161/67600 (epoch 11), train_loss = 1.267, time/batch=0.147\n",
      "16162/67600 (epoch 11), train_loss = 1.288, time/batch=0.107\n",
      "16163/67600 (epoch 11), train_loss = 1.257, time/batch=0.118\n",
      "16164/67600 (epoch 11), train_loss = 1.209, time/batch=0.108\n",
      "16165/67600 (epoch 11), train_loss = 1.209, time/batch=0.110\n",
      "16166/67600 (epoch 11), train_loss = 1.227, time/batch=0.117\n",
      "16167/67600 (epoch 11), train_loss = 1.226, time/batch=0.211\n",
      "16168/67600 (epoch 11), train_loss = 1.232, time/batch=0.153\n",
      "16169/67600 (epoch 11), train_loss = 1.246, time/batch=0.106\n",
      "16170/67600 (epoch 11), train_loss = 1.181, time/batch=0.144\n",
      "16171/67600 (epoch 11), train_loss = 1.252, time/batch=0.103\n",
      "16172/67600 (epoch 11), train_loss = 1.275, time/batch=0.128\n",
      "16173/67600 (epoch 11), train_loss = 1.228, time/batch=0.117\n",
      "16174/67600 (epoch 11), train_loss = 1.200, time/batch=0.110\n",
      "16175/67600 (epoch 11), train_loss = 1.227, time/batch=0.208\n",
      "16176/67600 (epoch 11), train_loss = 1.245, time/batch=0.137\n",
      "16177/67600 (epoch 11), train_loss = 1.171, time/batch=0.106\n",
      "16178/67600 (epoch 11), train_loss = 1.255, time/batch=0.120\n",
      "16179/67600 (epoch 11), train_loss = 1.241, time/batch=0.109\n",
      "16180/67600 (epoch 11), train_loss = 1.242, time/batch=0.119\n",
      "16181/67600 (epoch 11), train_loss = 1.234, time/batch=0.111\n",
      "16182/67600 (epoch 11), train_loss = 1.205, time/batch=0.192\n",
      "16183/67600 (epoch 11), train_loss = 1.217, time/batch=0.166\n",
      "16184/67600 (epoch 11), train_loss = 1.222, time/batch=0.134\n",
      "16185/67600 (epoch 11), train_loss = 1.292, time/batch=0.102\n",
      "16186/67600 (epoch 11), train_loss = 1.292, time/batch=0.126\n",
      "16187/67600 (epoch 11), train_loss = 1.242, time/batch=0.106\n",
      "16188/67600 (epoch 11), train_loss = 1.248, time/batch=0.105\n",
      "16189/67600 (epoch 11), train_loss = 1.264, time/batch=0.119\n",
      "16190/67600 (epoch 11), train_loss = 1.237, time/batch=0.241\n",
      "16191/67600 (epoch 11), train_loss = 1.210, time/batch=0.113\n",
      "16192/67600 (epoch 11), train_loss = 1.223, time/batch=0.110\n",
      "16193/67600 (epoch 11), train_loss = 1.224, time/batch=0.104\n",
      "16194/67600 (epoch 11), train_loss = 1.209, time/batch=0.126\n",
      "16195/67600 (epoch 11), train_loss = 1.229, time/batch=0.106\n",
      "16196/67600 (epoch 11), train_loss = 1.281, time/batch=0.220\n",
      "16197/67600 (epoch 11), train_loss = 1.222, time/batch=0.143\n",
      "16198/67600 (epoch 11), train_loss = 1.234, time/batch=0.106\n",
      "16199/67600 (epoch 11), train_loss = 1.215, time/batch=0.130\n",
      "16200/67600 (epoch 11), train_loss = 1.223, time/batch=0.106\n",
      "16201/67600 (epoch 11), train_loss = 1.244, time/batch=0.120\n",
      "16202/67600 (epoch 11), train_loss = 1.286, time/batch=0.110\n",
      "16203/67600 (epoch 11), train_loss = 1.276, time/batch=0.188\n",
      "16204/67600 (epoch 11), train_loss = 1.227, time/batch=0.159\n",
      "16205/67600 (epoch 11), train_loss = 1.210, time/batch=0.107\n",
      "16206/67600 (epoch 11), train_loss = 1.185, time/batch=0.108\n",
      "16207/67600 (epoch 11), train_loss = 1.253, time/batch=0.110\n",
      "16208/67600 (epoch 11), train_loss = 1.256, time/batch=0.111\n",
      "16209/67600 (epoch 11), train_loss = 1.234, time/batch=0.112\n",
      "16210/67600 (epoch 11), train_loss = 1.253, time/batch=0.112\n",
      "16211/67600 (epoch 11), train_loss = 1.226, time/batch=0.218\n",
      "16212/67600 (epoch 11), train_loss = 1.203, time/batch=0.143\n",
      "16213/67600 (epoch 11), train_loss = 1.230, time/batch=0.106\n",
      "16214/67600 (epoch 11), train_loss = 1.239, time/batch=0.108\n",
      "16215/67600 (epoch 11), train_loss = 1.226, time/batch=0.122\n",
      "16216/67600 (epoch 11), train_loss = 1.177, time/batch=0.107\n",
      "16217/67600 (epoch 11), train_loss = 1.225, time/batch=0.112\n",
      "16218/67600 (epoch 11), train_loss = 1.205, time/batch=0.124\n",
      "16219/67600 (epoch 11), train_loss = 1.230, time/batch=0.234\n",
      "16220/67600 (epoch 11), train_loss = 1.293, time/batch=0.123\n",
      "16221/67600 (epoch 11), train_loss = 1.320, time/batch=0.117\n",
      "16222/67600 (epoch 11), train_loss = 1.238, time/batch=0.116\n",
      "16223/67600 (epoch 11), train_loss = 1.250, time/batch=0.105\n",
      "16224/67600 (epoch 12), train_loss = 1.417, time/batch=0.111\n",
      "16225/67600 (epoch 12), train_loss = 1.179, time/batch=0.100\n",
      "16226/67600 (epoch 12), train_loss = 1.257, time/batch=0.229\n",
      "16227/67600 (epoch 12), train_loss = 1.217, time/batch=0.111\n",
      "16228/67600 (epoch 12), train_loss = 1.233, time/batch=0.120\n",
      "16229/67600 (epoch 12), train_loss = 1.258, time/batch=0.110\n",
      "16230/67600 (epoch 12), train_loss = 1.226, time/batch=0.108\n",
      "16231/67600 (epoch 12), train_loss = 1.232, time/batch=0.101\n",
      "16232/67600 (epoch 12), train_loss = 1.245, time/batch=0.121\n",
      "16233/67600 (epoch 12), train_loss = 1.222, time/batch=0.125\n",
      "16234/67600 (epoch 12), train_loss = 1.193, time/batch=0.238\n",
      "16235/67600 (epoch 12), train_loss = 1.204, time/batch=0.110\n",
      "16236/67600 (epoch 12), train_loss = 1.212, time/batch=0.117\n",
      "16237/67600 (epoch 12), train_loss = 1.279, time/batch=0.107\n",
      "16238/67600 (epoch 12), train_loss = 1.247, time/batch=0.114\n",
      "16239/67600 (epoch 12), train_loss = 1.226, time/batch=0.139\n",
      "16240/67600 (epoch 12), train_loss = 1.230, time/batch=0.127\n",
      "16241/67600 (epoch 12), train_loss = 1.242, time/batch=0.115\n",
      "16242/67600 (epoch 12), train_loss = 1.228, time/batch=0.110\n",
      "16243/67600 (epoch 12), train_loss = 1.221, time/batch=0.114\n",
      "16244/67600 (epoch 12), train_loss = 1.230, time/batch=0.107\n",
      "16245/67600 (epoch 12), train_loss = 1.164, time/batch=0.119\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16246/67600 (epoch 12), train_loss = 1.293, time/batch=0.258\n",
      "16247/67600 (epoch 12), train_loss = 1.257, time/batch=0.141\n",
      "16248/67600 (epoch 12), train_loss = 1.302, time/batch=0.107\n",
      "16249/67600 (epoch 12), train_loss = 1.157, time/batch=0.112\n",
      "16250/67600 (epoch 12), train_loss = 1.247, time/batch=0.093\n",
      "16251/67600 (epoch 12), train_loss = 1.266, time/batch=0.157\n",
      "16252/67600 (epoch 12), train_loss = 1.301, time/batch=0.121\n",
      "16253/67600 (epoch 12), train_loss = 1.221, time/batch=0.267\n",
      "16254/67600 (epoch 12), train_loss = 1.211, time/batch=0.124\n",
      "16255/67600 (epoch 12), train_loss = 1.287, time/batch=0.119\n",
      "16256/67600 (epoch 12), train_loss = 1.210, time/batch=0.108\n",
      "16257/67600 (epoch 12), train_loss = 1.281, time/batch=0.126\n",
      "16258/67600 (epoch 12), train_loss = 1.251, time/batch=0.121\n",
      "16259/67600 (epoch 12), train_loss = 1.238, time/batch=0.117\n",
      "16260/67600 (epoch 12), train_loss = 1.204, time/batch=0.257\n",
      "16261/67600 (epoch 12), train_loss = 1.249, time/batch=0.118\n",
      "16262/67600 (epoch 12), train_loss = 1.254, time/batch=0.131\n",
      "16263/67600 (epoch 12), train_loss = 1.234, time/batch=0.118\n",
      "16264/67600 (epoch 12), train_loss = 1.161, time/batch=0.108\n",
      "16265/67600 (epoch 12), train_loss = 1.261, time/batch=0.199\n",
      "16266/67600 (epoch 12), train_loss = 1.277, time/batch=0.151\n",
      "16267/67600 (epoch 12), train_loss = 1.254, time/batch=0.144\n",
      "16268/67600 (epoch 12), train_loss = 1.269, time/batch=0.128\n",
      "16269/67600 (epoch 12), train_loss = 1.229, time/batch=0.121\n",
      "16270/67600 (epoch 12), train_loss = 1.199, time/batch=0.117\n",
      "16271/67600 (epoch 12), train_loss = 1.241, time/batch=0.126\n",
      "16272/67600 (epoch 12), train_loss = 1.206, time/batch=0.115\n",
      "16273/67600 (epoch 12), train_loss = 1.199, time/batch=0.233\n",
      "16274/67600 (epoch 12), train_loss = 1.286, time/batch=0.146\n",
      "16275/67600 (epoch 12), train_loss = 1.206, time/batch=0.116\n",
      "16276/67600 (epoch 12), train_loss = 1.214, time/batch=0.127\n",
      "16277/67600 (epoch 12), train_loss = 1.307, time/batch=0.119\n",
      "16278/67600 (epoch 12), train_loss = 1.271, time/batch=0.116\n",
      "16279/67600 (epoch 12), train_loss = 1.232, time/batch=0.118\n",
      "16280/67600 (epoch 12), train_loss = 1.245, time/batch=0.251\n",
      "16281/67600 (epoch 12), train_loss = 1.238, time/batch=0.133\n",
      "16282/67600 (epoch 12), train_loss = 1.248, time/batch=0.125\n",
      "16283/67600 (epoch 12), train_loss = 1.238, time/batch=0.142\n",
      "16284/67600 (epoch 12), train_loss = 1.243, time/batch=0.113\n",
      "16285/67600 (epoch 12), train_loss = 1.224, time/batch=0.124\n",
      "16286/67600 (epoch 12), train_loss = 1.277, time/batch=0.127\n",
      "16287/67600 (epoch 12), train_loss = 1.279, time/batch=0.248\n",
      "16288/67600 (epoch 12), train_loss = 1.218, time/batch=0.128\n",
      "16289/67600 (epoch 12), train_loss = 1.219, time/batch=0.133\n",
      "16290/67600 (epoch 12), train_loss = 1.231, time/batch=0.115\n",
      "16291/67600 (epoch 12), train_loss = 1.248, time/batch=0.118\n",
      "16292/67600 (epoch 12), train_loss = 1.263, time/batch=0.110\n",
      "16293/67600 (epoch 12), train_loss = 1.259, time/batch=0.127\n",
      "16294/67600 (epoch 12), train_loss = 1.251, time/batch=0.260\n",
      "16295/67600 (epoch 12), train_loss = 1.256, time/batch=0.119\n",
      "16296/67600 (epoch 12), train_loss = 1.212, time/batch=0.115\n",
      "16297/67600 (epoch 12), train_loss = 1.289, time/batch=0.129\n",
      "16298/67600 (epoch 12), train_loss = 1.221, time/batch=0.125\n",
      "16299/67600 (epoch 12), train_loss = 1.278, time/batch=0.202\n",
      "16300/67600 (epoch 12), train_loss = 1.285, time/batch=0.151\n",
      "16301/67600 (epoch 12), train_loss = 1.360, time/batch=0.125\n",
      "16302/67600 (epoch 12), train_loss = 1.285, time/batch=0.131\n",
      "16303/67600 (epoch 12), train_loss = 1.210, time/batch=0.113\n",
      "16304/67600 (epoch 12), train_loss = 1.199, time/batch=0.112\n",
      "16305/67600 (epoch 12), train_loss = 1.247, time/batch=0.125\n",
      "16306/67600 (epoch 12), train_loss = 1.251, time/batch=0.239\n",
      "16307/67600 (epoch 12), train_loss = 1.227, time/batch=0.124\n",
      "16308/67600 (epoch 12), train_loss = 1.232, time/batch=0.135\n",
      "16309/67600 (epoch 12), train_loss = 1.235, time/batch=0.116\n",
      "16310/67600 (epoch 12), train_loss = 1.179, time/batch=0.124\n",
      "16311/67600 (epoch 12), train_loss = 1.292, time/batch=0.114\n",
      "16312/67600 (epoch 12), train_loss = 1.273, time/batch=0.130\n",
      "16313/67600 (epoch 12), train_loss = 1.269, time/batch=0.112\n",
      "16314/67600 (epoch 12), train_loss = 1.242, time/batch=0.227\n",
      "16315/67600 (epoch 12), train_loss = 1.261, time/batch=0.140\n",
      "16316/67600 (epoch 12), train_loss = 1.187, time/batch=0.118\n",
      "16317/67600 (epoch 12), train_loss = 1.210, time/batch=0.120\n",
      "16318/67600 (epoch 12), train_loss = 1.204, time/batch=0.123\n",
      "16319/67600 (epoch 12), train_loss = 1.150, time/batch=0.117\n",
      "16320/67600 (epoch 12), train_loss = 1.162, time/batch=0.120\n",
      "16321/67600 (epoch 12), train_loss = 1.238, time/batch=0.252\n",
      "16322/67600 (epoch 12), train_loss = 1.224, time/batch=0.126\n",
      "16323/67600 (epoch 12), train_loss = 1.268, time/batch=0.122\n",
      "16324/67600 (epoch 12), train_loss = 1.143, time/batch=0.114\n",
      "16325/67600 (epoch 12), train_loss = 1.223, time/batch=0.122\n",
      "16326/67600 (epoch 12), train_loss = 1.264, time/batch=0.122\n",
      "16327/67600 (epoch 12), train_loss = 1.165, time/batch=0.129\n",
      "16328/67600 (epoch 12), train_loss = 1.198, time/batch=0.241\n",
      "16329/67600 (epoch 12), train_loss = 1.249, time/batch=0.126\n",
      "16330/67600 (epoch 12), train_loss = 1.209, time/batch=0.115\n",
      "16331/67600 (epoch 12), train_loss = 1.247, time/batch=0.104\n",
      "16332/67600 (epoch 12), train_loss = 1.276, time/batch=0.139\n",
      "16333/67600 (epoch 12), train_loss = 1.244, time/batch=0.100\n",
      "16334/67600 (epoch 12), train_loss = 1.199, time/batch=0.128\n",
      "16335/67600 (epoch 12), train_loss = 1.241, time/batch=0.161\n",
      "16336/67600 (epoch 12), train_loss = 1.225, time/batch=0.216\n",
      "16337/67600 (epoch 12), train_loss = 1.262, time/batch=0.118\n",
      "16338/67600 (epoch 12), train_loss = 1.250, time/batch=0.118\n",
      "16339/67600 (epoch 12), train_loss = 1.199, time/batch=0.109\n",
      "16340/67600 (epoch 12), train_loss = 1.195, time/batch=0.125\n",
      "16341/67600 (epoch 12), train_loss = 1.229, time/batch=0.161\n",
      "16342/67600 (epoch 12), train_loss = 1.252, time/batch=0.144\n",
      "16343/67600 (epoch 12), train_loss = 1.249, time/batch=0.098\n",
      "16344/67600 (epoch 12), train_loss = 1.251, time/batch=0.137\n",
      "16345/67600 (epoch 12), train_loss = 1.258, time/batch=0.121\n",
      "16346/67600 (epoch 12), train_loss = 1.219, time/batch=0.110\n",
      "16347/67600 (epoch 12), train_loss = 1.196, time/batch=0.335\n",
      "16348/67600 (epoch 12), train_loss = 1.225, time/batch=0.114\n",
      "16349/67600 (epoch 12), train_loss = 1.150, time/batch=0.145\n",
      "16350/67600 (epoch 12), train_loss = 1.224, time/batch=0.110\n",
      "16351/67600 (epoch 12), train_loss = 1.262, time/batch=0.126\n",
      "16352/67600 (epoch 12), train_loss = 1.203, time/batch=0.122\n",
      "16353/67600 (epoch 12), train_loss = 1.222, time/batch=0.137\n",
      "16354/67600 (epoch 12), train_loss = 1.250, time/batch=0.244\n",
      "16355/67600 (epoch 12), train_loss = 1.223, time/batch=0.109\n",
      "16356/67600 (epoch 12), train_loss = 1.279, time/batch=0.126\n",
      "16357/67600 (epoch 12), train_loss = 1.209, time/batch=0.120\n",
      "16358/67600 (epoch 12), train_loss = 1.230, time/batch=0.113\n",
      "16359/67600 (epoch 12), train_loss = 1.236, time/batch=0.128\n",
      "16360/67600 (epoch 12), train_loss = 1.256, time/batch=0.108\n",
      "16361/67600 (epoch 12), train_loss = 1.241, time/batch=0.257\n",
      "16362/67600 (epoch 12), train_loss = 1.237, time/batch=0.113\n",
      "16363/67600 (epoch 12), train_loss = 1.208, time/batch=0.138\n",
      "16364/67600 (epoch 12), train_loss = 1.210, time/batch=0.112\n",
      "16365/67600 (epoch 12), train_loss = 1.191, time/batch=0.112\n",
      "16366/67600 (epoch 12), train_loss = 1.245, time/batch=0.240\n",
      "16367/67600 (epoch 12), train_loss = 1.194, time/batch=0.162\n",
      "16368/67600 (epoch 12), train_loss = 1.280, time/batch=0.112\n",
      "16369/67600 (epoch 12), train_loss = 1.319, time/batch=0.137\n",
      "16370/67600 (epoch 12), train_loss = 1.236, time/batch=0.109\n",
      "16371/67600 (epoch 12), train_loss = 1.220, time/batch=0.121\n",
      "16372/67600 (epoch 12), train_loss = 1.276, time/batch=0.129\n",
      "16373/67600 (epoch 12), train_loss = 1.174, time/batch=0.229\n",
      "16374/67600 (epoch 12), train_loss = 1.249, time/batch=0.168\n",
      "16375/67600 (epoch 12), train_loss = 1.192, time/batch=0.109\n",
      "16376/67600 (epoch 12), train_loss = 1.183, time/batch=0.110\n",
      "16377/67600 (epoch 12), train_loss = 1.239, time/batch=0.131\n",
      "16378/67600 (epoch 12), train_loss = 1.195, time/batch=0.111\n",
      "16379/67600 (epoch 12), train_loss = 1.251, time/batch=0.119\n",
      "16380/67600 (epoch 12), train_loss = 1.247, time/batch=0.231\n",
      "16381/67600 (epoch 12), train_loss = 1.265, time/batch=0.138\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16382/67600 (epoch 12), train_loss = 1.249, time/batch=0.127\n",
      "16383/67600 (epoch 12), train_loss = 1.217, time/batch=0.123\n",
      "16384/67600 (epoch 12), train_loss = 1.202, time/batch=0.116\n",
      "16385/67600 (epoch 12), train_loss = 1.182, time/batch=0.121\n",
      "16386/67600 (epoch 12), train_loss = 1.234, time/batch=0.116\n",
      "16387/67600 (epoch 12), train_loss = 1.223, time/batch=0.242\n",
      "16388/67600 (epoch 12), train_loss = 1.141, time/batch=0.136\n",
      "16389/67600 (epoch 12), train_loss = 1.227, time/batch=0.130\n",
      "16390/67600 (epoch 12), train_loss = 1.215, time/batch=0.118\n",
      "16391/67600 (epoch 12), train_loss = 1.193, time/batch=0.127\n",
      "16392/67600 (epoch 12), train_loss = 1.241, time/batch=0.120\n",
      "16393/67600 (epoch 12), train_loss = 1.248, time/batch=0.131\n",
      "16394/67600 (epoch 12), train_loss = 1.249, time/batch=0.254\n",
      "16395/67600 (epoch 12), train_loss = 1.197, time/batch=0.120\n",
      "16396/67600 (epoch 12), train_loss = 1.256, time/batch=0.152\n",
      "16397/67600 (epoch 12), train_loss = 1.206, time/batch=0.113\n",
      "16398/67600 (epoch 12), train_loss = 1.216, time/batch=0.123\n",
      "16399/67600 (epoch 12), train_loss = 1.171, time/batch=0.220\n",
      "16400/67600 (epoch 12), train_loss = 1.233, time/batch=0.153\n",
      "16401/67600 (epoch 12), train_loss = 1.268, time/batch=0.116\n",
      "16402/67600 (epoch 12), train_loss = 1.183, time/batch=0.126\n",
      "16403/67600 (epoch 12), train_loss = 1.199, time/batch=0.114\n",
      "16404/67600 (epoch 12), train_loss = 1.176, time/batch=0.116\n",
      "16405/67600 (epoch 12), train_loss = 1.167, time/batch=0.118\n",
      "16406/67600 (epoch 12), train_loss = 1.208, time/batch=0.180\n",
      "16407/67600 (epoch 12), train_loss = 1.313, time/batch=0.176\n",
      "16408/67600 (epoch 12), train_loss = 1.325, time/batch=0.146\n",
      "16409/67600 (epoch 12), train_loss = 1.287, time/batch=0.115\n",
      "16410/67600 (epoch 12), train_loss = 1.327, time/batch=0.133\n",
      "16411/67600 (epoch 12), train_loss = 1.228, time/batch=0.127\n",
      "16412/67600 (epoch 12), train_loss = 1.238, time/batch=0.121\n",
      "16413/67600 (epoch 12), train_loss = 1.228, time/batch=0.096\n",
      "16414/67600 (epoch 12), train_loss = 1.295, time/batch=0.253\n",
      "16415/67600 (epoch 12), train_loss = 1.266, time/batch=0.141\n",
      "16416/67600 (epoch 12), train_loss = 1.227, time/batch=0.099\n",
      "16417/67600 (epoch 12), train_loss = 1.267, time/batch=0.128\n",
      "16418/67600 (epoch 12), train_loss = 1.256, time/batch=0.112\n",
      "16419/67600 (epoch 12), train_loss = 1.240, time/batch=0.132\n",
      "16420/67600 (epoch 12), train_loss = 1.221, time/batch=0.118\n",
      "16421/67600 (epoch 12), train_loss = 1.222, time/batch=0.256\n",
      "16422/67600 (epoch 12), train_loss = 1.251, time/batch=0.151\n",
      "16423/67600 (epoch 12), train_loss = 1.199, time/batch=0.093\n",
      "16424/67600 (epoch 12), train_loss = 1.190, time/batch=0.130\n",
      "16425/67600 (epoch 12), train_loss = 1.165, time/batch=0.114\n",
      "16426/67600 (epoch 12), train_loss = 1.285, time/batch=0.121\n",
      "16427/67600 (epoch 12), train_loss = 1.229, time/batch=0.125\n",
      "16428/67600 (epoch 12), train_loss = 1.256, time/batch=0.250\n",
      "16429/67600 (epoch 12), train_loss = 1.172, time/batch=0.126\n",
      "16430/67600 (epoch 12), train_loss = 1.177, time/batch=0.111\n",
      "16431/67600 (epoch 12), train_loss = 1.195, time/batch=0.120\n",
      "16432/67600 (epoch 12), train_loss = 1.247, time/batch=0.125\n",
      "16433/67600 (epoch 12), train_loss = 1.279, time/batch=0.214\n",
      "16434/67600 (epoch 12), train_loss = 1.249, time/batch=0.153\n",
      "16435/67600 (epoch 12), train_loss = 1.296, time/batch=0.127\n",
      "16436/67600 (epoch 12), train_loss = 1.208, time/batch=0.130\n",
      "16437/67600 (epoch 12), train_loss = 1.218, time/batch=0.132\n",
      "16438/67600 (epoch 12), train_loss = 1.220, time/batch=0.101\n",
      "16439/67600 (epoch 12), train_loss = 1.259, time/batch=0.120\n",
      "16440/67600 (epoch 12), train_loss = 1.203, time/batch=0.122\n",
      "16441/67600 (epoch 12), train_loss = 1.210, time/batch=0.155\n",
      "16442/67600 (epoch 12), train_loss = 1.192, time/batch=0.123\n",
      "16443/67600 (epoch 12), train_loss = 1.173, time/batch=0.112\n",
      "16444/67600 (epoch 12), train_loss = 1.280, time/batch=0.121\n",
      "16445/67600 (epoch 12), train_loss = 1.195, time/batch=0.118\n",
      "16446/67600 (epoch 12), train_loss = 1.246, time/batch=0.228\n",
      "16447/67600 (epoch 12), train_loss = 1.231, time/batch=0.170\n",
      "16448/67600 (epoch 12), train_loss = 1.230, time/batch=0.145\n",
      "16449/67600 (epoch 12), train_loss = 1.205, time/batch=0.118\n",
      "16450/67600 (epoch 12), train_loss = 1.270, time/batch=0.119\n",
      "16451/67600 (epoch 12), train_loss = 1.187, time/batch=0.123\n",
      "16452/67600 (epoch 12), train_loss = 1.194, time/batch=0.110\n",
      "16453/67600 (epoch 12), train_loss = 1.206, time/batch=0.120\n",
      "16454/67600 (epoch 12), train_loss = 1.231, time/batch=0.264\n",
      "16455/67600 (epoch 12), train_loss = 1.232, time/batch=0.128\n",
      "16456/67600 (epoch 12), train_loss = 1.162, time/batch=0.117\n",
      "16457/67600 (epoch 12), train_loss = 1.167, time/batch=0.111\n",
      "16458/67600 (epoch 12), train_loss = 1.232, time/batch=0.115\n",
      "16459/67600 (epoch 12), train_loss = 1.222, time/batch=0.133\n",
      "16460/67600 (epoch 12), train_loss = 1.215, time/batch=0.119\n",
      "16461/67600 (epoch 12), train_loss = 1.215, time/batch=0.270\n",
      "16462/67600 (epoch 12), train_loss = 1.272, time/batch=0.125\n",
      "16463/67600 (epoch 12), train_loss = 1.242, time/batch=0.117\n",
      "16464/67600 (epoch 12), train_loss = 1.254, time/batch=0.127\n",
      "16465/67600 (epoch 12), train_loss = 1.179, time/batch=0.110\n",
      "16466/67600 (epoch 12), train_loss = 1.234, time/batch=0.239\n",
      "16467/67600 (epoch 12), train_loss = 1.234, time/batch=0.147\n",
      "16468/67600 (epoch 12), train_loss = 1.168, time/batch=0.101\n",
      "16469/67600 (epoch 12), train_loss = 1.241, time/batch=0.138\n",
      "16470/67600 (epoch 12), train_loss = 1.221, time/batch=0.126\n",
      "16471/67600 (epoch 12), train_loss = 1.232, time/batch=0.109\n",
      "16472/67600 (epoch 12), train_loss = 1.258, time/batch=0.123\n",
      "16473/67600 (epoch 12), train_loss = 1.203, time/batch=0.241\n",
      "16474/67600 (epoch 12), train_loss = 1.195, time/batch=0.137\n",
      "16475/67600 (epoch 12), train_loss = 1.281, time/batch=0.129\n",
      "16476/67600 (epoch 12), train_loss = 1.192, time/batch=0.098\n",
      "16477/67600 (epoch 12), train_loss = 1.231, time/batch=0.140\n",
      "16478/67600 (epoch 12), train_loss = 1.250, time/batch=0.114\n",
      "16479/67600 (epoch 12), train_loss = 1.296, time/batch=0.114\n",
      "16480/67600 (epoch 12), train_loss = 1.267, time/batch=0.238\n",
      "16481/67600 (epoch 12), train_loss = 1.276, time/batch=0.175\n",
      "16482/67600 (epoch 12), train_loss = 1.188, time/batch=0.137\n",
      "16483/67600 (epoch 12), train_loss = 1.188, time/batch=0.115\n",
      "16484/67600 (epoch 12), train_loss = 1.216, time/batch=0.114\n",
      "16485/67600 (epoch 12), train_loss = 1.202, time/batch=0.128\n",
      "16486/67600 (epoch 12), train_loss = 1.221, time/batch=0.118\n",
      "16487/67600 (epoch 12), train_loss = 1.225, time/batch=0.251\n",
      "16488/67600 (epoch 12), train_loss = 1.215, time/batch=0.132\n",
      "16489/67600 (epoch 12), train_loss = 1.206, time/batch=0.127\n",
      "16490/67600 (epoch 12), train_loss = 1.187, time/batch=0.123\n",
      "16491/67600 (epoch 12), train_loss = 1.234, time/batch=0.093\n",
      "16492/67600 (epoch 12), train_loss = 1.213, time/batch=0.141\n",
      "16493/67600 (epoch 12), train_loss = 1.197, time/batch=0.110\n",
      "16494/67600 (epoch 12), train_loss = 1.254, time/batch=0.273\n",
      "16495/67600 (epoch 12), train_loss = 1.223, time/batch=0.105\n",
      "16496/67600 (epoch 12), train_loss = 1.234, time/batch=0.128\n",
      "16497/67600 (epoch 12), train_loss = 1.263, time/batch=0.112\n",
      "16498/67600 (epoch 12), train_loss = 1.240, time/batch=0.117\n",
      "16499/67600 (epoch 12), train_loss = 1.227, time/batch=0.221\n",
      "16500/67600 (epoch 12), train_loss = 1.245, time/batch=0.124\n",
      "model saved to ./save/model.ckpt\n",
      "16501/67600 (epoch 12), train_loss = 1.200, time/batch=0.074\n",
      "16502/67600 (epoch 12), train_loss = 1.200, time/batch=0.083\n",
      "16503/67600 (epoch 12), train_loss = 1.245, time/batch=0.106\n",
      "16504/67600 (epoch 12), train_loss = 1.248, time/batch=0.121\n",
      "16505/67600 (epoch 12), train_loss = 1.204, time/batch=0.102\n",
      "16506/67600 (epoch 12), train_loss = 1.168, time/batch=0.245\n",
      "16507/67600 (epoch 12), train_loss = 1.254, time/batch=0.196\n",
      "16508/67600 (epoch 12), train_loss = 1.190, time/batch=0.120\n",
      "16509/67600 (epoch 12), train_loss = 1.311, time/batch=0.119\n",
      "16510/67600 (epoch 12), train_loss = 1.244, time/batch=0.132\n",
      "16511/67600 (epoch 12), train_loss = 1.222, time/batch=0.126\n",
      "16512/67600 (epoch 12), train_loss = 1.258, time/batch=0.115\n",
      "16513/67600 (epoch 12), train_loss = 1.250, time/batch=0.184\n",
      "16514/67600 (epoch 12), train_loss = 1.247, time/batch=0.199\n",
      "16515/67600 (epoch 12), train_loss = 1.234, time/batch=0.126\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16516/67600 (epoch 12), train_loss = 1.244, time/batch=0.117\n",
      "16517/67600 (epoch 12), train_loss = 1.229, time/batch=0.119\n",
      "16518/67600 (epoch 12), train_loss = 1.234, time/batch=0.095\n",
      "16519/67600 (epoch 12), train_loss = 1.242, time/batch=0.126\n",
      "16520/67600 (epoch 12), train_loss = 1.243, time/batch=0.128\n",
      "16521/67600 (epoch 12), train_loss = 1.214, time/batch=0.255\n",
      "16522/67600 (epoch 12), train_loss = 1.203, time/batch=0.134\n",
      "16523/67600 (epoch 12), train_loss = 1.269, time/batch=0.117\n",
      "16524/67600 (epoch 12), train_loss = 1.225, time/batch=0.126\n",
      "16525/67600 (epoch 12), train_loss = 1.251, time/batch=0.135\n",
      "16526/67600 (epoch 12), train_loss = 1.217, time/batch=0.225\n",
      "16527/67600 (epoch 12), train_loss = 1.249, time/batch=0.141\n",
      "16528/67600 (epoch 12), train_loss = 1.251, time/batch=0.114\n",
      "16529/67600 (epoch 12), train_loss = 1.268, time/batch=0.138\n",
      "16530/67600 (epoch 12), train_loss = 1.279, time/batch=0.104\n",
      "16531/67600 (epoch 12), train_loss = 1.258, time/batch=0.127\n",
      "16532/67600 (epoch 12), train_loss = 1.263, time/batch=0.114\n",
      "16533/67600 (epoch 12), train_loss = 1.259, time/batch=0.239\n",
      "16534/67600 (epoch 12), train_loss = 1.227, time/batch=0.182\n",
      "16535/67600 (epoch 12), train_loss = 1.194, time/batch=0.088\n",
      "16536/67600 (epoch 12), train_loss = 1.204, time/batch=0.122\n",
      "16537/67600 (epoch 12), train_loss = 1.260, time/batch=0.117\n",
      "16538/67600 (epoch 12), train_loss = 1.231, time/batch=0.112\n",
      "16539/67600 (epoch 12), train_loss = 1.308, time/batch=0.130\n",
      "16540/67600 (epoch 12), train_loss = 1.214, time/batch=0.227\n",
      "16541/67600 (epoch 12), train_loss = 1.249, time/batch=0.142\n",
      "16542/67600 (epoch 12), train_loss = 1.256, time/batch=0.108\n",
      "16543/67600 (epoch 12), train_loss = 1.268, time/batch=0.133\n",
      "16544/67600 (epoch 12), train_loss = 1.283, time/batch=0.107\n",
      "16545/67600 (epoch 12), train_loss = 1.231, time/batch=0.126\n",
      "16546/67600 (epoch 12), train_loss = 1.234, time/batch=0.111\n",
      "16547/67600 (epoch 12), train_loss = 1.207, time/batch=0.231\n",
      "16548/67600 (epoch 12), train_loss = 1.222, time/batch=0.151\n",
      "16549/67600 (epoch 12), train_loss = 1.195, time/batch=0.124\n",
      "16550/67600 (epoch 12), train_loss = 1.189, time/batch=0.141\n",
      "16551/67600 (epoch 12), train_loss = 1.260, time/batch=0.114\n",
      "16552/67600 (epoch 12), train_loss = 1.217, time/batch=0.121\n",
      "16553/67600 (epoch 12), train_loss = 1.234, time/batch=0.119\n",
      "16554/67600 (epoch 12), train_loss = 1.272, time/batch=0.160\n",
      "16555/67600 (epoch 12), train_loss = 1.184, time/batch=0.220\n",
      "16556/67600 (epoch 12), train_loss = 1.235, time/batch=0.111\n",
      "16557/67600 (epoch 12), train_loss = 1.227, time/batch=0.131\n",
      "16558/67600 (epoch 12), train_loss = 1.252, time/batch=0.116\n",
      "16559/67600 (epoch 12), train_loss = 1.261, time/batch=0.222\n",
      "16560/67600 (epoch 12), train_loss = 1.220, time/batch=0.114\n",
      "16561/67600 (epoch 12), train_loss = 1.201, time/batch=0.159\n",
      "16562/67600 (epoch 12), train_loss = 1.231, time/batch=0.116\n",
      "16563/67600 (epoch 12), train_loss = 1.273, time/batch=0.133\n",
      "16564/67600 (epoch 12), train_loss = 1.227, time/batch=0.119\n",
      "16565/67600 (epoch 12), train_loss = 1.212, time/batch=0.132\n",
      "16566/67600 (epoch 12), train_loss = 1.198, time/batch=0.123\n",
      "16567/67600 (epoch 12), train_loss = 1.190, time/batch=0.237\n",
      "16568/67600 (epoch 12), train_loss = 1.275, time/batch=0.144\n",
      "16569/67600 (epoch 12), train_loss = 1.297, time/batch=0.121\n",
      "16570/67600 (epoch 12), train_loss = 1.241, time/batch=0.119\n",
      "16571/67600 (epoch 12), train_loss = 1.235, time/batch=0.110\n",
      "16572/67600 (epoch 12), train_loss = 1.272, time/batch=0.127\n",
      "16573/67600 (epoch 12), train_loss = 1.280, time/batch=0.122\n",
      "16574/67600 (epoch 12), train_loss = 1.194, time/batch=0.237\n",
      "16575/67600 (epoch 12), train_loss = 1.176, time/batch=0.131\n",
      "16576/67600 (epoch 12), train_loss = 1.173, time/batch=0.126\n",
      "16577/67600 (epoch 12), train_loss = 1.189, time/batch=0.123\n",
      "16578/67600 (epoch 12), train_loss = 1.202, time/batch=0.108\n",
      "16579/67600 (epoch 12), train_loss = 1.267, time/batch=0.115\n",
      "16580/67600 (epoch 12), train_loss = 1.209, time/batch=0.123\n",
      "16581/67600 (epoch 12), train_loss = 1.224, time/batch=0.246\n",
      "16582/67600 (epoch 12), train_loss = 1.182, time/batch=0.133\n",
      "16583/67600 (epoch 12), train_loss = 1.304, time/batch=0.125\n",
      "16584/67600 (epoch 12), train_loss = 1.226, time/batch=0.125\n",
      "16585/67600 (epoch 12), train_loss = 1.190, time/batch=0.123\n",
      "16586/67600 (epoch 12), train_loss = 1.194, time/batch=0.121\n",
      "16587/67600 (epoch 12), train_loss = 1.271, time/batch=0.103\n",
      "16588/67600 (epoch 12), train_loss = 1.230, time/batch=0.253\n",
      "16589/67600 (epoch 12), train_loss = 1.218, time/batch=0.130\n",
      "16590/67600 (epoch 12), train_loss = 1.220, time/batch=0.105\n",
      "16591/67600 (epoch 12), train_loss = 1.171, time/batch=0.124\n",
      "16592/67600 (epoch 12), train_loss = 1.220, time/batch=0.128\n",
      "16593/67600 (epoch 12), train_loss = 1.302, time/batch=0.123\n",
      "16594/67600 (epoch 12), train_loss = 1.223, time/batch=0.118\n",
      "16595/67600 (epoch 12), train_loss = 1.226, time/batch=0.150\n",
      "16596/67600 (epoch 12), train_loss = 1.258, time/batch=0.230\n",
      "16597/67600 (epoch 12), train_loss = 1.232, time/batch=0.104\n",
      "16598/67600 (epoch 12), train_loss = 1.276, time/batch=0.131\n",
      "16599/67600 (epoch 12), train_loss = 1.309, time/batch=0.117\n",
      "16600/67600 (epoch 12), train_loss = 1.251, time/batch=0.133\n",
      "16601/67600 (epoch 12), train_loss = 1.226, time/batch=0.158\n",
      "16602/67600 (epoch 12), train_loss = 1.305, time/batch=0.121\n",
      "16603/67600 (epoch 12), train_loss = 1.313, time/batch=0.109\n",
      "16604/67600 (epoch 12), train_loss = 1.265, time/batch=0.140\n",
      "16605/67600 (epoch 12), train_loss = 1.219, time/batch=0.107\n",
      "16606/67600 (epoch 12), train_loss = 1.215, time/batch=0.134\n",
      "16607/67600 (epoch 12), train_loss = 1.265, time/batch=0.329\n",
      "16608/67600 (epoch 12), train_loss = 1.308, time/batch=0.109\n",
      "16609/67600 (epoch 12), train_loss = 1.240, time/batch=0.119\n",
      "16610/67600 (epoch 12), train_loss = 1.216, time/batch=0.118\n",
      "16611/67600 (epoch 12), train_loss = 1.228, time/batch=0.110\n",
      "16612/67600 (epoch 12), train_loss = 1.258, time/batch=0.127\n",
      "16613/67600 (epoch 12), train_loss = 1.250, time/batch=0.107\n",
      "16614/67600 (epoch 12), train_loss = 1.234, time/batch=0.271\n",
      "16615/67600 (epoch 12), train_loss = 1.223, time/batch=0.123\n",
      "16616/67600 (epoch 12), train_loss = 1.212, time/batch=0.125\n",
      "16617/67600 (epoch 12), train_loss = 1.244, time/batch=0.119\n",
      "16618/67600 (epoch 12), train_loss = 1.218, time/batch=0.108\n",
      "16619/67600 (epoch 12), train_loss = 1.223, time/batch=0.126\n",
      "16620/67600 (epoch 12), train_loss = 1.280, time/batch=0.115\n",
      "16621/67600 (epoch 12), train_loss = 1.282, time/batch=0.257\n",
      "16622/67600 (epoch 12), train_loss = 1.235, time/batch=0.126\n",
      "16623/67600 (epoch 12), train_loss = 1.214, time/batch=0.126\n",
      "16624/67600 (epoch 12), train_loss = 1.257, time/batch=0.123\n",
      "16625/67600 (epoch 12), train_loss = 1.323, time/batch=0.104\n",
      "16626/67600 (epoch 12), train_loss = 1.283, time/batch=0.273\n",
      "16627/67600 (epoch 12), train_loss = 1.249, time/batch=0.171\n",
      "16628/67600 (epoch 12), train_loss = 1.314, time/batch=0.125\n",
      "16629/67600 (epoch 12), train_loss = 1.275, time/batch=0.147\n",
      "16630/67600 (epoch 12), train_loss = 1.277, time/batch=0.104\n",
      "16631/67600 (epoch 12), train_loss = 1.210, time/batch=0.126\n",
      "16632/67600 (epoch 12), train_loss = 1.260, time/batch=0.195\n",
      "16633/67600 (epoch 12), train_loss = 1.264, time/batch=0.165\n",
      "16634/67600 (epoch 12), train_loss = 1.266, time/batch=0.164\n",
      "16635/67600 (epoch 12), train_loss = 1.201, time/batch=0.124\n",
      "16636/67600 (epoch 12), train_loss = 1.236, time/batch=0.120\n",
      "16637/67600 (epoch 12), train_loss = 1.243, time/batch=0.113\n",
      "16638/67600 (epoch 12), train_loss = 1.218, time/batch=0.124\n",
      "16639/67600 (epoch 12), train_loss = 1.277, time/batch=0.272\n",
      "16640/67600 (epoch 12), train_loss = 1.235, time/batch=0.138\n",
      "16641/67600 (epoch 12), train_loss = 1.268, time/batch=0.163\n",
      "16642/67600 (epoch 12), train_loss = 1.290, time/batch=0.121\n",
      "16643/67600 (epoch 12), train_loss = 1.211, time/batch=0.122\n",
      "16644/67600 (epoch 12), train_loss = 1.156, time/batch=0.114\n",
      "16645/67600 (epoch 12), train_loss = 1.184, time/batch=0.122\n",
      "16646/67600 (epoch 12), train_loss = 1.227, time/batch=0.287\n",
      "16647/67600 (epoch 12), train_loss = 1.179, time/batch=0.154\n",
      "16648/67600 (epoch 12), train_loss = 1.233, time/batch=0.130\n",
      "16649/67600 (epoch 12), train_loss = 1.202, time/batch=0.124\n",
      "16650/67600 (epoch 12), train_loss = 1.230, time/batch=0.152\n",
      "16651/67600 (epoch 12), train_loss = 1.229, time/batch=0.161\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16652/67600 (epoch 12), train_loss = 1.154, time/batch=0.261\n",
      "16653/67600 (epoch 12), train_loss = 1.198, time/batch=0.132\n",
      "16654/67600 (epoch 12), train_loss = 1.268, time/batch=0.147\n",
      "16655/67600 (epoch 12), train_loss = 1.190, time/batch=0.140\n",
      "16656/67600 (epoch 12), train_loss = 1.259, time/batch=0.260\n",
      "16657/67600 (epoch 12), train_loss = 1.262, time/batch=0.090\n",
      "16658/67600 (epoch 12), train_loss = 1.192, time/batch=0.203\n",
      "16659/67600 (epoch 12), train_loss = 1.295, time/batch=0.138\n",
      "16660/67600 (epoch 12), train_loss = 1.226, time/batch=0.121\n",
      "16661/67600 (epoch 12), train_loss = 1.243, time/batch=0.127\n",
      "16662/67600 (epoch 12), train_loss = 1.250, time/batch=0.131\n",
      "16663/67600 (epoch 12), train_loss = 1.216, time/batch=0.223\n",
      "16664/67600 (epoch 12), train_loss = 1.224, time/batch=0.156\n",
      "16665/67600 (epoch 12), train_loss = 1.248, time/batch=0.118\n",
      "16666/67600 (epoch 12), train_loss = 1.214, time/batch=0.134\n",
      "16667/67600 (epoch 12), train_loss = 1.192, time/batch=0.122\n",
      "16668/67600 (epoch 12), train_loss = 1.245, time/batch=0.111\n",
      "16669/67600 (epoch 12), train_loss = 1.274, time/batch=0.110\n",
      "16670/67600 (epoch 12), train_loss = 1.187, time/batch=0.235\n",
      "16671/67600 (epoch 12), train_loss = 1.202, time/batch=0.169\n",
      "16672/67600 (epoch 12), train_loss = 1.170, time/batch=0.114\n",
      "16673/67600 (epoch 12), train_loss = 1.192, time/batch=0.128\n",
      "16674/67600 (epoch 12), train_loss = 1.148, time/batch=0.124\n",
      "16675/67600 (epoch 12), train_loss = 1.257, time/batch=0.113\n",
      "16676/67600 (epoch 12), train_loss = 1.277, time/batch=0.109\n",
      "16677/67600 (epoch 12), train_loss = 1.173, time/batch=0.271\n",
      "16678/67600 (epoch 12), train_loss = 1.158, time/batch=0.132\n",
      "16679/67600 (epoch 12), train_loss = 1.189, time/batch=0.124\n",
      "16680/67600 (epoch 12), train_loss = 1.217, time/batch=0.117\n",
      "16681/67600 (epoch 12), train_loss = 1.232, time/batch=0.121\n",
      "16682/67600 (epoch 12), train_loss = 1.255, time/batch=0.119\n",
      "16683/67600 (epoch 12), train_loss = 1.226, time/batch=0.119\n",
      "16684/67600 (epoch 12), train_loss = 1.243, time/batch=0.260\n",
      "16685/67600 (epoch 12), train_loss = 1.188, time/batch=0.140\n",
      "16686/67600 (epoch 12), train_loss = 1.257, time/batch=0.102\n",
      "16687/67600 (epoch 12), train_loss = 1.235, time/batch=0.128\n",
      "16688/67600 (epoch 12), train_loss = 1.207, time/batch=0.109\n",
      "16689/67600 (epoch 12), train_loss = 1.220, time/batch=0.123\n",
      "16690/67600 (epoch 12), train_loss = 1.207, time/batch=0.104\n",
      "16691/67600 (epoch 12), train_loss = 1.261, time/batch=0.190\n",
      "16692/67600 (epoch 12), train_loss = 1.226, time/batch=0.214\n",
      "16693/67600 (epoch 12), train_loss = 1.193, time/batch=0.112\n",
      "16694/67600 (epoch 12), train_loss = 1.216, time/batch=0.129\n",
      "16695/67600 (epoch 12), train_loss = 1.220, time/batch=0.105\n",
      "16696/67600 (epoch 12), train_loss = 1.187, time/batch=0.112\n",
      "16697/67600 (epoch 12), train_loss = 1.243, time/batch=0.172\n",
      "16698/67600 (epoch 12), train_loss = 1.193, time/batch=0.130\n",
      "16699/67600 (epoch 12), train_loss = 1.167, time/batch=0.116\n",
      "16700/67600 (epoch 12), train_loss = 1.259, time/batch=0.109\n",
      "16701/67600 (epoch 12), train_loss = 1.185, time/batch=0.122\n",
      "16702/67600 (epoch 12), train_loss = 1.218, time/batch=0.185\n",
      "16703/67600 (epoch 12), train_loss = 1.240, time/batch=0.233\n",
      "16704/67600 (epoch 12), train_loss = 1.187, time/batch=0.147\n",
      "16705/67600 (epoch 12), train_loss = 1.224, time/batch=0.129\n",
      "16706/67600 (epoch 12), train_loss = 1.201, time/batch=0.113\n",
      "16707/67600 (epoch 12), train_loss = 1.182, time/batch=0.139\n",
      "16708/67600 (epoch 12), train_loss = 1.238, time/batch=0.105\n",
      "16709/67600 (epoch 12), train_loss = 1.239, time/batch=0.110\n",
      "16710/67600 (epoch 12), train_loss = 1.262, time/batch=0.278\n",
      "16711/67600 (epoch 12), train_loss = 1.241, time/batch=0.108\n",
      "16712/67600 (epoch 12), train_loss = 1.280, time/batch=0.126\n",
      "16713/67600 (epoch 12), train_loss = 1.258, time/batch=0.115\n",
      "16714/67600 (epoch 12), train_loss = 1.188, time/batch=0.130\n",
      "16715/67600 (epoch 12), train_loss = 1.226, time/batch=0.215\n",
      "16716/67600 (epoch 12), train_loss = 1.248, time/batch=0.147\n",
      "16717/67600 (epoch 12), train_loss = 1.196, time/batch=0.129\n",
      "16718/67600 (epoch 12), train_loss = 1.281, time/batch=0.144\n",
      "16719/67600 (epoch 12), train_loss = 1.240, time/batch=0.109\n",
      "16720/67600 (epoch 12), train_loss = 1.212, time/batch=0.121\n",
      "16721/67600 (epoch 12), train_loss = 1.240, time/batch=0.124\n",
      "16722/67600 (epoch 12), train_loss = 1.286, time/batch=0.210\n",
      "16723/67600 (epoch 12), train_loss = 1.229, time/batch=0.167\n",
      "16724/67600 (epoch 12), train_loss = 1.176, time/batch=0.118\n",
      "16725/67600 (epoch 12), train_loss = 1.182, time/batch=0.130\n",
      "16726/67600 (epoch 12), train_loss = 1.202, time/batch=0.127\n",
      "16727/67600 (epoch 12), train_loss = 1.242, time/batch=0.119\n",
      "16728/67600 (epoch 12), train_loss = 1.251, time/batch=0.128\n",
      "16729/67600 (epoch 12), train_loss = 1.269, time/batch=0.228\n",
      "16730/67600 (epoch 12), train_loss = 1.243, time/batch=0.154\n",
      "16731/67600 (epoch 12), train_loss = 1.246, time/batch=0.110\n",
      "16732/67600 (epoch 12), train_loss = 1.186, time/batch=0.113\n",
      "16733/67600 (epoch 12), train_loss = 1.220, time/batch=0.132\n",
      "16734/67600 (epoch 12), train_loss = 1.245, time/batch=0.101\n",
      "16735/67600 (epoch 12), train_loss = 1.232, time/batch=0.126\n",
      "16736/67600 (epoch 12), train_loss = 1.240, time/batch=0.243\n",
      "16737/67600 (epoch 12), train_loss = 1.213, time/batch=0.143\n",
      "16738/67600 (epoch 12), train_loss = 1.241, time/batch=0.135\n",
      "16739/67600 (epoch 12), train_loss = 1.264, time/batch=0.097\n",
      "16740/67600 (epoch 12), train_loss = 1.269, time/batch=0.131\n",
      "16741/67600 (epoch 12), train_loss = 1.253, time/batch=0.095\n",
      "16742/67600 (epoch 12), train_loss = 1.243, time/batch=0.116\n",
      "16743/67600 (epoch 12), train_loss = 1.172, time/batch=0.157\n",
      "16744/67600 (epoch 12), train_loss = 1.280, time/batch=0.237\n",
      "16745/67600 (epoch 12), train_loss = 1.279, time/batch=0.108\n",
      "16746/67600 (epoch 12), train_loss = 1.292, time/batch=0.121\n",
      "16747/67600 (epoch 12), train_loss = 1.243, time/batch=0.121\n",
      "16748/67600 (epoch 12), train_loss = 1.228, time/batch=0.121\n",
      "16749/67600 (epoch 12), train_loss = 1.239, time/batch=0.126\n",
      "16750/67600 (epoch 12), train_loss = 1.251, time/batch=0.107\n",
      "16751/67600 (epoch 12), train_loss = 1.205, time/batch=0.272\n",
      "16752/67600 (epoch 12), train_loss = 1.265, time/batch=0.109\n",
      "16753/67600 (epoch 12), train_loss = 1.226, time/batch=0.119\n",
      "16754/67600 (epoch 12), train_loss = 1.282, time/batch=0.133\n",
      "16755/67600 (epoch 12), train_loss = 1.267, time/batch=0.110\n",
      "16756/67600 (epoch 12), train_loss = 1.252, time/batch=0.232\n",
      "16757/67600 (epoch 12), train_loss = 1.207, time/batch=0.140\n",
      "16758/67600 (epoch 12), train_loss = 1.215, time/batch=0.126\n",
      "16759/67600 (epoch 12), train_loss = 1.181, time/batch=0.134\n",
      "16760/67600 (epoch 12), train_loss = 1.202, time/batch=0.112\n",
      "16761/67600 (epoch 12), train_loss = 1.233, time/batch=0.100\n",
      "16762/67600 (epoch 12), train_loss = 1.226, time/batch=0.134\n",
      "16763/67600 (epoch 12), train_loss = 1.232, time/batch=0.234\n",
      "16764/67600 (epoch 12), train_loss = 1.236, time/batch=0.151\n",
      "16765/67600 (epoch 12), train_loss = 1.177, time/batch=0.107\n",
      "16766/67600 (epoch 12), train_loss = 1.210, time/batch=0.119\n",
      "16767/67600 (epoch 12), train_loss = 1.192, time/batch=0.117\n",
      "16768/67600 (epoch 12), train_loss = 1.272, time/batch=0.140\n",
      "16769/67600 (epoch 12), train_loss = 1.229, time/batch=0.112\n",
      "16770/67600 (epoch 12), train_loss = 1.219, time/batch=0.227\n",
      "16771/67600 (epoch 12), train_loss = 1.232, time/batch=0.173\n",
      "16772/67600 (epoch 12), train_loss = 1.348, time/batch=0.111\n",
      "16773/67600 (epoch 12), train_loss = 1.261, time/batch=0.121\n",
      "16774/67600 (epoch 12), train_loss = 1.216, time/batch=0.107\n",
      "16775/67600 (epoch 12), train_loss = 1.271, time/batch=0.125\n",
      "16776/67600 (epoch 12), train_loss = 1.220, time/batch=0.144\n",
      "16777/67600 (epoch 12), train_loss = 1.216, time/batch=0.243\n",
      "16778/67600 (epoch 12), train_loss = 1.262, time/batch=0.126\n",
      "16779/67600 (epoch 12), train_loss = 1.214, time/batch=0.118\n",
      "16780/67600 (epoch 12), train_loss = 1.287, time/batch=0.120\n",
      "16781/67600 (epoch 12), train_loss = 1.222, time/batch=0.112\n",
      "16782/67600 (epoch 12), train_loss = 1.209, time/batch=0.164\n",
      "16783/67600 (epoch 12), train_loss = 1.164, time/batch=0.172\n",
      "16784/67600 (epoch 12), train_loss = 1.197, time/batch=0.139\n",
      "16785/67600 (epoch 12), train_loss = 1.222, time/batch=0.126\n",
      "16786/67600 (epoch 12), train_loss = 1.175, time/batch=0.172\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16787/67600 (epoch 12), train_loss = 1.216, time/batch=0.103\n",
      "16788/67600 (epoch 12), train_loss = 1.191, time/batch=0.124\n",
      "16789/67600 (epoch 12), train_loss = 1.214, time/batch=0.129\n",
      "16790/67600 (epoch 12), train_loss = 1.232, time/batch=0.111\n",
      "16791/67600 (epoch 12), train_loss = 1.248, time/batch=0.139\n",
      "16792/67600 (epoch 12), train_loss = 1.246, time/batch=0.260\n",
      "16793/67600 (epoch 12), train_loss = 1.210, time/batch=0.118\n",
      "16794/67600 (epoch 12), train_loss = 1.189, time/batch=0.119\n",
      "16795/67600 (epoch 12), train_loss = 1.186, time/batch=0.118\n",
      "16796/67600 (epoch 12), train_loss = 1.210, time/batch=0.125\n",
      "16797/67600 (epoch 12), train_loss = 1.218, time/batch=0.150\n",
      "16798/67600 (epoch 12), train_loss = 1.237, time/batch=0.126\n",
      "16799/67600 (epoch 12), train_loss = 1.196, time/batch=0.128\n",
      "16800/67600 (epoch 12), train_loss = 1.241, time/batch=0.116\n",
      "16801/67600 (epoch 12), train_loss = 1.231, time/batch=0.129\n",
      "16802/67600 (epoch 12), train_loss = 1.252, time/batch=0.237\n",
      "16803/67600 (epoch 12), train_loss = 1.228, time/batch=0.192\n",
      "16804/67600 (epoch 12), train_loss = 1.261, time/batch=0.104\n",
      "16805/67600 (epoch 12), train_loss = 1.228, time/batch=0.131\n",
      "16806/67600 (epoch 12), train_loss = 1.179, time/batch=0.114\n",
      "16807/67600 (epoch 12), train_loss = 1.200, time/batch=0.118\n",
      "16808/67600 (epoch 12), train_loss = 1.225, time/batch=0.100\n",
      "16809/67600 (epoch 12), train_loss = 1.285, time/batch=0.127\n",
      "16810/67600 (epoch 12), train_loss = 1.205, time/batch=0.263\n",
      "16811/67600 (epoch 12), train_loss = 1.281, time/batch=0.123\n",
      "16812/67600 (epoch 12), train_loss = 1.199, time/batch=0.110\n",
      "16813/67600 (epoch 12), train_loss = 1.227, time/batch=0.128\n",
      "16814/67600 (epoch 12), train_loss = 1.283, time/batch=0.109\n",
      "16815/67600 (epoch 12), train_loss = 1.193, time/batch=0.120\n",
      "16816/67600 (epoch 12), train_loss = 1.202, time/batch=0.143\n",
      "16817/67600 (epoch 12), train_loss = 1.233, time/batch=0.253\n",
      "16818/67600 (epoch 12), train_loss = 1.175, time/batch=0.126\n",
      "16819/67600 (epoch 12), train_loss = 1.221, time/batch=0.122\n",
      "16820/67600 (epoch 12), train_loss = 1.239, time/batch=0.140\n",
      "16821/67600 (epoch 12), train_loss = 1.190, time/batch=0.115\n",
      "16822/67600 (epoch 12), train_loss = 1.224, time/batch=0.238\n",
      "16823/67600 (epoch 12), train_loss = 1.211, time/batch=0.181\n",
      "16824/67600 (epoch 12), train_loss = 1.256, time/batch=0.121\n",
      "16825/67600 (epoch 12), train_loss = 1.170, time/batch=0.131\n",
      "16826/67600 (epoch 12), train_loss = 1.229, time/batch=0.132\n",
      "16827/67600 (epoch 12), train_loss = 1.213, time/batch=0.122\n",
      "16828/67600 (epoch 12), train_loss = 1.249, time/batch=0.186\n",
      "16829/67600 (epoch 12), train_loss = 1.200, time/batch=0.231\n",
      "16830/67600 (epoch 12), train_loss = 1.278, time/batch=0.110\n",
      "16831/67600 (epoch 12), train_loss = 1.210, time/batch=0.278\n",
      "16832/67600 (epoch 12), train_loss = 1.288, time/batch=0.122\n",
      "16833/67600 (epoch 12), train_loss = 1.217, time/batch=0.150\n",
      "16834/67600 (epoch 12), train_loss = 1.245, time/batch=0.245\n",
      "16835/67600 (epoch 12), train_loss = 1.317, time/batch=0.137\n",
      "16836/67600 (epoch 12), train_loss = 1.225, time/batch=0.125\n",
      "16837/67600 (epoch 12), train_loss = 1.221, time/batch=0.123\n",
      "16838/67600 (epoch 12), train_loss = 1.256, time/batch=0.125\n",
      "16839/67600 (epoch 12), train_loss = 1.286, time/batch=0.184\n",
      "16840/67600 (epoch 12), train_loss = 1.240, time/batch=0.291\n",
      "16841/67600 (epoch 12), train_loss = 1.301, time/batch=0.223\n",
      "16842/67600 (epoch 12), train_loss = 1.233, time/batch=0.148\n",
      "16843/67600 (epoch 12), train_loss = 1.195, time/batch=0.198\n",
      "16844/67600 (epoch 12), train_loss = 1.181, time/batch=0.086\n",
      "16845/67600 (epoch 12), train_loss = 1.221, time/batch=0.373\n",
      "16846/67600 (epoch 12), train_loss = 1.234, time/batch=0.142\n",
      "16847/67600 (epoch 12), train_loss = 1.194, time/batch=0.147\n",
      "16848/67600 (epoch 12), train_loss = 1.231, time/batch=0.098\n",
      "16849/67600 (epoch 12), train_loss = 1.213, time/batch=0.266\n",
      "16850/67600 (epoch 12), train_loss = 1.263, time/batch=0.191\n",
      "16851/67600 (epoch 12), train_loss = 1.267, time/batch=0.126\n",
      "16852/67600 (epoch 12), train_loss = 1.260, time/batch=0.115\n",
      "16853/67600 (epoch 12), train_loss = 1.225, time/batch=0.113\n",
      "16854/67600 (epoch 12), train_loss = 1.266, time/batch=0.135\n",
      "16855/67600 (epoch 12), train_loss = 1.298, time/batch=0.116\n",
      "16856/67600 (epoch 12), train_loss = 1.209, time/batch=0.276\n",
      "16857/67600 (epoch 12), train_loss = 1.285, time/batch=0.146\n",
      "16858/67600 (epoch 12), train_loss = 1.274, time/batch=0.171\n",
      "16859/67600 (epoch 12), train_loss = 1.153, time/batch=0.160\n",
      "16860/67600 (epoch 12), train_loss = 1.310, time/batch=0.147\n",
      "16861/67600 (epoch 12), train_loss = 1.209, time/batch=0.142\n",
      "16862/67600 (epoch 12), train_loss = 1.164, time/batch=0.219\n",
      "16863/67600 (epoch 12), train_loss = 1.159, time/batch=0.132\n",
      "16864/67600 (epoch 12), train_loss = 1.233, time/batch=0.123\n",
      "16865/67600 (epoch 12), train_loss = 1.210, time/batch=0.106\n",
      "16866/67600 (epoch 12), train_loss = 1.263, time/batch=0.121\n",
      "16867/67600 (epoch 12), train_loss = 1.311, time/batch=0.136\n",
      "16868/67600 (epoch 12), train_loss = 1.283, time/batch=0.336\n",
      "16869/67600 (epoch 12), train_loss = 1.231, time/batch=0.090\n",
      "16870/67600 (epoch 12), train_loss = 1.265, time/batch=0.432\n",
      "16871/67600 (epoch 12), train_loss = 1.249, time/batch=0.241\n",
      "16872/67600 (epoch 12), train_loss = 1.277, time/batch=0.268\n",
      "16873/67600 (epoch 12), train_loss = 1.240, time/batch=0.209\n",
      "16874/67600 (epoch 12), train_loss = 1.282, time/batch=0.120\n",
      "16875/67600 (epoch 12), train_loss = 1.306, time/batch=0.195\n",
      "16876/67600 (epoch 12), train_loss = 1.229, time/batch=0.231\n",
      "16877/67600 (epoch 12), train_loss = 1.221, time/batch=0.140\n",
      "16878/67600 (epoch 12), train_loss = 1.247, time/batch=0.148\n",
      "16879/67600 (epoch 12), train_loss = 1.228, time/batch=0.140\n",
      "16880/67600 (epoch 12), train_loss = 1.225, time/batch=0.121\n",
      "16881/67600 (epoch 12), train_loss = 1.301, time/batch=0.130\n",
      "16882/67600 (epoch 12), train_loss = 1.252, time/batch=0.131\n",
      "16883/67600 (epoch 12), train_loss = 1.174, time/batch=0.170\n",
      "16884/67600 (epoch 12), train_loss = 1.225, time/batch=0.138\n",
      "16885/67600 (epoch 12), train_loss = 1.221, time/batch=0.137\n",
      "16886/67600 (epoch 12), train_loss = 1.145, time/batch=0.162\n",
      "16887/67600 (epoch 12), train_loss = 1.179, time/batch=0.134\n",
      "16888/67600 (epoch 12), train_loss = 1.265, time/batch=0.303\n",
      "16889/67600 (epoch 12), train_loss = 1.242, time/batch=0.119\n",
      "16890/67600 (epoch 12), train_loss = 1.254, time/batch=0.142\n",
      "16891/67600 (epoch 12), train_loss = 1.225, time/batch=0.124\n",
      "16892/67600 (epoch 12), train_loss = 1.287, time/batch=0.126\n",
      "16893/67600 (epoch 12), train_loss = 1.196, time/batch=0.119\n",
      "16894/67600 (epoch 12), train_loss = 1.148, time/batch=0.147\n",
      "16895/67600 (epoch 12), train_loss = 1.205, time/batch=0.131\n",
      "16896/67600 (epoch 12), train_loss = 1.151, time/batch=0.124\n",
      "16897/67600 (epoch 12), train_loss = 1.291, time/batch=0.122\n",
      "16898/67600 (epoch 12), train_loss = 1.279, time/batch=0.319\n",
      "16899/67600 (epoch 12), train_loss = 1.201, time/batch=0.198\n",
      "16900/67600 (epoch 12), train_loss = 1.237, time/batch=0.143\n",
      "16901/67600 (epoch 12), train_loss = 1.266, time/batch=0.181\n",
      "16902/67600 (epoch 12), train_loss = 1.277, time/batch=0.137\n",
      "16903/67600 (epoch 12), train_loss = 1.211, time/batch=0.142\n",
      "16904/67600 (epoch 12), train_loss = 1.235, time/batch=0.135\n",
      "16905/67600 (epoch 12), train_loss = 1.255, time/batch=0.119\n",
      "16906/67600 (epoch 12), train_loss = 1.254, time/batch=0.218\n",
      "16907/67600 (epoch 12), train_loss = 1.225, time/batch=0.169\n",
      "16908/67600 (epoch 12), train_loss = 1.205, time/batch=0.157\n",
      "16909/67600 (epoch 12), train_loss = 1.288, time/batch=0.234\n",
      "16910/67600 (epoch 12), train_loss = 1.248, time/batch=0.179\n",
      "16911/67600 (epoch 12), train_loss = 1.190, time/batch=0.260\n",
      "16912/67600 (epoch 12), train_loss = 1.235, time/batch=0.144\n",
      "16913/67600 (epoch 12), train_loss = 1.182, time/batch=0.131\n",
      "16914/67600 (epoch 12), train_loss = 1.226, time/batch=0.148\n",
      "16915/67600 (epoch 12), train_loss = 1.222, time/batch=0.109\n",
      "16916/67600 (epoch 12), train_loss = 1.210, time/batch=0.141\n",
      "16917/67600 (epoch 12), train_loss = 1.261, time/batch=0.129\n",
      "16918/67600 (epoch 12), train_loss = 1.238, time/batch=0.235\n",
      "16919/67600 (epoch 12), train_loss = 1.156, time/batch=0.145\n",
      "16920/67600 (epoch 12), train_loss = 1.248, time/batch=0.134\n",
      "16921/67600 (epoch 12), train_loss = 1.267, time/batch=0.123\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16922/67600 (epoch 12), train_loss = 1.258, time/batch=0.157\n",
      "16923/67600 (epoch 12), train_loss = 1.186, time/batch=0.146\n",
      "16924/67600 (epoch 12), train_loss = 1.239, time/batch=0.195\n",
      "16925/67600 (epoch 12), train_loss = 1.264, time/batch=0.187\n",
      "16926/67600 (epoch 12), train_loss = 1.222, time/batch=0.098\n",
      "16927/67600 (epoch 12), train_loss = 1.179, time/batch=0.140\n",
      "16928/67600 (epoch 12), train_loss = 1.225, time/batch=0.106\n",
      "16929/67600 (epoch 12), train_loss = 1.211, time/batch=0.110\n",
      "16930/67600 (epoch 12), train_loss = 1.209, time/batch=0.117\n",
      "16931/67600 (epoch 12), train_loss = 1.255, time/batch=0.111\n",
      "16932/67600 (epoch 12), train_loss = 1.244, time/batch=0.260\n",
      "16933/67600 (epoch 12), train_loss = 1.196, time/batch=0.126\n",
      "16934/67600 (epoch 12), train_loss = 1.229, time/batch=0.119\n",
      "16935/67600 (epoch 12), train_loss = 1.135, time/batch=0.113\n",
      "16936/67600 (epoch 12), train_loss = 1.226, time/batch=0.109\n",
      "16937/67600 (epoch 12), train_loss = 1.213, time/batch=0.233\n",
      "16938/67600 (epoch 12), train_loss = 1.216, time/batch=0.139\n",
      "16939/67600 (epoch 12), train_loss = 1.203, time/batch=0.127\n",
      "16940/67600 (epoch 12), train_loss = 1.178, time/batch=0.213\n",
      "16941/67600 (epoch 12), train_loss = 1.222, time/batch=0.125\n",
      "16942/67600 (epoch 12), train_loss = 1.204, time/batch=0.346\n",
      "16943/67600 (epoch 12), train_loss = 1.208, time/batch=0.089\n",
      "16944/67600 (epoch 12), train_loss = 1.218, time/batch=0.200\n",
      "16945/67600 (epoch 12), train_loss = 1.251, time/batch=0.140\n",
      "16946/67600 (epoch 12), train_loss = 1.223, time/batch=0.116\n",
      "16947/67600 (epoch 12), train_loss = 1.238, time/batch=0.122\n",
      "16948/67600 (epoch 12), train_loss = 1.230, time/batch=0.124\n",
      "16949/67600 (epoch 12), train_loss = 1.244, time/batch=0.244\n",
      "16950/67600 (epoch 12), train_loss = 1.231, time/batch=0.150\n",
      "16951/67600 (epoch 12), train_loss = 1.235, time/batch=0.133\n",
      "16952/67600 (epoch 12), train_loss = 1.249, time/batch=0.150\n",
      "16953/67600 (epoch 12), train_loss = 1.216, time/batch=0.152\n",
      "16954/67600 (epoch 12), train_loss = 1.241, time/batch=0.108\n",
      "16955/67600 (epoch 12), train_loss = 1.260, time/batch=0.129\n",
      "16956/67600 (epoch 12), train_loss = 1.244, time/batch=0.315\n",
      "16957/67600 (epoch 12), train_loss = 1.235, time/batch=0.130\n",
      "16958/67600 (epoch 12), train_loss = 1.236, time/batch=0.115\n",
      "16959/67600 (epoch 12), train_loss = 1.185, time/batch=0.137\n",
      "16960/67600 (epoch 12), train_loss = 1.285, time/batch=0.113\n",
      "16961/67600 (epoch 12), train_loss = 1.210, time/batch=0.162\n",
      "16962/67600 (epoch 12), train_loss = 1.181, time/batch=0.254\n",
      "16963/67600 (epoch 12), train_loss = 1.258, time/batch=0.139\n",
      "16964/67600 (epoch 12), train_loss = 1.164, time/batch=0.126\n",
      "16965/67600 (epoch 12), train_loss = 1.183, time/batch=0.125\n",
      "16966/67600 (epoch 12), train_loss = 1.167, time/batch=0.130\n",
      "16967/67600 (epoch 12), train_loss = 1.209, time/batch=0.128\n",
      "16968/67600 (epoch 12), train_loss = 1.243, time/batch=0.132\n",
      "16969/67600 (epoch 12), train_loss = 1.240, time/batch=0.295\n",
      "16970/67600 (epoch 12), train_loss = 1.212, time/batch=0.120\n",
      "16971/67600 (epoch 12), train_loss = 1.221, time/batch=0.135\n",
      "16972/67600 (epoch 12), train_loss = 1.239, time/batch=0.124\n",
      "16973/67600 (epoch 12), train_loss = 1.197, time/batch=0.170\n",
      "16974/67600 (epoch 12), train_loss = 1.160, time/batch=0.117\n",
      "16975/67600 (epoch 12), train_loss = 1.195, time/batch=0.140\n",
      "16976/67600 (epoch 12), train_loss = 1.219, time/batch=0.119\n",
      "16977/67600 (epoch 12), train_loss = 1.272, time/batch=0.233\n",
      "16978/67600 (epoch 12), train_loss = 1.212, time/batch=0.209\n",
      "16979/67600 (epoch 12), train_loss = 1.224, time/batch=0.108\n",
      "16980/67600 (epoch 12), train_loss = 1.287, time/batch=0.336\n",
      "16981/67600 (epoch 12), train_loss = 1.231, time/batch=0.134\n",
      "16982/67600 (epoch 12), train_loss = 1.203, time/batch=0.124\n",
      "16983/67600 (epoch 12), train_loss = 1.194, time/batch=0.132\n",
      "16984/67600 (epoch 12), train_loss = 1.212, time/batch=0.121\n",
      "16985/67600 (epoch 12), train_loss = 1.213, time/batch=0.128\n",
      "16986/67600 (epoch 12), train_loss = 1.215, time/batch=0.173\n",
      "16987/67600 (epoch 12), train_loss = 1.255, time/batch=0.241\n",
      "16988/67600 (epoch 12), train_loss = 1.272, time/batch=0.131\n",
      "16989/67600 (epoch 12), train_loss = 1.190, time/batch=0.132\n",
      "16990/67600 (epoch 12), train_loss = 1.232, time/batch=0.105\n",
      "16991/67600 (epoch 12), train_loss = 1.216, time/batch=0.144\n",
      "16992/67600 (epoch 12), train_loss = 1.249, time/batch=0.128\n",
      "16993/67600 (epoch 12), train_loss = 1.250, time/batch=0.269\n",
      "16994/67600 (epoch 12), train_loss = 1.209, time/batch=0.118\n",
      "16995/67600 (epoch 12), train_loss = 1.268, time/batch=0.114\n",
      "16996/67600 (epoch 12), train_loss = 1.242, time/batch=0.112\n",
      "16997/67600 (epoch 12), train_loss = 1.211, time/batch=0.108\n",
      "16998/67600 (epoch 12), train_loss = 1.253, time/batch=0.236\n",
      "16999/67600 (epoch 12), train_loss = 1.295, time/batch=0.130\n",
      "17000/67600 (epoch 12), train_loss = 1.265, time/batch=0.190\n",
      "model saved to ./save/model.ckpt\n",
      "17001/67600 (epoch 12), train_loss = 1.244, time/batch=0.084\n",
      "17002/67600 (epoch 12), train_loss = 1.225, time/batch=0.085\n",
      "17003/67600 (epoch 12), train_loss = 1.248, time/batch=0.090\n",
      "17004/67600 (epoch 12), train_loss = 1.290, time/batch=0.110\n",
      "17005/67600 (epoch 12), train_loss = 1.221, time/batch=0.117\n",
      "17006/67600 (epoch 12), train_loss = 1.212, time/batch=0.139\n",
      "17007/67600 (epoch 12), train_loss = 1.232, time/batch=0.190\n",
      "17008/67600 (epoch 12), train_loss = 1.214, time/batch=0.150\n",
      "17009/67600 (epoch 12), train_loss = 1.255, time/batch=0.136\n",
      "17010/67600 (epoch 12), train_loss = 1.225, time/batch=0.142\n",
      "17011/67600 (epoch 12), train_loss = 1.235, time/batch=0.106\n",
      "17012/67600 (epoch 12), train_loss = 1.246, time/batch=0.113\n",
      "17013/67600 (epoch 12), train_loss = 1.190, time/batch=0.325\n",
      "17014/67600 (epoch 12), train_loss = 1.223, time/batch=0.132\n",
      "17015/67600 (epoch 12), train_loss = 1.229, time/batch=0.117\n",
      "17016/67600 (epoch 12), train_loss = 1.198, time/batch=0.141\n",
      "17017/67600 (epoch 12), train_loss = 1.253, time/batch=0.120\n",
      "17018/67600 (epoch 12), train_loss = 1.228, time/batch=0.134\n",
      "17019/67600 (epoch 12), train_loss = 1.234, time/batch=0.121\n",
      "17020/67600 (epoch 12), train_loss = 1.300, time/batch=0.279\n",
      "17021/67600 (epoch 12), train_loss = 1.239, time/batch=0.121\n",
      "17022/67600 (epoch 12), train_loss = 1.275, time/batch=0.112\n",
      "17023/67600 (epoch 12), train_loss = 1.225, time/batch=0.106\n",
      "17024/67600 (epoch 12), train_loss = 1.236, time/batch=0.112\n",
      "17025/67600 (epoch 12), train_loss = 1.224, time/batch=0.119\n",
      "17026/67600 (epoch 12), train_loss = 1.202, time/batch=0.113\n",
      "17027/67600 (epoch 12), train_loss = 1.222, time/batch=0.213\n",
      "17028/67600 (epoch 12), train_loss = 1.205, time/batch=0.146\n",
      "17029/67600 (epoch 12), train_loss = 1.176, time/batch=0.115\n",
      "17030/67600 (epoch 12), train_loss = 1.228, time/batch=0.113\n",
      "17031/67600 (epoch 12), train_loss = 1.209, time/batch=0.110\n",
      "17032/67600 (epoch 12), train_loss = 1.147, time/batch=0.117\n",
      "17033/67600 (epoch 12), train_loss = 1.249, time/batch=0.161\n",
      "17034/67600 (epoch 12), train_loss = 1.186, time/batch=0.110\n",
      "17035/67600 (epoch 12), train_loss = 1.263, time/batch=0.118\n",
      "17036/67600 (epoch 12), train_loss = 1.248, time/batch=0.130\n",
      "17037/67600 (epoch 12), train_loss = 1.237, time/batch=0.099\n",
      "17038/67600 (epoch 12), train_loss = 1.263, time/batch=0.136\n",
      "17039/67600 (epoch 12), train_loss = 1.180, time/batch=0.268\n",
      "17040/67600 (epoch 12), train_loss = 1.268, time/batch=0.138\n",
      "17041/67600 (epoch 12), train_loss = 1.203, time/batch=0.130\n",
      "17042/67600 (epoch 12), train_loss = 1.201, time/batch=0.133\n",
      "17043/67600 (epoch 12), train_loss = 1.226, time/batch=0.107\n",
      "17044/67600 (epoch 12), train_loss = 1.155, time/batch=0.106\n",
      "17045/67600 (epoch 12), train_loss = 1.265, time/batch=0.107\n",
      "17046/67600 (epoch 12), train_loss = 1.226, time/batch=0.227\n",
      "17047/67600 (epoch 12), train_loss = 1.297, time/batch=0.151\n",
      "17048/67600 (epoch 12), train_loss = 1.241, time/batch=0.109\n",
      "17049/67600 (epoch 12), train_loss = 1.270, time/batch=0.116\n",
      "17050/67600 (epoch 12), train_loss = 1.365, time/batch=0.116\n",
      "17051/67600 (epoch 12), train_loss = 1.201, time/batch=0.112\n",
      "17052/67600 (epoch 12), train_loss = 1.228, time/batch=0.126\n",
      "17053/67600 (epoch 12), train_loss = 1.260, time/batch=0.112\n",
      "17054/67600 (epoch 12), train_loss = 1.307, time/batch=0.234\n",
      "17055/67600 (epoch 12), train_loss = 1.212, time/batch=0.147\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17056/67600 (epoch 12), train_loss = 1.224, time/batch=0.149\n",
      "17057/67600 (epoch 12), train_loss = 1.224, time/batch=0.149\n",
      "17058/67600 (epoch 12), train_loss = 1.196, time/batch=0.234\n",
      "17059/67600 (epoch 12), train_loss = 1.272, time/batch=0.119\n",
      "17060/67600 (epoch 12), train_loss = 1.125, time/batch=0.175\n",
      "17061/67600 (epoch 12), train_loss = 1.259, time/batch=0.128\n",
      "17062/67600 (epoch 12), train_loss = 1.164, time/batch=0.147\n",
      "17063/67600 (epoch 12), train_loss = 1.225, time/batch=0.115\n",
      "17064/67600 (epoch 12), train_loss = 1.281, time/batch=0.169\n",
      "17065/67600 (epoch 12), train_loss = 1.242, time/batch=0.215\n",
      "17066/67600 (epoch 12), train_loss = 1.238, time/batch=0.296\n",
      "17067/67600 (epoch 12), train_loss = 1.236, time/batch=0.144\n",
      "17068/67600 (epoch 12), train_loss = 1.228, time/batch=0.144\n",
      "17069/67600 (epoch 12), train_loss = 1.211, time/batch=0.084\n",
      "17070/67600 (epoch 12), train_loss = 1.202, time/batch=0.127\n",
      "17071/67600 (epoch 12), train_loss = 1.214, time/batch=0.386\n",
      "17072/67600 (epoch 12), train_loss = 1.247, time/batch=0.105\n",
      "17073/67600 (epoch 12), train_loss = 1.223, time/batch=0.149\n",
      "17074/67600 (epoch 12), train_loss = 1.228, time/batch=0.152\n",
      "17075/67600 (epoch 12), train_loss = 1.304, time/batch=0.143\n",
      "17076/67600 (epoch 12), train_loss = 1.308, time/batch=0.250\n",
      "17077/67600 (epoch 12), train_loss = 1.280, time/batch=0.143\n",
      "17078/67600 (epoch 12), train_loss = 1.225, time/batch=0.159\n",
      "17079/67600 (epoch 12), train_loss = 1.262, time/batch=0.121\n",
      "17080/67600 (epoch 12), train_loss = 1.229, time/batch=0.150\n",
      "17081/67600 (epoch 12), train_loss = 1.251, time/batch=0.117\n",
      "17082/67600 (epoch 12), train_loss = 1.262, time/batch=0.129\n",
      "17083/67600 (epoch 12), train_loss = 1.279, time/batch=0.248\n",
      "17084/67600 (epoch 12), train_loss = 1.231, time/batch=0.136\n",
      "17085/67600 (epoch 12), train_loss = 1.284, time/batch=0.121\n",
      "17086/67600 (epoch 12), train_loss = 1.305, time/batch=0.124\n",
      "17087/67600 (epoch 12), train_loss = 1.257, time/batch=0.129\n",
      "17088/67600 (epoch 12), train_loss = 1.195, time/batch=0.245\n",
      "17089/67600 (epoch 12), train_loss = 1.292, time/batch=0.153\n",
      "17090/67600 (epoch 12), train_loss = 1.273, time/batch=0.145\n",
      "17091/67600 (epoch 12), train_loss = 1.213, time/batch=0.111\n",
      "17092/67600 (epoch 12), train_loss = 1.235, time/batch=0.134\n",
      "17093/67600 (epoch 12), train_loss = 1.228, time/batch=0.107\n",
      "17094/67600 (epoch 12), train_loss = 1.236, time/batch=0.143\n",
      "17095/67600 (epoch 12), train_loss = 1.209, time/batch=0.181\n",
      "17096/67600 (epoch 12), train_loss = 1.269, time/batch=0.146\n",
      "17097/67600 (epoch 12), train_loss = 1.192, time/batch=0.115\n",
      "17098/67600 (epoch 12), train_loss = 1.234, time/batch=0.115\n",
      "17099/67600 (epoch 12), train_loss = 1.288, time/batch=0.122\n",
      "17100/67600 (epoch 12), train_loss = 1.270, time/batch=0.112\n",
      "17101/67600 (epoch 12), train_loss = 1.142, time/batch=0.123\n",
      "17102/67600 (epoch 12), train_loss = 1.232, time/batch=0.241\n",
      "17103/67600 (epoch 12), train_loss = 1.135, time/batch=0.151\n",
      "17104/67600 (epoch 12), train_loss = 1.191, time/batch=0.112\n",
      "17105/67600 (epoch 12), train_loss = 1.202, time/batch=0.151\n",
      "17106/67600 (epoch 12), train_loss = 1.206, time/batch=0.128\n",
      "17107/67600 (epoch 12), train_loss = 1.232, time/batch=0.157\n",
      "17108/67600 (epoch 12), train_loss = 1.205, time/batch=0.110\n",
      "17109/67600 (epoch 12), train_loss = 1.223, time/batch=0.283\n",
      "17110/67600 (epoch 12), train_loss = 1.201, time/batch=0.138\n",
      "17111/67600 (epoch 12), train_loss = 1.173, time/batch=0.113\n",
      "17112/67600 (epoch 12), train_loss = 1.288, time/batch=0.126\n",
      "17113/67600 (epoch 12), train_loss = 1.259, time/batch=0.138\n",
      "17114/67600 (epoch 12), train_loss = 1.281, time/batch=0.130\n",
      "17115/67600 (epoch 12), train_loss = 1.277, time/batch=0.316\n",
      "17116/67600 (epoch 12), train_loss = 1.248, time/batch=0.129\n",
      "17117/67600 (epoch 12), train_loss = 1.211, time/batch=0.163\n",
      "17118/67600 (epoch 12), train_loss = 1.250, time/batch=0.096\n",
      "17119/67600 (epoch 12), train_loss = 1.214, time/batch=0.138\n",
      "17120/67600 (epoch 12), train_loss = 1.235, time/batch=0.114\n",
      "17121/67600 (epoch 12), train_loss = 1.297, time/batch=0.268\n",
      "17122/67600 (epoch 12), train_loss = 1.260, time/batch=0.171\n",
      "17123/67600 (epoch 12), train_loss = 1.269, time/batch=0.139\n",
      "17124/67600 (epoch 12), train_loss = 1.244, time/batch=0.127\n",
      "17125/67600 (epoch 12), train_loss = 1.281, time/batch=0.141\n",
      "17126/67600 (epoch 12), train_loss = 1.282, time/batch=0.163\n",
      "17127/67600 (epoch 12), train_loss = 1.174, time/batch=0.123\n",
      "17128/67600 (epoch 12), train_loss = 1.218, time/batch=0.131\n",
      "17129/67600 (epoch 12), train_loss = 1.265, time/batch=0.101\n",
      "17130/67600 (epoch 12), train_loss = 1.220, time/batch=0.118\n",
      "17131/67600 (epoch 12), train_loss = 1.206, time/batch=0.128\n",
      "17132/67600 (epoch 12), train_loss = 1.281, time/batch=0.311\n",
      "17133/67600 (epoch 12), train_loss = 1.211, time/batch=0.149\n",
      "17134/67600 (epoch 12), train_loss = 1.226, time/batch=0.115\n",
      "17135/67600 (epoch 12), train_loss = 1.245, time/batch=0.113\n",
      "17136/67600 (epoch 12), train_loss = 1.228, time/batch=0.101\n",
      "17137/67600 (epoch 12), train_loss = 1.258, time/batch=0.127\n",
      "17138/67600 (epoch 12), train_loss = 1.278, time/batch=0.165\n",
      "17139/67600 (epoch 12), train_loss = 1.199, time/batch=0.280\n",
      "17140/67600 (epoch 12), train_loss = 1.227, time/batch=0.120\n",
      "17141/67600 (epoch 12), train_loss = 1.219, time/batch=0.112\n",
      "17142/67600 (epoch 12), train_loss = 1.237, time/batch=0.123\n",
      "17143/67600 (epoch 12), train_loss = 1.232, time/batch=0.103\n",
      "17144/67600 (epoch 12), train_loss = 1.261, time/batch=0.141\n",
      "17145/67600 (epoch 12), train_loss = 1.236, time/batch=0.115\n",
      "17146/67600 (epoch 12), train_loss = 1.248, time/batch=0.289\n",
      "17147/67600 (epoch 12), train_loss = 1.196, time/batch=0.112\n",
      "17148/67600 (epoch 12), train_loss = 1.196, time/batch=0.119\n",
      "17149/67600 (epoch 12), train_loss = 1.215, time/batch=0.126\n",
      "17150/67600 (epoch 12), train_loss = 1.211, time/batch=0.123\n",
      "17151/67600 (epoch 12), train_loss = 1.227, time/batch=0.205\n",
      "17152/67600 (epoch 12), train_loss = 1.205, time/batch=0.143\n",
      "17153/67600 (epoch 12), train_loss = 1.224, time/batch=0.106\n",
      "17154/67600 (epoch 12), train_loss = 1.182, time/batch=0.128\n",
      "17155/67600 (epoch 12), train_loss = 1.236, time/batch=0.108\n",
      "17156/67600 (epoch 12), train_loss = 1.211, time/batch=0.121\n",
      "17157/67600 (epoch 12), train_loss = 1.181, time/batch=0.147\n",
      "17158/67600 (epoch 12), train_loss = 1.209, time/batch=0.328\n",
      "17159/67600 (epoch 12), train_loss = 1.202, time/batch=0.107\n",
      "17160/67600 (epoch 12), train_loss = 1.255, time/batch=0.128\n",
      "17161/67600 (epoch 12), train_loss = 1.215, time/batch=0.109\n",
      "17162/67600 (epoch 12), train_loss = 1.209, time/batch=0.132\n",
      "17163/67600 (epoch 12), train_loss = 1.207, time/batch=0.116\n",
      "17164/67600 (epoch 12), train_loss = 1.228, time/batch=0.100\n",
      "17165/67600 (epoch 12), train_loss = 1.186, time/batch=0.230\n",
      "17166/67600 (epoch 12), train_loss = 1.170, time/batch=0.141\n",
      "17167/67600 (epoch 12), train_loss = 1.255, time/batch=0.101\n",
      "17168/67600 (epoch 12), train_loss = 1.214, time/batch=0.123\n",
      "17169/67600 (epoch 12), train_loss = 1.234, time/batch=0.115\n",
      "17170/67600 (epoch 12), train_loss = 1.203, time/batch=0.126\n",
      "17171/67600 (epoch 12), train_loss = 1.181, time/batch=0.103\n",
      "17172/67600 (epoch 12), train_loss = 1.236, time/batch=0.147\n",
      "17173/67600 (epoch 12), train_loss = 1.182, time/batch=0.228\n",
      "17174/67600 (epoch 12), train_loss = 1.249, time/batch=0.140\n",
      "17175/67600 (epoch 12), train_loss = 1.202, time/batch=0.110\n",
      "17176/67600 (epoch 12), train_loss = 1.249, time/batch=0.135\n",
      "17177/67600 (epoch 12), train_loss = 1.193, time/batch=0.113\n",
      "17178/67600 (epoch 12), train_loss = 1.161, time/batch=0.115\n",
      "17179/67600 (epoch 12), train_loss = 1.273, time/batch=0.149\n",
      "17180/67600 (epoch 12), train_loss = 1.246, time/batch=0.236\n",
      "17181/67600 (epoch 12), train_loss = 1.245, time/batch=0.134\n",
      "17182/67600 (epoch 12), train_loss = 1.190, time/batch=0.106\n",
      "17183/67600 (epoch 12), train_loss = 1.200, time/batch=0.129\n",
      "17184/67600 (epoch 12), train_loss = 1.190, time/batch=0.224\n",
      "17185/67600 (epoch 12), train_loss = 1.145, time/batch=0.116\n",
      "17186/67600 (epoch 12), train_loss = 1.157, time/batch=0.174\n",
      "17187/67600 (epoch 12), train_loss = 1.156, time/batch=0.106\n",
      "17188/67600 (epoch 12), train_loss = 1.155, time/batch=0.128\n",
      "17189/67600 (epoch 12), train_loss = 1.237, time/batch=0.132\n",
      "17190/67600 (epoch 12), train_loss = 1.222, time/batch=0.126\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17191/67600 (epoch 12), train_loss = 1.171, time/batch=0.216\n",
      "17192/67600 (epoch 12), train_loss = 1.183, time/batch=0.110\n",
      "17193/67600 (epoch 12), train_loss = 1.181, time/batch=0.186\n",
      "17194/67600 (epoch 12), train_loss = 1.216, time/batch=0.111\n",
      "17195/67600 (epoch 12), train_loss = 1.232, time/batch=0.130\n",
      "17196/67600 (epoch 12), train_loss = 1.168, time/batch=0.102\n",
      "17197/67600 (epoch 12), train_loss = 1.230, time/batch=0.107\n",
      "17198/67600 (epoch 12), train_loss = 1.262, time/batch=0.124\n",
      "17199/67600 (epoch 12), train_loss = 1.152, time/batch=0.297\n",
      "17200/67600 (epoch 12), train_loss = 1.155, time/batch=0.112\n",
      "17201/67600 (epoch 12), train_loss = 1.184, time/batch=0.131\n",
      "17202/67600 (epoch 12), train_loss = 1.231, time/batch=0.110\n",
      "17203/67600 (epoch 12), train_loss = 1.209, time/batch=0.113\n",
      "17204/67600 (epoch 12), train_loss = 1.223, time/batch=0.123\n",
      "17205/67600 (epoch 12), train_loss = 1.180, time/batch=0.157\n",
      "17206/67600 (epoch 12), train_loss = 1.205, time/batch=0.242\n",
      "17207/67600 (epoch 12), train_loss = 1.253, time/batch=0.143\n",
      "17208/67600 (epoch 12), train_loss = 1.196, time/batch=0.136\n",
      "17209/67600 (epoch 12), train_loss = 1.280, time/batch=0.111\n",
      "17210/67600 (epoch 12), train_loss = 1.219, time/batch=0.112\n",
      "17211/67600 (epoch 12), train_loss = 1.285, time/batch=0.109\n",
      "17212/67600 (epoch 12), train_loss = 1.182, time/batch=0.291\n",
      "17213/67600 (epoch 12), train_loss = 1.214, time/batch=0.104\n",
      "17214/67600 (epoch 12), train_loss = 1.241, time/batch=0.111\n",
      "17215/67600 (epoch 12), train_loss = 1.207, time/batch=0.129\n",
      "17216/67600 (epoch 12), train_loss = 1.255, time/batch=0.109\n",
      "17217/67600 (epoch 12), train_loss = 1.215, time/batch=0.138\n",
      "17218/67600 (epoch 12), train_loss = 1.198, time/batch=0.142\n",
      "17219/67600 (epoch 12), train_loss = 1.216, time/batch=0.266\n",
      "17220/67600 (epoch 12), train_loss = 1.209, time/batch=0.131\n",
      "17221/67600 (epoch 12), train_loss = 1.229, time/batch=0.141\n",
      "17222/67600 (epoch 12), train_loss = 1.185, time/batch=0.137\n",
      "17223/67600 (epoch 12), train_loss = 1.201, time/batch=0.120\n",
      "17224/67600 (epoch 12), train_loss = 1.217, time/batch=0.169\n",
      "17225/67600 (epoch 12), train_loss = 1.230, time/batch=0.109\n",
      "17226/67600 (epoch 12), train_loss = 1.195, time/batch=0.118\n",
      "17227/67600 (epoch 12), train_loss = 1.210, time/batch=0.143\n",
      "17228/67600 (epoch 12), train_loss = 1.165, time/batch=0.126\n",
      "17229/67600 (epoch 12), train_loss = 1.235, time/batch=0.122\n",
      "17230/67600 (epoch 12), train_loss = 1.216, time/batch=0.309\n",
      "17231/67600 (epoch 12), train_loss = 1.178, time/batch=0.129\n",
      "17232/67600 (epoch 12), train_loss = 1.219, time/batch=0.126\n",
      "17233/67600 (epoch 12), train_loss = 1.173, time/batch=0.158\n",
      "17234/67600 (epoch 12), train_loss = 1.200, time/batch=0.121\n",
      "17235/67600 (epoch 12), train_loss = 1.191, time/batch=0.117\n",
      "17236/67600 (epoch 12), train_loss = 1.151, time/batch=0.136\n",
      "17237/67600 (epoch 12), train_loss = 1.198, time/batch=0.283\n",
      "17238/67600 (epoch 12), train_loss = 1.186, time/batch=0.131\n",
      "17239/67600 (epoch 12), train_loss = 1.209, time/batch=0.119\n",
      "17240/67600 (epoch 12), train_loss = 1.185, time/batch=0.110\n",
      "17241/67600 (epoch 12), train_loss = 1.234, time/batch=0.100\n",
      "17242/67600 (epoch 12), train_loss = 1.210, time/batch=0.123\n",
      "17243/67600 (epoch 12), train_loss = 1.226, time/batch=0.114\n",
      "17244/67600 (epoch 12), train_loss = 1.199, time/batch=0.242\n",
      "17245/67600 (epoch 12), train_loss = 1.207, time/batch=0.157\n",
      "17246/67600 (epoch 12), train_loss = 1.202, time/batch=0.116\n",
      "17247/67600 (epoch 12), train_loss = 1.199, time/batch=0.148\n",
      "17248/67600 (epoch 12), train_loss = 1.199, time/batch=0.232\n",
      "17249/67600 (epoch 12), train_loss = 1.162, time/batch=0.191\n",
      "17250/67600 (epoch 12), train_loss = 1.248, time/batch=0.120\n",
      "17251/67600 (epoch 12), train_loss = 1.165, time/batch=0.138\n",
      "17252/67600 (epoch 12), train_loss = 1.253, time/batch=0.120\n",
      "17253/67600 (epoch 12), train_loss = 1.223, time/batch=0.129\n",
      "17254/67600 (epoch 12), train_loss = 1.251, time/batch=0.110\n",
      "17255/67600 (epoch 12), train_loss = 1.260, time/batch=0.245\n",
      "17256/67600 (epoch 12), train_loss = 1.232, time/batch=0.159\n",
      "17257/67600 (epoch 12), train_loss = 1.195, time/batch=0.129\n",
      "17258/67600 (epoch 12), train_loss = 1.214, time/batch=0.121\n",
      "17259/67600 (epoch 12), train_loss = 1.191, time/batch=0.126\n",
      "17260/67600 (epoch 12), train_loss = 1.187, time/batch=0.120\n",
      "17261/67600 (epoch 12), train_loss = 1.182, time/batch=0.133\n",
      "17262/67600 (epoch 12), train_loss = 1.222, time/batch=0.210\n",
      "17263/67600 (epoch 12), train_loss = 1.204, time/batch=0.164\n",
      "17264/67600 (epoch 12), train_loss = 1.222, time/batch=0.121\n",
      "17265/67600 (epoch 12), train_loss = 1.222, time/batch=0.118\n",
      "17266/67600 (epoch 12), train_loss = 1.251, time/batch=0.125\n",
      "17267/67600 (epoch 12), train_loss = 1.119, time/batch=0.107\n",
      "17268/67600 (epoch 12), train_loss = 1.206, time/batch=0.108\n",
      "17269/67600 (epoch 12), train_loss = 1.211, time/batch=0.256\n",
      "17270/67600 (epoch 12), train_loss = 1.217, time/batch=0.113\n",
      "17271/67600 (epoch 12), train_loss = 1.275, time/batch=0.154\n",
      "17272/67600 (epoch 12), train_loss = 1.249, time/batch=0.105\n",
      "17273/67600 (epoch 12), train_loss = 1.235, time/batch=0.121\n",
      "17274/67600 (epoch 12), train_loss = 1.215, time/batch=0.112\n",
      "17275/67600 (epoch 12), train_loss = 1.185, time/batch=0.127\n",
      "17276/67600 (epoch 12), train_loss = 1.216, time/batch=0.261\n",
      "17277/67600 (epoch 12), train_loss = 1.213, time/batch=0.120\n",
      "17278/67600 (epoch 12), train_loss = 1.237, time/batch=0.135\n",
      "17279/67600 (epoch 12), train_loss = 1.211, time/batch=0.131\n",
      "17280/67600 (epoch 12), train_loss = 1.145, time/batch=0.098\n",
      "17281/67600 (epoch 12), train_loss = 1.256, time/batch=0.226\n",
      "17282/67600 (epoch 12), train_loss = 1.288, time/batch=0.161\n",
      "17283/67600 (epoch 12), train_loss = 1.208, time/batch=0.126\n",
      "17284/67600 (epoch 12), train_loss = 1.235, time/batch=0.117\n",
      "17285/67600 (epoch 12), train_loss = 1.239, time/batch=0.105\n",
      "17286/67600 (epoch 12), train_loss = 1.220, time/batch=0.112\n",
      "17287/67600 (epoch 12), train_loss = 1.184, time/batch=0.118\n",
      "17288/67600 (epoch 12), train_loss = 1.227, time/batch=0.118\n",
      "17289/67600 (epoch 12), train_loss = 1.214, time/batch=0.215\n",
      "17290/67600 (epoch 12), train_loss = 1.215, time/batch=0.157\n",
      "17291/67600 (epoch 12), train_loss = 1.256, time/batch=0.120\n",
      "17292/67600 (epoch 12), train_loss = 1.182, time/batch=0.121\n",
      "17293/67600 (epoch 12), train_loss = 1.233, time/batch=0.105\n",
      "17294/67600 (epoch 12), train_loss = 1.251, time/batch=0.157\n",
      "17295/67600 (epoch 12), train_loss = 1.270, time/batch=0.103\n",
      "17296/67600 (epoch 12), train_loss = 1.223, time/batch=0.218\n",
      "17297/67600 (epoch 12), train_loss = 1.200, time/batch=0.149\n",
      "17298/67600 (epoch 12), train_loss = 1.175, time/batch=0.129\n",
      "17299/67600 (epoch 12), train_loss = 1.213, time/batch=0.105\n",
      "17300/67600 (epoch 12), train_loss = 1.267, time/batch=0.135\n",
      "17301/67600 (epoch 12), train_loss = 1.268, time/batch=0.105\n",
      "17302/67600 (epoch 12), train_loss = 1.265, time/batch=0.120\n",
      "17303/67600 (epoch 12), train_loss = 1.256, time/batch=0.289\n",
      "17304/67600 (epoch 12), train_loss = 1.273, time/batch=0.154\n",
      "17305/67600 (epoch 12), train_loss = 1.188, time/batch=0.118\n",
      "17306/67600 (epoch 12), train_loss = 1.254, time/batch=0.117\n",
      "17307/67600 (epoch 12), train_loss = 1.190, time/batch=0.122\n",
      "17308/67600 (epoch 12), train_loss = 1.185, time/batch=0.111\n",
      "17309/67600 (epoch 12), train_loss = 1.287, time/batch=0.121\n",
      "17310/67600 (epoch 12), train_loss = 1.254, time/batch=0.231\n",
      "17311/67600 (epoch 12), train_loss = 1.159, time/batch=0.134\n",
      "17312/67600 (epoch 12), train_loss = 1.200, time/batch=0.123\n",
      "17313/67600 (epoch 12), train_loss = 1.187, time/batch=0.126\n",
      "17314/67600 (epoch 12), train_loss = 1.235, time/batch=0.108\n",
      "17315/67600 (epoch 12), train_loss = 1.195, time/batch=0.210\n",
      "17316/67600 (epoch 12), train_loss = 1.261, time/batch=0.166\n",
      "17317/67600 (epoch 12), train_loss = 1.212, time/batch=0.115\n",
      "17318/67600 (epoch 12), train_loss = 1.217, time/batch=0.159\n",
      "17319/67600 (epoch 12), train_loss = 1.185, time/batch=0.113\n",
      "17320/67600 (epoch 12), train_loss = 1.224, time/batch=0.118\n",
      "17321/67600 (epoch 12), train_loss = 1.213, time/batch=0.110\n",
      "17322/67600 (epoch 12), train_loss = 1.190, time/batch=0.162\n",
      "17323/67600 (epoch 12), train_loss = 1.151, time/batch=0.106\n",
      "17324/67600 (epoch 12), train_loss = 1.223, time/batch=0.115\n",
      "17325/67600 (epoch 12), train_loss = 1.204, time/batch=0.117\n",
      "17326/67600 (epoch 12), train_loss = 1.197, time/batch=0.113\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17327/67600 (epoch 12), train_loss = 1.174, time/batch=0.110\n",
      "17328/67600 (epoch 12), train_loss = 1.292, time/batch=0.348\n",
      "17329/67600 (epoch 12), train_loss = 1.199, time/batch=0.172\n",
      "17330/67600 (epoch 12), train_loss = 1.207, time/batch=0.101\n",
      "17331/67600 (epoch 12), train_loss = 1.245, time/batch=0.109\n",
      "17332/67600 (epoch 12), train_loss = 1.198, time/batch=0.131\n",
      "17333/67600 (epoch 12), train_loss = 1.227, time/batch=0.124\n",
      "17334/67600 (epoch 12), train_loss = 1.244, time/batch=0.131\n",
      "17335/67600 (epoch 12), train_loss = 1.212, time/batch=0.215\n",
      "17336/67600 (epoch 12), train_loss = 1.276, time/batch=0.160\n",
      "17337/67600 (epoch 12), train_loss = 1.270, time/batch=0.146\n",
      "17338/67600 (epoch 12), train_loss = 1.245, time/batch=0.102\n",
      "17339/67600 (epoch 12), train_loss = 1.317, time/batch=0.152\n",
      "17340/67600 (epoch 12), train_loss = 1.220, time/batch=0.120\n",
      "17341/67600 (epoch 12), train_loss = 1.252, time/batch=0.133\n",
      "17342/67600 (epoch 12), train_loss = 1.220, time/batch=0.239\n",
      "17343/67600 (epoch 12), train_loss = 1.317, time/batch=0.129\n",
      "17344/67600 (epoch 12), train_loss = 1.206, time/batch=0.168\n",
      "17345/67600 (epoch 12), train_loss = 1.260, time/batch=0.123\n",
      "17346/67600 (epoch 12), train_loss = 1.321, time/batch=0.128\n",
      "17347/67600 (epoch 12), train_loss = 1.239, time/batch=0.232\n",
      "17348/67600 (epoch 12), train_loss = 1.214, time/batch=0.140\n",
      "17349/67600 (epoch 12), train_loss = 1.215, time/batch=0.125\n",
      "17350/67600 (epoch 12), train_loss = 1.279, time/batch=0.116\n",
      "17351/67600 (epoch 12), train_loss = 1.229, time/batch=0.106\n",
      "17352/67600 (epoch 12), train_loss = 1.242, time/batch=0.114\n",
      "17353/67600 (epoch 12), train_loss = 1.235, time/batch=0.122\n",
      "17354/67600 (epoch 12), train_loss = 1.243, time/batch=0.214\n",
      "17355/67600 (epoch 12), train_loss = 1.249, time/batch=0.165\n",
      "17356/67600 (epoch 12), train_loss = 1.209, time/batch=0.117\n",
      "17357/67600 (epoch 12), train_loss = 1.276, time/batch=0.127\n",
      "17358/67600 (epoch 12), train_loss = 1.298, time/batch=0.132\n",
      "17359/67600 (epoch 12), train_loss = 1.295, time/batch=0.110\n",
      "17360/67600 (epoch 12), train_loss = 1.265, time/batch=0.118\n",
      "17361/67600 (epoch 12), train_loss = 1.234, time/batch=0.206\n",
      "17362/67600 (epoch 12), train_loss = 1.236, time/batch=0.162\n",
      "17363/67600 (epoch 12), train_loss = 1.286, time/batch=0.130\n",
      "17364/67600 (epoch 12), train_loss = 1.229, time/batch=0.115\n",
      "17365/67600 (epoch 12), train_loss = 1.228, time/batch=0.132\n",
      "17366/67600 (epoch 12), train_loss = 1.268, time/batch=0.112\n",
      "17367/67600 (epoch 12), train_loss = 1.264, time/batch=0.121\n",
      "17368/67600 (epoch 12), train_loss = 1.251, time/batch=0.199\n",
      "17369/67600 (epoch 12), train_loss = 1.205, time/batch=0.174\n",
      "17370/67600 (epoch 12), train_loss = 1.191, time/batch=0.119\n",
      "17371/67600 (epoch 12), train_loss = 1.181, time/batch=0.125\n",
      "17372/67600 (epoch 12), train_loss = 1.198, time/batch=0.115\n",
      "17373/67600 (epoch 12), train_loss = 1.214, time/batch=0.128\n",
      "17374/67600 (epoch 12), train_loss = 1.161, time/batch=0.119\n",
      "17375/67600 (epoch 12), train_loss = 1.256, time/batch=0.274\n",
      "17376/67600 (epoch 12), train_loss = 1.221, time/batch=0.096\n",
      "17377/67600 (epoch 12), train_loss = 1.199, time/batch=0.134\n",
      "17378/67600 (epoch 12), train_loss = 1.229, time/batch=0.134\n",
      "17379/67600 (epoch 12), train_loss = 1.207, time/batch=0.115\n",
      "17380/67600 (epoch 12), train_loss = 1.207, time/batch=0.134\n",
      "17381/67600 (epoch 12), train_loss = 1.163, time/batch=0.205\n",
      "17382/67600 (epoch 12), train_loss = 1.266, time/batch=0.149\n",
      "17383/67600 (epoch 12), train_loss = 1.260, time/batch=0.135\n",
      "17384/67600 (epoch 12), train_loss = 1.183, time/batch=0.110\n",
      "17385/67600 (epoch 12), train_loss = 1.195, time/batch=0.129\n",
      "17386/67600 (epoch 12), train_loss = 1.212, time/batch=0.110\n",
      "17387/67600 (epoch 12), train_loss = 1.171, time/batch=0.099\n",
      "17388/67600 (epoch 12), train_loss = 1.228, time/batch=0.231\n",
      "17389/67600 (epoch 12), train_loss = 1.180, time/batch=0.144\n",
      "17390/67600 (epoch 12), train_loss = 1.197, time/batch=0.169\n",
      "17391/67600 (epoch 12), train_loss = 1.228, time/batch=0.121\n",
      "17392/67600 (epoch 12), train_loss = 1.233, time/batch=0.136\n",
      "17393/67600 (epoch 12), train_loss = 1.150, time/batch=0.118\n",
      "17394/67600 (epoch 12), train_loss = 1.183, time/batch=0.252\n",
      "17395/67600 (epoch 12), train_loss = 1.183, time/batch=0.123\n",
      "17396/67600 (epoch 12), train_loss = 1.211, time/batch=0.132\n",
      "17397/67600 (epoch 12), train_loss = 1.223, time/batch=0.118\n",
      "17398/67600 (epoch 12), train_loss = 1.209, time/batch=0.102\n",
      "17399/67600 (epoch 12), train_loss = 1.218, time/batch=0.139\n",
      "17400/67600 (epoch 12), train_loss = 1.221, time/batch=0.099\n",
      "17401/67600 (epoch 12), train_loss = 1.214, time/batch=0.136\n",
      "17402/67600 (epoch 12), train_loss = 1.258, time/batch=0.237\n",
      "17403/67600 (epoch 12), train_loss = 1.315, time/batch=0.139\n",
      "17404/67600 (epoch 12), train_loss = 1.280, time/batch=0.130\n",
      "17405/67600 (epoch 12), train_loss = 1.241, time/batch=0.122\n",
      "17406/67600 (epoch 12), train_loss = 1.228, time/batch=0.101\n",
      "17407/67600 (epoch 12), train_loss = 1.217, time/batch=0.124\n",
      "17408/67600 (epoch 12), train_loss = 1.241, time/batch=0.131\n",
      "17409/67600 (epoch 12), train_loss = 1.146, time/batch=0.296\n",
      "17410/67600 (epoch 12), train_loss = 1.176, time/batch=0.113\n",
      "17411/67600 (epoch 12), train_loss = 1.269, time/batch=0.115\n",
      "17412/67600 (epoch 12), train_loss = 1.215, time/batch=0.138\n",
      "17413/67600 (epoch 12), train_loss = 1.182, time/batch=0.197\n",
      "17414/67600 (epoch 12), train_loss = 1.223, time/batch=0.246\n",
      "17415/67600 (epoch 12), train_loss = 1.199, time/batch=0.126\n",
      "17416/67600 (epoch 12), train_loss = 1.209, time/batch=0.136\n",
      "17417/67600 (epoch 12), train_loss = 1.217, time/batch=0.122\n",
      "17418/67600 (epoch 12), train_loss = 1.175, time/batch=0.116\n",
      "17419/67600 (epoch 12), train_loss = 1.191, time/batch=0.121\n",
      "17420/67600 (epoch 12), train_loss = 1.235, time/batch=0.167\n",
      "17421/67600 (epoch 12), train_loss = 1.244, time/batch=0.118\n",
      "17422/67600 (epoch 12), train_loss = 1.258, time/batch=0.169\n",
      "17423/67600 (epoch 12), train_loss = 1.205, time/batch=0.139\n",
      "17424/67600 (epoch 12), train_loss = 1.235, time/batch=0.149\n",
      "17425/67600 (epoch 12), train_loss = 1.196, time/batch=0.360\n",
      "17426/67600 (epoch 12), train_loss = 1.183, time/batch=0.164\n",
      "17427/67600 (epoch 12), train_loss = 1.187, time/batch=0.174\n",
      "17428/67600 (epoch 12), train_loss = 1.291, time/batch=0.142\n",
      "17429/67600 (epoch 12), train_loss = 1.212, time/batch=0.123\n",
      "17430/67600 (epoch 12), train_loss = 1.176, time/batch=0.111\n",
      "17431/67600 (epoch 12), train_loss = 1.223, time/batch=0.273\n",
      "17432/67600 (epoch 12), train_loss = 1.180, time/batch=0.132\n",
      "17433/67600 (epoch 12), train_loss = 1.184, time/batch=0.121\n",
      "17434/67600 (epoch 12), train_loss = 1.243, time/batch=0.116\n",
      "17435/67600 (epoch 12), train_loss = 1.194, time/batch=0.132\n",
      "17436/67600 (epoch 12), train_loss = 1.188, time/batch=0.163\n",
      "17437/67600 (epoch 12), train_loss = 1.226, time/batch=0.112\n",
      "17438/67600 (epoch 12), train_loss = 1.240, time/batch=0.285\n",
      "17439/67600 (epoch 12), train_loss = 1.208, time/batch=0.128\n",
      "17440/67600 (epoch 12), train_loss = 1.228, time/batch=0.161\n",
      "17441/67600 (epoch 12), train_loss = 1.229, time/batch=0.138\n",
      "17442/67600 (epoch 12), train_loss = 1.214, time/batch=0.285\n",
      "17443/67600 (epoch 12), train_loss = 1.215, time/batch=0.187\n",
      "17444/67600 (epoch 12), train_loss = 1.200, time/batch=0.149\n",
      "17445/67600 (epoch 12), train_loss = 1.199, time/batch=0.130\n",
      "17446/67600 (epoch 12), train_loss = 1.245, time/batch=0.133\n",
      "17447/67600 (epoch 12), train_loss = 1.203, time/batch=0.167\n",
      "17448/67600 (epoch 12), train_loss = 1.259, time/batch=0.257\n",
      "17449/67600 (epoch 12), train_loss = 1.237, time/batch=0.145\n",
      "17450/67600 (epoch 12), train_loss = 1.252, time/batch=0.118\n",
      "17451/67600 (epoch 12), train_loss = 1.221, time/batch=0.135\n",
      "17452/67600 (epoch 12), train_loss = 1.254, time/batch=0.133\n",
      "17453/67600 (epoch 12), train_loss = 1.202, time/batch=0.134\n",
      "17454/67600 (epoch 12), train_loss = 1.234, time/batch=0.100\n",
      "17455/67600 (epoch 12), train_loss = 1.234, time/batch=0.317\n",
      "17456/67600 (epoch 12), train_loss = 1.316, time/batch=0.142\n",
      "17457/67600 (epoch 12), train_loss = 1.274, time/batch=0.137\n",
      "17458/67600 (epoch 12), train_loss = 1.178, time/batch=0.134\n",
      "17459/67600 (epoch 12), train_loss = 1.212, time/batch=0.131\n",
      "17460/67600 (epoch 12), train_loss = 1.203, time/batch=0.238\n",
      "17461/67600 (epoch 12), train_loss = 1.237, time/batch=0.210\n",
      "17462/67600 (epoch 12), train_loss = 1.215, time/batch=0.138\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17463/67600 (epoch 12), train_loss = 1.198, time/batch=0.132\n",
      "17464/67600 (epoch 12), train_loss = 1.267, time/batch=0.151\n",
      "17465/67600 (epoch 12), train_loss = 1.201, time/batch=0.135\n",
      "17466/67600 (epoch 12), train_loss = 1.214, time/batch=0.315\n",
      "17467/67600 (epoch 12), train_loss = 1.246, time/batch=0.136\n",
      "17468/67600 (epoch 12), train_loss = 1.309, time/batch=0.111\n",
      "17469/67600 (epoch 12), train_loss = 1.234, time/batch=0.135\n",
      "17470/67600 (epoch 12), train_loss = 1.220, time/batch=0.146\n",
      "17471/67600 (epoch 12), train_loss = 1.214, time/batch=0.248\n",
      "17472/67600 (epoch 12), train_loss = 1.243, time/batch=0.199\n",
      "17473/67600 (epoch 12), train_loss = 1.211, time/batch=0.094\n",
      "17474/67600 (epoch 12), train_loss = 1.178, time/batch=0.175\n",
      "17475/67600 (epoch 12), train_loss = 1.282, time/batch=0.138\n",
      "17476/67600 (epoch 12), train_loss = 1.189, time/batch=0.127\n",
      "17477/67600 (epoch 12), train_loss = 1.270, time/batch=0.283\n",
      "17478/67600 (epoch 12), train_loss = 1.251, time/batch=0.141\n",
      "17479/67600 (epoch 12), train_loss = 1.263, time/batch=0.130\n",
      "17480/67600 (epoch 12), train_loss = 1.254, time/batch=0.111\n",
      "17481/67600 (epoch 12), train_loss = 1.247, time/batch=0.124\n",
      "17482/67600 (epoch 12), train_loss = 1.290, time/batch=0.136\n",
      "17483/67600 (epoch 12), train_loss = 1.223, time/batch=0.121\n",
      "17484/67600 (epoch 12), train_loss = 1.242, time/batch=0.273\n",
      "17485/67600 (epoch 12), train_loss = 1.203, time/batch=0.131\n",
      "17486/67600 (epoch 12), train_loss = 1.299, time/batch=0.143\n",
      "17487/67600 (epoch 12), train_loss = 1.285, time/batch=0.137\n",
      "17488/67600 (epoch 12), train_loss = 1.284, time/batch=0.128\n",
      "17489/67600 (epoch 12), train_loss = 1.220, time/batch=0.118\n",
      "17490/67600 (epoch 12), train_loss = 1.281, time/batch=0.267\n",
      "17491/67600 (epoch 12), train_loss = 1.194, time/batch=0.122\n",
      "17492/67600 (epoch 12), train_loss = 1.171, time/batch=0.129\n",
      "17493/67600 (epoch 12), train_loss = 1.232, time/batch=0.102\n",
      "17494/67600 (epoch 12), train_loss = 1.228, time/batch=0.135\n",
      "17495/67600 (epoch 12), train_loss = 1.168, time/batch=0.173\n",
      "17496/67600 (epoch 12), train_loss = 1.226, time/batch=0.138\n",
      "17497/67600 (epoch 12), train_loss = 1.213, time/batch=0.401\n",
      "17498/67600 (epoch 12), train_loss = 1.201, time/batch=0.203\n",
      "17499/67600 (epoch 12), train_loss = 1.244, time/batch=0.130\n",
      "17500/67600 (epoch 12), train_loss = 1.256, time/batch=0.278\n",
      "model saved to ./save/model.ckpt\n",
      "17501/67600 (epoch 12), train_loss = 1.237, time/batch=0.083\n",
      "17502/67600 (epoch 12), train_loss = 1.160, time/batch=0.085\n",
      "17503/67600 (epoch 12), train_loss = 1.178, time/batch=0.122\n",
      "17504/67600 (epoch 12), train_loss = 1.194, time/batch=0.117\n",
      "17505/67600 (epoch 12), train_loss = 1.220, time/batch=0.219\n",
      "17506/67600 (epoch 12), train_loss = 1.181, time/batch=0.160\n",
      "17507/67600 (epoch 12), train_loss = 1.236, time/batch=0.119\n",
      "17508/67600 (epoch 12), train_loss = 1.260, time/batch=0.137\n",
      "17509/67600 (epoch 12), train_loss = 1.216, time/batch=0.121\n",
      "17510/67600 (epoch 12), train_loss = 1.199, time/batch=0.115\n",
      "17511/67600 (epoch 12), train_loss = 1.275, time/batch=0.123\n",
      "17512/67600 (epoch 12), train_loss = 1.200, time/batch=0.121\n",
      "17513/67600 (epoch 12), train_loss = 1.258, time/batch=0.297\n",
      "17514/67600 (epoch 12), train_loss = 1.285, time/batch=0.134\n",
      "17515/67600 (epoch 12), train_loss = 1.252, time/batch=0.144\n",
      "17516/67600 (epoch 12), train_loss = 1.205, time/batch=0.134\n",
      "17517/67600 (epoch 12), train_loss = 1.207, time/batch=0.133\n",
      "17518/67600 (epoch 12), train_loss = 1.224, time/batch=0.246\n",
      "17519/67600 (epoch 12), train_loss = 1.220, time/batch=0.126\n",
      "17520/67600 (epoch 12), train_loss = 1.231, time/batch=0.133\n",
      "17521/67600 (epoch 12), train_loss = 1.243, time/batch=0.127\n",
      "17522/67600 (epoch 12), train_loss = 1.177, time/batch=0.123\n",
      "17523/67600 (epoch 12), train_loss = 1.250, time/batch=0.120\n",
      "17524/67600 (epoch 12), train_loss = 1.270, time/batch=0.123\n",
      "17525/67600 (epoch 12), train_loss = 1.227, time/batch=0.240\n",
      "17526/67600 (epoch 12), train_loss = 1.198, time/batch=0.148\n",
      "17527/67600 (epoch 12), train_loss = 1.224, time/batch=0.124\n",
      "17528/67600 (epoch 12), train_loss = 1.242, time/batch=0.100\n",
      "17529/67600 (epoch 12), train_loss = 1.164, time/batch=0.104\n",
      "17530/67600 (epoch 12), train_loss = 1.252, time/batch=0.145\n",
      "17531/67600 (epoch 12), train_loss = 1.239, time/batch=0.106\n",
      "17532/67600 (epoch 12), train_loss = 1.236, time/batch=0.133\n",
      "17533/67600 (epoch 12), train_loss = 1.232, time/batch=0.282\n",
      "17534/67600 (epoch 12), train_loss = 1.199, time/batch=0.132\n",
      "17535/67600 (epoch 12), train_loss = 1.212, time/batch=0.134\n",
      "17536/67600 (epoch 12), train_loss = 1.219, time/batch=0.110\n",
      "17537/67600 (epoch 12), train_loss = 1.292, time/batch=0.112\n",
      "17538/67600 (epoch 12), train_loss = 1.288, time/batch=0.133\n",
      "17539/67600 (epoch 12), train_loss = 1.238, time/batch=0.256\n",
      "17540/67600 (epoch 12), train_loss = 1.246, time/batch=0.123\n",
      "17541/67600 (epoch 12), train_loss = 1.259, time/batch=0.137\n",
      "17542/67600 (epoch 12), train_loss = 1.232, time/batch=0.109\n",
      "17543/67600 (epoch 12), train_loss = 1.204, time/batch=0.122\n",
      "17544/67600 (epoch 12), train_loss = 1.221, time/batch=0.114\n",
      "17545/67600 (epoch 12), train_loss = 1.219, time/batch=0.127\n",
      "17546/67600 (epoch 12), train_loss = 1.204, time/batch=0.257\n",
      "17547/67600 (epoch 12), train_loss = 1.227, time/batch=0.125\n",
      "17548/67600 (epoch 12), train_loss = 1.279, time/batch=0.123\n",
      "17549/67600 (epoch 12), train_loss = 1.220, time/batch=0.122\n",
      "17550/67600 (epoch 12), train_loss = 1.232, time/batch=0.111\n",
      "17551/67600 (epoch 12), train_loss = 1.214, time/batch=0.160\n",
      "17552/67600 (epoch 12), train_loss = 1.222, time/batch=0.137\n",
      "17553/67600 (epoch 12), train_loss = 1.239, time/batch=0.109\n",
      "17554/67600 (epoch 12), train_loss = 1.281, time/batch=0.128\n",
      "17555/67600 (epoch 12), train_loss = 1.272, time/batch=0.115\n",
      "17556/67600 (epoch 12), train_loss = 1.225, time/batch=0.102\n",
      "17557/67600 (epoch 12), train_loss = 1.204, time/batch=0.282\n",
      "17558/67600 (epoch 12), train_loss = 1.183, time/batch=0.140\n",
      "17559/67600 (epoch 12), train_loss = 1.251, time/batch=0.119\n",
      "17560/67600 (epoch 12), train_loss = 1.253, time/batch=0.131\n",
      "17561/67600 (epoch 12), train_loss = 1.233, time/batch=0.109\n",
      "17562/67600 (epoch 12), train_loss = 1.248, time/batch=0.122\n",
      "17563/67600 (epoch 12), train_loss = 1.221, time/batch=0.121\n",
      "17564/67600 (epoch 12), train_loss = 1.201, time/batch=0.138\n",
      "17565/67600 (epoch 12), train_loss = 1.227, time/batch=0.246\n",
      "17566/67600 (epoch 12), train_loss = 1.237, time/batch=0.099\n",
      "17567/67600 (epoch 12), train_loss = 1.222, time/batch=0.129\n",
      "17568/67600 (epoch 12), train_loss = 1.171, time/batch=0.118\n",
      "17569/67600 (epoch 12), train_loss = 1.222, time/batch=0.112\n",
      "17570/67600 (epoch 12), train_loss = 1.203, time/batch=0.122\n",
      "17571/67600 (epoch 12), train_loss = 1.228, time/batch=0.119\n",
      "17572/67600 (epoch 12), train_loss = 1.292, time/batch=0.251\n",
      "17573/67600 (epoch 12), train_loss = 1.315, time/batch=0.129\n",
      "17574/67600 (epoch 12), train_loss = 1.233, time/batch=0.117\n",
      "17575/67600 (epoch 12), train_loss = 1.249, time/batch=0.127\n",
      "17576/67600 (epoch 13), train_loss = 1.412, time/batch=0.120\n",
      "17577/67600 (epoch 13), train_loss = 1.176, time/batch=0.177\n",
      "17578/67600 (epoch 13), train_loss = 1.252, time/batch=0.173\n",
      "17579/67600 (epoch 13), train_loss = 1.214, time/batch=0.119\n",
      "17580/67600 (epoch 13), train_loss = 1.229, time/batch=0.154\n",
      "17581/67600 (epoch 13), train_loss = 1.254, time/batch=0.132\n",
      "17582/67600 (epoch 13), train_loss = 1.222, time/batch=0.141\n",
      "17583/67600 (epoch 13), train_loss = 1.229, time/batch=0.240\n",
      "17584/67600 (epoch 13), train_loss = 1.240, time/batch=0.151\n",
      "17585/67600 (epoch 13), train_loss = 1.219, time/batch=0.137\n",
      "17586/67600 (epoch 13), train_loss = 1.190, time/batch=0.124\n",
      "17587/67600 (epoch 13), train_loss = 1.201, time/batch=0.131\n",
      "17588/67600 (epoch 13), train_loss = 1.211, time/batch=0.136\n",
      "17589/67600 (epoch 13), train_loss = 1.276, time/batch=0.087\n",
      "17590/67600 (epoch 13), train_loss = 1.240, time/batch=0.256\n",
      "17591/67600 (epoch 13), train_loss = 1.222, time/batch=0.150\n",
      "17592/67600 (epoch 13), train_loss = 1.227, time/batch=0.120\n",
      "17593/67600 (epoch 13), train_loss = 1.239, time/batch=0.118\n",
      "17594/67600 (epoch 13), train_loss = 1.225, time/batch=0.112\n",
      "17595/67600 (epoch 13), train_loss = 1.217, time/batch=0.136\n",
      "17596/67600 (epoch 13), train_loss = 1.229, time/batch=0.110\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17597/67600 (epoch 13), train_loss = 1.161, time/batch=0.242\n",
      "17598/67600 (epoch 13), train_loss = 1.288, time/batch=0.122\n",
      "17599/67600 (epoch 13), train_loss = 1.255, time/batch=0.120\n",
      "17600/67600 (epoch 13), train_loss = 1.296, time/batch=0.130\n",
      "17601/67600 (epoch 13), train_loss = 1.156, time/batch=0.125\n",
      "17602/67600 (epoch 13), train_loss = 1.244, time/batch=0.123\n",
      "17603/67600 (epoch 13), train_loss = 1.259, time/batch=0.121\n",
      "17604/67600 (epoch 13), train_loss = 1.296, time/batch=0.316\n",
      "17605/67600 (epoch 13), train_loss = 1.217, time/batch=0.115\n",
      "17606/67600 (epoch 13), train_loss = 1.205, time/batch=0.132\n",
      "17607/67600 (epoch 13), train_loss = 1.285, time/batch=0.125\n",
      "17608/67600 (epoch 13), train_loss = 1.208, time/batch=0.100\n",
      "17609/67600 (epoch 13), train_loss = 1.277, time/batch=0.228\n",
      "17610/67600 (epoch 13), train_loss = 1.247, time/batch=0.230\n",
      "17611/67600 (epoch 13), train_loss = 1.234, time/batch=0.162\n",
      "17612/67600 (epoch 13), train_loss = 1.200, time/batch=0.130\n",
      "17613/67600 (epoch 13), train_loss = 1.244, time/batch=0.173\n",
      "17614/67600 (epoch 13), train_loss = 1.253, time/batch=0.274\n",
      "17615/67600 (epoch 13), train_loss = 1.232, time/batch=0.152\n",
      "17616/67600 (epoch 13), train_loss = 1.158, time/batch=0.147\n",
      "17617/67600 (epoch 13), train_loss = 1.259, time/batch=0.123\n",
      "17618/67600 (epoch 13), train_loss = 1.273, time/batch=0.128\n",
      "17619/67600 (epoch 13), train_loss = 1.249, time/batch=0.201\n",
      "17620/67600 (epoch 13), train_loss = 1.264, time/batch=0.241\n",
      "17621/67600 (epoch 13), train_loss = 1.226, time/batch=0.173\n",
      "17622/67600 (epoch 13), train_loss = 1.195, time/batch=0.135\n",
      "17623/67600 (epoch 13), train_loss = 1.236, time/batch=0.125\n",
      "17624/67600 (epoch 13), train_loss = 1.203, time/batch=0.121\n",
      "17625/67600 (epoch 13), train_loss = 1.196, time/batch=0.134\n",
      "17626/67600 (epoch 13), train_loss = 1.278, time/batch=0.138\n",
      "17627/67600 (epoch 13), train_loss = 1.203, time/batch=0.273\n",
      "17628/67600 (epoch 13), train_loss = 1.210, time/batch=0.158\n",
      "17629/67600 (epoch 13), train_loss = 1.303, time/batch=0.112\n",
      "17630/67600 (epoch 13), train_loss = 1.269, time/batch=0.134\n",
      "17631/67600 (epoch 13), train_loss = 1.229, time/batch=0.114\n",
      "17632/67600 (epoch 13), train_loss = 1.241, time/batch=0.124\n",
      "17633/67600 (epoch 13), train_loss = 1.235, time/batch=0.122\n",
      "17634/67600 (epoch 13), train_loss = 1.244, time/batch=0.278\n",
      "17635/67600 (epoch 13), train_loss = 1.234, time/batch=0.129\n",
      "17636/67600 (epoch 13), train_loss = 1.239, time/batch=0.138\n",
      "17637/67600 (epoch 13), train_loss = 1.217, time/batch=0.113\n",
      "17638/67600 (epoch 13), train_loss = 1.273, time/batch=0.255\n",
      "17639/67600 (epoch 13), train_loss = 1.272, time/batch=0.154\n",
      "17640/67600 (epoch 13), train_loss = 1.214, time/batch=0.132\n",
      "17641/67600 (epoch 13), train_loss = 1.214, time/batch=0.158\n",
      "17642/67600 (epoch 13), train_loss = 1.229, time/batch=0.108\n",
      "17643/67600 (epoch 13), train_loss = 1.246, time/batch=0.116\n",
      "17644/67600 (epoch 13), train_loss = 1.260, time/batch=0.124\n",
      "17645/67600 (epoch 13), train_loss = 1.254, time/batch=0.169\n",
      "17646/67600 (epoch 13), train_loss = 1.246, time/batch=0.128\n",
      "17647/67600 (epoch 13), train_loss = 1.251, time/batch=0.114\n",
      "17648/67600 (epoch 13), train_loss = 1.211, time/batch=0.125\n",
      "17649/67600 (epoch 13), train_loss = 1.286, time/batch=0.115\n",
      "17650/67600 (epoch 13), train_loss = 1.220, time/batch=0.122\n",
      "17651/67600 (epoch 13), train_loss = 1.273, time/batch=0.313\n",
      "17652/67600 (epoch 13), train_loss = 1.280, time/batch=0.148\n",
      "17653/67600 (epoch 13), train_loss = 1.356, time/batch=0.117\n",
      "17654/67600 (epoch 13), train_loss = 1.283, time/batch=0.118\n",
      "17655/67600 (epoch 13), train_loss = 1.207, time/batch=0.125\n",
      "17656/67600 (epoch 13), train_loss = 1.195, time/batch=0.111\n",
      "17657/67600 (epoch 13), train_loss = 1.244, time/batch=0.106\n",
      "17658/67600 (epoch 13), train_loss = 1.247, time/batch=0.351\n",
      "17659/67600 (epoch 13), train_loss = 1.222, time/batch=0.102\n",
      "17660/67600 (epoch 13), train_loss = 1.226, time/batch=0.139\n",
      "17661/67600 (epoch 13), train_loss = 1.233, time/batch=0.166\n",
      "17662/67600 (epoch 13), train_loss = 1.178, time/batch=0.122\n",
      "17663/67600 (epoch 13), train_loss = 1.286, time/batch=0.145\n",
      "17664/67600 (epoch 13), train_loss = 1.268, time/batch=0.270\n",
      "17665/67600 (epoch 13), train_loss = 1.265, time/batch=0.118\n",
      "17666/67600 (epoch 13), train_loss = 1.240, time/batch=0.116\n",
      "17667/67600 (epoch 13), train_loss = 1.259, time/batch=0.140\n",
      "17668/67600 (epoch 13), train_loss = 1.185, time/batch=0.218\n",
      "17669/67600 (epoch 13), train_loss = 1.207, time/batch=0.153\n",
      "17670/67600 (epoch 13), train_loss = 1.203, time/batch=0.147\n",
      "17671/67600 (epoch 13), train_loss = 1.147, time/batch=0.142\n",
      "17672/67600 (epoch 13), train_loss = 1.159, time/batch=0.147\n",
      "17673/67600 (epoch 13), train_loss = 1.236, time/batch=0.119\n",
      "17674/67600 (epoch 13), train_loss = 1.218, time/batch=0.132\n",
      "17675/67600 (epoch 13), train_loss = 1.259, time/batch=0.286\n",
      "17676/67600 (epoch 13), train_loss = 1.141, time/batch=0.170\n",
      "17677/67600 (epoch 13), train_loss = 1.219, time/batch=0.126\n",
      "17678/67600 (epoch 13), train_loss = 1.262, time/batch=0.130\n",
      "17679/67600 (epoch 13), train_loss = 1.163, time/batch=0.128\n",
      "17680/67600 (epoch 13), train_loss = 1.196, time/batch=0.125\n",
      "17681/67600 (epoch 13), train_loss = 1.242, time/batch=0.315\n",
      "17682/67600 (epoch 13), train_loss = 1.208, time/batch=0.130\n",
      "17683/67600 (epoch 13), train_loss = 1.244, time/batch=0.114\n",
      "17684/67600 (epoch 13), train_loss = 1.274, time/batch=0.110\n",
      "17685/67600 (epoch 13), train_loss = 1.240, time/batch=0.138\n",
      "17686/67600 (epoch 13), train_loss = 1.196, time/batch=0.137\n",
      "17687/67600 (epoch 13), train_loss = 1.238, time/batch=0.146\n",
      "17688/67600 (epoch 13), train_loss = 1.225, time/batch=0.262\n",
      "17689/67600 (epoch 13), train_loss = 1.257, time/batch=0.140\n",
      "17690/67600 (epoch 13), train_loss = 1.247, time/batch=0.127\n",
      "17691/67600 (epoch 13), train_loss = 1.195, time/batch=0.160\n",
      "17692/67600 (epoch 13), train_loss = 1.192, time/batch=0.100\n",
      "17693/67600 (epoch 13), train_loss = 1.226, time/batch=0.153\n",
      "17694/67600 (epoch 13), train_loss = 1.248, time/batch=0.221\n",
      "17695/67600 (epoch 13), train_loss = 1.245, time/batch=0.142\n",
      "17696/67600 (epoch 13), train_loss = 1.251, time/batch=0.122\n",
      "17697/67600 (epoch 13), train_loss = 1.253, time/batch=0.120\n",
      "17698/67600 (epoch 13), train_loss = 1.214, time/batch=0.124\n",
      "17699/67600 (epoch 13), train_loss = 1.193, time/batch=0.258\n",
      "17700/67600 (epoch 13), train_loss = 1.219, time/batch=0.163\n",
      "17701/67600 (epoch 13), train_loss = 1.150, time/batch=0.126\n",
      "17702/67600 (epoch 13), train_loss = 1.220, time/batch=0.131\n",
      "17703/67600 (epoch 13), train_loss = 1.259, time/batch=0.120\n",
      "17704/67600 (epoch 13), train_loss = 1.200, time/batch=0.121\n",
      "17705/67600 (epoch 13), train_loss = 1.218, time/batch=0.117\n",
      "17706/67600 (epoch 13), train_loss = 1.246, time/batch=0.286\n",
      "17707/67600 (epoch 13), train_loss = 1.219, time/batch=0.164\n",
      "17708/67600 (epoch 13), train_loss = 1.276, time/batch=0.102\n",
      "17709/67600 (epoch 13), train_loss = 1.206, time/batch=0.124\n",
      "17710/67600 (epoch 13), train_loss = 1.229, time/batch=0.148\n",
      "17711/67600 (epoch 13), train_loss = 1.232, time/batch=0.101\n",
      "17712/67600 (epoch 13), train_loss = 1.252, time/batch=0.118\n",
      "17713/67600 (epoch 13), train_loss = 1.239, time/batch=0.236\n",
      "17714/67600 (epoch 13), train_loss = 1.234, time/batch=0.146\n",
      "17715/67600 (epoch 13), train_loss = 1.205, time/batch=0.134\n",
      "17716/67600 (epoch 13), train_loss = 1.210, time/batch=0.123\n",
      "17717/67600 (epoch 13), train_loss = 1.189, time/batch=0.120\n",
      "17718/67600 (epoch 13), train_loss = 1.240, time/batch=0.128\n",
      "17719/67600 (epoch 13), train_loss = 1.192, time/batch=0.121\n",
      "17720/67600 (epoch 13), train_loss = 1.277, time/batch=0.254\n",
      "17721/67600 (epoch 13), train_loss = 1.315, time/batch=0.133\n",
      "17722/67600 (epoch 13), train_loss = 1.230, time/batch=0.119\n",
      "17723/67600 (epoch 13), train_loss = 1.214, time/batch=0.108\n",
      "17724/67600 (epoch 13), train_loss = 1.271, time/batch=0.136\n",
      "17725/67600 (epoch 13), train_loss = 1.171, time/batch=0.118\n",
      "17726/67600 (epoch 13), train_loss = 1.245, time/batch=0.120\n",
      "17727/67600 (epoch 13), train_loss = 1.188, time/batch=0.272\n",
      "17728/67600 (epoch 13), train_loss = 1.178, time/batch=0.130\n",
      "17729/67600 (epoch 13), train_loss = 1.239, time/batch=0.131\n",
      "17730/67600 (epoch 13), train_loss = 1.190, time/batch=0.117\n",
      "17731/67600 (epoch 13), train_loss = 1.246, time/batch=0.110\n",
      "17732/67600 (epoch 13), train_loss = 1.244, time/batch=0.134\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17733/67600 (epoch 13), train_loss = 1.259, time/batch=0.107\n",
      "17734/67600 (epoch 13), train_loss = 1.247, time/batch=0.284\n",
      "17735/67600 (epoch 13), train_loss = 1.212, time/batch=0.103\n",
      "17736/67600 (epoch 13), train_loss = 1.196, time/batch=0.157\n",
      "17737/67600 (epoch 13), train_loss = 1.179, time/batch=0.125\n",
      "17738/67600 (epoch 13), train_loss = 1.229, time/batch=0.115\n",
      "17739/67600 (epoch 13), train_loss = 1.219, time/batch=0.161\n",
      "17740/67600 (epoch 13), train_loss = 1.139, time/batch=0.113\n",
      "17741/67600 (epoch 13), train_loss = 1.223, time/batch=0.121\n",
      "17742/67600 (epoch 13), train_loss = 1.208, time/batch=0.119\n",
      "17743/67600 (epoch 13), train_loss = 1.190, time/batch=0.113\n",
      "17744/67600 (epoch 13), train_loss = 1.236, time/batch=0.123\n",
      "17745/67600 (epoch 13), train_loss = 1.242, time/batch=0.284\n",
      "17746/67600 (epoch 13), train_loss = 1.242, time/batch=0.143\n",
      "17747/67600 (epoch 13), train_loss = 1.194, time/batch=0.117\n",
      "17748/67600 (epoch 13), train_loss = 1.252, time/batch=0.135\n",
      "17749/67600 (epoch 13), train_loss = 1.203, time/batch=0.114\n",
      "17750/67600 (epoch 13), train_loss = 1.214, time/batch=0.112\n",
      "17751/67600 (epoch 13), train_loss = 1.169, time/batch=0.118\n",
      "17752/67600 (epoch 13), train_loss = 1.228, time/batch=0.272\n",
      "17753/67600 (epoch 13), train_loss = 1.266, time/batch=0.145\n",
      "17754/67600 (epoch 13), train_loss = 1.182, time/batch=0.126\n",
      "17755/67600 (epoch 13), train_loss = 1.197, time/batch=0.110\n",
      "17756/67600 (epoch 13), train_loss = 1.175, time/batch=0.142\n",
      "17757/67600 (epoch 13), train_loss = 1.164, time/batch=0.128\n",
      "17758/67600 (epoch 13), train_loss = 1.205, time/batch=0.141\n",
      "17759/67600 (epoch 13), train_loss = 1.311, time/batch=0.277\n",
      "17760/67600 (epoch 13), train_loss = 1.324, time/batch=0.121\n",
      "17761/67600 (epoch 13), train_loss = 1.282, time/batch=0.127\n",
      "17762/67600 (epoch 13), train_loss = 1.320, time/batch=0.117\n",
      "17763/67600 (epoch 13), train_loss = 1.225, time/batch=0.276\n",
      "17764/67600 (epoch 13), train_loss = 1.233, time/batch=0.215\n",
      "17765/67600 (epoch 13), train_loss = 1.221, time/batch=0.184\n",
      "17766/67600 (epoch 13), train_loss = 1.295, time/batch=0.110\n",
      "17767/67600 (epoch 13), train_loss = 1.264, time/batch=0.152\n",
      "17768/67600 (epoch 13), train_loss = 1.225, time/batch=0.111\n",
      "17769/67600 (epoch 13), train_loss = 1.265, time/batch=0.251\n",
      "17770/67600 (epoch 13), train_loss = 1.252, time/batch=0.157\n",
      "17771/67600 (epoch 13), train_loss = 1.233, time/batch=0.128\n",
      "17772/67600 (epoch 13), train_loss = 1.217, time/batch=0.119\n",
      "17773/67600 (epoch 13), train_loss = 1.220, time/batch=0.118\n",
      "17774/67600 (epoch 13), train_loss = 1.249, time/batch=0.133\n",
      "17775/67600 (epoch 13), train_loss = 1.194, time/batch=0.119\n",
      "17776/67600 (epoch 13), train_loss = 1.188, time/batch=0.246\n",
      "17777/67600 (epoch 13), train_loss = 1.162, time/batch=0.160\n",
      "17778/67600 (epoch 13), train_loss = 1.278, time/batch=0.120\n",
      "17779/67600 (epoch 13), train_loss = 1.228, time/batch=0.110\n",
      "17780/67600 (epoch 13), train_loss = 1.255, time/batch=0.142\n",
      "17781/67600 (epoch 13), train_loss = 1.168, time/batch=0.121\n",
      "17782/67600 (epoch 13), train_loss = 1.176, time/batch=0.125\n",
      "17783/67600 (epoch 13), train_loss = 1.189, time/batch=0.281\n",
      "17784/67600 (epoch 13), train_loss = 1.246, time/batch=0.122\n",
      "17785/67600 (epoch 13), train_loss = 1.274, time/batch=0.115\n",
      "17786/67600 (epoch 13), train_loss = 1.248, time/batch=0.122\n",
      "17787/67600 (epoch 13), train_loss = 1.291, time/batch=0.115\n",
      "17788/67600 (epoch 13), train_loss = 1.206, time/batch=0.132\n",
      "17789/67600 (epoch 13), train_loss = 1.214, time/batch=0.129\n",
      "17790/67600 (epoch 13), train_loss = 1.217, time/batch=0.242\n",
      "17791/67600 (epoch 13), train_loss = 1.257, time/batch=0.123\n",
      "17792/67600 (epoch 13), train_loss = 1.201, time/batch=0.124\n",
      "17793/67600 (epoch 13), train_loss = 1.205, time/batch=0.096\n",
      "17794/67600 (epoch 13), train_loss = 1.189, time/batch=0.186\n",
      "17795/67600 (epoch 13), train_loss = 1.171, time/batch=0.192\n",
      "17796/67600 (epoch 13), train_loss = 1.276, time/batch=0.162\n",
      "17797/67600 (epoch 13), train_loss = 1.195, time/batch=0.133\n",
      "17798/67600 (epoch 13), train_loss = 1.241, time/batch=0.122\n",
      "17799/67600 (epoch 13), train_loss = 1.227, time/batch=0.128\n",
      "17800/67600 (epoch 13), train_loss = 1.229, time/batch=0.130\n",
      "17801/67600 (epoch 13), train_loss = 1.200, time/batch=0.336\n",
      "17802/67600 (epoch 13), train_loss = 1.269, time/batch=0.174\n",
      "17803/67600 (epoch 13), train_loss = 1.181, time/batch=0.157\n",
      "17804/67600 (epoch 13), train_loss = 1.192, time/batch=0.120\n",
      "17805/67600 (epoch 13), train_loss = 1.204, time/batch=0.178\n",
      "17806/67600 (epoch 13), train_loss = 1.229, time/batch=0.127\n",
      "17807/67600 (epoch 13), train_loss = 1.228, time/batch=0.244\n",
      "17808/67600 (epoch 13), train_loss = 1.158, time/batch=0.140\n",
      "17809/67600 (epoch 13), train_loss = 1.165, time/batch=0.136\n",
      "17810/67600 (epoch 13), train_loss = 1.227, time/batch=0.125\n",
      "17811/67600 (epoch 13), train_loss = 1.220, time/batch=0.133\n",
      "17812/67600 (epoch 13), train_loss = 1.213, time/batch=0.123\n",
      "17813/67600 (epoch 13), train_loss = 1.216, time/batch=0.119\n",
      "17814/67600 (epoch 13), train_loss = 1.268, time/batch=0.328\n",
      "17815/67600 (epoch 13), train_loss = 1.239, time/batch=0.116\n",
      "17816/67600 (epoch 13), train_loss = 1.249, time/batch=0.137\n",
      "17817/67600 (epoch 13), train_loss = 1.176, time/batch=0.138\n",
      "17818/67600 (epoch 13), train_loss = 1.230, time/batch=0.096\n",
      "17819/67600 (epoch 13), train_loss = 1.230, time/batch=0.131\n",
      "17820/67600 (epoch 13), train_loss = 1.163, time/batch=0.268\n",
      "17821/67600 (epoch 13), train_loss = 1.235, time/batch=0.099\n",
      "17822/67600 (epoch 13), train_loss = 1.220, time/batch=0.124\n",
      "17823/67600 (epoch 13), train_loss = 1.227, time/batch=0.127\n",
      "17824/67600 (epoch 13), train_loss = 1.257, time/batch=0.113\n",
      "17825/67600 (epoch 13), train_loss = 1.198, time/batch=0.241\n",
      "17826/67600 (epoch 13), train_loss = 1.191, time/batch=0.145\n",
      "17827/67600 (epoch 13), train_loss = 1.279, time/batch=0.127\n",
      "17828/67600 (epoch 13), train_loss = 1.191, time/batch=0.134\n",
      "17829/67600 (epoch 13), train_loss = 1.229, time/batch=0.131\n",
      "17830/67600 (epoch 13), train_loss = 1.247, time/batch=0.121\n",
      "17831/67600 (epoch 13), train_loss = 1.291, time/batch=0.119\n",
      "17832/67600 (epoch 13), train_loss = 1.261, time/batch=0.165\n",
      "17833/67600 (epoch 13), train_loss = 1.271, time/batch=0.127\n",
      "17834/67600 (epoch 13), train_loss = 1.183, time/batch=0.118\n",
      "17835/67600 (epoch 13), train_loss = 1.183, time/batch=0.159\n",
      "17836/67600 (epoch 13), train_loss = 1.213, time/batch=0.121\n",
      "17837/67600 (epoch 13), train_loss = 1.195, time/batch=0.135\n",
      "17838/67600 (epoch 13), train_loss = 1.217, time/batch=0.386\n",
      "17839/67600 (epoch 13), train_loss = 1.223, time/batch=0.127\n",
      "17840/67600 (epoch 13), train_loss = 1.211, time/batch=0.131\n",
      "17841/67600 (epoch 13), train_loss = 1.203, time/batch=0.162\n",
      "17842/67600 (epoch 13), train_loss = 1.184, time/batch=0.126\n",
      "17843/67600 (epoch 13), train_loss = 1.230, time/batch=0.120\n",
      "17844/67600 (epoch 13), train_loss = 1.211, time/batch=0.288\n",
      "17845/67600 (epoch 13), train_loss = 1.195, time/batch=0.121\n",
      "17846/67600 (epoch 13), train_loss = 1.252, time/batch=0.165\n",
      "17847/67600 (epoch 13), train_loss = 1.219, time/batch=0.148\n",
      "17848/67600 (epoch 13), train_loss = 1.230, time/batch=0.255\n",
      "17849/67600 (epoch 13), train_loss = 1.258, time/batch=0.189\n",
      "17850/67600 (epoch 13), train_loss = 1.237, time/batch=0.153\n",
      "17851/67600 (epoch 13), train_loss = 1.224, time/batch=0.113\n",
      "17852/67600 (epoch 13), train_loss = 1.242, time/batch=0.158\n",
      "17853/67600 (epoch 13), train_loss = 1.197, time/batch=0.122\n",
      "17854/67600 (epoch 13), train_loss = 1.198, time/batch=0.264\n",
      "17855/67600 (epoch 13), train_loss = 1.242, time/batch=0.220\n",
      "17856/67600 (epoch 13), train_loss = 1.244, time/batch=0.119\n",
      "17857/67600 (epoch 13), train_loss = 1.202, time/batch=0.122\n",
      "17858/67600 (epoch 13), train_loss = 1.166, time/batch=0.116\n",
      "17859/67600 (epoch 13), train_loss = 1.252, time/batch=0.146\n",
      "17860/67600 (epoch 13), train_loss = 1.185, time/batch=0.259\n",
      "17861/67600 (epoch 13), train_loss = 1.306, time/batch=0.147\n",
      "17862/67600 (epoch 13), train_loss = 1.240, time/batch=0.119\n",
      "17863/67600 (epoch 13), train_loss = 1.220, time/batch=0.125\n",
      "17864/67600 (epoch 13), train_loss = 1.255, time/batch=0.112\n",
      "17865/67600 (epoch 13), train_loss = 1.248, time/batch=0.114\n",
      "17866/67600 (epoch 13), train_loss = 1.246, time/batch=0.126\n",
      "17867/67600 (epoch 13), train_loss = 1.233, time/batch=0.236\n",
      "17868/67600 (epoch 13), train_loss = 1.241, time/batch=0.153\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17869/67600 (epoch 13), train_loss = 1.223, time/batch=0.120\n",
      "17870/67600 (epoch 13), train_loss = 1.230, time/batch=0.113\n",
      "17871/67600 (epoch 13), train_loss = 1.239, time/batch=0.105\n",
      "17872/67600 (epoch 13), train_loss = 1.241, time/batch=0.126\n",
      "17873/67600 (epoch 13), train_loss = 1.211, time/batch=0.116\n",
      "17874/67600 (epoch 13), train_loss = 1.201, time/batch=0.265\n",
      "17875/67600 (epoch 13), train_loss = 1.265, time/batch=0.119\n",
      "17876/67600 (epoch 13), train_loss = 1.223, time/batch=0.133\n",
      "17877/67600 (epoch 13), train_loss = 1.249, time/batch=0.116\n",
      "17878/67600 (epoch 13), train_loss = 1.212, time/batch=0.115\n",
      "17879/67600 (epoch 13), train_loss = 1.247, time/batch=0.130\n",
      "17880/67600 (epoch 13), train_loss = 1.249, time/batch=0.121\n",
      "17881/67600 (epoch 13), train_loss = 1.264, time/batch=0.279\n",
      "17882/67600 (epoch 13), train_loss = 1.278, time/batch=0.131\n",
      "17883/67600 (epoch 13), train_loss = 1.255, time/batch=0.119\n",
      "17884/67600 (epoch 13), train_loss = 1.261, time/batch=0.135\n",
      "17885/67600 (epoch 13), train_loss = 1.256, time/batch=0.126\n",
      "17886/67600 (epoch 13), train_loss = 1.222, time/batch=0.238\n",
      "17887/67600 (epoch 13), train_loss = 1.193, time/batch=0.158\n",
      "17888/67600 (epoch 13), train_loss = 1.199, time/batch=0.125\n",
      "17889/67600 (epoch 13), train_loss = 1.259, time/batch=0.120\n",
      "17890/67600 (epoch 13), train_loss = 1.231, time/batch=0.119\n",
      "17891/67600 (epoch 13), train_loss = 1.305, time/batch=0.121\n",
      "17892/67600 (epoch 13), train_loss = 1.212, time/batch=0.126\n",
      "17893/67600 (epoch 13), train_loss = 1.245, time/batch=0.222\n",
      "17894/67600 (epoch 13), train_loss = 1.253, time/batch=0.149\n",
      "17895/67600 (epoch 13), train_loss = 1.263, time/batch=0.108\n",
      "17896/67600 (epoch 13), train_loss = 1.277, time/batch=0.133\n",
      "17897/67600 (epoch 13), train_loss = 1.231, time/batch=0.111\n",
      "17898/67600 (epoch 13), train_loss = 1.230, time/batch=0.114\n",
      "17899/67600 (epoch 13), train_loss = 1.207, time/batch=0.126\n",
      "17900/67600 (epoch 13), train_loss = 1.216, time/batch=0.241\n",
      "17901/67600 (epoch 13), train_loss = 1.193, time/batch=0.161\n",
      "17902/67600 (epoch 13), train_loss = 1.182, time/batch=0.102\n",
      "17903/67600 (epoch 13), train_loss = 1.257, time/batch=0.126\n",
      "17904/67600 (epoch 13), train_loss = 1.212, time/batch=0.127\n",
      "17905/67600 (epoch 13), train_loss = 1.228, time/batch=0.119\n",
      "17906/67600 (epoch 13), train_loss = 1.270, time/batch=0.128\n",
      "17907/67600 (epoch 13), train_loss = 1.181, time/batch=0.199\n",
      "17908/67600 (epoch 13), train_loss = 1.234, time/batch=0.180\n",
      "17909/67600 (epoch 13), train_loss = 1.224, time/batch=0.126\n",
      "17910/67600 (epoch 13), train_loss = 1.249, time/batch=0.109\n",
      "17911/67600 (epoch 13), train_loss = 1.259, time/batch=0.132\n",
      "17912/67600 (epoch 13), train_loss = 1.216, time/batch=0.115\n",
      "17913/67600 (epoch 13), train_loss = 1.200, time/batch=0.122\n",
      "17914/67600 (epoch 13), train_loss = 1.226, time/batch=0.154\n",
      "17915/67600 (epoch 13), train_loss = 1.273, time/batch=0.231\n",
      "17916/67600 (epoch 13), train_loss = 1.225, time/batch=0.136\n",
      "17917/67600 (epoch 13), train_loss = 1.212, time/batch=0.121\n",
      "17918/67600 (epoch 13), train_loss = 1.195, time/batch=0.117\n",
      "17919/67600 (epoch 13), train_loss = 1.189, time/batch=0.119\n",
      "17920/67600 (epoch 13), train_loss = 1.274, time/batch=0.108\n",
      "17921/67600 (epoch 13), train_loss = 1.293, time/batch=0.128\n",
      "17922/67600 (epoch 13), train_loss = 1.239, time/batch=0.268\n",
      "17923/67600 (epoch 13), train_loss = 1.233, time/batch=0.118\n",
      "17924/67600 (epoch 13), train_loss = 1.267, time/batch=0.115\n",
      "17925/67600 (epoch 13), train_loss = 1.274, time/batch=0.185\n",
      "17926/67600 (epoch 13), train_loss = 1.194, time/batch=0.174\n",
      "17927/67600 (epoch 13), train_loss = 1.174, time/batch=0.132\n",
      "17928/67600 (epoch 13), train_loss = 1.171, time/batch=0.100\n",
      "17929/67600 (epoch 13), train_loss = 1.184, time/batch=0.145\n",
      "17930/67600 (epoch 13), train_loss = 1.199, time/batch=0.120\n",
      "17931/67600 (epoch 13), train_loss = 1.262, time/batch=0.118\n",
      "17932/67600 (epoch 13), train_loss = 1.207, time/batch=0.316\n",
      "17933/67600 (epoch 13), train_loss = 1.222, time/batch=0.135\n",
      "17934/67600 (epoch 13), train_loss = 1.180, time/batch=0.124\n",
      "17935/67600 (epoch 13), train_loss = 1.302, time/batch=0.119\n",
      "17936/67600 (epoch 13), train_loss = 1.224, time/batch=0.132\n",
      "17937/67600 (epoch 13), train_loss = 1.185, time/batch=0.226\n",
      "17938/67600 (epoch 13), train_loss = 1.188, time/batch=0.142\n",
      "17939/67600 (epoch 13), train_loss = 1.268, time/batch=0.140\n",
      "17940/67600 (epoch 13), train_loss = 1.228, time/batch=0.158\n",
      "17941/67600 (epoch 13), train_loss = 1.215, time/batch=0.129\n",
      "17942/67600 (epoch 13), train_loss = 1.215, time/batch=0.110\n",
      "17943/67600 (epoch 13), train_loss = 1.164, time/batch=0.155\n",
      "17944/67600 (epoch 13), train_loss = 1.213, time/batch=0.199\n",
      "17945/67600 (epoch 13), train_loss = 1.296, time/batch=0.155\n",
      "17946/67600 (epoch 13), train_loss = 1.220, time/batch=0.143\n",
      "17947/67600 (epoch 13), train_loss = 1.220, time/batch=0.128\n",
      "17948/67600 (epoch 13), train_loss = 1.252, time/batch=0.105\n",
      "17949/67600 (epoch 13), train_loss = 1.227, time/batch=0.147\n",
      "17950/67600 (epoch 13), train_loss = 1.273, time/batch=0.142\n",
      "17951/67600 (epoch 13), train_loss = 1.307, time/batch=0.181\n",
      "17952/67600 (epoch 13), train_loss = 1.247, time/batch=0.175\n",
      "17953/67600 (epoch 13), train_loss = 1.223, time/batch=0.104\n",
      "17954/67600 (epoch 13), train_loss = 1.304, time/batch=0.126\n",
      "17955/67600 (epoch 13), train_loss = 1.313, time/batch=0.103\n",
      "17956/67600 (epoch 13), train_loss = 1.265, time/batch=0.125\n",
      "17957/67600 (epoch 13), train_loss = 1.212, time/batch=0.106\n",
      "17958/67600 (epoch 13), train_loss = 1.210, time/batch=0.221\n",
      "17959/67600 (epoch 13), train_loss = 1.262, time/batch=0.163\n",
      "17960/67600 (epoch 13), train_loss = 1.302, time/batch=0.101\n",
      "17961/67600 (epoch 13), train_loss = 1.237, time/batch=0.136\n",
      "17962/67600 (epoch 13), train_loss = 1.214, time/batch=0.098\n",
      "17963/67600 (epoch 13), train_loss = 1.224, time/batch=0.121\n",
      "17964/67600 (epoch 13), train_loss = 1.254, time/batch=0.115\n",
      "17965/67600 (epoch 13), train_loss = 1.247, time/batch=0.203\n",
      "17966/67600 (epoch 13), train_loss = 1.228, time/batch=0.148\n",
      "17967/67600 (epoch 13), train_loss = 1.217, time/batch=0.112\n",
      "17968/67600 (epoch 13), train_loss = 1.206, time/batch=0.115\n",
      "17969/67600 (epoch 13), train_loss = 1.239, time/batch=0.123\n",
      "17970/67600 (epoch 13), train_loss = 1.215, time/batch=0.115\n",
      "17971/67600 (epoch 13), train_loss = 1.221, time/batch=0.109\n",
      "17972/67600 (epoch 13), train_loss = 1.276, time/batch=0.110\n",
      "17973/67600 (epoch 13), train_loss = 1.281, time/batch=0.228\n",
      "17974/67600 (epoch 13), train_loss = 1.230, time/batch=0.131\n",
      "17975/67600 (epoch 13), train_loss = 1.209, time/batch=0.104\n",
      "17976/67600 (epoch 13), train_loss = 1.253, time/batch=0.110\n",
      "17977/67600 (epoch 13), train_loss = 1.320, time/batch=0.111\n",
      "17978/67600 (epoch 13), train_loss = 1.279, time/batch=0.111\n",
      "17979/67600 (epoch 13), train_loss = 1.245, time/batch=0.117\n",
      "17980/67600 (epoch 13), train_loss = 1.309, time/batch=0.108\n",
      "17981/67600 (epoch 13), train_loss = 1.271, time/batch=0.218\n",
      "17982/67600 (epoch 13), train_loss = 1.272, time/batch=0.136\n",
      "17983/67600 (epoch 13), train_loss = 1.205, time/batch=0.108\n",
      "17984/67600 (epoch 13), train_loss = 1.258, time/batch=0.109\n",
      "17985/67600 (epoch 13), train_loss = 1.262, time/batch=0.109\n",
      "17986/67600 (epoch 13), train_loss = 1.264, time/batch=0.117\n",
      "17987/67600 (epoch 13), train_loss = 1.197, time/batch=0.192\n",
      "17988/67600 (epoch 13), train_loss = 1.232, time/batch=0.126\n",
      "17989/67600 (epoch 13), train_loss = 1.241, time/batch=0.120\n",
      "17990/67600 (epoch 13), train_loss = 1.211, time/batch=0.111\n",
      "17991/67600 (epoch 13), train_loss = 1.274, time/batch=0.114\n",
      "17992/67600 (epoch 13), train_loss = 1.230, time/batch=0.116\n",
      "17993/67600 (epoch 13), train_loss = 1.264, time/batch=0.100\n",
      "17994/67600 (epoch 13), train_loss = 1.286, time/batch=0.148\n",
      "17995/67600 (epoch 13), train_loss = 1.207, time/batch=0.178\n",
      "17996/67600 (epoch 13), train_loss = 1.153, time/batch=0.137\n",
      "17997/67600 (epoch 13), train_loss = 1.180, time/batch=0.112\n",
      "17998/67600 (epoch 13), train_loss = 1.227, time/batch=0.119\n",
      "17999/67600 (epoch 13), train_loss = 1.177, time/batch=0.105\n",
      "18000/67600 (epoch 13), train_loss = 1.232, time/batch=0.106\n",
      "model saved to ./save/model.ckpt\n",
      "18001/67600 (epoch 13), train_loss = 1.199, time/batch=0.073\n",
      "18002/67600 (epoch 13), train_loss = 1.226, time/batch=0.086\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18003/67600 (epoch 13), train_loss = 1.227, time/batch=0.085\n",
      "18004/67600 (epoch 13), train_loss = 1.149, time/batch=0.113\n",
      "18005/67600 (epoch 13), train_loss = 1.194, time/batch=0.223\n",
      "18006/67600 (epoch 13), train_loss = 1.264, time/batch=0.117\n",
      "18007/67600 (epoch 13), train_loss = 1.190, time/batch=0.134\n",
      "18008/67600 (epoch 13), train_loss = 1.255, time/batch=0.106\n",
      "18009/67600 (epoch 13), train_loss = 1.261, time/batch=0.107\n",
      "18010/67600 (epoch 13), train_loss = 1.190, time/batch=0.106\n",
      "18011/67600 (epoch 13), train_loss = 1.291, time/batch=0.089\n",
      "18012/67600 (epoch 13), train_loss = 1.225, time/batch=0.219\n",
      "18013/67600 (epoch 13), train_loss = 1.240, time/batch=0.149\n",
      "18014/67600 (epoch 13), train_loss = 1.245, time/batch=0.118\n",
      "18015/67600 (epoch 13), train_loss = 1.214, time/batch=0.116\n",
      "18016/67600 (epoch 13), train_loss = 1.219, time/batch=0.108\n",
      "18017/67600 (epoch 13), train_loss = 1.245, time/batch=0.108\n",
      "18018/67600 (epoch 13), train_loss = 1.209, time/batch=0.218\n",
      "18019/67600 (epoch 13), train_loss = 1.189, time/batch=0.148\n",
      "18020/67600 (epoch 13), train_loss = 1.243, time/batch=0.135\n",
      "18021/67600 (epoch 13), train_loss = 1.272, time/batch=0.118\n",
      "18022/67600 (epoch 13), train_loss = 1.183, time/batch=0.111\n",
      "18023/67600 (epoch 13), train_loss = 1.196, time/batch=0.095\n",
      "18024/67600 (epoch 13), train_loss = 1.167, time/batch=0.122\n",
      "18025/67600 (epoch 13), train_loss = 1.193, time/batch=0.233\n",
      "18026/67600 (epoch 13), train_loss = 1.146, time/batch=0.138\n",
      "18027/67600 (epoch 13), train_loss = 1.253, time/batch=0.143\n",
      "18028/67600 (epoch 13), train_loss = 1.275, time/batch=0.099\n",
      "18029/67600 (epoch 13), train_loss = 1.170, time/batch=0.109\n",
      "18030/67600 (epoch 13), train_loss = 1.154, time/batch=0.114\n",
      "18031/67600 (epoch 13), train_loss = 1.187, time/batch=0.109\n",
      "18032/67600 (epoch 13), train_loss = 1.215, time/batch=0.123\n",
      "18033/67600 (epoch 13), train_loss = 1.229, time/batch=0.215\n",
      "18034/67600 (epoch 13), train_loss = 1.253, time/batch=0.153\n",
      "18035/67600 (epoch 13), train_loss = 1.224, time/batch=0.101\n",
      "18036/67600 (epoch 13), train_loss = 1.238, time/batch=0.120\n",
      "18037/67600 (epoch 13), train_loss = 1.185, time/batch=0.108\n",
      "18038/67600 (epoch 13), train_loss = 1.254, time/batch=0.094\n",
      "18039/67600 (epoch 13), train_loss = 1.231, time/batch=0.149\n",
      "18040/67600 (epoch 13), train_loss = 1.202, time/batch=0.154\n",
      "18041/67600 (epoch 13), train_loss = 1.215, time/batch=0.203\n",
      "18042/67600 (epoch 13), train_loss = 1.203, time/batch=0.111\n",
      "18043/67600 (epoch 13), train_loss = 1.257, time/batch=0.112\n",
      "18044/67600 (epoch 13), train_loss = 1.221, time/batch=0.116\n",
      "18045/67600 (epoch 13), train_loss = 1.189, time/batch=0.110\n",
      "18046/67600 (epoch 13), train_loss = 1.211, time/batch=0.114\n",
      "18047/67600 (epoch 13), train_loss = 1.218, time/batch=0.115\n",
      "18048/67600 (epoch 13), train_loss = 1.184, time/batch=0.247\n",
      "18049/67600 (epoch 13), train_loss = 1.238, time/batch=0.111\n",
      "18050/67600 (epoch 13), train_loss = 1.191, time/batch=0.125\n",
      "18051/67600 (epoch 13), train_loss = 1.165, time/batch=0.116\n",
      "18052/67600 (epoch 13), train_loss = 1.254, time/batch=0.110\n",
      "18053/67600 (epoch 13), train_loss = 1.180, time/batch=0.198\n",
      "18054/67600 (epoch 13), train_loss = 1.217, time/batch=0.149\n",
      "18055/67600 (epoch 13), train_loss = 1.234, time/batch=0.148\n",
      "18056/67600 (epoch 13), train_loss = 1.186, time/batch=0.115\n",
      "18057/67600 (epoch 13), train_loss = 1.220, time/batch=0.116\n",
      "18058/67600 (epoch 13), train_loss = 1.196, time/batch=0.117\n",
      "18059/67600 (epoch 13), train_loss = 1.177, time/batch=0.103\n",
      "18060/67600 (epoch 13), train_loss = 1.233, time/batch=0.120\n",
      "18061/67600 (epoch 13), train_loss = 1.236, time/batch=0.212\n",
      "18062/67600 (epoch 13), train_loss = 1.258, time/batch=0.158\n",
      "18063/67600 (epoch 13), train_loss = 1.239, time/batch=0.132\n",
      "18064/67600 (epoch 13), train_loss = 1.273, time/batch=0.103\n",
      "18065/67600 (epoch 13), train_loss = 1.253, time/batch=0.124\n",
      "18066/67600 (epoch 13), train_loss = 1.185, time/batch=0.104\n",
      "18067/67600 (epoch 13), train_loss = 1.224, time/batch=0.125\n",
      "18068/67600 (epoch 13), train_loss = 1.245, time/batch=0.163\n",
      "18069/67600 (epoch 13), train_loss = 1.195, time/batch=0.159\n",
      "18070/67600 (epoch 13), train_loss = 1.275, time/batch=0.147\n",
      "18071/67600 (epoch 13), train_loss = 1.235, time/batch=0.117\n",
      "18072/67600 (epoch 13), train_loss = 1.210, time/batch=0.104\n",
      "18073/67600 (epoch 13), train_loss = 1.236, time/batch=0.109\n",
      "18074/67600 (epoch 13), train_loss = 1.283, time/batch=0.130\n",
      "18075/67600 (epoch 13), train_loss = 1.224, time/batch=0.095\n",
      "18076/67600 (epoch 13), train_loss = 1.173, time/batch=0.258\n",
      "18077/67600 (epoch 13), train_loss = 1.180, time/batch=0.157\n",
      "18078/67600 (epoch 13), train_loss = 1.198, time/batch=0.098\n",
      "18079/67600 (epoch 13), train_loss = 1.239, time/batch=0.136\n",
      "18080/67600 (epoch 13), train_loss = 1.247, time/batch=0.109\n",
      "18081/67600 (epoch 13), train_loss = 1.267, time/batch=0.100\n",
      "18082/67600 (epoch 13), train_loss = 1.238, time/batch=0.083\n",
      "18083/67600 (epoch 13), train_loss = 1.242, time/batch=0.147\n",
      "18084/67600 (epoch 13), train_loss = 1.186, time/batch=0.216\n",
      "18085/67600 (epoch 13), train_loss = 1.217, time/batch=0.117\n",
      "18086/67600 (epoch 13), train_loss = 1.240, time/batch=0.119\n",
      "18087/67600 (epoch 13), train_loss = 1.229, time/batch=0.118\n",
      "18088/67600 (epoch 13), train_loss = 1.238, time/batch=0.126\n",
      "18089/67600 (epoch 13), train_loss = 1.209, time/batch=0.108\n",
      "18090/67600 (epoch 13), train_loss = 1.236, time/batch=0.112\n",
      "18091/67600 (epoch 13), train_loss = 1.263, time/batch=0.224\n",
      "18092/67600 (epoch 13), train_loss = 1.266, time/batch=0.150\n",
      "18093/67600 (epoch 13), train_loss = 1.252, time/batch=0.110\n",
      "18094/67600 (epoch 13), train_loss = 1.237, time/batch=0.102\n",
      "18095/67600 (epoch 13), train_loss = 1.170, time/batch=0.133\n",
      "18096/67600 (epoch 13), train_loss = 1.280, time/batch=0.152\n",
      "18097/67600 (epoch 13), train_loss = 1.276, time/batch=0.106\n",
      "18098/67600 (epoch 13), train_loss = 1.289, time/batch=0.119\n",
      "18099/67600 (epoch 13), train_loss = 1.241, time/batch=0.112\n",
      "18100/67600 (epoch 13), train_loss = 1.226, time/batch=0.105\n",
      "18101/67600 (epoch 13), train_loss = 1.235, time/batch=0.118\n",
      "18102/67600 (epoch 13), train_loss = 1.247, time/batch=0.113\n",
      "18103/67600 (epoch 13), train_loss = 1.201, time/batch=0.263\n",
      "18104/67600 (epoch 13), train_loss = 1.259, time/batch=0.127\n",
      "18105/67600 (epoch 13), train_loss = 1.221, time/batch=0.124\n",
      "18106/67600 (epoch 13), train_loss = 1.276, time/batch=0.128\n",
      "18107/67600 (epoch 13), train_loss = 1.263, time/batch=0.113\n",
      "18108/67600 (epoch 13), train_loss = 1.250, time/batch=0.108\n",
      "18109/67600 (epoch 13), train_loss = 1.203, time/batch=0.136\n",
      "18110/67600 (epoch 13), train_loss = 1.211, time/batch=0.184\n",
      "18111/67600 (epoch 13), train_loss = 1.179, time/batch=0.167\n",
      "18112/67600 (epoch 13), train_loss = 1.200, time/batch=0.130\n",
      "18113/67600 (epoch 13), train_loss = 1.228, time/batch=0.106\n",
      "18114/67600 (epoch 13), train_loss = 1.224, time/batch=0.115\n",
      "18115/67600 (epoch 13), train_loss = 1.227, time/batch=0.108\n",
      "18116/67600 (epoch 13), train_loss = 1.231, time/batch=0.110\n",
      "18117/67600 (epoch 13), train_loss = 1.173, time/batch=0.140\n",
      "18118/67600 (epoch 13), train_loss = 1.203, time/batch=0.242\n",
      "18119/67600 (epoch 13), train_loss = 1.190, time/batch=0.119\n",
      "18120/67600 (epoch 13), train_loss = 1.266, time/batch=0.098\n",
      "18121/67600 (epoch 13), train_loss = 1.227, time/batch=0.126\n",
      "18122/67600 (epoch 13), train_loss = 1.216, time/batch=0.109\n",
      "18123/67600 (epoch 13), train_loss = 1.227, time/batch=0.213\n",
      "18124/67600 (epoch 13), train_loss = 1.342, time/batch=0.130\n",
      "18125/67600 (epoch 13), train_loss = 1.259, time/batch=0.145\n",
      "18126/67600 (epoch 13), train_loss = 1.209, time/batch=0.108\n",
      "18127/67600 (epoch 13), train_loss = 1.269, time/batch=0.145\n",
      "18128/67600 (epoch 13), train_loss = 1.213, time/batch=0.096\n",
      "18129/67600 (epoch 13), train_loss = 1.214, time/batch=0.154\n",
      "18130/67600 (epoch 13), train_loss = 1.259, time/batch=0.147\n",
      "18131/67600 (epoch 13), train_loss = 1.210, time/batch=0.224\n",
      "18132/67600 (epoch 13), train_loss = 1.279, time/batch=0.144\n",
      "18133/67600 (epoch 13), train_loss = 1.223, time/batch=0.145\n",
      "18134/67600 (epoch 13), train_loss = 1.206, time/batch=0.122\n",
      "18135/67600 (epoch 13), train_loss = 1.159, time/batch=0.103\n",
      "18136/67600 (epoch 13), train_loss = 1.197, time/batch=0.124\n",
      "18137/67600 (epoch 13), train_loss = 1.218, time/batch=0.233\n",
      "18138/67600 (epoch 13), train_loss = 1.172, time/batch=0.136\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18139/67600 (epoch 13), train_loss = 1.215, time/batch=0.132\n",
      "18140/67600 (epoch 13), train_loss = 1.188, time/batch=0.112\n",
      "18141/67600 (epoch 13), train_loss = 1.207, time/batch=0.113\n",
      "18142/67600 (epoch 13), train_loss = 1.227, time/batch=0.123\n",
      "18143/67600 (epoch 13), train_loss = 1.244, time/batch=0.120\n",
      "18144/67600 (epoch 13), train_loss = 1.239, time/batch=0.131\n",
      "18145/67600 (epoch 13), train_loss = 1.205, time/batch=0.244\n",
      "18146/67600 (epoch 13), train_loss = 1.186, time/batch=0.136\n",
      "18147/67600 (epoch 13), train_loss = 1.186, time/batch=0.119\n",
      "18148/67600 (epoch 13), train_loss = 1.208, time/batch=0.118\n",
      "18149/67600 (epoch 13), train_loss = 1.215, time/batch=0.119\n",
      "18150/67600 (epoch 13), train_loss = 1.234, time/batch=0.117\n",
      "18151/67600 (epoch 13), train_loss = 1.192, time/batch=0.155\n",
      "18152/67600 (epoch 13), train_loss = 1.237, time/batch=0.248\n",
      "18153/67600 (epoch 13), train_loss = 1.223, time/batch=0.121\n",
      "18154/67600 (epoch 13), train_loss = 1.249, time/batch=0.114\n",
      "18155/67600 (epoch 13), train_loss = 1.226, time/batch=0.123\n",
      "18156/67600 (epoch 13), train_loss = 1.257, time/batch=0.111\n",
      "18157/67600 (epoch 13), train_loss = 1.222, time/batch=0.224\n",
      "18158/67600 (epoch 13), train_loss = 1.177, time/batch=0.153\n",
      "18159/67600 (epoch 13), train_loss = 1.197, time/batch=0.130\n",
      "18160/67600 (epoch 13), train_loss = 1.219, time/batch=0.116\n",
      "18161/67600 (epoch 13), train_loss = 1.281, time/batch=0.135\n",
      "18162/67600 (epoch 13), train_loss = 1.201, time/batch=0.139\n",
      "18163/67600 (epoch 13), train_loss = 1.277, time/batch=0.115\n",
      "18164/67600 (epoch 13), train_loss = 1.195, time/batch=0.232\n",
      "18165/67600 (epoch 13), train_loss = 1.227, time/batch=0.132\n",
      "18166/67600 (epoch 13), train_loss = 1.280, time/batch=0.131\n",
      "18167/67600 (epoch 13), train_loss = 1.192, time/batch=0.124\n",
      "18168/67600 (epoch 13), train_loss = 1.197, time/batch=0.124\n",
      "18169/67600 (epoch 13), train_loss = 1.229, time/batch=0.120\n",
      "18170/67600 (epoch 13), train_loss = 1.173, time/batch=0.120\n",
      "18171/67600 (epoch 13), train_loss = 1.218, time/batch=0.232\n",
      "18172/67600 (epoch 13), train_loss = 1.238, time/batch=0.149\n",
      "18173/67600 (epoch 13), train_loss = 1.187, time/batch=0.128\n",
      "18174/67600 (epoch 13), train_loss = 1.220, time/batch=0.114\n",
      "18175/67600 (epoch 13), train_loss = 1.207, time/batch=0.119\n",
      "18176/67600 (epoch 13), train_loss = 1.250, time/batch=0.112\n",
      "18177/67600 (epoch 13), train_loss = 1.164, time/batch=0.112\n",
      "18178/67600 (epoch 13), train_loss = 1.226, time/batch=0.272\n",
      "18179/67600 (epoch 13), train_loss = 1.208, time/batch=0.127\n",
      "18180/67600 (epoch 13), train_loss = 1.242, time/batch=0.121\n",
      "18181/67600 (epoch 13), train_loss = 1.196, time/batch=0.129\n",
      "18182/67600 (epoch 13), train_loss = 1.274, time/batch=0.120\n",
      "18183/67600 (epoch 13), train_loss = 1.208, time/batch=0.098\n",
      "18184/67600 (epoch 13), train_loss = 1.287, time/batch=0.154\n",
      "18185/67600 (epoch 13), train_loss = 1.214, time/batch=0.351\n",
      "18186/67600 (epoch 13), train_loss = 1.244, time/batch=0.131\n",
      "18187/67600 (epoch 13), train_loss = 1.315, time/batch=0.136\n",
      "18188/67600 (epoch 13), train_loss = 1.224, time/batch=0.136\n",
      "18189/67600 (epoch 13), train_loss = 1.218, time/batch=0.125\n",
      "18190/67600 (epoch 13), train_loss = 1.253, time/batch=0.143\n",
      "18191/67600 (epoch 13), train_loss = 1.284, time/batch=0.289\n",
      "18192/67600 (epoch 13), train_loss = 1.235, time/batch=0.131\n",
      "18193/67600 (epoch 13), train_loss = 1.298, time/batch=0.151\n",
      "18194/67600 (epoch 13), train_loss = 1.229, time/batch=0.139\n",
      "18195/67600 (epoch 13), train_loss = 1.192, time/batch=0.225\n",
      "18196/67600 (epoch 13), train_loss = 1.177, time/batch=0.133\n",
      "18197/67600 (epoch 13), train_loss = 1.215, time/batch=0.144\n",
      "18198/67600 (epoch 13), train_loss = 1.229, time/batch=0.118\n",
      "18199/67600 (epoch 13), train_loss = 1.193, time/batch=0.142\n",
      "18200/67600 (epoch 13), train_loss = 1.228, time/batch=0.341\n",
      "18201/67600 (epoch 13), train_loss = 1.208, time/batch=0.188\n",
      "18202/67600 (epoch 13), train_loss = 1.260, time/batch=0.166\n",
      "18203/67600 (epoch 13), train_loss = 1.264, time/batch=0.118\n",
      "18204/67600 (epoch 13), train_loss = 1.258, time/batch=0.136\n",
      "18205/67600 (epoch 13), train_loss = 1.221, time/batch=0.122\n",
      "18206/67600 (epoch 13), train_loss = 1.265, time/batch=0.284\n",
      "18207/67600 (epoch 13), train_loss = 1.294, time/batch=0.130\n",
      "18208/67600 (epoch 13), train_loss = 1.207, time/batch=0.127\n",
      "18209/67600 (epoch 13), train_loss = 1.281, time/batch=0.126\n",
      "18210/67600 (epoch 13), train_loss = 1.269, time/batch=0.148\n",
      "18211/67600 (epoch 13), train_loss = 1.149, time/batch=0.093\n",
      "18212/67600 (epoch 13), train_loss = 1.309, time/batch=0.257\n",
      "18213/67600 (epoch 13), train_loss = 1.205, time/batch=0.242\n",
      "18214/67600 (epoch 13), train_loss = 1.160, time/batch=0.198\n",
      "18215/67600 (epoch 13), train_loss = 1.157, time/batch=0.131\n",
      "18216/67600 (epoch 13), train_loss = 1.226, time/batch=0.237\n",
      "18217/67600 (epoch 13), train_loss = 1.206, time/batch=0.172\n",
      "18218/67600 (epoch 13), train_loss = 1.260, time/batch=0.135\n",
      "18219/67600 (epoch 13), train_loss = 1.308, time/batch=0.167\n",
      "18220/67600 (epoch 13), train_loss = 1.279, time/batch=0.171\n",
      "18221/67600 (epoch 13), train_loss = 1.232, time/batch=0.190\n",
      "18222/67600 (epoch 13), train_loss = 1.262, time/batch=0.340\n",
      "18223/67600 (epoch 13), train_loss = 1.246, time/batch=0.141\n",
      "18224/67600 (epoch 13), train_loss = 1.273, time/batch=0.171\n",
      "18225/67600 (epoch 13), train_loss = 1.236, time/batch=0.147\n",
      "18226/67600 (epoch 13), train_loss = 1.278, time/batch=0.184\n",
      "18227/67600 (epoch 13), train_loss = 1.303, time/batch=0.351\n",
      "18228/67600 (epoch 13), train_loss = 1.223, time/batch=0.277\n",
      "18229/67600 (epoch 13), train_loss = 1.221, time/batch=0.119\n",
      "18230/67600 (epoch 13), train_loss = 1.246, time/batch=0.112\n",
      "18231/67600 (epoch 13), train_loss = 1.223, time/batch=0.346\n",
      "18232/67600 (epoch 13), train_loss = 1.220, time/batch=0.130\n",
      "18233/67600 (epoch 13), train_loss = 1.297, time/batch=0.141\n",
      "18234/67600 (epoch 13), train_loss = 1.248, time/batch=0.148\n",
      "18235/67600 (epoch 13), train_loss = 1.171, time/batch=0.157\n",
      "18236/67600 (epoch 13), train_loss = 1.221, time/batch=0.140\n",
      "18237/67600 (epoch 13), train_loss = 1.217, time/batch=0.144\n",
      "18238/67600 (epoch 13), train_loss = 1.144, time/batch=0.230\n",
      "18239/67600 (epoch 13), train_loss = 1.176, time/batch=0.104\n",
      "18240/67600 (epoch 13), train_loss = 1.262, time/batch=0.119\n",
      "18241/67600 (epoch 13), train_loss = 1.240, time/batch=0.118\n",
      "18242/67600 (epoch 13), train_loss = 1.250, time/batch=0.130\n",
      "18243/67600 (epoch 13), train_loss = 1.221, time/batch=0.208\n",
      "18244/67600 (epoch 13), train_loss = 1.283, time/batch=0.136\n",
      "18245/67600 (epoch 13), train_loss = 1.192, time/batch=0.116\n",
      "18246/67600 (epoch 13), train_loss = 1.147, time/batch=0.122\n",
      "18247/67600 (epoch 13), train_loss = 1.203, time/batch=0.121\n",
      "18248/67600 (epoch 13), train_loss = 1.144, time/batch=0.104\n",
      "18249/67600 (epoch 13), train_loss = 1.286, time/batch=0.129\n",
      "18250/67600 (epoch 13), train_loss = 1.274, time/batch=0.235\n",
      "18251/67600 (epoch 13), train_loss = 1.197, time/batch=0.143\n",
      "18252/67600 (epoch 13), train_loss = 1.233, time/batch=0.111\n",
      "18253/67600 (epoch 13), train_loss = 1.265, time/batch=0.122\n",
      "18254/67600 (epoch 13), train_loss = 1.277, time/batch=0.130\n",
      "18255/67600 (epoch 13), train_loss = 1.211, time/batch=0.127\n",
      "18256/67600 (epoch 13), train_loss = 1.230, time/batch=0.122\n",
      "18257/67600 (epoch 13), train_loss = 1.251, time/batch=0.267\n",
      "18258/67600 (epoch 13), train_loss = 1.253, time/batch=0.144\n",
      "18259/67600 (epoch 13), train_loss = 1.222, time/batch=0.132\n",
      "18260/67600 (epoch 13), train_loss = 1.200, time/batch=0.183\n",
      "18261/67600 (epoch 13), train_loss = 1.283, time/batch=0.122\n",
      "18262/67600 (epoch 13), train_loss = 1.247, time/batch=0.125\n",
      "18263/67600 (epoch 13), train_loss = 1.186, time/batch=0.351\n",
      "18264/67600 (epoch 13), train_loss = 1.232, time/batch=0.203\n",
      "18265/67600 (epoch 13), train_loss = 1.178, time/batch=0.135\n",
      "18266/67600 (epoch 13), train_loss = 1.224, time/batch=0.131\n",
      "18267/67600 (epoch 13), train_loss = 1.217, time/batch=0.148\n",
      "18268/67600 (epoch 13), train_loss = 1.207, time/batch=0.124\n",
      "18269/67600 (epoch 13), train_loss = 1.257, time/batch=0.336\n",
      "18270/67600 (epoch 13), train_loss = 1.234, time/batch=0.137\n",
      "18271/67600 (epoch 13), train_loss = 1.152, time/batch=0.181\n",
      "18272/67600 (epoch 13), train_loss = 1.245, time/batch=0.167\n",
      "18273/67600 (epoch 13), train_loss = 1.262, time/batch=0.125\n",
      "18274/67600 (epoch 13), train_loss = 1.254, time/batch=0.171\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18275/67600 (epoch 13), train_loss = 1.182, time/batch=0.251\n",
      "18276/67600 (epoch 13), train_loss = 1.233, time/batch=0.170\n",
      "18277/67600 (epoch 13), train_loss = 1.259, time/batch=0.146\n",
      "18278/67600 (epoch 13), train_loss = 1.218, time/batch=0.183\n",
      "18279/67600 (epoch 13), train_loss = 1.176, time/batch=0.162\n",
      "18280/67600 (epoch 13), train_loss = 1.223, time/batch=0.147\n",
      "18281/67600 (epoch 13), train_loss = 1.206, time/batch=0.113\n",
      "18282/67600 (epoch 13), train_loss = 1.209, time/batch=0.146\n",
      "18283/67600 (epoch 13), train_loss = 1.251, time/batch=0.216\n",
      "18284/67600 (epoch 13), train_loss = 1.240, time/batch=0.266\n",
      "18285/67600 (epoch 13), train_loss = 1.192, time/batch=0.119\n",
      "18286/67600 (epoch 13), train_loss = 1.228, time/batch=0.111\n",
      "18287/67600 (epoch 13), train_loss = 1.132, time/batch=0.137\n",
      "18288/67600 (epoch 13), train_loss = 1.221, time/batch=0.139\n",
      "18289/67600 (epoch 13), train_loss = 1.211, time/batch=0.127\n",
      "18290/67600 (epoch 13), train_loss = 1.212, time/batch=0.256\n",
      "18291/67600 (epoch 13), train_loss = 1.198, time/batch=0.125\n",
      "18292/67600 (epoch 13), train_loss = 1.175, time/batch=0.115\n",
      "18293/67600 (epoch 13), train_loss = 1.219, time/batch=0.207\n",
      "18294/67600 (epoch 13), train_loss = 1.201, time/batch=0.160\n",
      "18295/67600 (epoch 13), train_loss = 1.205, time/batch=0.279\n",
      "18296/67600 (epoch 13), train_loss = 1.216, time/batch=0.123\n",
      "18297/67600 (epoch 13), train_loss = 1.248, time/batch=0.122\n",
      "18298/67600 (epoch 13), train_loss = 1.219, time/batch=0.121\n",
      "18299/67600 (epoch 13), train_loss = 1.237, time/batch=0.135\n",
      "18300/67600 (epoch 13), train_loss = 1.228, time/batch=0.128\n",
      "18301/67600 (epoch 13), train_loss = 1.238, time/batch=0.229\n",
      "18302/67600 (epoch 13), train_loss = 1.228, time/batch=0.172\n",
      "18303/67600 (epoch 13), train_loss = 1.229, time/batch=0.121\n",
      "18304/67600 (epoch 13), train_loss = 1.246, time/batch=0.123\n",
      "18305/67600 (epoch 13), train_loss = 1.212, time/batch=0.145\n",
      "18306/67600 (epoch 13), train_loss = 1.237, time/batch=0.115\n",
      "18307/67600 (epoch 13), train_loss = 1.254, time/batch=0.261\n",
      "18308/67600 (epoch 13), train_loss = 1.241, time/batch=0.107\n",
      "18309/67600 (epoch 13), train_loss = 1.231, time/batch=0.159\n",
      "18310/67600 (epoch 13), train_loss = 1.233, time/batch=0.168\n",
      "18311/67600 (epoch 13), train_loss = 1.183, time/batch=0.203\n",
      "18312/67600 (epoch 13), train_loss = 1.282, time/batch=0.115\n",
      "18313/67600 (epoch 13), train_loss = 1.205, time/batch=0.299\n",
      "18314/67600 (epoch 13), train_loss = 1.179, time/batch=0.168\n",
      "18315/67600 (epoch 13), train_loss = 1.254, time/batch=0.143\n",
      "18316/67600 (epoch 13), train_loss = 1.163, time/batch=0.130\n",
      "18317/67600 (epoch 13), train_loss = 1.176, time/batch=0.143\n",
      "18318/67600 (epoch 13), train_loss = 1.165, time/batch=0.124\n",
      "18319/67600 (epoch 13), train_loss = 1.208, time/batch=0.290\n",
      "18320/67600 (epoch 13), train_loss = 1.241, time/batch=0.145\n",
      "18321/67600 (epoch 13), train_loss = 1.236, time/batch=0.125\n",
      "18322/67600 (epoch 13), train_loss = 1.210, time/batch=0.145\n",
      "18323/67600 (epoch 13), train_loss = 1.218, time/batch=0.124\n",
      "18324/67600 (epoch 13), train_loss = 1.232, time/batch=0.146\n",
      "18325/67600 (epoch 13), train_loss = 1.195, time/batch=0.133\n",
      "18326/67600 (epoch 13), train_loss = 1.156, time/batch=0.267\n",
      "18327/67600 (epoch 13), train_loss = 1.195, time/batch=0.122\n",
      "18328/67600 (epoch 13), train_loss = 1.214, time/batch=0.142\n",
      "18329/67600 (epoch 13), train_loss = 1.270, time/batch=0.093\n",
      "18330/67600 (epoch 13), train_loss = 1.210, time/batch=0.266\n",
      "18331/67600 (epoch 13), train_loss = 1.221, time/batch=0.115\n",
      "18332/67600 (epoch 13), train_loss = 1.284, time/batch=0.160\n",
      "18333/67600 (epoch 13), train_loss = 1.229, time/batch=0.133\n",
      "18334/67600 (epoch 13), train_loss = 1.202, time/batch=0.134\n",
      "18335/67600 (epoch 13), train_loss = 1.191, time/batch=0.115\n",
      "18336/67600 (epoch 13), train_loss = 1.208, time/batch=0.165\n",
      "18337/67600 (epoch 13), train_loss = 1.209, time/batch=0.241\n",
      "18338/67600 (epoch 13), train_loss = 1.208, time/batch=0.170\n",
      "18339/67600 (epoch 13), train_loss = 1.251, time/batch=0.121\n",
      "18340/67600 (epoch 13), train_loss = 1.272, time/batch=0.135\n",
      "18341/67600 (epoch 13), train_loss = 1.187, time/batch=0.114\n",
      "18342/67600 (epoch 13), train_loss = 1.229, time/batch=0.136\n",
      "18343/67600 (epoch 13), train_loss = 1.212, time/batch=0.123\n",
      "18344/67600 (epoch 13), train_loss = 1.248, time/batch=0.334\n",
      "18345/67600 (epoch 13), train_loss = 1.244, time/batch=0.170\n",
      "18346/67600 (epoch 13), train_loss = 1.206, time/batch=0.142\n",
      "18347/67600 (epoch 13), train_loss = 1.263, time/batch=0.148\n",
      "18348/67600 (epoch 13), train_loss = 1.238, time/batch=0.212\n",
      "18349/67600 (epoch 13), train_loss = 1.213, time/batch=0.311\n",
      "18350/67600 (epoch 13), train_loss = 1.252, time/batch=0.167\n",
      "18351/67600 (epoch 13), train_loss = 1.290, time/batch=0.134\n",
      "18352/67600 (epoch 13), train_loss = 1.260, time/batch=0.147\n",
      "18353/67600 (epoch 13), train_loss = 1.241, time/batch=0.167\n",
      "18354/67600 (epoch 13), train_loss = 1.221, time/batch=0.305\n",
      "18355/67600 (epoch 13), train_loss = 1.246, time/batch=0.134\n",
      "18356/67600 (epoch 13), train_loss = 1.286, time/batch=0.122\n",
      "18357/67600 (epoch 13), train_loss = 1.219, time/batch=0.137\n",
      "18358/67600 (epoch 13), train_loss = 1.210, time/batch=0.209\n",
      "18359/67600 (epoch 13), train_loss = 1.228, time/batch=0.147\n",
      "18360/67600 (epoch 13), train_loss = 1.212, time/batch=0.154\n",
      "18361/67600 (epoch 13), train_loss = 1.249, time/batch=0.131\n",
      "18362/67600 (epoch 13), train_loss = 1.218, time/batch=0.152\n",
      "18363/67600 (epoch 13), train_loss = 1.233, time/batch=0.114\n",
      "18364/67600 (epoch 13), train_loss = 1.240, time/batch=0.125\n",
      "18365/67600 (epoch 13), train_loss = 1.185, time/batch=0.185\n",
      "18366/67600 (epoch 13), train_loss = 1.219, time/batch=0.139\n",
      "18367/67600 (epoch 13), train_loss = 1.228, time/batch=0.132\n",
      "18368/67600 (epoch 13), train_loss = 1.195, time/batch=0.127\n",
      "18369/67600 (epoch 13), train_loss = 1.249, time/batch=0.149\n",
      "18370/67600 (epoch 13), train_loss = 1.224, time/batch=0.103\n",
      "18371/67600 (epoch 13), train_loss = 1.232, time/batch=0.287\n",
      "18372/67600 (epoch 13), train_loss = 1.297, time/batch=0.147\n",
      "18373/67600 (epoch 13), train_loss = 1.239, time/batch=0.108\n",
      "18374/67600 (epoch 13), train_loss = 1.273, time/batch=0.157\n",
      "18375/67600 (epoch 13), train_loss = 1.224, time/batch=0.107\n",
      "18376/67600 (epoch 13), train_loss = 1.235, time/batch=0.110\n",
      "18377/67600 (epoch 13), train_loss = 1.221, time/batch=0.121\n",
      "18378/67600 (epoch 13), train_loss = 1.197, time/batch=0.261\n",
      "18379/67600 (epoch 13), train_loss = 1.218, time/batch=0.144\n",
      "18380/67600 (epoch 13), train_loss = 1.200, time/batch=0.118\n",
      "18381/67600 (epoch 13), train_loss = 1.173, time/batch=0.118\n",
      "18382/67600 (epoch 13), train_loss = 1.224, time/batch=0.128\n",
      "18383/67600 (epoch 13), train_loss = 1.204, time/batch=0.153\n",
      "18384/67600 (epoch 13), train_loss = 1.144, time/batch=0.144\n",
      "18385/67600 (epoch 13), train_loss = 1.247, time/batch=0.223\n",
      "18386/67600 (epoch 13), train_loss = 1.185, time/batch=0.116\n",
      "18387/67600 (epoch 13), train_loss = 1.258, time/batch=0.119\n",
      "18388/67600 (epoch 13), train_loss = 1.245, time/batch=0.107\n",
      "18389/67600 (epoch 13), train_loss = 1.234, time/batch=0.126\n",
      "18390/67600 (epoch 13), train_loss = 1.264, time/batch=0.210\n",
      "18391/67600 (epoch 13), train_loss = 1.178, time/batch=0.119\n",
      "18392/67600 (epoch 13), train_loss = 1.265, time/batch=0.122\n",
      "18393/67600 (epoch 13), train_loss = 1.201, time/batch=0.176\n",
      "18394/67600 (epoch 13), train_loss = 1.198, time/batch=0.112\n",
      "18395/67600 (epoch 13), train_loss = 1.223, time/batch=0.170\n",
      "18396/67600 (epoch 13), train_loss = 1.153, time/batch=0.106\n",
      "18397/67600 (epoch 13), train_loss = 1.262, time/batch=0.244\n",
      "18398/67600 (epoch 13), train_loss = 1.220, time/batch=0.185\n",
      "18399/67600 (epoch 13), train_loss = 1.294, time/batch=0.118\n",
      "18400/67600 (epoch 13), train_loss = 1.238, time/batch=0.115\n",
      "18401/67600 (epoch 13), train_loss = 1.268, time/batch=0.158\n",
      "18402/67600 (epoch 13), train_loss = 1.362, time/batch=0.125\n",
      "18403/67600 (epoch 13), train_loss = 1.197, time/batch=0.394\n",
      "18404/67600 (epoch 13), train_loss = 1.222, time/batch=0.124\n",
      "18405/67600 (epoch 13), train_loss = 1.257, time/batch=0.142\n",
      "18406/67600 (epoch 13), train_loss = 1.302, time/batch=0.124\n",
      "18407/67600 (epoch 13), train_loss = 1.210, time/batch=0.161\n",
      "18408/67600 (epoch 13), train_loss = 1.221, time/batch=0.141\n",
      "18409/67600 (epoch 13), train_loss = 1.222, time/batch=0.292\n",
      "18410/67600 (epoch 13), train_loss = 1.195, time/batch=0.122\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18411/67600 (epoch 13), train_loss = 1.270, time/batch=0.143\n",
      "18412/67600 (epoch 13), train_loss = 1.127, time/batch=0.159\n",
      "18413/67600 (epoch 13), train_loss = 1.252, time/batch=0.114\n",
      "18414/67600 (epoch 13), train_loss = 1.163, time/batch=0.160\n",
      "18415/67600 (epoch 13), train_loss = 1.221, time/batch=0.246\n",
      "18416/67600 (epoch 13), train_loss = 1.278, time/batch=0.146\n",
      "18417/67600 (epoch 13), train_loss = 1.237, time/batch=0.134\n",
      "18418/67600 (epoch 13), train_loss = 1.234, time/batch=0.133\n",
      "18419/67600 (epoch 13), train_loss = 1.231, time/batch=0.174\n",
      "18420/67600 (epoch 13), train_loss = 1.225, time/batch=0.215\n",
      "18421/67600 (epoch 13), train_loss = 1.208, time/batch=0.127\n",
      "18422/67600 (epoch 13), train_loss = 1.200, time/batch=0.172\n",
      "18423/67600 (epoch 13), train_loss = 1.213, time/batch=0.160\n",
      "18424/67600 (epoch 13), train_loss = 1.245, time/batch=0.121\n",
      "18425/67600 (epoch 13), train_loss = 1.217, time/batch=0.102\n",
      "18426/67600 (epoch 13), train_loss = 1.225, time/batch=0.239\n",
      "18427/67600 (epoch 13), train_loss = 1.301, time/batch=0.174\n",
      "18428/67600 (epoch 13), train_loss = 1.306, time/batch=0.129\n",
      "18429/67600 (epoch 13), train_loss = 1.278, time/batch=0.115\n",
      "18430/67600 (epoch 13), train_loss = 1.225, time/batch=0.177\n",
      "18431/67600 (epoch 13), train_loss = 1.258, time/batch=0.174\n",
      "18432/67600 (epoch 13), train_loss = 1.227, time/batch=0.237\n",
      "18433/67600 (epoch 13), train_loss = 1.249, time/batch=0.169\n",
      "18434/67600 (epoch 13), train_loss = 1.254, time/batch=0.179\n",
      "18435/67600 (epoch 13), train_loss = 1.275, time/batch=0.101\n",
      "18436/67600 (epoch 13), train_loss = 1.226, time/batch=0.129\n",
      "18437/67600 (epoch 13), train_loss = 1.280, time/batch=0.158\n",
      "18438/67600 (epoch 13), train_loss = 1.303, time/batch=0.283\n",
      "18439/67600 (epoch 13), train_loss = 1.255, time/batch=0.130\n",
      "18440/67600 (epoch 13), train_loss = 1.193, time/batch=0.150\n",
      "18441/67600 (epoch 13), train_loss = 1.289, time/batch=0.108\n",
      "18442/67600 (epoch 13), train_loss = 1.270, time/batch=0.154\n",
      "18443/67600 (epoch 13), train_loss = 1.209, time/batch=0.121\n",
      "18444/67600 (epoch 13), train_loss = 1.234, time/batch=0.169\n",
      "18445/67600 (epoch 13), train_loss = 1.227, time/batch=0.232\n",
      "18446/67600 (epoch 13), train_loss = 1.230, time/batch=0.111\n",
      "18447/67600 (epoch 13), train_loss = 1.204, time/batch=0.169\n",
      "18448/67600 (epoch 13), train_loss = 1.264, time/batch=0.131\n",
      "18449/67600 (epoch 13), train_loss = 1.187, time/batch=0.225\n",
      "18450/67600 (epoch 13), train_loss = 1.228, time/batch=0.211\n",
      "18451/67600 (epoch 13), train_loss = 1.283, time/batch=0.142\n",
      "18452/67600 (epoch 13), train_loss = 1.271, time/batch=0.113\n",
      "18453/67600 (epoch 13), train_loss = 1.139, time/batch=0.091\n",
      "18454/67600 (epoch 13), train_loss = 1.228, time/batch=0.129\n",
      "18455/67600 (epoch 13), train_loss = 1.132, time/batch=0.106\n",
      "18456/67600 (epoch 13), train_loss = 1.187, time/batch=0.198\n",
      "18457/67600 (epoch 13), train_loss = 1.197, time/batch=0.145\n",
      "18458/67600 (epoch 13), train_loss = 1.201, time/batch=0.187\n",
      "18459/67600 (epoch 13), train_loss = 1.228, time/batch=0.103\n",
      "18460/67600 (epoch 13), train_loss = 1.201, time/batch=0.291\n",
      "18461/67600 (epoch 13), train_loss = 1.220, time/batch=0.185\n",
      "18462/67600 (epoch 13), train_loss = 1.198, time/batch=0.174\n",
      "18463/67600 (epoch 13), train_loss = 1.170, time/batch=0.084\n",
      "18464/67600 (epoch 13), train_loss = 1.285, time/batch=0.136\n",
      "18465/67600 (epoch 13), train_loss = 1.257, time/batch=0.157\n",
      "18466/67600 (epoch 13), train_loss = 1.279, time/batch=0.093\n",
      "18467/67600 (epoch 13), train_loss = 1.276, time/batch=0.140\n",
      "18468/67600 (epoch 13), train_loss = 1.245, time/batch=0.288\n",
      "18469/67600 (epoch 13), train_loss = 1.208, time/batch=0.122\n",
      "18470/67600 (epoch 13), train_loss = 1.245, time/batch=0.125\n",
      "18471/67600 (epoch 13), train_loss = 1.208, time/batch=0.075\n",
      "18472/67600 (epoch 13), train_loss = 1.232, time/batch=0.132\n",
      "18473/67600 (epoch 13), train_loss = 1.295, time/batch=0.111\n",
      "18474/67600 (epoch 13), train_loss = 1.258, time/batch=0.115\n",
      "18475/67600 (epoch 13), train_loss = 1.264, time/batch=0.252\n",
      "18476/67600 (epoch 13), train_loss = 1.239, time/batch=0.127\n",
      "18477/67600 (epoch 13), train_loss = 1.278, time/batch=0.111\n",
      "18478/67600 (epoch 13), train_loss = 1.279, time/batch=0.114\n",
      "18479/67600 (epoch 13), train_loss = 1.170, time/batch=0.126\n",
      "18480/67600 (epoch 13), train_loss = 1.216, time/batch=0.229\n",
      "18481/67600 (epoch 13), train_loss = 1.261, time/batch=0.155\n",
      "18482/67600 (epoch 13), train_loss = 1.215, time/batch=0.121\n",
      "18483/67600 (epoch 13), train_loss = 1.200, time/batch=0.129\n",
      "18484/67600 (epoch 13), train_loss = 1.277, time/batch=0.133\n",
      "18485/67600 (epoch 13), train_loss = 1.207, time/batch=0.108\n",
      "18486/67600 (epoch 13), train_loss = 1.226, time/batch=0.140\n",
      "18487/67600 (epoch 13), train_loss = 1.241, time/batch=0.246\n",
      "18488/67600 (epoch 13), train_loss = 1.225, time/batch=0.138\n",
      "18489/67600 (epoch 13), train_loss = 1.256, time/batch=0.118\n",
      "18490/67600 (epoch 13), train_loss = 1.274, time/batch=0.117\n",
      "18491/67600 (epoch 13), train_loss = 1.195, time/batch=0.134\n",
      "18492/67600 (epoch 13), train_loss = 1.223, time/batch=0.148\n",
      "18493/67600 (epoch 13), train_loss = 1.218, time/batch=0.235\n",
      "18494/67600 (epoch 13), train_loss = 1.234, time/batch=0.157\n",
      "18495/67600 (epoch 13), train_loss = 1.228, time/batch=0.167\n",
      "18496/67600 (epoch 13), train_loss = 1.257, time/batch=0.137\n",
      "18497/67600 (epoch 13), train_loss = 1.234, time/batch=0.108\n",
      "18498/67600 (epoch 13), train_loss = 1.243, time/batch=0.199\n",
      "18499/67600 (epoch 13), train_loss = 1.194, time/batch=0.162\n",
      "18500/67600 (epoch 13), train_loss = 1.191, time/batch=0.280\n",
      "model saved to ./save/model.ckpt\n",
      "18501/67600 (epoch 13), train_loss = 1.212, time/batch=0.080\n",
      "18502/67600 (epoch 13), train_loss = 1.207, time/batch=0.086\n",
      "18503/67600 (epoch 13), train_loss = 1.222, time/batch=0.099\n",
      "18504/67600 (epoch 13), train_loss = 1.202, time/batch=0.126\n",
      "18505/67600 (epoch 13), train_loss = 1.221, time/batch=0.107\n",
      "18506/67600 (epoch 13), train_loss = 1.178, time/batch=0.113\n",
      "18507/67600 (epoch 13), train_loss = 1.232, time/batch=0.115\n",
      "18508/67600 (epoch 13), train_loss = 1.206, time/batch=0.239\n",
      "18509/67600 (epoch 13), train_loss = 1.175, time/batch=0.129\n",
      "18510/67600 (epoch 13), train_loss = 1.208, time/batch=0.110\n",
      "18511/67600 (epoch 13), train_loss = 1.197, time/batch=0.124\n",
      "18512/67600 (epoch 13), train_loss = 1.252, time/batch=0.104\n",
      "18513/67600 (epoch 13), train_loss = 1.212, time/batch=0.165\n",
      "18514/67600 (epoch 13), train_loss = 1.203, time/batch=0.134\n",
      "18515/67600 (epoch 13), train_loss = 1.203, time/batch=0.108\n",
      "18516/67600 (epoch 13), train_loss = 1.224, time/batch=0.135\n",
      "18517/67600 (epoch 13), train_loss = 1.182, time/batch=0.119\n",
      "18518/67600 (epoch 13), train_loss = 1.166, time/batch=0.120\n",
      "18519/67600 (epoch 13), train_loss = 1.251, time/batch=0.205\n",
      "18520/67600 (epoch 13), train_loss = 1.212, time/batch=0.197\n",
      "18521/67600 (epoch 13), train_loss = 1.230, time/batch=0.139\n",
      "18522/67600 (epoch 13), train_loss = 1.198, time/batch=0.114\n",
      "18523/67600 (epoch 13), train_loss = 1.178, time/batch=0.119\n",
      "18524/67600 (epoch 13), train_loss = 1.233, time/batch=0.120\n",
      "18525/67600 (epoch 13), train_loss = 1.176, time/batch=0.097\n",
      "18526/67600 (epoch 13), train_loss = 1.247, time/batch=0.115\n",
      "18527/67600 (epoch 13), train_loss = 1.199, time/batch=0.257\n",
      "18528/67600 (epoch 13), train_loss = 1.243, time/batch=0.136\n",
      "18529/67600 (epoch 13), train_loss = 1.189, time/batch=0.118\n",
      "18530/67600 (epoch 13), train_loss = 1.157, time/batch=0.118\n",
      "18531/67600 (epoch 13), train_loss = 1.269, time/batch=0.111\n",
      "18532/67600 (epoch 13), train_loss = 1.241, time/batch=0.109\n",
      "18533/67600 (epoch 13), train_loss = 1.239, time/batch=0.120\n",
      "18534/67600 (epoch 13), train_loss = 1.184, time/batch=0.175\n",
      "18535/67600 (epoch 13), train_loss = 1.193, time/batch=0.181\n",
      "18536/67600 (epoch 13), train_loss = 1.185, time/batch=0.112\n",
      "18537/67600 (epoch 13), train_loss = 1.143, time/batch=0.106\n",
      "18538/67600 (epoch 13), train_loss = 1.152, time/batch=0.118\n",
      "18539/67600 (epoch 13), train_loss = 1.154, time/batch=0.108\n",
      "18540/67600 (epoch 13), train_loss = 1.154, time/batch=0.207\n",
      "18541/67600 (epoch 13), train_loss = 1.236, time/batch=0.144\n",
      "18542/67600 (epoch 13), train_loss = 1.219, time/batch=0.113\n",
      "18543/67600 (epoch 13), train_loss = 1.165, time/batch=0.114\n",
      "18544/67600 (epoch 13), train_loss = 1.181, time/batch=0.109\n",
      "18545/67600 (epoch 13), train_loss = 1.178, time/batch=0.108\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18546/67600 (epoch 13), train_loss = 1.214, time/batch=0.122\n",
      "18547/67600 (epoch 13), train_loss = 1.226, time/batch=0.103\n",
      "18548/67600 (epoch 13), train_loss = 1.165, time/batch=0.238\n",
      "18549/67600 (epoch 13), train_loss = 1.227, time/batch=0.136\n",
      "18550/67600 (epoch 13), train_loss = 1.259, time/batch=0.114\n",
      "18551/67600 (epoch 13), train_loss = 1.145, time/batch=0.104\n",
      "18552/67600 (epoch 13), train_loss = 1.154, time/batch=0.127\n",
      "18553/67600 (epoch 13), train_loss = 1.180, time/batch=0.111\n",
      "18554/67600 (epoch 13), train_loss = 1.228, time/batch=0.112\n",
      "18555/67600 (epoch 13), train_loss = 1.207, time/batch=0.246\n",
      "18556/67600 (epoch 13), train_loss = 1.219, time/batch=0.125\n",
      "18557/67600 (epoch 13), train_loss = 1.178, time/batch=0.129\n",
      "18558/67600 (epoch 13), train_loss = 1.202, time/batch=0.108\n",
      "18559/67600 (epoch 13), train_loss = 1.251, time/batch=0.125\n",
      "18560/67600 (epoch 13), train_loss = 1.196, time/batch=0.118\n",
      "18561/67600 (epoch 13), train_loss = 1.277, time/batch=0.118\n",
      "18562/67600 (epoch 13), train_loss = 1.213, time/batch=0.112\n",
      "18563/67600 (epoch 13), train_loss = 1.281, time/batch=0.262\n",
      "18564/67600 (epoch 13), train_loss = 1.182, time/batch=0.129\n",
      "18565/67600 (epoch 13), train_loss = 1.212, time/batch=0.122\n",
      "18566/67600 (epoch 13), train_loss = 1.240, time/batch=0.130\n",
      "18567/67600 (epoch 13), train_loss = 1.202, time/batch=0.090\n",
      "18568/67600 (epoch 13), train_loss = 1.251, time/batch=0.099\n",
      "18569/67600 (epoch 13), train_loss = 1.212, time/batch=0.121\n",
      "18570/67600 (epoch 13), train_loss = 1.194, time/batch=0.243\n",
      "18571/67600 (epoch 13), train_loss = 1.211, time/batch=0.111\n",
      "18572/67600 (epoch 13), train_loss = 1.204, time/batch=0.112\n",
      "18573/67600 (epoch 13), train_loss = 1.223, time/batch=0.116\n",
      "18574/67600 (epoch 13), train_loss = 1.182, time/batch=0.098\n",
      "18575/67600 (epoch 13), train_loss = 1.198, time/batch=0.130\n",
      "18576/67600 (epoch 13), train_loss = 1.212, time/batch=0.195\n",
      "18577/67600 (epoch 13), train_loss = 1.229, time/batch=0.140\n",
      "18578/67600 (epoch 13), train_loss = 1.190, time/batch=0.124\n",
      "18579/67600 (epoch 13), train_loss = 1.204, time/batch=0.117\n",
      "18580/67600 (epoch 13), train_loss = 1.158, time/batch=0.111\n",
      "18581/67600 (epoch 13), train_loss = 1.233, time/batch=0.105\n",
      "18582/67600 (epoch 13), train_loss = 1.215, time/batch=0.115\n",
      "18583/67600 (epoch 13), train_loss = 1.175, time/batch=0.129\n",
      "18584/67600 (epoch 13), train_loss = 1.217, time/batch=0.194\n",
      "18585/67600 (epoch 13), train_loss = 1.172, time/batch=0.144\n",
      "18586/67600 (epoch 13), train_loss = 1.196, time/batch=0.110\n",
      "18587/67600 (epoch 13), train_loss = 1.188, time/batch=0.111\n",
      "18588/67600 (epoch 13), train_loss = 1.150, time/batch=0.114\n",
      "18589/67600 (epoch 13), train_loss = 1.195, time/batch=0.114\n",
      "18590/67600 (epoch 13), train_loss = 1.184, time/batch=0.112\n",
      "18591/67600 (epoch 13), train_loss = 1.204, time/batch=0.225\n",
      "18592/67600 (epoch 13), train_loss = 1.185, time/batch=0.140\n",
      "18593/67600 (epoch 13), train_loss = 1.228, time/batch=0.129\n",
      "18594/67600 (epoch 13), train_loss = 1.211, time/batch=0.130\n",
      "18595/67600 (epoch 13), train_loss = 1.223, time/batch=0.104\n",
      "18596/67600 (epoch 13), train_loss = 1.197, time/batch=0.112\n",
      "18597/67600 (epoch 13), train_loss = 1.203, time/batch=0.120\n",
      "18598/67600 (epoch 13), train_loss = 1.200, time/batch=0.190\n",
      "18599/67600 (epoch 13), train_loss = 1.196, time/batch=0.168\n",
      "18600/67600 (epoch 13), train_loss = 1.196, time/batch=0.125\n",
      "18601/67600 (epoch 13), train_loss = 1.159, time/batch=0.111\n",
      "18602/67600 (epoch 13), train_loss = 1.243, time/batch=0.114\n",
      "18603/67600 (epoch 13), train_loss = 1.162, time/batch=0.128\n",
      "18604/67600 (epoch 13), train_loss = 1.249, time/batch=0.129\n",
      "18605/67600 (epoch 13), train_loss = 1.221, time/batch=0.113\n",
      "18606/67600 (epoch 13), train_loss = 1.248, time/batch=0.260\n",
      "18607/67600 (epoch 13), train_loss = 1.258, time/batch=0.124\n",
      "18608/67600 (epoch 13), train_loss = 1.230, time/batch=0.119\n",
      "18609/67600 (epoch 13), train_loss = 1.191, time/batch=0.112\n",
      "18610/67600 (epoch 13), train_loss = 1.209, time/batch=0.112\n",
      "18611/67600 (epoch 13), train_loss = 1.188, time/batch=0.088\n",
      "18612/67600 (epoch 13), train_loss = 1.184, time/batch=0.120\n",
      "18613/67600 (epoch 13), train_loss = 1.180, time/batch=0.150\n",
      "18614/67600 (epoch 13), train_loss = 1.219, time/batch=0.226\n",
      "18615/67600 (epoch 13), train_loss = 1.202, time/batch=0.130\n",
      "18616/67600 (epoch 13), train_loss = 1.217, time/batch=0.117\n",
      "18617/67600 (epoch 13), train_loss = 1.221, time/batch=0.122\n",
      "18618/67600 (epoch 13), train_loss = 1.251, time/batch=0.186\n",
      "18619/67600 (epoch 13), train_loss = 1.117, time/batch=0.122\n",
      "18620/67600 (epoch 13), train_loss = 1.202, time/batch=0.109\n",
      "18621/67600 (epoch 13), train_loss = 1.209, time/batch=0.123\n",
      "18622/67600 (epoch 13), train_loss = 1.214, time/batch=0.105\n",
      "18623/67600 (epoch 13), train_loss = 1.273, time/batch=0.120\n",
      "18624/67600 (epoch 13), train_loss = 1.245, time/batch=0.113\n",
      "18625/67600 (epoch 13), train_loss = 1.231, time/batch=0.271\n",
      "18626/67600 (epoch 13), train_loss = 1.212, time/batch=0.128\n",
      "18627/67600 (epoch 13), train_loss = 1.183, time/batch=0.110\n",
      "18628/67600 (epoch 13), train_loss = 1.213, time/batch=0.124\n",
      "18629/67600 (epoch 13), train_loss = 1.211, time/batch=0.105\n",
      "18630/67600 (epoch 13), train_loss = 1.233, time/batch=0.122\n",
      "18631/67600 (epoch 13), train_loss = 1.206, time/batch=0.128\n",
      "18632/67600 (epoch 13), train_loss = 1.141, time/batch=0.265\n",
      "18633/67600 (epoch 13), train_loss = 1.253, time/batch=0.128\n",
      "18634/67600 (epoch 13), train_loss = 1.287, time/batch=0.119\n",
      "18635/67600 (epoch 13), train_loss = 1.204, time/batch=0.113\n",
      "18636/67600 (epoch 13), train_loss = 1.233, time/batch=0.115\n",
      "18637/67600 (epoch 13), train_loss = 1.235, time/batch=0.300\n",
      "18638/67600 (epoch 13), train_loss = 1.217, time/batch=0.189\n",
      "18639/67600 (epoch 13), train_loss = 1.181, time/batch=0.147\n",
      "18640/67600 (epoch 13), train_loss = 1.224, time/batch=0.114\n",
      "18641/67600 (epoch 13), train_loss = 1.211, time/batch=0.115\n",
      "18642/67600 (epoch 13), train_loss = 1.212, time/batch=0.122\n",
      "18643/67600 (epoch 13), train_loss = 1.254, time/batch=0.238\n",
      "18644/67600 (epoch 13), train_loss = 1.180, time/batch=0.134\n",
      "18645/67600 (epoch 13), train_loss = 1.231, time/batch=0.133\n",
      "18646/67600 (epoch 13), train_loss = 1.249, time/batch=0.140\n",
      "18647/67600 (epoch 13), train_loss = 1.269, time/batch=0.119\n",
      "18648/67600 (epoch 13), train_loss = 1.220, time/batch=0.127\n",
      "18649/67600 (epoch 13), train_loss = 1.197, time/batch=0.117\n",
      "18650/67600 (epoch 13), train_loss = 1.172, time/batch=0.238\n",
      "18651/67600 (epoch 13), train_loss = 1.212, time/batch=0.199\n",
      "18652/67600 (epoch 13), train_loss = 1.266, time/batch=0.131\n",
      "18653/67600 (epoch 13), train_loss = 1.268, time/batch=0.093\n",
      "18654/67600 (epoch 13), train_loss = 1.262, time/batch=0.139\n",
      "18655/67600 (epoch 13), train_loss = 1.255, time/batch=0.146\n",
      "18656/67600 (epoch 13), train_loss = 1.270, time/batch=0.114\n",
      "18657/67600 (epoch 13), train_loss = 1.184, time/batch=0.221\n",
      "18658/67600 (epoch 13), train_loss = 1.250, time/batch=0.158\n",
      "18659/67600 (epoch 13), train_loss = 1.189, time/batch=0.135\n",
      "18660/67600 (epoch 13), train_loss = 1.183, time/batch=0.102\n",
      "18661/67600 (epoch 13), train_loss = 1.281, time/batch=0.121\n",
      "18662/67600 (epoch 13), train_loss = 1.251, time/batch=0.130\n",
      "18663/67600 (epoch 13), train_loss = 1.158, time/batch=0.109\n",
      "18664/67600 (epoch 13), train_loss = 1.196, time/batch=0.249\n",
      "18665/67600 (epoch 13), train_loss = 1.184, time/batch=0.152\n",
      "18666/67600 (epoch 13), train_loss = 1.229, time/batch=0.088\n",
      "18667/67600 (epoch 13), train_loss = 1.191, time/batch=0.144\n",
      "18668/67600 (epoch 13), train_loss = 1.257, time/batch=0.114\n",
      "18669/67600 (epoch 13), train_loss = 1.211, time/batch=0.166\n",
      "18670/67600 (epoch 13), train_loss = 1.213, time/batch=0.109\n",
      "18671/67600 (epoch 13), train_loss = 1.182, time/batch=0.268\n",
      "18672/67600 (epoch 13), train_loss = 1.221, time/batch=0.100\n",
      "18673/67600 (epoch 13), train_loss = 1.212, time/batch=0.115\n",
      "18674/67600 (epoch 13), train_loss = 1.182, time/batch=0.120\n",
      "18675/67600 (epoch 13), train_loss = 1.148, time/batch=0.132\n",
      "18676/67600 (epoch 13), train_loss = 1.216, time/batch=0.224\n",
      "18677/67600 (epoch 13), train_loss = 1.200, time/batch=0.139\n",
      "18678/67600 (epoch 13), train_loss = 1.192, time/batch=0.126\n",
      "18679/67600 (epoch 13), train_loss = 1.171, time/batch=0.110\n",
      "18680/67600 (epoch 13), train_loss = 1.291, time/batch=0.099\n",
      "18681/67600 (epoch 13), train_loss = 1.196, time/batch=0.124\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18682/67600 (epoch 13), train_loss = 1.202, time/batch=0.117\n",
      "18683/67600 (epoch 13), train_loss = 1.239, time/batch=0.231\n",
      "18684/67600 (epoch 13), train_loss = 1.193, time/batch=0.120\n",
      "18685/67600 (epoch 13), train_loss = 1.224, time/batch=0.139\n",
      "18686/67600 (epoch 13), train_loss = 1.241, time/batch=0.115\n",
      "18687/67600 (epoch 13), train_loss = 1.207, time/batch=0.132\n",
      "18688/67600 (epoch 13), train_loss = 1.276, time/batch=0.121\n",
      "18689/67600 (epoch 13), train_loss = 1.266, time/batch=0.114\n",
      "18690/67600 (epoch 13), train_loss = 1.244, time/batch=0.135\n",
      "18691/67600 (epoch 13), train_loss = 1.309, time/batch=0.231\n",
      "18692/67600 (epoch 13), train_loss = 1.217, time/batch=0.165\n",
      "18693/67600 (epoch 13), train_loss = 1.250, time/batch=0.094\n",
      "18694/67600 (epoch 13), train_loss = 1.217, time/batch=0.138\n",
      "18695/67600 (epoch 13), train_loss = 1.311, time/batch=0.100\n",
      "18696/67600 (epoch 13), train_loss = 1.202, time/batch=0.150\n",
      "18697/67600 (epoch 13), train_loss = 1.257, time/batch=0.105\n",
      "18698/67600 (epoch 13), train_loss = 1.317, time/batch=0.244\n",
      "18699/67600 (epoch 13), train_loss = 1.235, time/batch=0.120\n",
      "18700/67600 (epoch 13), train_loss = 1.213, time/batch=0.118\n",
      "18701/67600 (epoch 13), train_loss = 1.213, time/batch=0.122\n",
      "18702/67600 (epoch 13), train_loss = 1.276, time/batch=0.108\n",
      "18703/67600 (epoch 13), train_loss = 1.226, time/batch=0.114\n",
      "18704/67600 (epoch 13), train_loss = 1.238, time/batch=0.102\n",
      "18705/67600 (epoch 13), train_loss = 1.233, time/batch=0.232\n",
      "18706/67600 (epoch 13), train_loss = 1.241, time/batch=0.142\n",
      "18707/67600 (epoch 13), train_loss = 1.245, time/batch=0.118\n",
      "18708/67600 (epoch 13), train_loss = 1.206, time/batch=0.112\n",
      "18709/67600 (epoch 13), train_loss = 1.271, time/batch=0.123\n",
      "18710/67600 (epoch 13), train_loss = 1.293, time/batch=0.132\n",
      "18711/67600 (epoch 13), train_loss = 1.292, time/batch=0.148\n",
      "18712/67600 (epoch 13), train_loss = 1.261, time/batch=0.186\n",
      "18713/67600 (epoch 13), train_loss = 1.231, time/batch=0.186\n",
      "18714/67600 (epoch 13), train_loss = 1.235, time/batch=0.120\n",
      "18715/67600 (epoch 13), train_loss = 1.284, time/batch=0.120\n",
      "18716/67600 (epoch 13), train_loss = 1.230, time/batch=0.110\n",
      "18717/67600 (epoch 13), train_loss = 1.226, time/batch=0.106\n",
      "18718/67600 (epoch 13), train_loss = 1.264, time/batch=0.156\n",
      "18719/67600 (epoch 13), train_loss = 1.261, time/batch=0.110\n",
      "18720/67600 (epoch 13), train_loss = 1.247, time/batch=0.117\n",
      "18721/67600 (epoch 13), train_loss = 1.202, time/batch=0.108\n",
      "18722/67600 (epoch 13), train_loss = 1.189, time/batch=0.102\n",
      "18723/67600 (epoch 13), train_loss = 1.178, time/batch=0.125\n",
      "18724/67600 (epoch 13), train_loss = 1.198, time/batch=0.330\n",
      "18725/67600 (epoch 13), train_loss = 1.213, time/batch=0.157\n",
      "18726/67600 (epoch 13), train_loss = 1.158, time/batch=0.109\n",
      "18727/67600 (epoch 13), train_loss = 1.254, time/batch=0.140\n",
      "18728/67600 (epoch 13), train_loss = 1.217, time/batch=0.103\n",
      "18729/67600 (epoch 13), train_loss = 1.197, time/batch=0.114\n",
      "18730/67600 (epoch 13), train_loss = 1.225, time/batch=0.121\n",
      "18731/67600 (epoch 13), train_loss = 1.205, time/batch=0.259\n",
      "18732/67600 (epoch 13), train_loss = 1.205, time/batch=0.129\n",
      "18733/67600 (epoch 13), train_loss = 1.158, time/batch=0.118\n",
      "18734/67600 (epoch 13), train_loss = 1.261, time/batch=0.095\n",
      "18735/67600 (epoch 13), train_loss = 1.256, time/batch=0.124\n",
      "18736/67600 (epoch 13), train_loss = 1.180, time/batch=0.113\n",
      "18737/67600 (epoch 13), train_loss = 1.191, time/batch=0.110\n",
      "18738/67600 (epoch 13), train_loss = 1.211, time/batch=0.235\n",
      "18739/67600 (epoch 13), train_loss = 1.170, time/batch=0.187\n",
      "18740/67600 (epoch 13), train_loss = 1.225, time/batch=0.124\n",
      "18741/67600 (epoch 13), train_loss = 1.176, time/batch=0.109\n",
      "18742/67600 (epoch 13), train_loss = 1.193, time/batch=0.128\n",
      "18743/67600 (epoch 13), train_loss = 1.227, time/batch=0.235\n",
      "18744/67600 (epoch 13), train_loss = 1.230, time/batch=0.139\n",
      "18745/67600 (epoch 13), train_loss = 1.149, time/batch=0.110\n",
      "18746/67600 (epoch 13), train_loss = 1.181, time/batch=0.096\n",
      "18747/67600 (epoch 13), train_loss = 1.182, time/batch=0.153\n",
      "18748/67600 (epoch 13), train_loss = 1.207, time/batch=0.122\n",
      "18749/67600 (epoch 13), train_loss = 1.218, time/batch=0.111\n",
      "18750/67600 (epoch 13), train_loss = 1.206, time/batch=0.265\n",
      "18751/67600 (epoch 13), train_loss = 1.218, time/batch=0.114\n",
      "18752/67600 (epoch 13), train_loss = 1.215, time/batch=0.136\n",
      "18753/67600 (epoch 13), train_loss = 1.210, time/batch=0.106\n",
      "18754/67600 (epoch 13), train_loss = 1.255, time/batch=0.130\n",
      "18755/67600 (epoch 13), train_loss = 1.309, time/batch=0.146\n",
      "18756/67600 (epoch 13), train_loss = 1.276, time/batch=0.109\n",
      "18757/67600 (epoch 13), train_loss = 1.236, time/batch=0.276\n",
      "18758/67600 (epoch 13), train_loss = 1.225, time/batch=0.137\n",
      "18759/67600 (epoch 13), train_loss = 1.217, time/batch=0.126\n",
      "18760/67600 (epoch 13), train_loss = 1.239, time/batch=0.119\n",
      "18761/67600 (epoch 13), train_loss = 1.142, time/batch=0.111\n",
      "18762/67600 (epoch 13), train_loss = 1.173, time/batch=0.116\n",
      "18763/67600 (epoch 13), train_loss = 1.267, time/batch=0.108\n",
      "18764/67600 (epoch 13), train_loss = 1.213, time/batch=0.107\n",
      "18765/67600 (epoch 13), train_loss = 1.178, time/batch=0.266\n",
      "18766/67600 (epoch 13), train_loss = 1.219, time/batch=0.113\n",
      "18767/67600 (epoch 13), train_loss = 1.195, time/batch=0.136\n",
      "18768/67600 (epoch 13), train_loss = 1.205, time/batch=0.136\n",
      "18769/67600 (epoch 13), train_loss = 1.214, time/batch=0.116\n",
      "18770/67600 (epoch 13), train_loss = 1.172, time/batch=0.112\n",
      "18771/67600 (epoch 13), train_loss = 1.186, time/batch=0.277\n",
      "18772/67600 (epoch 13), train_loss = 1.231, time/batch=0.125\n",
      "18773/67600 (epoch 13), train_loss = 1.240, time/batch=0.119\n",
      "18774/67600 (epoch 13), train_loss = 1.254, time/batch=0.120\n",
      "18775/67600 (epoch 13), train_loss = 1.200, time/batch=0.106\n",
      "18776/67600 (epoch 13), train_loss = 1.231, time/batch=0.111\n",
      "18777/67600 (epoch 13), train_loss = 1.190, time/batch=0.197\n",
      "18778/67600 (epoch 13), train_loss = 1.177, time/batch=0.209\n",
      "18779/67600 (epoch 13), train_loss = 1.183, time/batch=0.109\n",
      "18780/67600 (epoch 13), train_loss = 1.285, time/batch=0.118\n",
      "18781/67600 (epoch 13), train_loss = 1.207, time/batch=0.113\n",
      "18782/67600 (epoch 13), train_loss = 1.173, time/batch=0.117\n",
      "18783/67600 (epoch 13), train_loss = 1.218, time/batch=0.123\n",
      "18784/67600 (epoch 13), train_loss = 1.177, time/batch=0.229\n",
      "18785/67600 (epoch 13), train_loss = 1.178, time/batch=0.132\n",
      "18786/67600 (epoch 13), train_loss = 1.241, time/batch=0.129\n",
      "18787/67600 (epoch 13), train_loss = 1.189, time/batch=0.145\n",
      "18788/67600 (epoch 13), train_loss = 1.187, time/batch=0.145\n",
      "18789/67600 (epoch 13), train_loss = 1.225, time/batch=0.136\n",
      "18790/67600 (epoch 13), train_loss = 1.236, time/batch=0.110\n",
      "18791/67600 (epoch 13), train_loss = 1.204, time/batch=0.255\n",
      "18792/67600 (epoch 13), train_loss = 1.224, time/batch=0.184\n",
      "18793/67600 (epoch 13), train_loss = 1.228, time/batch=0.127\n",
      "18794/67600 (epoch 13), train_loss = 1.211, time/batch=0.122\n",
      "18795/67600 (epoch 13), train_loss = 1.213, time/batch=0.126\n",
      "18796/67600 (epoch 13), train_loss = 1.195, time/batch=0.110\n",
      "18797/67600 (epoch 13), train_loss = 1.197, time/batch=0.275\n",
      "18798/67600 (epoch 13), train_loss = 1.242, time/batch=0.168\n",
      "18799/67600 (epoch 13), train_loss = 1.198, time/batch=0.204\n",
      "18800/67600 (epoch 13), train_loss = 1.258, time/batch=0.106\n",
      "18801/67600 (epoch 13), train_loss = 1.235, time/batch=0.136\n",
      "18802/67600 (epoch 13), train_loss = 1.251, time/batch=0.131\n",
      "18803/67600 (epoch 13), train_loss = 1.218, time/batch=0.247\n",
      "18804/67600 (epoch 13), train_loss = 1.252, time/batch=0.144\n",
      "18805/67600 (epoch 13), train_loss = 1.197, time/batch=0.140\n",
      "18806/67600 (epoch 13), train_loss = 1.228, time/batch=0.174\n",
      "18807/67600 (epoch 13), train_loss = 1.230, time/batch=0.269\n",
      "18808/67600 (epoch 13), train_loss = 1.312, time/batch=0.165\n",
      "18809/67600 (epoch 13), train_loss = 1.273, time/batch=0.160\n",
      "18810/67600 (epoch 13), train_loss = 1.175, time/batch=0.132\n",
      "18811/67600 (epoch 13), train_loss = 1.210, time/batch=0.115\n",
      "18812/67600 (epoch 13), train_loss = 1.199, time/batch=0.164\n",
      "18813/67600 (epoch 13), train_loss = 1.231, time/batch=0.153\n",
      "18814/67600 (epoch 13), train_loss = 1.215, time/batch=0.155\n",
      "18815/67600 (epoch 13), train_loss = 1.197, time/batch=0.117\n",
      "18816/67600 (epoch 13), train_loss = 1.262, time/batch=0.137\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18817/67600 (epoch 13), train_loss = 1.197, time/batch=0.141\n",
      "18818/67600 (epoch 13), train_loss = 1.213, time/batch=0.114\n",
      "18819/67600 (epoch 13), train_loss = 1.245, time/batch=0.309\n",
      "18820/67600 (epoch 13), train_loss = 1.302, time/batch=0.148\n",
      "18821/67600 (epoch 13), train_loss = 1.231, time/batch=0.128\n",
      "18822/67600 (epoch 13), train_loss = 1.215, time/batch=0.119\n",
      "18823/67600 (epoch 13), train_loss = 1.210, time/batch=0.127\n",
      "18824/67600 (epoch 13), train_loss = 1.239, time/batch=0.144\n",
      "18825/67600 (epoch 13), train_loss = 1.211, time/batch=0.130\n",
      "18826/67600 (epoch 13), train_loss = 1.175, time/batch=0.261\n",
      "18827/67600 (epoch 13), train_loss = 1.279, time/batch=0.132\n",
      "18828/67600 (epoch 13), train_loss = 1.186, time/batch=0.128\n",
      "18829/67600 (epoch 13), train_loss = 1.266, time/batch=0.114\n",
      "18830/67600 (epoch 13), train_loss = 1.247, time/batch=0.174\n",
      "18831/67600 (epoch 13), train_loss = 1.262, time/batch=0.148\n",
      "18832/67600 (epoch 13), train_loss = 1.249, time/batch=0.237\n",
      "18833/67600 (epoch 13), train_loss = 1.242, time/batch=0.142\n",
      "18834/67600 (epoch 13), train_loss = 1.287, time/batch=0.123\n",
      "18835/67600 (epoch 13), train_loss = 1.216, time/batch=0.137\n",
      "18836/67600 (epoch 13), train_loss = 1.242, time/batch=0.132\n",
      "18837/67600 (epoch 13), train_loss = 1.203, time/batch=0.246\n",
      "18838/67600 (epoch 13), train_loss = 1.297, time/batch=0.147\n",
      "18839/67600 (epoch 13), train_loss = 1.283, time/batch=0.140\n",
      "18840/67600 (epoch 13), train_loss = 1.282, time/batch=0.176\n",
      "18841/67600 (epoch 13), train_loss = 1.214, time/batch=0.152\n",
      "18842/67600 (epoch 13), train_loss = 1.276, time/batch=0.104\n",
      "18843/67600 (epoch 13), train_loss = 1.190, time/batch=0.225\n",
      "18844/67600 (epoch 13), train_loss = 1.171, time/batch=0.170\n",
      "18845/67600 (epoch 13), train_loss = 1.227, time/batch=0.123\n",
      "18846/67600 (epoch 13), train_loss = 1.226, time/batch=0.154\n",
      "18847/67600 (epoch 13), train_loss = 1.163, time/batch=0.127\n",
      "18848/67600 (epoch 13), train_loss = 1.222, time/batch=0.105\n",
      "18849/67600 (epoch 13), train_loss = 1.210, time/batch=0.140\n",
      "18850/67600 (epoch 13), train_loss = 1.197, time/batch=0.239\n",
      "18851/67600 (epoch 13), train_loss = 1.241, time/batch=0.144\n",
      "18852/67600 (epoch 13), train_loss = 1.258, time/batch=0.152\n",
      "18853/67600 (epoch 13), train_loss = 1.234, time/batch=0.121\n",
      "18854/67600 (epoch 13), train_loss = 1.154, time/batch=0.135\n",
      "18855/67600 (epoch 13), train_loss = 1.176, time/batch=0.162\n",
      "18856/67600 (epoch 13), train_loss = 1.189, time/batch=0.216\n",
      "18857/67600 (epoch 13), train_loss = 1.215, time/batch=0.141\n",
      "18858/67600 (epoch 13), train_loss = 1.178, time/batch=0.123\n",
      "18859/67600 (epoch 13), train_loss = 1.231, time/batch=0.221\n",
      "18860/67600 (epoch 13), train_loss = 1.255, time/batch=0.143\n",
      "18861/67600 (epoch 13), train_loss = 1.214, time/batch=0.109\n",
      "18862/67600 (epoch 13), train_loss = 1.197, time/batch=0.315\n",
      "18863/67600 (epoch 13), train_loss = 1.272, time/batch=0.148\n",
      "18864/67600 (epoch 13), train_loss = 1.197, time/batch=0.115\n",
      "18865/67600 (epoch 13), train_loss = 1.252, time/batch=0.129\n",
      "18866/67600 (epoch 13), train_loss = 1.281, time/batch=0.164\n",
      "18867/67600 (epoch 13), train_loss = 1.248, time/batch=0.247\n",
      "18868/67600 (epoch 13), train_loss = 1.200, time/batch=0.179\n",
      "18869/67600 (epoch 13), train_loss = 1.204, time/batch=0.140\n",
      "18870/67600 (epoch 13), train_loss = 1.220, time/batch=0.106\n",
      "18871/67600 (epoch 13), train_loss = 1.216, time/batch=0.114\n",
      "18872/67600 (epoch 13), train_loss = 1.229, time/batch=0.143\n",
      "18873/67600 (epoch 13), train_loss = 1.240, time/batch=0.228\n",
      "18874/67600 (epoch 13), train_loss = 1.173, time/batch=0.145\n",
      "18875/67600 (epoch 13), train_loss = 1.247, time/batch=0.125\n",
      "18876/67600 (epoch 13), train_loss = 1.270, time/batch=0.132\n",
      "18877/67600 (epoch 13), train_loss = 1.228, time/batch=0.114\n",
      "18878/67600 (epoch 13), train_loss = 1.194, time/batch=0.137\n",
      "18879/67600 (epoch 13), train_loss = 1.219, time/batch=0.137\n",
      "18880/67600 (epoch 13), train_loss = 1.239, time/batch=0.235\n",
      "18881/67600 (epoch 13), train_loss = 1.160, time/batch=0.174\n",
      "18882/67600 (epoch 13), train_loss = 1.247, time/batch=0.120\n",
      "18883/67600 (epoch 13), train_loss = 1.239, time/batch=0.136\n",
      "18884/67600 (epoch 13), train_loss = 1.235, time/batch=0.117\n",
      "18885/67600 (epoch 13), train_loss = 1.230, time/batch=0.113\n",
      "18886/67600 (epoch 13), train_loss = 1.195, time/batch=0.140\n",
      "18887/67600 (epoch 13), train_loss = 1.207, time/batch=0.250\n",
      "18888/67600 (epoch 13), train_loss = 1.217, time/batch=0.177\n",
      "18889/67600 (epoch 13), train_loss = 1.287, time/batch=0.110\n",
      "18890/67600 (epoch 13), train_loss = 1.286, time/batch=0.110\n",
      "18891/67600 (epoch 13), train_loss = 1.234, time/batch=0.128\n",
      "18892/67600 (epoch 13), train_loss = 1.243, time/batch=0.108\n",
      "18893/67600 (epoch 13), train_loss = 1.255, time/batch=0.116\n",
      "18894/67600 (epoch 13), train_loss = 1.228, time/batch=0.257\n",
      "18895/67600 (epoch 13), train_loss = 1.198, time/batch=0.130\n",
      "18896/67600 (epoch 13), train_loss = 1.217, time/batch=0.135\n",
      "18897/67600 (epoch 13), train_loss = 1.215, time/batch=0.121\n",
      "18898/67600 (epoch 13), train_loss = 1.203, time/batch=0.101\n",
      "18899/67600 (epoch 13), train_loss = 1.223, time/batch=0.113\n",
      "18900/67600 (epoch 13), train_loss = 1.277, time/batch=0.118\n",
      "18901/67600 (epoch 13), train_loss = 1.218, time/batch=0.275\n",
      "18902/67600 (epoch 13), train_loss = 1.230, time/batch=0.113\n",
      "18903/67600 (epoch 13), train_loss = 1.213, time/batch=0.106\n",
      "18904/67600 (epoch 13), train_loss = 1.216, time/batch=0.126\n",
      "18905/67600 (epoch 13), train_loss = 1.234, time/batch=0.126\n",
      "18906/67600 (epoch 13), train_loss = 1.276, time/batch=0.131\n",
      "18907/67600 (epoch 13), train_loss = 1.268, time/batch=0.110\n",
      "18908/67600 (epoch 13), train_loss = 1.221, time/batch=0.118\n",
      "18909/67600 (epoch 13), train_loss = 1.202, time/batch=0.117\n",
      "18910/67600 (epoch 13), train_loss = 1.179, time/batch=0.110\n",
      "18911/67600 (epoch 13), train_loss = 1.247, time/batch=0.142\n",
      "18912/67600 (epoch 13), train_loss = 1.249, time/batch=0.273\n",
      "18913/67600 (epoch 13), train_loss = 1.232, time/batch=0.128\n",
      "18914/67600 (epoch 13), train_loss = 1.242, time/batch=0.127\n",
      "18915/67600 (epoch 13), train_loss = 1.215, time/batch=0.146\n",
      "18916/67600 (epoch 13), train_loss = 1.199, time/batch=0.124\n",
      "18917/67600 (epoch 13), train_loss = 1.223, time/batch=0.138\n",
      "18918/67600 (epoch 13), train_loss = 1.236, time/batch=0.144\n",
      "18919/67600 (epoch 13), train_loss = 1.221, time/batch=0.261\n",
      "18920/67600 (epoch 13), train_loss = 1.166, time/batch=0.145\n",
      "18921/67600 (epoch 13), train_loss = 1.221, time/batch=0.094\n",
      "18922/67600 (epoch 13), train_loss = 1.200, time/batch=0.120\n",
      "18923/67600 (epoch 13), train_loss = 1.226, time/batch=0.124\n",
      "18924/67600 (epoch 13), train_loss = 1.290, time/batch=0.126\n",
      "18925/67600 (epoch 13), train_loss = 1.314, time/batch=0.131\n",
      "18926/67600 (epoch 13), train_loss = 1.228, time/batch=0.230\n",
      "18927/67600 (epoch 13), train_loss = 1.246, time/batch=0.141\n",
      "18928/67600 (epoch 14), train_loss = 1.409, time/batch=0.131\n",
      "18929/67600 (epoch 14), train_loss = 1.174, time/batch=0.119\n",
      "18930/67600 (epoch 14), train_loss = 1.250, time/batch=0.176\n",
      "18931/67600 (epoch 14), train_loss = 1.210, time/batch=0.165\n",
      "18932/67600 (epoch 14), train_loss = 1.229, time/batch=0.168\n",
      "18933/67600 (epoch 14), train_loss = 1.251, time/batch=0.116\n",
      "18934/67600 (epoch 14), train_loss = 1.219, time/batch=0.163\n",
      "18935/67600 (epoch 14), train_loss = 1.225, time/batch=0.137\n",
      "18936/67600 (epoch 14), train_loss = 1.237, time/batch=0.138\n",
      "18937/67600 (epoch 14), train_loss = 1.215, time/batch=0.280\n",
      "18938/67600 (epoch 14), train_loss = 1.186, time/batch=0.164\n",
      "18939/67600 (epoch 14), train_loss = 1.196, time/batch=0.149\n",
      "18940/67600 (epoch 14), train_loss = 1.210, time/batch=0.110\n",
      "18941/67600 (epoch 14), train_loss = 1.273, time/batch=0.139\n",
      "18942/67600 (epoch 14), train_loss = 1.235, time/batch=0.143\n",
      "18943/67600 (epoch 14), train_loss = 1.217, time/batch=0.266\n",
      "18944/67600 (epoch 14), train_loss = 1.227, time/batch=0.170\n",
      "18945/67600 (epoch 14), train_loss = 1.234, time/batch=0.162\n",
      "18946/67600 (epoch 14), train_loss = 1.225, time/batch=0.130\n",
      "18947/67600 (epoch 14), train_loss = 1.212, time/batch=0.160\n",
      "18948/67600 (epoch 14), train_loss = 1.228, time/batch=0.131\n",
      "18949/67600 (epoch 14), train_loss = 1.157, time/batch=0.275\n",
      "18950/67600 (epoch 14), train_loss = 1.286, time/batch=0.173\n",
      "18951/67600 (epoch 14), train_loss = 1.254, time/batch=0.113\n",
      "18952/67600 (epoch 14), train_loss = 1.289, time/batch=0.155\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18953/67600 (epoch 14), train_loss = 1.154, time/batch=0.170\n",
      "18954/67600 (epoch 14), train_loss = 1.242, time/batch=0.109\n",
      "18955/67600 (epoch 14), train_loss = 1.254, time/batch=0.284\n",
      "18956/67600 (epoch 14), train_loss = 1.291, time/batch=0.167\n",
      "18957/67600 (epoch 14), train_loss = 1.213, time/batch=0.150\n",
      "18958/67600 (epoch 14), train_loss = 1.204, time/batch=0.167\n",
      "18959/67600 (epoch 14), train_loss = 1.284, time/batch=0.254\n",
      "18960/67600 (epoch 14), train_loss = 1.208, time/batch=0.132\n",
      "18961/67600 (epoch 14), train_loss = 1.274, time/batch=0.171\n",
      "18962/67600 (epoch 14), train_loss = 1.246, time/batch=0.127\n",
      "18963/67600 (epoch 14), train_loss = 1.232, time/batch=0.140\n",
      "18964/67600 (epoch 14), train_loss = 1.200, time/batch=0.115\n",
      "18965/67600 (epoch 14), train_loss = 1.239, time/batch=0.292\n",
      "18966/67600 (epoch 14), train_loss = 1.251, time/batch=0.121\n",
      "18967/67600 (epoch 14), train_loss = 1.228, time/batch=0.137\n",
      "18968/67600 (epoch 14), train_loss = 1.154, time/batch=0.132\n",
      "18969/67600 (epoch 14), train_loss = 1.258, time/batch=0.106\n",
      "18970/67600 (epoch 14), train_loss = 1.270, time/batch=0.129\n",
      "18971/67600 (epoch 14), train_loss = 1.246, time/batch=0.135\n",
      "18972/67600 (epoch 14), train_loss = 1.258, time/batch=0.233\n",
      "18973/67600 (epoch 14), train_loss = 1.223, time/batch=0.138\n",
      "18974/67600 (epoch 14), train_loss = 1.189, time/batch=0.135\n",
      "18975/67600 (epoch 14), train_loss = 1.230, time/batch=0.119\n",
      "18976/67600 (epoch 14), train_loss = 1.201, time/batch=0.115\n",
      "18977/67600 (epoch 14), train_loss = 1.193, time/batch=0.180\n",
      "18978/67600 (epoch 14), train_loss = 1.276, time/batch=0.122\n",
      "18979/67600 (epoch 14), train_loss = 1.199, time/batch=0.287\n",
      "18980/67600 (epoch 14), train_loss = 1.207, time/batch=0.115\n",
      "18981/67600 (epoch 14), train_loss = 1.298, time/batch=0.104\n",
      "18982/67600 (epoch 14), train_loss = 1.268, time/batch=0.115\n",
      "18983/67600 (epoch 14), train_loss = 1.227, time/batch=0.143\n",
      "18984/67600 (epoch 14), train_loss = 1.240, time/batch=0.130\n",
      "18985/67600 (epoch 14), train_loss = 1.232, time/batch=0.110\n",
      "18986/67600 (epoch 14), train_loss = 1.242, time/batch=0.240\n",
      "18987/67600 (epoch 14), train_loss = 1.232, time/batch=0.126\n",
      "18988/67600 (epoch 14), train_loss = 1.237, time/batch=0.115\n",
      "18989/67600 (epoch 14), train_loss = 1.212, time/batch=0.102\n",
      "18990/67600 (epoch 14), train_loss = 1.270, time/batch=0.139\n",
      "18991/67600 (epoch 14), train_loss = 1.268, time/batch=0.104\n",
      "18992/67600 (epoch 14), train_loss = 1.211, time/batch=0.103\n",
      "18993/67600 (epoch 14), train_loss = 1.210, time/batch=0.248\n",
      "18994/67600 (epoch 14), train_loss = 1.226, time/batch=0.113\n",
      "18995/67600 (epoch 14), train_loss = 1.244, time/batch=0.116\n",
      "18996/67600 (epoch 14), train_loss = 1.257, time/batch=0.111\n",
      "18997/67600 (epoch 14), train_loss = 1.252, time/batch=0.104\n",
      "18998/67600 (epoch 14), train_loss = 1.244, time/batch=0.119\n",
      "18999/67600 (epoch 14), train_loss = 1.251, time/batch=0.171\n",
      "19000/67600 (epoch 14), train_loss = 1.208, time/batch=0.108\n",
      "model saved to ./save/model.ckpt\n",
      "19001/67600 (epoch 14), train_loss = 1.284, time/batch=0.076\n",
      "19002/67600 (epoch 14), train_loss = 1.217, time/batch=0.106\n",
      "19003/67600 (epoch 14), train_loss = 1.268, time/batch=0.179\n",
      "19004/67600 (epoch 14), train_loss = 1.276, time/batch=0.111\n",
      "19005/67600 (epoch 14), train_loss = 1.353, time/batch=0.112\n",
      "19006/67600 (epoch 14), train_loss = 1.275, time/batch=0.156\n",
      "19007/67600 (epoch 14), train_loss = 1.203, time/batch=0.125\n",
      "19008/67600 (epoch 14), train_loss = 1.192, time/batch=0.247\n",
      "19009/67600 (epoch 14), train_loss = 1.241, time/batch=0.120\n",
      "19010/67600 (epoch 14), train_loss = 1.244, time/batch=0.126\n",
      "19011/67600 (epoch 14), train_loss = 1.217, time/batch=0.125\n",
      "19012/67600 (epoch 14), train_loss = 1.225, time/batch=0.112\n",
      "19013/67600 (epoch 14), train_loss = 1.226, time/batch=0.110\n",
      "19014/67600 (epoch 14), train_loss = 1.174, time/batch=0.112\n",
      "19015/67600 (epoch 14), train_loss = 1.282, time/batch=0.111\n",
      "19016/67600 (epoch 14), train_loss = 1.264, time/batch=0.106\n",
      "19017/67600 (epoch 14), train_loss = 1.259, time/batch=0.094\n",
      "19018/67600 (epoch 14), train_loss = 1.238, time/batch=0.275\n",
      "19019/67600 (epoch 14), train_loss = 1.259, time/batch=0.098\n",
      "19020/67600 (epoch 14), train_loss = 1.183, time/batch=0.132\n",
      "19021/67600 (epoch 14), train_loss = 1.205, time/batch=0.120\n",
      "19022/67600 (epoch 14), train_loss = 1.199, time/batch=0.110\n",
      "19023/67600 (epoch 14), train_loss = 1.145, time/batch=0.197\n",
      "19024/67600 (epoch 14), train_loss = 1.157, time/batch=0.149\n",
      "19025/67600 (epoch 14), train_loss = 1.235, time/batch=0.106\n",
      "19026/67600 (epoch 14), train_loss = 1.215, time/batch=0.118\n",
      "19027/67600 (epoch 14), train_loss = 1.255, time/batch=0.108\n",
      "19028/67600 (epoch 14), train_loss = 1.138, time/batch=0.107\n",
      "19029/67600 (epoch 14), train_loss = 1.217, time/batch=0.118\n",
      "19030/67600 (epoch 14), train_loss = 1.260, time/batch=0.105\n",
      "19031/67600 (epoch 14), train_loss = 1.159, time/batch=0.247\n",
      "19032/67600 (epoch 14), train_loss = 1.194, time/batch=0.138\n",
      "19033/67600 (epoch 14), train_loss = 1.238, time/batch=0.125\n",
      "19034/67600 (epoch 14), train_loss = 1.207, time/batch=0.115\n",
      "19035/67600 (epoch 14), train_loss = 1.240, time/batch=0.106\n",
      "19036/67600 (epoch 14), train_loss = 1.271, time/batch=0.105\n",
      "19037/67600 (epoch 14), train_loss = 1.236, time/batch=0.127\n",
      "19038/67600 (epoch 14), train_loss = 1.193, time/batch=0.189\n",
      "19039/67600 (epoch 14), train_loss = 1.236, time/batch=0.169\n",
      "19040/67600 (epoch 14), train_loss = 1.223, time/batch=0.135\n",
      "19041/67600 (epoch 14), train_loss = 1.253, time/batch=0.107\n",
      "19042/67600 (epoch 14), train_loss = 1.244, time/batch=0.111\n",
      "19043/67600 (epoch 14), train_loss = 1.190, time/batch=0.123\n",
      "19044/67600 (epoch 14), train_loss = 1.189, time/batch=0.122\n",
      "19045/67600 (epoch 14), train_loss = 1.222, time/batch=0.134\n",
      "19046/67600 (epoch 14), train_loss = 1.244, time/batch=0.237\n",
      "19047/67600 (epoch 14), train_loss = 1.242, time/batch=0.108\n",
      "19048/67600 (epoch 14), train_loss = 1.250, time/batch=0.110\n",
      "19049/67600 (epoch 14), train_loss = 1.248, time/batch=0.132\n",
      "19050/67600 (epoch 14), train_loss = 1.209, time/batch=0.103\n",
      "19051/67600 (epoch 14), train_loss = 1.190, time/batch=0.106\n",
      "19052/67600 (epoch 14), train_loss = 1.215, time/batch=0.119\n",
      "19053/67600 (epoch 14), train_loss = 1.147, time/batch=0.243\n",
      "19054/67600 (epoch 14), train_loss = 1.215, time/batch=0.109\n",
      "19055/67600 (epoch 14), train_loss = 1.257, time/batch=0.109\n",
      "19056/67600 (epoch 14), train_loss = 1.196, time/batch=0.125\n",
      "19057/67600 (epoch 14), train_loss = 1.215, time/batch=0.105\n",
      "19058/67600 (epoch 14), train_loss = 1.243, time/batch=0.129\n",
      "19059/67600 (epoch 14), train_loss = 1.217, time/batch=0.162\n",
      "19060/67600 (epoch 14), train_loss = 1.270, time/batch=0.106\n",
      "19061/67600 (epoch 14), train_loss = 1.204, time/batch=0.113\n",
      "19062/67600 (epoch 14), train_loss = 1.228, time/batch=0.116\n",
      "19063/67600 (epoch 14), train_loss = 1.228, time/batch=0.111\n",
      "19064/67600 (epoch 14), train_loss = 1.248, time/batch=0.105\n",
      "19065/67600 (epoch 14), train_loss = 1.238, time/batch=0.267\n",
      "19066/67600 (epoch 14), train_loss = 1.230, time/batch=0.125\n",
      "19067/67600 (epoch 14), train_loss = 1.204, time/batch=0.110\n",
      "19068/67600 (epoch 14), train_loss = 1.207, time/batch=0.115\n",
      "19069/67600 (epoch 14), train_loss = 1.187, time/batch=0.116\n",
      "19070/67600 (epoch 14), train_loss = 1.235, time/batch=0.112\n",
      "19071/67600 (epoch 14), train_loss = 1.189, time/batch=0.116\n",
      "19072/67600 (epoch 14), train_loss = 1.275, time/batch=0.102\n",
      "19073/67600 (epoch 14), train_loss = 1.313, time/batch=0.231\n",
      "19074/67600 (epoch 14), train_loss = 1.225, time/batch=0.126\n",
      "19075/67600 (epoch 14), train_loss = 1.210, time/batch=0.109\n",
      "19076/67600 (epoch 14), train_loss = 1.268, time/batch=0.117\n",
      "19077/67600 (epoch 14), train_loss = 1.167, time/batch=0.118\n",
      "19078/67600 (epoch 14), train_loss = 1.241, time/batch=0.112\n",
      "19079/67600 (epoch 14), train_loss = 1.185, time/batch=0.128\n",
      "19080/67600 (epoch 14), train_loss = 1.173, time/batch=0.164\n",
      "19081/67600 (epoch 14), train_loss = 1.237, time/batch=0.197\n",
      "19082/67600 (epoch 14), train_loss = 1.188, time/batch=0.115\n",
      "19083/67600 (epoch 14), train_loss = 1.242, time/batch=0.103\n",
      "19084/67600 (epoch 14), train_loss = 1.240, time/batch=0.113\n",
      "19085/67600 (epoch 14), train_loss = 1.257, time/batch=0.127\n",
      "19086/67600 (epoch 14), train_loss = 1.244, time/batch=0.191\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19087/67600 (epoch 14), train_loss = 1.208, time/batch=0.153\n",
      "19088/67600 (epoch 14), train_loss = 1.192, time/batch=0.111\n",
      "19089/67600 (epoch 14), train_loss = 1.177, time/batch=0.127\n",
      "19090/67600 (epoch 14), train_loss = 1.224, time/batch=0.109\n",
      "19091/67600 (epoch 14), train_loss = 1.212, time/batch=0.125\n",
      "19092/67600 (epoch 14), train_loss = 1.136, time/batch=0.126\n",
      "19093/67600 (epoch 14), train_loss = 1.218, time/batch=0.216\n",
      "19094/67600 (epoch 14), train_loss = 1.204, time/batch=0.166\n",
      "19095/67600 (epoch 14), train_loss = 1.186, time/batch=0.118\n",
      "19096/67600 (epoch 14), train_loss = 1.232, time/batch=0.141\n",
      "19097/67600 (epoch 14), train_loss = 1.240, time/batch=0.121\n",
      "19098/67600 (epoch 14), train_loss = 1.239, time/batch=0.117\n",
      "19099/67600 (epoch 14), train_loss = 1.190, time/batch=0.102\n",
      "19100/67600 (epoch 14), train_loss = 1.250, time/batch=0.147\n",
      "19101/67600 (epoch 14), train_loss = 1.200, time/batch=0.192\n",
      "19102/67600 (epoch 14), train_loss = 1.213, time/batch=0.145\n",
      "19103/67600 (epoch 14), train_loss = 1.173, time/batch=0.105\n",
      "19104/67600 (epoch 14), train_loss = 1.223, time/batch=0.120\n",
      "19105/67600 (epoch 14), train_loss = 1.262, time/batch=0.107\n",
      "19106/67600 (epoch 14), train_loss = 1.181, time/batch=0.110\n",
      "19107/67600 (epoch 14), train_loss = 1.197, time/batch=0.106\n",
      "19108/67600 (epoch 14), train_loss = 1.172, time/batch=0.188\n",
      "19109/67600 (epoch 14), train_loss = 1.164, time/batch=0.178\n",
      "19110/67600 (epoch 14), train_loss = 1.203, time/batch=0.127\n",
      "19111/67600 (epoch 14), train_loss = 1.309, time/batch=0.142\n",
      "19112/67600 (epoch 14), train_loss = 1.321, time/batch=0.107\n",
      "19113/67600 (epoch 14), train_loss = 1.278, time/batch=0.132\n",
      "19114/67600 (epoch 14), train_loss = 1.319, time/batch=0.111\n",
      "19115/67600 (epoch 14), train_loss = 1.220, time/batch=0.224\n",
      "19116/67600 (epoch 14), train_loss = 1.230, time/batch=0.155\n",
      "19117/67600 (epoch 14), train_loss = 1.216, time/batch=0.102\n",
      "19118/67600 (epoch 14), train_loss = 1.294, time/batch=0.126\n",
      "19119/67600 (epoch 14), train_loss = 1.259, time/batch=0.107\n",
      "19120/67600 (epoch 14), train_loss = 1.220, time/batch=0.128\n",
      "19121/67600 (epoch 14), train_loss = 1.261, time/batch=0.210\n",
      "19122/67600 (epoch 14), train_loss = 1.251, time/batch=0.137\n",
      "19123/67600 (epoch 14), train_loss = 1.229, time/batch=0.134\n",
      "19124/67600 (epoch 14), train_loss = 1.216, time/batch=0.106\n",
      "19125/67600 (epoch 14), train_loss = 1.216, time/batch=0.115\n",
      "19126/67600 (epoch 14), train_loss = 1.246, time/batch=0.112\n",
      "19127/67600 (epoch 14), train_loss = 1.189, time/batch=0.122\n",
      "19128/67600 (epoch 14), train_loss = 1.184, time/batch=0.170\n",
      "19129/67600 (epoch 14), train_loss = 1.159, time/batch=0.145\n",
      "19130/67600 (epoch 14), train_loss = 1.274, time/batch=0.142\n",
      "19131/67600 (epoch 14), train_loss = 1.227, time/batch=0.119\n",
      "19132/67600 (epoch 14), train_loss = 1.253, time/batch=0.098\n",
      "19133/67600 (epoch 14), train_loss = 1.161, time/batch=0.115\n",
      "19134/67600 (epoch 14), train_loss = 1.171, time/batch=0.117\n",
      "19135/67600 (epoch 14), train_loss = 1.186, time/batch=0.113\n",
      "19136/67600 (epoch 14), train_loss = 1.244, time/batch=0.232\n",
      "19137/67600 (epoch 14), train_loss = 1.271, time/batch=0.134\n",
      "19138/67600 (epoch 14), train_loss = 1.245, time/batch=0.113\n",
      "19139/67600 (epoch 14), train_loss = 1.288, time/batch=0.105\n",
      "19140/67600 (epoch 14), train_loss = 1.203, time/batch=0.113\n",
      "19141/67600 (epoch 14), train_loss = 1.211, time/batch=0.113\n",
      "19142/67600 (epoch 14), train_loss = 1.211, time/batch=0.123\n",
      "19143/67600 (epoch 14), train_loss = 1.253, time/batch=0.118\n",
      "19144/67600 (epoch 14), train_loss = 1.197, time/batch=0.224\n",
      "19145/67600 (epoch 14), train_loss = 1.204, time/batch=0.140\n",
      "19146/67600 (epoch 14), train_loss = 1.185, time/batch=0.132\n",
      "19147/67600 (epoch 14), train_loss = 1.169, time/batch=0.085\n",
      "19148/67600 (epoch 14), train_loss = 1.273, time/batch=0.116\n",
      "19149/67600 (epoch 14), train_loss = 1.194, time/batch=0.111\n",
      "19150/67600 (epoch 14), train_loss = 1.238, time/batch=0.120\n",
      "19151/67600 (epoch 14), train_loss = 1.227, time/batch=0.169\n",
      "19152/67600 (epoch 14), train_loss = 1.229, time/batch=0.174\n",
      "19153/67600 (epoch 14), train_loss = 1.198, time/batch=0.138\n",
      "19154/67600 (epoch 14), train_loss = 1.268, time/batch=0.114\n",
      "19155/67600 (epoch 14), train_loss = 1.180, time/batch=0.106\n",
      "19156/67600 (epoch 14), train_loss = 1.190, time/batch=0.123\n",
      "19157/67600 (epoch 14), train_loss = 1.200, time/batch=0.229\n",
      "19158/67600 (epoch 14), train_loss = 1.227, time/batch=0.133\n",
      "19159/67600 (epoch 14), train_loss = 1.226, time/batch=0.123\n",
      "19160/67600 (epoch 14), train_loss = 1.154, time/batch=0.113\n",
      "19161/67600 (epoch 14), train_loss = 1.160, time/batch=0.109\n",
      "19162/67600 (epoch 14), train_loss = 1.222, time/batch=0.109\n",
      "19163/67600 (epoch 14), train_loss = 1.218, time/batch=0.114\n",
      "19164/67600 (epoch 14), train_loss = 1.210, time/batch=0.124\n",
      "19165/67600 (epoch 14), train_loss = 1.214, time/batch=0.147\n",
      "19166/67600 (epoch 14), train_loss = 1.263, time/batch=0.103\n",
      "19167/67600 (epoch 14), train_loss = 1.238, time/batch=0.115\n",
      "19168/67600 (epoch 14), train_loss = 1.249, time/batch=0.109\n",
      "19169/67600 (epoch 14), train_loss = 1.175, time/batch=0.111\n",
      "19170/67600 (epoch 14), train_loss = 1.225, time/batch=0.113\n",
      "19171/67600 (epoch 14), train_loss = 1.229, time/batch=0.266\n",
      "19172/67600 (epoch 14), train_loss = 1.161, time/batch=0.125\n",
      "19173/67600 (epoch 14), train_loss = 1.229, time/batch=0.115\n",
      "19174/67600 (epoch 14), train_loss = 1.216, time/batch=0.119\n",
      "19175/67600 (epoch 14), train_loss = 1.224, time/batch=0.105\n",
      "19176/67600 (epoch 14), train_loss = 1.256, time/batch=0.113\n",
      "19177/67600 (epoch 14), train_loss = 1.191, time/batch=0.117\n",
      "19178/67600 (epoch 14), train_loss = 1.184, time/batch=0.111\n",
      "19179/67600 (epoch 14), train_loss = 1.277, time/batch=0.240\n",
      "19180/67600 (epoch 14), train_loss = 1.189, time/batch=0.114\n",
      "19181/67600 (epoch 14), train_loss = 1.225, time/batch=0.116\n",
      "19182/67600 (epoch 14), train_loss = 1.244, time/batch=0.110\n",
      "19183/67600 (epoch 14), train_loss = 1.287, time/batch=0.115\n",
      "19184/67600 (epoch 14), train_loss = 1.256, time/batch=0.116\n",
      "19185/67600 (epoch 14), train_loss = 1.268, time/batch=0.096\n",
      "19186/67600 (epoch 14), train_loss = 1.181, time/batch=0.161\n",
      "19187/67600 (epoch 14), train_loss = 1.181, time/batch=0.214\n",
      "19188/67600 (epoch 14), train_loss = 1.211, time/batch=0.109\n",
      "19189/67600 (epoch 14), train_loss = 1.193, time/batch=0.104\n",
      "19190/67600 (epoch 14), train_loss = 1.212, time/batch=0.122\n",
      "19191/67600 (epoch 14), train_loss = 1.222, time/batch=0.111\n",
      "19192/67600 (epoch 14), train_loss = 1.209, time/batch=0.211\n",
      "19193/67600 (epoch 14), train_loss = 1.199, time/batch=0.135\n",
      "19194/67600 (epoch 14), train_loss = 1.182, time/batch=0.130\n",
      "19195/67600 (epoch 14), train_loss = 1.229, time/batch=0.119\n",
      "19196/67600 (epoch 14), train_loss = 1.212, time/batch=0.111\n",
      "19197/67600 (epoch 14), train_loss = 1.191, time/batch=0.119\n",
      "19198/67600 (epoch 14), train_loss = 1.252, time/batch=0.103\n",
      "19199/67600 (epoch 14), train_loss = 1.215, time/batch=0.144\n",
      "19200/67600 (epoch 14), train_loss = 1.228, time/batch=0.178\n",
      "19201/67600 (epoch 14), train_loss = 1.255, time/batch=0.148\n",
      "19202/67600 (epoch 14), train_loss = 1.235, time/batch=0.121\n",
      "19203/67600 (epoch 14), train_loss = 1.220, time/batch=0.108\n",
      "19204/67600 (epoch 14), train_loss = 1.239, time/batch=0.123\n",
      "19205/67600 (epoch 14), train_loss = 1.194, time/batch=0.106\n",
      "19206/67600 (epoch 14), train_loss = 1.192, time/batch=0.120\n",
      "19207/67600 (epoch 14), train_loss = 1.240, time/batch=0.166\n",
      "19208/67600 (epoch 14), train_loss = 1.240, time/batch=0.143\n",
      "19209/67600 (epoch 14), train_loss = 1.195, time/batch=0.145\n",
      "19210/67600 (epoch 14), train_loss = 1.164, time/batch=0.117\n",
      "19211/67600 (epoch 14), train_loss = 1.250, time/batch=0.111\n",
      "19212/67600 (epoch 14), train_loss = 1.182, time/batch=0.109\n",
      "19213/67600 (epoch 14), train_loss = 1.300, time/batch=0.115\n",
      "19214/67600 (epoch 14), train_loss = 1.237, time/batch=0.111\n",
      "19215/67600 (epoch 14), train_loss = 1.217, time/batch=0.222\n",
      "19216/67600 (epoch 14), train_loss = 1.251, time/batch=0.126\n",
      "19217/67600 (epoch 14), train_loss = 1.244, time/batch=0.107\n",
      "19218/67600 (epoch 14), train_loss = 1.243, time/batch=0.112\n",
      "19219/67600 (epoch 14), train_loss = 1.231, time/batch=0.120\n",
      "19220/67600 (epoch 14), train_loss = 1.237, time/batch=0.110\n",
      "19221/67600 (epoch 14), train_loss = 1.218, time/batch=0.106\n",
      "19222/67600 (epoch 14), train_loss = 1.226, time/batch=0.112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19223/67600 (epoch 14), train_loss = 1.235, time/batch=0.236\n",
      "19224/67600 (epoch 14), train_loss = 1.239, time/batch=0.123\n",
      "19225/67600 (epoch 14), train_loss = 1.207, time/batch=0.114\n",
      "19226/67600 (epoch 14), train_loss = 1.199, time/batch=0.106\n",
      "19227/67600 (epoch 14), train_loss = 1.262, time/batch=0.110\n",
      "19228/67600 (epoch 14), train_loss = 1.222, time/batch=0.158\n",
      "19229/67600 (epoch 14), train_loss = 1.245, time/batch=0.149\n",
      "19230/67600 (epoch 14), train_loss = 1.209, time/batch=0.151\n",
      "19231/67600 (epoch 14), train_loss = 1.245, time/batch=0.107\n",
      "19232/67600 (epoch 14), train_loss = 1.247, time/batch=0.109\n",
      "19233/67600 (epoch 14), train_loss = 1.260, time/batch=0.111\n",
      "19234/67600 (epoch 14), train_loss = 1.276, time/batch=0.118\n",
      "19235/67600 (epoch 14), train_loss = 1.252, time/batch=0.112\n",
      "19236/67600 (epoch 14), train_loss = 1.259, time/batch=0.201\n",
      "19237/67600 (epoch 14), train_loss = 1.253, time/batch=0.114\n",
      "19238/67600 (epoch 14), train_loss = 1.218, time/batch=0.145\n",
      "19239/67600 (epoch 14), train_loss = 1.189, time/batch=0.109\n",
      "19240/67600 (epoch 14), train_loss = 1.196, time/batch=0.119\n",
      "19241/67600 (epoch 14), train_loss = 1.258, time/batch=0.104\n",
      "19242/67600 (epoch 14), train_loss = 1.228, time/batch=0.103\n",
      "19243/67600 (epoch 14), train_loss = 1.301, time/batch=0.119\n",
      "19244/67600 (epoch 14), train_loss = 1.207, time/batch=0.222\n",
      "19245/67600 (epoch 14), train_loss = 1.244, time/batch=0.130\n",
      "19246/67600 (epoch 14), train_loss = 1.247, time/batch=0.116\n",
      "19247/67600 (epoch 14), train_loss = 1.258, time/batch=0.112\n",
      "19248/67600 (epoch 14), train_loss = 1.273, time/batch=0.112\n",
      "19249/67600 (epoch 14), train_loss = 1.229, time/batch=0.137\n",
      "19250/67600 (epoch 14), train_loss = 1.226, time/batch=0.101\n",
      "19251/67600 (epoch 14), train_loss = 1.205, time/batch=0.118\n",
      "19252/67600 (epoch 14), train_loss = 1.211, time/batch=0.228\n",
      "19253/67600 (epoch 14), train_loss = 1.189, time/batch=0.129\n",
      "19254/67600 (epoch 14), train_loss = 1.177, time/batch=0.110\n",
      "19255/67600 (epoch 14), train_loss = 1.252, time/batch=0.112\n",
      "19256/67600 (epoch 14), train_loss = 1.208, time/batch=0.113\n",
      "19257/67600 (epoch 14), train_loss = 1.223, time/batch=0.106\n",
      "19258/67600 (epoch 14), train_loss = 1.267, time/batch=0.117\n",
      "19259/67600 (epoch 14), train_loss = 1.180, time/batch=0.113\n",
      "19260/67600 (epoch 14), train_loss = 1.231, time/batch=0.227\n",
      "19261/67600 (epoch 14), train_loss = 1.221, time/batch=0.134\n",
      "19262/67600 (epoch 14), train_loss = 1.249, time/batch=0.104\n",
      "19263/67600 (epoch 14), train_loss = 1.258, time/batch=0.117\n",
      "19264/67600 (epoch 14), train_loss = 1.212, time/batch=0.109\n",
      "19265/67600 (epoch 14), train_loss = 1.195, time/batch=0.112\n",
      "19266/67600 (epoch 14), train_loss = 1.223, time/batch=0.121\n",
      "19267/67600 (epoch 14), train_loss = 1.272, time/batch=0.174\n",
      "19268/67600 (epoch 14), train_loss = 1.223, time/batch=0.170\n",
      "19269/67600 (epoch 14), train_loss = 1.210, time/batch=0.114\n",
      "19270/67600 (epoch 14), train_loss = 1.192, time/batch=0.105\n",
      "19271/67600 (epoch 14), train_loss = 1.186, time/batch=0.118\n",
      "19272/67600 (epoch 14), train_loss = 1.273, time/batch=0.105\n",
      "19273/67600 (epoch 14), train_loss = 1.291, time/batch=0.152\n",
      "19274/67600 (epoch 14), train_loss = 1.234, time/batch=0.117\n",
      "19275/67600 (epoch 14), train_loss = 1.228, time/batch=0.099\n",
      "19276/67600 (epoch 14), train_loss = 1.263, time/batch=0.116\n",
      "19277/67600 (epoch 14), train_loss = 1.271, time/batch=0.102\n",
      "19278/67600 (epoch 14), train_loss = 1.190, time/batch=0.113\n",
      "19279/67600 (epoch 14), train_loss = 1.173, time/batch=0.157\n",
      "19280/67600 (epoch 14), train_loss = 1.167, time/batch=0.252\n",
      "19281/67600 (epoch 14), train_loss = 1.182, time/batch=0.134\n",
      "19282/67600 (epoch 14), train_loss = 1.199, time/batch=0.097\n",
      "19283/67600 (epoch 14), train_loss = 1.260, time/batch=0.125\n",
      "19284/67600 (epoch 14), train_loss = 1.204, time/batch=0.106\n",
      "19285/67600 (epoch 14), train_loss = 1.219, time/batch=0.108\n",
      "19286/67600 (epoch 14), train_loss = 1.178, time/batch=0.119\n",
      "19287/67600 (epoch 14), train_loss = 1.299, time/batch=0.254\n",
      "19288/67600 (epoch 14), train_loss = 1.222, time/batch=0.114\n",
      "19289/67600 (epoch 14), train_loss = 1.180, time/batch=0.109\n",
      "19290/67600 (epoch 14), train_loss = 1.183, time/batch=0.108\n",
      "19291/67600 (epoch 14), train_loss = 1.266, time/batch=0.107\n",
      "19292/67600 (epoch 14), train_loss = 1.226, time/batch=0.116\n",
      "19293/67600 (epoch 14), train_loss = 1.212, time/batch=0.103\n",
      "19294/67600 (epoch 14), train_loss = 1.212, time/batch=0.119\n",
      "19295/67600 (epoch 14), train_loss = 1.159, time/batch=0.226\n",
      "19296/67600 (epoch 14), train_loss = 1.208, time/batch=0.116\n",
      "19297/67600 (epoch 14), train_loss = 1.293, time/batch=0.137\n",
      "19298/67600 (epoch 14), train_loss = 1.219, time/batch=0.105\n",
      "19299/67600 (epoch 14), train_loss = 1.215, time/batch=0.103\n",
      "19300/67600 (epoch 14), train_loss = 1.251, time/batch=0.136\n",
      "19301/67600 (epoch 14), train_loss = 1.224, time/batch=0.186\n",
      "19302/67600 (epoch 14), train_loss = 1.271, time/batch=0.127\n",
      "19303/67600 (epoch 14), train_loss = 1.305, time/batch=0.128\n",
      "19304/67600 (epoch 14), train_loss = 1.244, time/batch=0.119\n",
      "19305/67600 (epoch 14), train_loss = 1.219, time/batch=0.107\n",
      "19306/67600 (epoch 14), train_loss = 1.303, time/batch=0.110\n",
      "19307/67600 (epoch 14), train_loss = 1.310, time/batch=0.110\n",
      "19308/67600 (epoch 14), train_loss = 1.262, time/batch=0.146\n",
      "19309/67600 (epoch 14), train_loss = 1.206, time/batch=0.177\n",
      "19310/67600 (epoch 14), train_loss = 1.206, time/batch=0.134\n",
      "19311/67600 (epoch 14), train_loss = 1.261, time/batch=0.114\n",
      "19312/67600 (epoch 14), train_loss = 1.296, time/batch=0.118\n",
      "19313/67600 (epoch 14), train_loss = 1.232, time/batch=0.115\n",
      "19314/67600 (epoch 14), train_loss = 1.212, time/batch=0.103\n",
      "19315/67600 (epoch 14), train_loss = 1.219, time/batch=0.115\n",
      "19316/67600 (epoch 14), train_loss = 1.252, time/batch=0.201\n",
      "19317/67600 (epoch 14), train_loss = 1.245, time/batch=0.116\n",
      "19318/67600 (epoch 14), train_loss = 1.224, time/batch=0.137\n",
      "19319/67600 (epoch 14), train_loss = 1.212, time/batch=0.118\n",
      "19320/67600 (epoch 14), train_loss = 1.202, time/batch=0.113\n",
      "19321/67600 (epoch 14), train_loss = 1.237, time/batch=0.114\n",
      "19322/67600 (epoch 14), train_loss = 1.210, time/batch=0.103\n",
      "19323/67600 (epoch 14), train_loss = 1.220, time/batch=0.109\n",
      "19324/67600 (epoch 14), train_loss = 1.272, time/batch=0.232\n",
      "19325/67600 (epoch 14), train_loss = 1.281, time/batch=0.148\n",
      "19326/67600 (epoch 14), train_loss = 1.222, time/batch=0.115\n",
      "19327/67600 (epoch 14), train_loss = 1.202, time/batch=0.109\n",
      "19328/67600 (epoch 14), train_loss = 1.250, time/batch=0.124\n",
      "19329/67600 (epoch 14), train_loss = 1.315, time/batch=0.104\n",
      "19330/67600 (epoch 14), train_loss = 1.277, time/batch=0.090\n",
      "19331/67600 (epoch 14), train_loss = 1.240, time/batch=0.129\n",
      "19332/67600 (epoch 14), train_loss = 1.307, time/batch=0.243\n",
      "19333/67600 (epoch 14), train_loss = 1.266, time/batch=0.126\n",
      "19334/67600 (epoch 14), train_loss = 1.270, time/batch=0.106\n",
      "19335/67600 (epoch 14), train_loss = 1.201, time/batch=0.112\n",
      "19336/67600 (epoch 14), train_loss = 1.256, time/batch=0.114\n",
      "19337/67600 (epoch 14), train_loss = 1.258, time/batch=0.204\n",
      "19338/67600 (epoch 14), train_loss = 1.260, time/batch=0.143\n",
      "19339/67600 (epoch 14), train_loss = 1.194, time/batch=0.111\n",
      "19340/67600 (epoch 14), train_loss = 1.228, time/batch=0.125\n",
      "19341/67600 (epoch 14), train_loss = 1.236, time/batch=0.107\n",
      "19342/67600 (epoch 14), train_loss = 1.207, time/batch=0.126\n",
      "19343/67600 (epoch 14), train_loss = 1.271, time/batch=0.109\n",
      "19344/67600 (epoch 14), train_loss = 1.227, time/batch=0.111\n",
      "19345/67600 (epoch 14), train_loss = 1.260, time/batch=0.203\n",
      "19346/67600 (epoch 14), train_loss = 1.285, time/batch=0.138\n",
      "19347/67600 (epoch 14), train_loss = 1.205, time/batch=0.126\n",
      "19348/67600 (epoch 14), train_loss = 1.150, time/batch=0.103\n",
      "19349/67600 (epoch 14), train_loss = 1.176, time/batch=0.113\n",
      "19350/67600 (epoch 14), train_loss = 1.225, time/batch=0.111\n",
      "19351/67600 (epoch 14), train_loss = 1.174, time/batch=0.110\n",
      "19352/67600 (epoch 14), train_loss = 1.227, time/batch=0.115\n",
      "19353/67600 (epoch 14), train_loss = 1.198, time/batch=0.208\n",
      "19354/67600 (epoch 14), train_loss = 1.222, time/batch=0.141\n",
      "19355/67600 (epoch 14), train_loss = 1.226, time/batch=0.107\n",
      "19356/67600 (epoch 14), train_loss = 1.145, time/batch=0.117\n",
      "19357/67600 (epoch 14), train_loss = 1.193, time/batch=0.114\n",
      "19358/67600 (epoch 14), train_loss = 1.258, time/batch=0.111\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19359/67600 (epoch 14), train_loss = 1.190, time/batch=0.116\n",
      "19360/67600 (epoch 14), train_loss = 1.250, time/batch=0.178\n",
      "19361/67600 (epoch 14), train_loss = 1.255, time/batch=0.166\n",
      "19362/67600 (epoch 14), train_loss = 1.187, time/batch=0.138\n",
      "19363/67600 (epoch 14), train_loss = 1.290, time/batch=0.113\n",
      "19364/67600 (epoch 14), train_loss = 1.222, time/batch=0.109\n",
      "19365/67600 (epoch 14), train_loss = 1.236, time/batch=0.104\n",
      "19366/67600 (epoch 14), train_loss = 1.239, time/batch=0.117\n",
      "19367/67600 (epoch 14), train_loss = 1.212, time/batch=0.114\n",
      "19368/67600 (epoch 14), train_loss = 1.216, time/batch=0.233\n",
      "19369/67600 (epoch 14), train_loss = 1.244, time/batch=0.112\n",
      "19370/67600 (epoch 14), train_loss = 1.205, time/batch=0.108\n",
      "19371/67600 (epoch 14), train_loss = 1.187, time/batch=0.104\n",
      "19372/67600 (epoch 14), train_loss = 1.241, time/batch=0.114\n",
      "19373/67600 (epoch 14), train_loss = 1.273, time/batch=0.114\n",
      "19374/67600 (epoch 14), train_loss = 1.180, time/batch=0.207\n",
      "19375/67600 (epoch 14), train_loss = 1.192, time/batch=0.162\n",
      "19376/67600 (epoch 14), train_loss = 1.162, time/batch=0.105\n",
      "19377/67600 (epoch 14), train_loss = 1.190, time/batch=0.130\n",
      "19378/67600 (epoch 14), train_loss = 1.143, time/batch=0.114\n",
      "19379/67600 (epoch 14), train_loss = 1.249, time/batch=0.112\n",
      "19380/67600 (epoch 14), train_loss = 1.271, time/batch=0.102\n",
      "19381/67600 (epoch 14), train_loss = 1.170, time/batch=0.143\n",
      "19382/67600 (epoch 14), train_loss = 1.148, time/batch=0.133\n",
      "19383/67600 (epoch 14), train_loss = 1.183, time/batch=0.118\n",
      "19384/67600 (epoch 14), train_loss = 1.213, time/batch=0.112\n",
      "19385/67600 (epoch 14), train_loss = 1.225, time/batch=0.112\n",
      "19386/67600 (epoch 14), train_loss = 1.248, time/batch=0.118\n",
      "19387/67600 (epoch 14), train_loss = 1.223, time/batch=0.104\n",
      "19388/67600 (epoch 14), train_loss = 1.233, time/batch=0.245\n",
      "19389/67600 (epoch 14), train_loss = 1.181, time/batch=0.134\n",
      "19390/67600 (epoch 14), train_loss = 1.251, time/batch=0.119\n",
      "19391/67600 (epoch 14), train_loss = 1.227, time/batch=0.116\n",
      "19392/67600 (epoch 14), train_loss = 1.197, time/batch=0.107\n",
      "19393/67600 (epoch 14), train_loss = 1.212, time/batch=0.100\n",
      "19394/67600 (epoch 14), train_loss = 1.201, time/batch=0.121\n",
      "19395/67600 (epoch 14), train_loss = 1.252, time/batch=0.106\n",
      "19396/67600 (epoch 14), train_loss = 1.218, time/batch=0.231\n",
      "19397/67600 (epoch 14), train_loss = 1.185, time/batch=0.132\n",
      "19398/67600 (epoch 14), train_loss = 1.209, time/batch=0.115\n",
      "19399/67600 (epoch 14), train_loss = 1.216, time/batch=0.108\n",
      "19400/67600 (epoch 14), train_loss = 1.181, time/batch=0.105\n",
      "19401/67600 (epoch 14), train_loss = 1.234, time/batch=0.112\n",
      "19402/67600 (epoch 14), train_loss = 1.185, time/batch=0.107\n",
      "19403/67600 (epoch 14), train_loss = 1.164, time/batch=0.114\n",
      "19404/67600 (epoch 14), train_loss = 1.248, time/batch=0.235\n",
      "19405/67600 (epoch 14), train_loss = 1.176, time/batch=0.113\n",
      "19406/67600 (epoch 14), train_loss = 1.216, time/batch=0.117\n",
      "19407/67600 (epoch 14), train_loss = 1.230, time/batch=0.106\n",
      "19408/67600 (epoch 14), train_loss = 1.182, time/batch=0.117\n",
      "19409/67600 (epoch 14), train_loss = 1.218, time/batch=0.191\n",
      "19410/67600 (epoch 14), train_loss = 1.193, time/batch=0.178\n",
      "19411/67600 (epoch 14), train_loss = 1.175, time/batch=0.106\n",
      "19412/67600 (epoch 14), train_loss = 1.231, time/batch=0.113\n",
      "19413/67600 (epoch 14), train_loss = 1.232, time/batch=0.111\n",
      "19414/67600 (epoch 14), train_loss = 1.255, time/batch=0.107\n",
      "19415/67600 (epoch 14), train_loss = 1.235, time/batch=0.094\n",
      "19416/67600 (epoch 14), train_loss = 1.266, time/batch=0.109\n",
      "19417/67600 (epoch 14), train_loss = 1.248, time/batch=0.190\n",
      "19418/67600 (epoch 14), train_loss = 1.184, time/batch=0.170\n",
      "19419/67600 (epoch 14), train_loss = 1.221, time/batch=0.097\n",
      "19420/67600 (epoch 14), train_loss = 1.241, time/batch=0.112\n",
      "19421/67600 (epoch 14), train_loss = 1.193, time/batch=0.115\n",
      "19422/67600 (epoch 14), train_loss = 1.272, time/batch=0.105\n",
      "19423/67600 (epoch 14), train_loss = 1.232, time/batch=0.126\n",
      "19424/67600 (epoch 14), train_loss = 1.208, time/batch=0.116\n",
      "19425/67600 (epoch 14), train_loss = 1.232, time/batch=0.211\n",
      "19426/67600 (epoch 14), train_loss = 1.279, time/batch=0.137\n",
      "19427/67600 (epoch 14), train_loss = 1.219, time/batch=0.105\n",
      "19428/67600 (epoch 14), train_loss = 1.169, time/batch=0.126\n",
      "19429/67600 (epoch 14), train_loss = 1.178, time/batch=0.103\n",
      "19430/67600 (epoch 14), train_loss = 1.194, time/batch=0.116\n",
      "19431/67600 (epoch 14), train_loss = 1.239, time/batch=0.110\n",
      "19432/67600 (epoch 14), train_loss = 1.241, time/batch=0.119\n",
      "19433/67600 (epoch 14), train_loss = 1.260, time/batch=0.221\n",
      "19434/67600 (epoch 14), train_loss = 1.236, time/batch=0.148\n",
      "19435/67600 (epoch 14), train_loss = 1.240, time/batch=0.111\n",
      "19436/67600 (epoch 14), train_loss = 1.185, time/batch=0.114\n",
      "19437/67600 (epoch 14), train_loss = 1.214, time/batch=0.105\n",
      "19438/67600 (epoch 14), train_loss = 1.237, time/batch=0.126\n",
      "19439/67600 (epoch 14), train_loss = 1.226, time/batch=0.104\n",
      "19440/67600 (epoch 14), train_loss = 1.235, time/batch=0.177\n",
      "19441/67600 (epoch 14), train_loss = 1.206, time/batch=0.168\n",
      "19442/67600 (epoch 14), train_loss = 1.230, time/batch=0.106\n",
      "19443/67600 (epoch 14), train_loss = 1.260, time/batch=0.118\n",
      "19444/67600 (epoch 14), train_loss = 1.265, time/batch=0.118\n",
      "19445/67600 (epoch 14), train_loss = 1.252, time/batch=0.103\n",
      "19446/67600 (epoch 14), train_loss = 1.232, time/batch=0.187\n",
      "19447/67600 (epoch 14), train_loss = 1.169, time/batch=0.155\n",
      "19448/67600 (epoch 14), train_loss = 1.275, time/batch=0.112\n",
      "19449/67600 (epoch 14), train_loss = 1.274, time/batch=0.110\n",
      "19450/67600 (epoch 14), train_loss = 1.287, time/batch=0.107\n",
      "19451/67600 (epoch 14), train_loss = 1.240, time/batch=0.112\n",
      "19452/67600 (epoch 14), train_loss = 1.224, time/batch=0.116\n",
      "19453/67600 (epoch 14), train_loss = 1.233, time/batch=0.110\n",
      "19454/67600 (epoch 14), train_loss = 1.245, time/batch=0.207\n",
      "19455/67600 (epoch 14), train_loss = 1.198, time/batch=0.138\n",
      "19456/67600 (epoch 14), train_loss = 1.254, time/batch=0.110\n",
      "19457/67600 (epoch 14), train_loss = 1.219, time/batch=0.118\n",
      "19458/67600 (epoch 14), train_loss = 1.271, time/batch=0.117\n",
      "19459/67600 (epoch 14), train_loss = 1.259, time/batch=0.101\n",
      "19460/67600 (epoch 14), train_loss = 1.250, time/batch=0.107\n",
      "19461/67600 (epoch 14), train_loss = 1.199, time/batch=0.126\n",
      "19462/67600 (epoch 14), train_loss = 1.209, time/batch=0.214\n",
      "19463/67600 (epoch 14), train_loss = 1.177, time/batch=0.135\n",
      "19464/67600 (epoch 14), train_loss = 1.200, time/batch=0.115\n",
      "19465/67600 (epoch 14), train_loss = 1.224, time/batch=0.113\n",
      "19466/67600 (epoch 14), train_loss = 1.222, time/batch=0.111\n",
      "19467/67600 (epoch 14), train_loss = 1.224, time/batch=0.107\n",
      "19468/67600 (epoch 14), train_loss = 1.229, time/batch=0.113\n",
      "19469/67600 (epoch 14), train_loss = 1.171, time/batch=0.106\n",
      "19470/67600 (epoch 14), train_loss = 1.200, time/batch=0.236\n",
      "19471/67600 (epoch 14), train_loss = 1.189, time/batch=0.124\n",
      "19472/67600 (epoch 14), train_loss = 1.268, time/batch=0.111\n",
      "19473/67600 (epoch 14), train_loss = 1.225, time/batch=0.116\n",
      "19474/67600 (epoch 14), train_loss = 1.215, time/batch=0.102\n",
      "19475/67600 (epoch 14), train_loss = 1.219, time/batch=0.108\n",
      "19476/67600 (epoch 14), train_loss = 1.342, time/batch=0.109\n",
      "19477/67600 (epoch 14), train_loss = 1.256, time/batch=0.159\n",
      "19478/67600 (epoch 14), train_loss = 1.205, time/batch=0.206\n",
      "19479/67600 (epoch 14), train_loss = 1.265, time/batch=0.098\n",
      "19480/67600 (epoch 14), train_loss = 1.210, time/batch=0.123\n",
      "19481/67600 (epoch 14), train_loss = 1.212, time/batch=0.112\n",
      "19482/67600 (epoch 14), train_loss = 1.256, time/batch=0.108\n",
      "19483/67600 (epoch 14), train_loss = 1.212, time/batch=0.129\n",
      "19484/67600 (epoch 14), train_loss = 1.275, time/batch=0.118\n",
      "19485/67600 (epoch 14), train_loss = 1.221, time/batch=0.246\n",
      "19486/67600 (epoch 14), train_loss = 1.203, time/batch=0.124\n",
      "19487/67600 (epoch 14), train_loss = 1.155, time/batch=0.108\n",
      "19488/67600 (epoch 14), train_loss = 1.195, time/batch=0.116\n",
      "19489/67600 (epoch 14), train_loss = 1.213, time/batch=0.145\n",
      "19490/67600 (epoch 14), train_loss = 1.172, time/batch=0.163\n",
      "19491/67600 (epoch 14), train_loss = 1.215, time/batch=0.127\n",
      "19492/67600 (epoch 14), train_loss = 1.187, time/batch=0.121\n",
      "19493/67600 (epoch 14), train_loss = 1.202, time/batch=0.106\n",
      "19494/67600 (epoch 14), train_loss = 1.223, time/batch=0.124\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19495/67600 (epoch 14), train_loss = 1.240, time/batch=0.095\n",
      "19496/67600 (epoch 14), train_loss = 1.235, time/batch=0.200\n",
      "19497/67600 (epoch 14), train_loss = 1.200, time/batch=0.182\n",
      "19498/67600 (epoch 14), train_loss = 1.183, time/batch=0.121\n",
      "19499/67600 (epoch 14), train_loss = 1.185, time/batch=0.116\n",
      "19500/67600 (epoch 14), train_loss = 1.208, time/batch=0.093\n",
      "model saved to ./save/model.ckpt\n",
      "19501/67600 (epoch 14), train_loss = 1.215, time/batch=0.070\n",
      "19502/67600 (epoch 14), train_loss = 1.231, time/batch=0.069\n",
      "19503/67600 (epoch 14), train_loss = 1.188, time/batch=0.189\n",
      "19504/67600 (epoch 14), train_loss = 1.236, time/batch=0.140\n",
      "19505/67600 (epoch 14), train_loss = 1.221, time/batch=0.099\n",
      "19506/67600 (epoch 14), train_loss = 1.247, time/batch=0.121\n",
      "19507/67600 (epoch 14), train_loss = 1.223, time/batch=0.118\n",
      "19508/67600 (epoch 14), train_loss = 1.255, time/batch=0.116\n",
      "19509/67600 (epoch 14), train_loss = 1.216, time/batch=0.107\n",
      "19510/67600 (epoch 14), train_loss = 1.175, time/batch=0.106\n",
      "19511/67600 (epoch 14), train_loss = 1.195, time/batch=0.239\n",
      "19512/67600 (epoch 14), train_loss = 1.215, time/batch=0.122\n",
      "19513/67600 (epoch 14), train_loss = 1.277, time/batch=0.120\n",
      "19514/67600 (epoch 14), train_loss = 1.199, time/batch=0.103\n",
      "19515/67600 (epoch 14), train_loss = 1.273, time/batch=0.106\n",
      "19516/67600 (epoch 14), train_loss = 1.192, time/batch=0.177\n",
      "19517/67600 (epoch 14), train_loss = 1.227, time/batch=0.141\n",
      "19518/67600 (epoch 14), train_loss = 1.276, time/batch=0.152\n",
      "19519/67600 (epoch 14), train_loss = 1.191, time/batch=0.115\n",
      "19520/67600 (epoch 14), train_loss = 1.192, time/batch=0.121\n",
      "19521/67600 (epoch 14), train_loss = 1.228, time/batch=0.102\n",
      "19522/67600 (epoch 14), train_loss = 1.171, time/batch=0.109\n",
      "19523/67600 (epoch 14), train_loss = 1.215, time/batch=0.118\n",
      "19524/67600 (epoch 14), train_loss = 1.235, time/batch=0.192\n",
      "19525/67600 (epoch 14), train_loss = 1.181, time/batch=0.132\n",
      "19526/67600 (epoch 14), train_loss = 1.217, time/batch=0.129\n",
      "19527/67600 (epoch 14), train_loss = 1.205, time/batch=0.125\n",
      "19528/67600 (epoch 14), train_loss = 1.246, time/batch=0.108\n",
      "19529/67600 (epoch 14), train_loss = 1.161, time/batch=0.114\n",
      "19530/67600 (epoch 14), train_loss = 1.222, time/batch=0.151\n",
      "19531/67600 (epoch 14), train_loss = 1.203, time/batch=0.192\n",
      "19532/67600 (epoch 14), train_loss = 1.238, time/batch=0.205\n",
      "19533/67600 (epoch 14), train_loss = 1.193, time/batch=0.110\n",
      "19534/67600 (epoch 14), train_loss = 1.269, time/batch=0.118\n",
      "19535/67600 (epoch 14), train_loss = 1.203, time/batch=0.125\n",
      "19536/67600 (epoch 14), train_loss = 1.285, time/batch=0.121\n",
      "19537/67600 (epoch 14), train_loss = 1.213, time/batch=0.115\n",
      "19538/67600 (epoch 14), train_loss = 1.244, time/batch=0.119\n",
      "19539/67600 (epoch 14), train_loss = 1.311, time/batch=0.323\n",
      "19540/67600 (epoch 14), train_loss = 1.220, time/batch=0.149\n",
      "19541/67600 (epoch 14), train_loss = 1.215, time/batch=0.118\n",
      "19542/67600 (epoch 14), train_loss = 1.251, time/batch=0.129\n",
      "19543/67600 (epoch 14), train_loss = 1.282, time/batch=0.132\n",
      "19544/67600 (epoch 14), train_loss = 1.233, time/batch=0.129\n",
      "19545/67600 (epoch 14), train_loss = 1.295, time/batch=0.280\n",
      "19546/67600 (epoch 14), train_loss = 1.225, time/batch=0.123\n",
      "19547/67600 (epoch 14), train_loss = 1.189, time/batch=0.155\n",
      "19548/67600 (epoch 14), train_loss = 1.173, time/batch=0.116\n",
      "19549/67600 (epoch 14), train_loss = 1.212, time/batch=0.234\n",
      "19550/67600 (epoch 14), train_loss = 1.226, time/batch=0.185\n",
      "19551/67600 (epoch 14), train_loss = 1.192, time/batch=0.110\n",
      "19552/67600 (epoch 14), train_loss = 1.224, time/batch=0.132\n",
      "19553/67600 (epoch 14), train_loss = 1.207, time/batch=0.121\n",
      "19554/67600 (epoch 14), train_loss = 1.256, time/batch=0.112\n",
      "19555/67600 (epoch 14), train_loss = 1.261, time/batch=0.122\n",
      "19556/67600 (epoch 14), train_loss = 1.257, time/batch=0.147\n",
      "19557/67600 (epoch 14), train_loss = 1.218, time/batch=0.120\n",
      "19558/67600 (epoch 14), train_loss = 1.262, time/batch=0.120\n",
      "19559/67600 (epoch 14), train_loss = 1.290, time/batch=0.139\n",
      "19560/67600 (epoch 14), train_loss = 1.205, time/batch=0.138\n",
      "19561/67600 (epoch 14), train_loss = 1.280, time/batch=0.100\n",
      "19562/67600 (epoch 14), train_loss = 1.267, time/batch=0.266\n",
      "19563/67600 (epoch 14), train_loss = 1.142, time/batch=0.146\n",
      "19564/67600 (epoch 14), train_loss = 1.307, time/batch=0.116\n",
      "19565/67600 (epoch 14), train_loss = 1.202, time/batch=0.131\n",
      "19566/67600 (epoch 14), train_loss = 1.159, time/batch=0.157\n",
      "19567/67600 (epoch 14), train_loss = 1.153, time/batch=0.148\n",
      "19568/67600 (epoch 14), train_loss = 1.224, time/batch=0.106\n",
      "19569/67600 (epoch 14), train_loss = 1.202, time/batch=0.292\n",
      "19570/67600 (epoch 14), train_loss = 1.257, time/batch=0.116\n",
      "19571/67600 (epoch 14), train_loss = 1.304, time/batch=0.132\n",
      "19572/67600 (epoch 14), train_loss = 1.273, time/batch=0.119\n",
      "19573/67600 (epoch 14), train_loss = 1.227, time/batch=0.143\n",
      "19574/67600 (epoch 14), train_loss = 1.259, time/batch=0.246\n",
      "19575/67600 (epoch 14), train_loss = 1.245, time/batch=0.143\n",
      "19576/67600 (epoch 14), train_loss = 1.270, time/batch=0.124\n",
      "19577/67600 (epoch 14), train_loss = 1.235, time/batch=0.153\n",
      "19578/67600 (epoch 14), train_loss = 1.274, time/batch=0.116\n",
      "19579/67600 (epoch 14), train_loss = 1.300, time/batch=0.111\n",
      "19580/67600 (epoch 14), train_loss = 1.221, time/batch=0.135\n",
      "19581/67600 (epoch 14), train_loss = 1.219, time/batch=0.220\n",
      "19582/67600 (epoch 14), train_loss = 1.244, time/batch=0.155\n",
      "19583/67600 (epoch 14), train_loss = 1.222, time/batch=0.101\n",
      "19584/67600 (epoch 14), train_loss = 1.214, time/batch=0.114\n",
      "19585/67600 (epoch 14), train_loss = 1.295, time/batch=0.115\n",
      "19586/67600 (epoch 14), train_loss = 1.244, time/batch=0.124\n",
      "19587/67600 (epoch 14), train_loss = 1.167, time/batch=0.117\n",
      "19588/67600 (epoch 14), train_loss = 1.216, time/batch=0.209\n",
      "19589/67600 (epoch 14), train_loss = 1.214, time/batch=0.151\n",
      "19590/67600 (epoch 14), train_loss = 1.141, time/batch=0.108\n",
      "19591/67600 (epoch 14), train_loss = 1.175, time/batch=0.107\n",
      "19592/67600 (epoch 14), train_loss = 1.258, time/batch=0.111\n",
      "19593/67600 (epoch 14), train_loss = 1.238, time/batch=0.107\n",
      "19594/67600 (epoch 14), train_loss = 1.248, time/batch=0.108\n",
      "19595/67600 (epoch 14), train_loss = 1.217, time/batch=0.107\n",
      "19596/67600 (epoch 14), train_loss = 1.281, time/batch=0.211\n",
      "19597/67600 (epoch 14), train_loss = 1.189, time/batch=0.141\n",
      "19598/67600 (epoch 14), train_loss = 1.144, time/batch=0.118\n",
      "19599/67600 (epoch 14), train_loss = 1.198, time/batch=0.125\n",
      "19600/67600 (epoch 14), train_loss = 1.140, time/batch=0.107\n",
      "19601/67600 (epoch 14), train_loss = 1.283, time/batch=0.125\n",
      "19602/67600 (epoch 14), train_loss = 1.270, time/batch=0.112\n",
      "19603/67600 (epoch 14), train_loss = 1.194, time/batch=0.141\n",
      "19604/67600 (epoch 14), train_loss = 1.230, time/batch=0.214\n",
      "19605/67600 (epoch 14), train_loss = 1.261, time/batch=0.127\n",
      "19606/67600 (epoch 14), train_loss = 1.274, time/batch=0.113\n",
      "19607/67600 (epoch 14), train_loss = 1.210, time/batch=0.103\n",
      "19608/67600 (epoch 14), train_loss = 1.227, time/batch=0.107\n",
      "19609/67600 (epoch 14), train_loss = 1.248, time/batch=0.112\n",
      "19610/67600 (epoch 14), train_loss = 1.249, time/batch=0.106\n",
      "19611/67600 (epoch 14), train_loss = 1.216, time/batch=0.222\n",
      "19612/67600 (epoch 14), train_loss = 1.197, time/batch=0.129\n",
      "19613/67600 (epoch 14), train_loss = 1.280, time/batch=0.114\n",
      "19614/67600 (epoch 14), train_loss = 1.245, time/batch=0.116\n",
      "19615/67600 (epoch 14), train_loss = 1.185, time/batch=0.102\n",
      "19616/67600 (epoch 14), train_loss = 1.229, time/batch=0.141\n",
      "19617/67600 (epoch 14), train_loss = 1.175, time/batch=0.202\n",
      "19618/67600 (epoch 14), train_loss = 1.222, time/batch=0.139\n",
      "19619/67600 (epoch 14), train_loss = 1.213, time/batch=0.123\n",
      "19620/67600 (epoch 14), train_loss = 1.205, time/batch=0.120\n",
      "19621/67600 (epoch 14), train_loss = 1.254, time/batch=0.106\n",
      "19622/67600 (epoch 14), train_loss = 1.231, time/batch=0.111\n",
      "19623/67600 (epoch 14), train_loss = 1.149, time/batch=0.109\n",
      "19624/67600 (epoch 14), train_loss = 1.243, time/batch=0.143\n",
      "19625/67600 (epoch 14), train_loss = 1.258, time/batch=0.184\n",
      "19626/67600 (epoch 14), train_loss = 1.250, time/batch=0.145\n",
      "19627/67600 (epoch 14), train_loss = 1.181, time/batch=0.120\n",
      "19628/67600 (epoch 14), train_loss = 1.226, time/batch=0.100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19629/67600 (epoch 14), train_loss = 1.255, time/batch=0.108\n",
      "19630/67600 (epoch 14), train_loss = 1.215, time/batch=0.102\n",
      "19631/67600 (epoch 14), train_loss = 1.172, time/batch=0.124\n",
      "19632/67600 (epoch 14), train_loss = 1.222, time/batch=0.186\n",
      "19633/67600 (epoch 14), train_loss = 1.202, time/batch=0.174\n",
      "19634/67600 (epoch 14), train_loss = 1.209, time/batch=0.109\n",
      "19635/67600 (epoch 14), train_loss = 1.247, time/batch=0.108\n",
      "19636/67600 (epoch 14), train_loss = 1.236, time/batch=0.116\n",
      "19637/67600 (epoch 14), train_loss = 1.188, time/batch=0.107\n",
      "19638/67600 (epoch 14), train_loss = 1.226, time/batch=0.118\n",
      "19639/67600 (epoch 14), train_loss = 1.130, time/batch=0.130\n",
      "19640/67600 (epoch 14), train_loss = 1.218, time/batch=0.219\n",
      "19641/67600 (epoch 14), train_loss = 1.209, time/batch=0.135\n",
      "19642/67600 (epoch 14), train_loss = 1.209, time/batch=0.119\n",
      "19643/67600 (epoch 14), train_loss = 1.194, time/batch=0.124\n",
      "19644/67600 (epoch 14), train_loss = 1.169, time/batch=0.129\n",
      "19645/67600 (epoch 14), train_loss = 1.217, time/batch=0.184\n",
      "19646/67600 (epoch 14), train_loss = 1.199, time/batch=0.167\n",
      "19647/67600 (epoch 14), train_loss = 1.204, time/batch=0.123\n",
      "19648/67600 (epoch 14), train_loss = 1.212, time/batch=0.150\n",
      "19649/67600 (epoch 14), train_loss = 1.243, time/batch=0.109\n",
      "19650/67600 (epoch 14), train_loss = 1.217, time/batch=0.118\n",
      "19651/67600 (epoch 14), train_loss = 1.235, time/batch=0.113\n",
      "19652/67600 (epoch 14), train_loss = 1.226, time/batch=0.108\n",
      "19653/67600 (epoch 14), train_loss = 1.233, time/batch=0.159\n",
      "19654/67600 (epoch 14), train_loss = 1.225, time/batch=0.219\n",
      "19655/67600 (epoch 14), train_loss = 1.229, time/batch=0.182\n",
      "19656/67600 (epoch 14), train_loss = 1.245, time/batch=0.120\n",
      "19657/67600 (epoch 14), train_loss = 1.211, time/batch=0.112\n",
      "19658/67600 (epoch 14), train_loss = 1.232, time/batch=0.107\n",
      "19659/67600 (epoch 14), train_loss = 1.250, time/batch=0.119\n",
      "19660/67600 (epoch 14), train_loss = 1.237, time/batch=0.138\n",
      "19661/67600 (epoch 14), train_loss = 1.228, time/batch=0.150\n",
      "19662/67600 (epoch 14), train_loss = 1.228, time/batch=0.109\n",
      "19663/67600 (epoch 14), train_loss = 1.180, time/batch=0.111\n",
      "19664/67600 (epoch 14), train_loss = 1.281, time/batch=0.113\n",
      "19665/67600 (epoch 14), train_loss = 1.203, time/batch=0.122\n",
      "19666/67600 (epoch 14), train_loss = 1.180, time/batch=0.291\n",
      "19667/67600 (epoch 14), train_loss = 1.253, time/batch=0.160\n",
      "19668/67600 (epoch 14), train_loss = 1.163, time/batch=0.133\n",
      "19669/67600 (epoch 14), train_loss = 1.171, time/batch=0.129\n",
      "19670/67600 (epoch 14), train_loss = 1.162, time/batch=0.125\n",
      "19671/67600 (epoch 14), train_loss = 1.207, time/batch=0.117\n",
      "19672/67600 (epoch 14), train_loss = 1.239, time/batch=0.136\n",
      "19673/67600 (epoch 14), train_loss = 1.231, time/batch=0.236\n",
      "19674/67600 (epoch 14), train_loss = 1.206, time/batch=0.117\n",
      "19675/67600 (epoch 14), train_loss = 1.214, time/batch=0.116\n",
      "19676/67600 (epoch 14), train_loss = 1.229, time/batch=0.109\n",
      "19677/67600 (epoch 14), train_loss = 1.192, time/batch=0.118\n",
      "19678/67600 (epoch 14), train_loss = 1.152, time/batch=0.114\n",
      "19679/67600 (epoch 14), train_loss = 1.193, time/batch=0.132\n",
      "19680/67600 (epoch 14), train_loss = 1.210, time/batch=0.250\n",
      "19681/67600 (epoch 14), train_loss = 1.267, time/batch=0.101\n",
      "19682/67600 (epoch 14), train_loss = 1.209, time/batch=0.130\n",
      "19683/67600 (epoch 14), train_loss = 1.218, time/batch=0.116\n",
      "19684/67600 (epoch 14), train_loss = 1.282, time/batch=0.121\n",
      "19685/67600 (epoch 14), train_loss = 1.227, time/batch=0.221\n",
      "19686/67600 (epoch 14), train_loss = 1.200, time/batch=0.127\n",
      "19687/67600 (epoch 14), train_loss = 1.190, time/batch=0.148\n",
      "19688/67600 (epoch 14), train_loss = 1.206, time/batch=0.181\n",
      "19689/67600 (epoch 14), train_loss = 1.206, time/batch=0.128\n",
      "19690/67600 (epoch 14), train_loss = 1.204, time/batch=0.145\n",
      "19691/67600 (epoch 14), train_loss = 1.247, time/batch=0.114\n",
      "19692/67600 (epoch 14), train_loss = 1.270, time/batch=0.252\n",
      "19693/67600 (epoch 14), train_loss = 1.186, time/batch=0.155\n",
      "19694/67600 (epoch 14), train_loss = 1.227, time/batch=0.128\n",
      "19695/67600 (epoch 14), train_loss = 1.209, time/batch=0.131\n",
      "19696/67600 (epoch 14), train_loss = 1.247, time/batch=0.106\n",
      "19697/67600 (epoch 14), train_loss = 1.240, time/batch=0.127\n",
      "19698/67600 (epoch 14), train_loss = 1.204, time/batch=0.131\n",
      "19699/67600 (epoch 14), train_loss = 1.262, time/batch=0.232\n",
      "19700/67600 (epoch 14), train_loss = 1.232, time/batch=0.125\n",
      "19701/67600 (epoch 14), train_loss = 1.210, time/batch=0.125\n",
      "19702/67600 (epoch 14), train_loss = 1.251, time/batch=0.140\n",
      "19703/67600 (epoch 14), train_loss = 1.288, time/batch=0.143\n",
      "19704/67600 (epoch 14), train_loss = 1.256, time/batch=0.148\n",
      "19705/67600 (epoch 14), train_loss = 1.239, time/batch=0.267\n",
      "19706/67600 (epoch 14), train_loss = 1.216, time/batch=0.133\n",
      "19707/67600 (epoch 14), train_loss = 1.242, time/batch=0.138\n",
      "19708/67600 (epoch 14), train_loss = 1.283, time/batch=0.107\n",
      "19709/67600 (epoch 14), train_loss = 1.217, time/batch=0.157\n",
      "19710/67600 (epoch 14), train_loss = 1.207, time/batch=0.146\n",
      "19711/67600 (epoch 14), train_loss = 1.226, time/batch=0.273\n",
      "19712/67600 (epoch 14), train_loss = 1.209, time/batch=0.125\n",
      "19713/67600 (epoch 14), train_loss = 1.246, time/batch=0.120\n",
      "19714/67600 (epoch 14), train_loss = 1.214, time/batch=0.126\n",
      "19715/67600 (epoch 14), train_loss = 1.231, time/batch=0.135\n",
      "19716/67600 (epoch 14), train_loss = 1.238, time/batch=0.172\n",
      "19717/67600 (epoch 14), train_loss = 1.179, time/batch=0.189\n",
      "19718/67600 (epoch 14), train_loss = 1.217, time/batch=0.135\n",
      "19719/67600 (epoch 14), train_loss = 1.230, time/batch=0.132\n",
      "19720/67600 (epoch 14), train_loss = 1.192, time/batch=0.117\n",
      "19721/67600 (epoch 14), train_loss = 1.247, time/batch=0.111\n",
      "19722/67600 (epoch 14), train_loss = 1.222, time/batch=0.106\n",
      "19723/67600 (epoch 14), train_loss = 1.227, time/batch=0.121\n",
      "19724/67600 (epoch 14), train_loss = 1.295, time/batch=0.204\n",
      "19725/67600 (epoch 14), train_loss = 1.236, time/batch=0.131\n",
      "19726/67600 (epoch 14), train_loss = 1.271, time/batch=0.113\n",
      "19727/67600 (epoch 14), train_loss = 1.223, time/batch=0.118\n",
      "19728/67600 (epoch 14), train_loss = 1.233, time/batch=0.105\n",
      "19729/67600 (epoch 14), train_loss = 1.218, time/batch=0.109\n",
      "19730/67600 (epoch 14), train_loss = 1.192, time/batch=0.110\n",
      "19731/67600 (epoch 14), train_loss = 1.216, time/batch=0.178\n",
      "19732/67600 (epoch 14), train_loss = 1.196, time/batch=0.190\n",
      "19733/67600 (epoch 14), train_loss = 1.172, time/batch=0.151\n",
      "19734/67600 (epoch 14), train_loss = 1.221, time/batch=0.134\n",
      "19735/67600 (epoch 14), train_loss = 1.199, time/batch=0.122\n",
      "19736/67600 (epoch 14), train_loss = 1.141, time/batch=0.111\n",
      "19737/67600 (epoch 14), train_loss = 1.244, time/batch=0.107\n",
      "19738/67600 (epoch 14), train_loss = 1.184, time/batch=0.328\n",
      "19739/67600 (epoch 14), train_loss = 1.252, time/batch=0.111\n",
      "19740/67600 (epoch 14), train_loss = 1.242, time/batch=0.161\n",
      "19741/67600 (epoch 14), train_loss = 1.230, time/batch=0.138\n",
      "19742/67600 (epoch 14), train_loss = 1.266, time/batch=0.110\n",
      "19743/67600 (epoch 14), train_loss = 1.175, time/batch=0.137\n",
      "19744/67600 (epoch 14), train_loss = 1.261, time/batch=0.113\n",
      "19745/67600 (epoch 14), train_loss = 1.198, time/batch=0.297\n",
      "19746/67600 (epoch 14), train_loss = 1.197, time/batch=0.129\n",
      "19747/67600 (epoch 14), train_loss = 1.220, time/batch=0.139\n",
      "19748/67600 (epoch 14), train_loss = 1.153, time/batch=0.130\n",
      "19749/67600 (epoch 14), train_loss = 1.257, time/batch=0.168\n",
      "19750/67600 (epoch 14), train_loss = 1.217, time/batch=0.218\n",
      "19751/67600 (epoch 14), train_loss = 1.289, time/batch=0.131\n",
      "19752/67600 (epoch 14), train_loss = 1.232, time/batch=0.136\n",
      "19753/67600 (epoch 14), train_loss = 1.266, time/batch=0.119\n",
      "19754/67600 (epoch 14), train_loss = 1.357, time/batch=0.135\n",
      "19755/67600 (epoch 14), train_loss = 1.194, time/batch=0.144\n",
      "19756/67600 (epoch 14), train_loss = 1.218, time/batch=0.207\n",
      "19757/67600 (epoch 14), train_loss = 1.255, time/batch=0.115\n",
      "19758/67600 (epoch 14), train_loss = 1.300, time/batch=0.115\n",
      "19759/67600 (epoch 14), train_loss = 1.207, time/batch=0.129\n",
      "19760/67600 (epoch 14), train_loss = 1.218, time/batch=0.123\n",
      "19761/67600 (epoch 14), train_loss = 1.221, time/batch=0.171\n",
      "19762/67600 (epoch 14), train_loss = 1.194, time/batch=0.231\n",
      "19763/67600 (epoch 14), train_loss = 1.265, time/batch=0.133\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19764/67600 (epoch 14), train_loss = 1.125, time/batch=0.147\n",
      "19765/67600 (epoch 14), train_loss = 1.246, time/batch=0.117\n",
      "19766/67600 (epoch 14), train_loss = 1.159, time/batch=0.107\n",
      "19767/67600 (epoch 14), train_loss = 1.216, time/batch=0.112\n",
      "19768/67600 (epoch 14), train_loss = 1.276, time/batch=0.124\n",
      "19769/67600 (epoch 14), train_loss = 1.232, time/batch=0.264\n",
      "19770/67600 (epoch 14), train_loss = 1.229, time/batch=0.122\n",
      "19771/67600 (epoch 14), train_loss = 1.225, time/batch=0.138\n",
      "19772/67600 (epoch 14), train_loss = 1.220, time/batch=0.117\n",
      "19773/67600 (epoch 14), train_loss = 1.206, time/batch=0.110\n",
      "19774/67600 (epoch 14), train_loss = 1.198, time/batch=0.111\n",
      "19775/67600 (epoch 14), train_loss = 1.209, time/batch=0.123\n",
      "19776/67600 (epoch 14), train_loss = 1.242, time/batch=0.265\n",
      "19777/67600 (epoch 14), train_loss = 1.214, time/batch=0.119\n",
      "19778/67600 (epoch 14), train_loss = 1.222, time/batch=0.113\n",
      "19779/67600 (epoch 14), train_loss = 1.299, time/batch=0.131\n",
      "19780/67600 (epoch 14), train_loss = 1.299, time/batch=0.114\n",
      "19781/67600 (epoch 14), train_loss = 1.278, time/batch=0.265\n",
      "19782/67600 (epoch 14), train_loss = 1.223, time/batch=0.168\n",
      "19783/67600 (epoch 14), train_loss = 1.255, time/batch=0.107\n",
      "19784/67600 (epoch 14), train_loss = 1.226, time/batch=0.124\n",
      "19785/67600 (epoch 14), train_loss = 1.247, time/batch=0.110\n",
      "19786/67600 (epoch 14), train_loss = 1.247, time/batch=0.106\n",
      "19787/67600 (epoch 14), train_loss = 1.271, time/batch=0.097\n",
      "19788/67600 (epoch 14), train_loss = 1.221, time/batch=0.224\n",
      "19789/67600 (epoch 14), train_loss = 1.278, time/batch=0.154\n",
      "19790/67600 (epoch 14), train_loss = 1.298, time/batch=0.112\n",
      "19791/67600 (epoch 14), train_loss = 1.252, time/batch=0.101\n",
      "19792/67600 (epoch 14), train_loss = 1.192, time/batch=0.122\n",
      "19793/67600 (epoch 14), train_loss = 1.286, time/batch=0.114\n",
      "19794/67600 (epoch 14), train_loss = 1.268, time/batch=0.113\n",
      "19795/67600 (epoch 14), train_loss = 1.205, time/batch=0.118\n",
      "19796/67600 (epoch 14), train_loss = 1.231, time/batch=0.211\n",
      "19797/67600 (epoch 14), train_loss = 1.225, time/batch=0.144\n",
      "19798/67600 (epoch 14), train_loss = 1.225, time/batch=0.129\n",
      "19799/67600 (epoch 14), train_loss = 1.201, time/batch=0.096\n",
      "19800/67600 (epoch 14), train_loss = 1.257, time/batch=0.135\n",
      "19801/67600 (epoch 14), train_loss = 1.183, time/batch=0.111\n",
      "19802/67600 (epoch 14), train_loss = 1.225, time/batch=0.111\n",
      "19803/67600 (epoch 14), train_loss = 1.280, time/batch=0.189\n",
      "19804/67600 (epoch 14), train_loss = 1.270, time/batch=0.150\n",
      "19805/67600 (epoch 14), train_loss = 1.136, time/batch=0.139\n",
      "19806/67600 (epoch 14), train_loss = 1.227, time/batch=0.100\n",
      "19807/67600 (epoch 14), train_loss = 1.129, time/batch=0.093\n",
      "19808/67600 (epoch 14), train_loss = 1.184, time/batch=0.096\n",
      "19809/67600 (epoch 14), train_loss = 1.198, time/batch=0.110\n",
      "19810/67600 (epoch 14), train_loss = 1.198, time/batch=0.111\n",
      "19811/67600 (epoch 14), train_loss = 1.225, time/batch=0.162\n",
      "19812/67600 (epoch 14), train_loss = 1.195, time/batch=0.180\n",
      "19813/67600 (epoch 14), train_loss = 1.217, time/batch=0.112\n",
      "19814/67600 (epoch 14), train_loss = 1.196, time/batch=0.119\n",
      "19815/67600 (epoch 14), train_loss = 1.168, time/batch=0.107\n",
      "19816/67600 (epoch 14), train_loss = 1.284, time/batch=0.128\n",
      "19817/67600 (epoch 14), train_loss = 1.255, time/batch=0.194\n",
      "19818/67600 (epoch 14), train_loss = 1.277, time/batch=0.142\n",
      "19819/67600 (epoch 14), train_loss = 1.273, time/batch=0.115\n",
      "19820/67600 (epoch 14), train_loss = 1.240, time/batch=0.113\n",
      "19821/67600 (epoch 14), train_loss = 1.203, time/batch=0.111\n",
      "19822/67600 (epoch 14), train_loss = 1.239, time/batch=0.112\n",
      "19823/67600 (epoch 14), train_loss = 1.202, time/batch=0.107\n",
      "19824/67600 (epoch 14), train_loss = 1.229, time/batch=0.121\n",
      "19825/67600 (epoch 14), train_loss = 1.293, time/batch=0.195\n",
      "19826/67600 (epoch 14), train_loss = 1.254, time/batch=0.146\n",
      "19827/67600 (epoch 14), train_loss = 1.263, time/batch=0.131\n",
      "19828/67600 (epoch 14), train_loss = 1.235, time/batch=0.105\n",
      "19829/67600 (epoch 14), train_loss = 1.276, time/batch=0.119\n",
      "19830/67600 (epoch 14), train_loss = 1.275, time/batch=0.117\n",
      "19831/67600 (epoch 14), train_loss = 1.168, time/batch=0.106\n",
      "19832/67600 (epoch 14), train_loss = 1.213, time/batch=0.115\n",
      "19833/67600 (epoch 14), train_loss = 1.259, time/batch=0.228\n",
      "19834/67600 (epoch 14), train_loss = 1.212, time/batch=0.157\n",
      "19835/67600 (epoch 14), train_loss = 1.196, time/batch=0.102\n",
      "19836/67600 (epoch 14), train_loss = 1.277, time/batch=0.107\n",
      "19837/67600 (epoch 14), train_loss = 1.204, time/batch=0.106\n",
      "19838/67600 (epoch 14), train_loss = 1.223, time/batch=0.113\n",
      "19839/67600 (epoch 14), train_loss = 1.240, time/batch=0.121\n",
      "19840/67600 (epoch 14), train_loss = 1.220, time/batch=0.232\n",
      "19841/67600 (epoch 14), train_loss = 1.255, time/batch=0.135\n",
      "19842/67600 (epoch 14), train_loss = 1.273, time/batch=0.104\n",
      "19843/67600 (epoch 14), train_loss = 1.191, time/batch=0.113\n",
      "19844/67600 (epoch 14), train_loss = 1.221, time/batch=0.121\n",
      "19845/67600 (epoch 14), train_loss = 1.215, time/batch=0.109\n",
      "19846/67600 (epoch 14), train_loss = 1.231, time/batch=0.119\n",
      "19847/67600 (epoch 14), train_loss = 1.224, time/batch=0.112\n",
      "19848/67600 (epoch 14), train_loss = 1.254, time/batch=0.230\n",
      "19849/67600 (epoch 14), train_loss = 1.232, time/batch=0.120\n",
      "19850/67600 (epoch 14), train_loss = 1.239, time/batch=0.132\n",
      "19851/67600 (epoch 14), train_loss = 1.192, time/batch=0.102\n",
      "19852/67600 (epoch 14), train_loss = 1.187, time/batch=0.109\n",
      "19853/67600 (epoch 14), train_loss = 1.209, time/batch=0.195\n",
      "19854/67600 (epoch 14), train_loss = 1.205, time/batch=0.119\n",
      "19855/67600 (epoch 14), train_loss = 1.219, time/batch=0.140\n",
      "19856/67600 (epoch 14), train_loss = 1.201, time/batch=0.118\n",
      "19857/67600 (epoch 14), train_loss = 1.219, time/batch=0.114\n",
      "19858/67600 (epoch 14), train_loss = 1.174, time/batch=0.104\n",
      "19859/67600 (epoch 14), train_loss = 1.229, time/batch=0.118\n",
      "19860/67600 (epoch 14), train_loss = 1.199, time/batch=0.095\n",
      "19861/67600 (epoch 14), train_loss = 1.174, time/batch=0.169\n",
      "19862/67600 (epoch 14), train_loss = 1.208, time/batch=0.105\n",
      "19863/67600 (epoch 14), train_loss = 1.196, time/batch=0.105\n",
      "19864/67600 (epoch 14), train_loss = 1.248, time/batch=0.114\n",
      "19865/67600 (epoch 14), train_loss = 1.210, time/batch=0.117\n",
      "19866/67600 (epoch 14), train_loss = 1.199, time/batch=0.102\n",
      "19867/67600 (epoch 14), train_loss = 1.203, time/batch=0.107\n",
      "19868/67600 (epoch 14), train_loss = 1.220, time/batch=0.285\n",
      "19869/67600 (epoch 14), train_loss = 1.179, time/batch=0.128\n",
      "19870/67600 (epoch 14), train_loss = 1.162, time/batch=0.130\n",
      "19871/67600 (epoch 14), train_loss = 1.249, time/batch=0.100\n",
      "19872/67600 (epoch 14), train_loss = 1.210, time/batch=0.114\n",
      "19873/67600 (epoch 14), train_loss = 1.227, time/batch=0.112\n",
      "19874/67600 (epoch 14), train_loss = 1.195, time/batch=0.115\n",
      "19875/67600 (epoch 14), train_loss = 1.173, time/batch=0.192\n",
      "19876/67600 (epoch 14), train_loss = 1.230, time/batch=0.165\n",
      "19877/67600 (epoch 14), train_loss = 1.172, time/batch=0.122\n",
      "19878/67600 (epoch 14), train_loss = 1.247, time/batch=0.110\n",
      "19879/67600 (epoch 14), train_loss = 1.196, time/batch=0.130\n",
      "19880/67600 (epoch 14), train_loss = 1.241, time/batch=0.108\n",
      "19881/67600 (epoch 14), train_loss = 1.186, time/batch=0.101\n",
      "19882/67600 (epoch 14), train_loss = 1.154, time/batch=0.113\n",
      "19883/67600 (epoch 14), train_loss = 1.264, time/batch=0.239\n",
      "19884/67600 (epoch 14), train_loss = 1.237, time/batch=0.127\n",
      "19885/67600 (epoch 14), train_loss = 1.235, time/batch=0.118\n",
      "19886/67600 (epoch 14), train_loss = 1.181, time/batch=0.102\n",
      "19887/67600 (epoch 14), train_loss = 1.190, time/batch=0.116\n",
      "19888/67600 (epoch 14), train_loss = 1.182, time/batch=0.120\n",
      "19889/67600 (epoch 14), train_loss = 1.141, time/batch=0.209\n",
      "19890/67600 (epoch 14), train_loss = 1.147, time/batch=0.134\n",
      "19891/67600 (epoch 14), train_loss = 1.152, time/batch=0.111\n",
      "19892/67600 (epoch 14), train_loss = 1.153, time/batch=0.119\n",
      "19893/67600 (epoch 14), train_loss = 1.232, time/batch=0.113\n",
      "19894/67600 (epoch 14), train_loss = 1.216, time/batch=0.104\n",
      "19895/67600 (epoch 14), train_loss = 1.160, time/batch=0.113\n",
      "19896/67600 (epoch 14), train_loss = 1.175, time/batch=0.186\n",
      "19897/67600 (epoch 14), train_loss = 1.175, time/batch=0.133\n",
      "19898/67600 (epoch 14), train_loss = 1.210, time/batch=0.142\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19899/67600 (epoch 14), train_loss = 1.225, time/batch=0.112\n",
      "19900/67600 (epoch 14), train_loss = 1.162, time/batch=0.120\n",
      "19901/67600 (epoch 14), train_loss = 1.223, time/batch=0.102\n",
      "19902/67600 (epoch 14), train_loss = 1.257, time/batch=0.105\n",
      "19903/67600 (epoch 14), train_loss = 1.141, time/batch=0.119\n",
      "19904/67600 (epoch 14), train_loss = 1.154, time/batch=0.203\n",
      "19905/67600 (epoch 14), train_loss = 1.177, time/batch=0.159\n",
      "19906/67600 (epoch 14), train_loss = 1.227, time/batch=0.110\n",
      "19907/67600 (epoch 14), train_loss = 1.204, time/batch=0.116\n",
      "19908/67600 (epoch 14), train_loss = 1.218, time/batch=0.109\n",
      "19909/67600 (epoch 14), train_loss = 1.174, time/batch=0.109\n",
      "19910/67600 (epoch 14), train_loss = 1.200, time/batch=0.116\n",
      "19911/67600 (epoch 14), train_loss = 1.247, time/batch=0.116\n",
      "19912/67600 (epoch 14), train_loss = 1.196, time/batch=0.228\n",
      "19913/67600 (epoch 14), train_loss = 1.274, time/batch=0.109\n",
      "19914/67600 (epoch 14), train_loss = 1.208, time/batch=0.123\n",
      "19915/67600 (epoch 14), train_loss = 1.278, time/batch=0.117\n",
      "19916/67600 (epoch 14), train_loss = 1.183, time/batch=0.106\n",
      "19917/67600 (epoch 14), train_loss = 1.208, time/batch=0.118\n",
      "19918/67600 (epoch 14), train_loss = 1.236, time/batch=0.108\n",
      "19919/67600 (epoch 14), train_loss = 1.198, time/batch=0.108\n",
      "19920/67600 (epoch 14), train_loss = 1.249, time/batch=0.236\n",
      "19921/67600 (epoch 14), train_loss = 1.210, time/batch=0.128\n",
      "19922/67600 (epoch 14), train_loss = 1.191, time/batch=0.121\n",
      "19923/67600 (epoch 14), train_loss = 1.210, time/batch=0.097\n",
      "19924/67600 (epoch 14), train_loss = 1.201, time/batch=0.126\n",
      "19925/67600 (epoch 14), train_loss = 1.218, time/batch=0.195\n",
      "19926/67600 (epoch 14), train_loss = 1.180, time/batch=0.129\n",
      "19927/67600 (epoch 14), train_loss = 1.195, time/batch=0.137\n",
      "19928/67600 (epoch 14), train_loss = 1.209, time/batch=0.100\n",
      "19929/67600 (epoch 14), train_loss = 1.226, time/batch=0.116\n",
      "19930/67600 (epoch 14), train_loss = 1.186, time/batch=0.114\n",
      "19931/67600 (epoch 14), train_loss = 1.199, time/batch=0.108\n",
      "19932/67600 (epoch 14), train_loss = 1.153, time/batch=0.105\n",
      "19933/67600 (epoch 14), train_loss = 1.230, time/batch=0.224\n",
      "19934/67600 (epoch 14), train_loss = 1.214, time/batch=0.135\n",
      "19935/67600 (epoch 14), train_loss = 1.174, time/batch=0.138\n",
      "19936/67600 (epoch 14), train_loss = 1.215, time/batch=0.098\n",
      "19937/67600 (epoch 14), train_loss = 1.167, time/batch=0.115\n",
      "19938/67600 (epoch 14), train_loss = 1.194, time/batch=0.110\n",
      "19939/67600 (epoch 14), train_loss = 1.185, time/batch=0.108\n",
      "19940/67600 (epoch 14), train_loss = 1.150, time/batch=0.101\n",
      "19941/67600 (epoch 14), train_loss = 1.190, time/batch=0.237\n",
      "19942/67600 (epoch 14), train_loss = 1.181, time/batch=0.129\n",
      "19943/67600 (epoch 14), train_loss = 1.202, time/batch=0.115\n",
      "19944/67600 (epoch 14), train_loss = 1.181, time/batch=0.104\n",
      "19945/67600 (epoch 14), train_loss = 1.222, time/batch=0.110\n",
      "19946/67600 (epoch 14), train_loss = 1.209, time/batch=0.105\n",
      "19947/67600 (epoch 14), train_loss = 1.221, time/batch=0.128\n",
      "19948/67600 (epoch 14), train_loss = 1.195, time/batch=0.269\n",
      "19949/67600 (epoch 14), train_loss = 1.200, time/batch=0.169\n",
      "19950/67600 (epoch 14), train_loss = 1.196, time/batch=0.104\n",
      "19951/67600 (epoch 14), train_loss = 1.195, time/batch=0.116\n",
      "19952/67600 (epoch 14), train_loss = 1.194, time/batch=0.142\n",
      "19953/67600 (epoch 14), train_loss = 1.157, time/batch=0.122\n",
      "19954/67600 (epoch 14), train_loss = 1.239, time/batch=0.123\n",
      "19955/67600 (epoch 14), train_loss = 1.161, time/batch=0.242\n",
      "19956/67600 (epoch 14), train_loss = 1.244, time/batch=0.114\n",
      "19957/67600 (epoch 14), train_loss = 1.219, time/batch=0.116\n",
      "19958/67600 (epoch 14), train_loss = 1.246, time/batch=0.129\n",
      "19959/67600 (epoch 14), train_loss = 1.253, time/batch=0.103\n",
      "19960/67600 (epoch 14), train_loss = 1.227, time/batch=0.113\n",
      "19961/67600 (epoch 14), train_loss = 1.187, time/batch=0.108\n",
      "19962/67600 (epoch 14), train_loss = 1.207, time/batch=0.110\n",
      "19963/67600 (epoch 14), train_loss = 1.184, time/batch=0.255\n",
      "19964/67600 (epoch 14), train_loss = 1.181, time/batch=0.107\n",
      "19965/67600 (epoch 14), train_loss = 1.179, time/batch=0.111\n",
      "19966/67600 (epoch 14), train_loss = 1.215, time/batch=0.105\n",
      "19967/67600 (epoch 14), train_loss = 1.198, time/batch=0.121\n",
      "19968/67600 (epoch 14), train_loss = 1.215, time/batch=0.141\n",
      "19969/67600 (epoch 14), train_loss = 1.219, time/batch=0.126\n",
      "19970/67600 (epoch 14), train_loss = 1.248, time/batch=0.107\n",
      "19971/67600 (epoch 14), train_loss = 1.114, time/batch=0.114\n",
      "19972/67600 (epoch 14), train_loss = 1.200, time/batch=0.125\n",
      "19973/67600 (epoch 14), train_loss = 1.206, time/batch=0.107\n",
      "19974/67600 (epoch 14), train_loss = 1.211, time/batch=0.103\n",
      "19975/67600 (epoch 14), train_loss = 1.272, time/batch=0.270\n",
      "19976/67600 (epoch 14), train_loss = 1.244, time/batch=0.125\n",
      "19977/67600 (epoch 14), train_loss = 1.228, time/batch=0.116\n",
      "19978/67600 (epoch 14), train_loss = 1.207, time/batch=0.105\n",
      "19979/67600 (epoch 14), train_loss = 1.182, time/batch=0.110\n",
      "19980/67600 (epoch 14), train_loss = 1.210, time/batch=0.120\n",
      "19981/67600 (epoch 14), train_loss = 1.209, time/batch=0.107\n",
      "19982/67600 (epoch 14), train_loss = 1.229, time/batch=0.120\n",
      "19983/67600 (epoch 14), train_loss = 1.203, time/batch=0.242\n",
      "19984/67600 (epoch 14), train_loss = 1.139, time/batch=0.116\n",
      "19985/67600 (epoch 14), train_loss = 1.252, time/batch=0.108\n",
      "19986/67600 (epoch 14), train_loss = 1.285, time/batch=0.111\n",
      "19987/67600 (epoch 14), train_loss = 1.199, time/batch=0.115\n",
      "19988/67600 (epoch 14), train_loss = 1.231, time/batch=0.123\n",
      "19989/67600 (epoch 14), train_loss = 1.234, time/batch=0.111\n",
      "19990/67600 (epoch 14), train_loss = 1.213, time/batch=0.223\n",
      "19991/67600 (epoch 14), train_loss = 1.178, time/batch=0.124\n",
      "19992/67600 (epoch 14), train_loss = 1.222, time/batch=0.123\n",
      "19993/67600 (epoch 14), train_loss = 1.208, time/batch=0.105\n",
      "19994/67600 (epoch 14), train_loss = 1.210, time/batch=0.118\n",
      "19995/67600 (epoch 14), train_loss = 1.250, time/batch=0.111\n",
      "19996/67600 (epoch 14), train_loss = 1.176, time/batch=0.208\n",
      "19997/67600 (epoch 14), train_loss = 1.227, time/batch=0.146\n",
      "19998/67600 (epoch 14), train_loss = 1.248, time/batch=0.114\n",
      "19999/67600 (epoch 14), train_loss = 1.265, time/batch=0.117\n",
      "20000/67600 (epoch 14), train_loss = 1.219, time/batch=0.099\n",
      "model saved to ./save/model.ckpt\n",
      "20001/67600 (epoch 14), train_loss = 1.195, time/batch=0.078\n",
      "20002/67600 (epoch 14), train_loss = 1.172, time/batch=0.080\n",
      "20003/67600 (epoch 14), train_loss = 1.211, time/batch=0.094\n",
      "20004/67600 (epoch 14), train_loss = 1.262, time/batch=0.090\n",
      "20005/67600 (epoch 14), train_loss = 1.268, time/batch=0.215\n",
      "20006/67600 (epoch 14), train_loss = 1.260, time/batch=0.116\n",
      "20007/67600 (epoch 14), train_loss = 1.253, time/batch=0.128\n",
      "20008/67600 (epoch 14), train_loss = 1.267, time/batch=0.111\n",
      "20009/67600 (epoch 14), train_loss = 1.182, time/batch=0.118\n",
      "20010/67600 (epoch 14), train_loss = 1.245, time/batch=0.114\n",
      "20011/67600 (epoch 14), train_loss = 1.187, time/batch=0.104\n",
      "20012/67600 (epoch 14), train_loss = 1.181, time/batch=0.110\n",
      "20013/67600 (epoch 14), train_loss = 1.276, time/batch=0.219\n",
      "20014/67600 (epoch 14), train_loss = 1.249, time/batch=0.136\n",
      "20015/67600 (epoch 14), train_loss = 1.156, time/batch=0.114\n",
      "20016/67600 (epoch 14), train_loss = 1.193, time/batch=0.109\n",
      "20017/67600 (epoch 14), train_loss = 1.183, time/batch=0.106\n",
      "20018/67600 (epoch 14), train_loss = 1.224, time/batch=0.118\n",
      "20019/67600 (epoch 14), train_loss = 1.188, time/batch=0.118\n",
      "20020/67600 (epoch 14), train_loss = 1.253, time/batch=0.099\n",
      "20021/67600 (epoch 14), train_loss = 1.207, time/batch=0.244\n",
      "20022/67600 (epoch 14), train_loss = 1.210, time/batch=0.133\n",
      "20023/67600 (epoch 14), train_loss = 1.179, time/batch=0.116\n",
      "20024/67600 (epoch 14), train_loss = 1.218, time/batch=0.116\n",
      "20025/67600 (epoch 14), train_loss = 1.211, time/batch=0.112\n",
      "20026/67600 (epoch 14), train_loss = 1.178, time/batch=0.105\n",
      "20027/67600 (epoch 14), train_loss = 1.145, time/batch=0.118\n",
      "20028/67600 (epoch 14), train_loss = 1.212, time/batch=0.168\n",
      "20029/67600 (epoch 14), train_loss = 1.198, time/batch=0.168\n",
      "20030/67600 (epoch 14), train_loss = 1.188, time/batch=0.128\n",
      "20031/67600 (epoch 14), train_loss = 1.169, time/batch=0.111\n",
      "20032/67600 (epoch 14), train_loss = 1.291, time/batch=0.117\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20033/67600 (epoch 14), train_loss = 1.191, time/batch=0.106\n",
      "20034/67600 (epoch 14), train_loss = 1.196, time/batch=0.217\n",
      "20035/67600 (epoch 14), train_loss = 1.232, time/batch=0.136\n",
      "20036/67600 (epoch 14), train_loss = 1.189, time/batch=0.111\n",
      "20037/67600 (epoch 14), train_loss = 1.219, time/batch=0.133\n",
      "20038/67600 (epoch 14), train_loss = 1.237, time/batch=0.100\n",
      "20039/67600 (epoch 14), train_loss = 1.205, time/batch=0.116\n",
      "20040/67600 (epoch 14), train_loss = 1.274, time/batch=0.115\n",
      "20041/67600 (epoch 14), train_loss = 1.263, time/batch=0.116\n",
      "20042/67600 (epoch 14), train_loss = 1.241, time/batch=0.177\n",
      "20043/67600 (epoch 14), train_loss = 1.305, time/batch=0.105\n",
      "20044/67600 (epoch 14), train_loss = 1.216, time/batch=0.109\n",
      "20045/67600 (epoch 14), train_loss = 1.249, time/batch=0.114\n",
      "20046/67600 (epoch 14), train_loss = 1.214, time/batch=0.107\n",
      "20047/67600 (epoch 14), train_loss = 1.309, time/batch=0.105\n",
      "20048/67600 (epoch 14), train_loss = 1.201, time/batch=0.268\n",
      "20049/67600 (epoch 14), train_loss = 1.254, time/batch=0.124\n",
      "20050/67600 (epoch 14), train_loss = 1.315, time/batch=0.143\n",
      "20051/67600 (epoch 14), train_loss = 1.231, time/batch=0.110\n",
      "20052/67600 (epoch 14), train_loss = 1.210, time/batch=0.105\n",
      "20053/67600 (epoch 14), train_loss = 1.211, time/batch=0.138\n",
      "20054/67600 (epoch 14), train_loss = 1.277, time/batch=0.106\n",
      "20055/67600 (epoch 14), train_loss = 1.222, time/batch=0.114\n",
      "20056/67600 (epoch 14), train_loss = 1.233, time/batch=0.246\n",
      "20057/67600 (epoch 14), train_loss = 1.230, time/batch=0.114\n",
      "20058/67600 (epoch 14), train_loss = 1.239, time/batch=0.108\n",
      "20059/67600 (epoch 14), train_loss = 1.242, time/batch=0.111\n",
      "20060/67600 (epoch 14), train_loss = 1.203, time/batch=0.124\n",
      "20061/67600 (epoch 14), train_loss = 1.268, time/batch=0.106\n",
      "20062/67600 (epoch 14), train_loss = 1.289, time/batch=0.108\n",
      "20063/67600 (epoch 14), train_loss = 1.288, time/batch=0.173\n",
      "20064/67600 (epoch 14), train_loss = 1.259, time/batch=0.181\n",
      "20065/67600 (epoch 14), train_loss = 1.230, time/batch=0.126\n",
      "20066/67600 (epoch 14), train_loss = 1.233, time/batch=0.105\n",
      "20067/67600 (epoch 14), train_loss = 1.281, time/batch=0.126\n",
      "20068/67600 (epoch 14), train_loss = 1.228, time/batch=0.106\n",
      "20069/67600 (epoch 14), train_loss = 1.222, time/batch=0.196\n",
      "20070/67600 (epoch 14), train_loss = 1.262, time/batch=0.190\n",
      "20071/67600 (epoch 14), train_loss = 1.259, time/batch=0.097\n",
      "20072/67600 (epoch 14), train_loss = 1.244, time/batch=0.125\n",
      "20073/67600 (epoch 14), train_loss = 1.199, time/batch=0.105\n",
      "20074/67600 (epoch 14), train_loss = 1.184, time/batch=0.116\n",
      "20075/67600 (epoch 14), train_loss = 1.175, time/batch=0.104\n",
      "20076/67600 (epoch 14), train_loss = 1.197, time/batch=0.175\n",
      "20077/67600 (epoch 14), train_loss = 1.210, time/batch=0.152\n",
      "20078/67600 (epoch 14), train_loss = 1.156, time/batch=0.138\n",
      "20079/67600 (epoch 14), train_loss = 1.251, time/batch=0.114\n",
      "20080/67600 (epoch 14), train_loss = 1.213, time/batch=0.102\n",
      "20081/67600 (epoch 14), train_loss = 1.195, time/batch=0.119\n",
      "20082/67600 (epoch 14), train_loss = 1.222, time/batch=0.107\n",
      "20083/67600 (epoch 14), train_loss = 1.203, time/batch=0.117\n",
      "20084/67600 (epoch 14), train_loss = 1.202, time/batch=0.204\n",
      "20085/67600 (epoch 14), train_loss = 1.153, time/batch=0.136\n",
      "20086/67600 (epoch 14), train_loss = 1.256, time/batch=0.118\n",
      "20087/67600 (epoch 14), train_loss = 1.252, time/batch=0.111\n",
      "20088/67600 (epoch 14), train_loss = 1.179, time/batch=0.114\n",
      "20089/67600 (epoch 14), train_loss = 1.188, time/batch=0.109\n",
      "20090/67600 (epoch 14), train_loss = 1.207, time/batch=0.107\n",
      "20091/67600 (epoch 14), train_loss = 1.169, time/batch=0.112\n",
      "20092/67600 (epoch 14), train_loss = 1.224, time/batch=0.224\n",
      "20093/67600 (epoch 14), train_loss = 1.173, time/batch=0.125\n",
      "20094/67600 (epoch 14), train_loss = 1.188, time/batch=0.118\n",
      "20095/67600 (epoch 14), train_loss = 1.225, time/batch=0.113\n",
      "20096/67600 (epoch 14), train_loss = 1.227, time/batch=0.112\n",
      "20097/67600 (epoch 14), train_loss = 1.145, time/batch=0.118\n",
      "20098/67600 (epoch 14), train_loss = 1.179, time/batch=0.101\n",
      "20099/67600 (epoch 14), train_loss = 1.181, time/batch=0.110\n",
      "20100/67600 (epoch 14), train_loss = 1.201, time/batch=0.244\n",
      "20101/67600 (epoch 14), train_loss = 1.212, time/batch=0.106\n",
      "20102/67600 (epoch 14), train_loss = 1.201, time/batch=0.110\n",
      "20103/67600 (epoch 14), train_loss = 1.216, time/batch=0.121\n",
      "20104/67600 (epoch 14), train_loss = 1.210, time/batch=0.124\n",
      "20105/67600 (epoch 14), train_loss = 1.206, time/batch=0.183\n",
      "20106/67600 (epoch 14), train_loss = 1.252, time/batch=0.142\n",
      "20107/67600 (epoch 14), train_loss = 1.304, time/batch=0.145\n",
      "20108/67600 (epoch 14), train_loss = 1.273, time/batch=0.130\n",
      "20109/67600 (epoch 14), train_loss = 1.232, time/batch=0.127\n",
      "20110/67600 (epoch 14), train_loss = 1.222, time/batch=0.127\n",
      "20111/67600 (epoch 14), train_loss = 1.215, time/batch=0.116\n",
      "20112/67600 (epoch 14), train_loss = 1.235, time/batch=0.202\n",
      "20113/67600 (epoch 14), train_loss = 1.139, time/batch=0.157\n",
      "20114/67600 (epoch 14), train_loss = 1.172, time/batch=0.140\n",
      "20115/67600 (epoch 14), train_loss = 1.263, time/batch=0.129\n",
      "20116/67600 (epoch 14), train_loss = 1.210, time/batch=0.113\n",
      "20117/67600 (epoch 14), train_loss = 1.174, time/batch=0.127\n",
      "20118/67600 (epoch 14), train_loss = 1.216, time/batch=0.126\n",
      "20119/67600 (epoch 14), train_loss = 1.190, time/batch=0.096\n",
      "20120/67600 (epoch 14), train_loss = 1.202, time/batch=0.239\n",
      "20121/67600 (epoch 14), train_loss = 1.212, time/batch=0.139\n",
      "20122/67600 (epoch 14), train_loss = 1.170, time/batch=0.128\n",
      "20123/67600 (epoch 14), train_loss = 1.182, time/batch=0.121\n",
      "20124/67600 (epoch 14), train_loss = 1.227, time/batch=0.117\n",
      "20125/67600 (epoch 14), train_loss = 1.237, time/batch=0.116\n",
      "20126/67600 (epoch 14), train_loss = 1.253, time/batch=0.112\n",
      "20127/67600 (epoch 14), train_loss = 1.197, time/batch=0.262\n",
      "20128/67600 (epoch 14), train_loss = 1.228, time/batch=0.143\n",
      "20129/67600 (epoch 14), train_loss = 1.188, time/batch=0.111\n",
      "20130/67600 (epoch 14), train_loss = 1.173, time/batch=0.138\n",
      "20131/67600 (epoch 14), train_loss = 1.182, time/batch=0.104\n",
      "20132/67600 (epoch 14), train_loss = 1.280, time/batch=0.119\n",
      "20133/67600 (epoch 14), train_loss = 1.203, time/batch=0.129\n",
      "20134/67600 (epoch 14), train_loss = 1.168, time/batch=0.260\n",
      "20135/67600 (epoch 14), train_loss = 1.214, time/batch=0.121\n",
      "20136/67600 (epoch 14), train_loss = 1.174, time/batch=0.120\n",
      "20137/67600 (epoch 14), train_loss = 1.175, time/batch=0.112\n",
      "20138/67600 (epoch 14), train_loss = 1.239, time/batch=0.124\n",
      "20139/67600 (epoch 14), train_loss = 1.186, time/batch=0.144\n",
      "20140/67600 (epoch 14), train_loss = 1.187, time/batch=0.099\n",
      "20141/67600 (epoch 14), train_loss = 1.226, time/batch=0.291\n",
      "20142/67600 (epoch 14), train_loss = 1.233, time/batch=0.115\n",
      "20143/67600 (epoch 14), train_loss = 1.201, time/batch=0.120\n",
      "20144/67600 (epoch 14), train_loss = 1.220, time/batch=0.127\n",
      "20145/67600 (epoch 14), train_loss = 1.227, time/batch=0.110\n",
      "20146/67600 (epoch 14), train_loss = 1.208, time/batch=0.171\n",
      "20147/67600 (epoch 14), train_loss = 1.211, time/batch=0.119\n",
      "20148/67600 (epoch 14), train_loss = 1.192, time/batch=0.117\n",
      "20149/67600 (epoch 14), train_loss = 1.196, time/batch=0.119\n",
      "20150/67600 (epoch 14), train_loss = 1.237, time/batch=0.119\n",
      "20151/67600 (epoch 14), train_loss = 1.195, time/batch=0.117\n",
      "20152/67600 (epoch 14), train_loss = 1.256, time/batch=0.317\n",
      "20153/67600 (epoch 14), train_loss = 1.232, time/batch=0.131\n",
      "20154/67600 (epoch 14), train_loss = 1.248, time/batch=0.131\n",
      "20155/67600 (epoch 14), train_loss = 1.216, time/batch=0.122\n",
      "20156/67600 (epoch 14), train_loss = 1.250, time/batch=0.122\n",
      "20157/67600 (epoch 14), train_loss = 1.193, time/batch=0.115\n",
      "20158/67600 (epoch 14), train_loss = 1.224, time/batch=0.121\n",
      "20159/67600 (epoch 14), train_loss = 1.226, time/batch=0.263\n",
      "20160/67600 (epoch 14), train_loss = 1.308, time/batch=0.127\n",
      "20161/67600 (epoch 14), train_loss = 1.268, time/batch=0.104\n",
      "20162/67600 (epoch 14), train_loss = 1.173, time/batch=0.130\n",
      "20163/67600 (epoch 14), train_loss = 1.210, time/batch=0.120\n",
      "20164/67600 (epoch 14), train_loss = 1.193, time/batch=0.107\n",
      "20165/67600 (epoch 14), train_loss = 1.228, time/batch=0.123\n",
      "20166/67600 (epoch 14), train_loss = 1.213, time/batch=0.234\n",
      "20167/67600 (epoch 14), train_loss = 1.194, time/batch=0.155\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20168/67600 (epoch 14), train_loss = 1.261, time/batch=0.100\n",
      "20169/67600 (epoch 14), train_loss = 1.195, time/batch=0.132\n",
      "20170/67600 (epoch 14), train_loss = 1.211, time/batch=0.133\n",
      "20171/67600 (epoch 14), train_loss = 1.244, time/batch=0.175\n",
      "20172/67600 (epoch 14), train_loss = 1.296, time/batch=0.156\n",
      "20173/67600 (epoch 14), train_loss = 1.229, time/batch=0.150\n",
      "20174/67600 (epoch 14), train_loss = 1.215, time/batch=0.123\n",
      "20175/67600 (epoch 14), train_loss = 1.205, time/batch=0.123\n",
      "20176/67600 (epoch 14), train_loss = 1.237, time/batch=0.135\n",
      "20177/67600 (epoch 14), train_loss = 1.211, time/batch=0.110\n",
      "20178/67600 (epoch 14), train_loss = 1.171, time/batch=0.137\n",
      "20179/67600 (epoch 14), train_loss = 1.277, time/batch=0.205\n",
      "20180/67600 (epoch 14), train_loss = 1.184, time/batch=0.159\n",
      "20181/67600 (epoch 14), train_loss = 1.264, time/batch=0.103\n",
      "20182/67600 (epoch 14), train_loss = 1.242, time/batch=0.127\n",
      "20183/67600 (epoch 14), train_loss = 1.259, time/batch=0.115\n",
      "20184/67600 (epoch 14), train_loss = 1.245, time/batch=0.110\n",
      "20185/67600 (epoch 14), train_loss = 1.237, time/batch=0.141\n",
      "20186/67600 (epoch 14), train_loss = 1.283, time/batch=0.217\n",
      "20187/67600 (epoch 14), train_loss = 1.212, time/batch=0.158\n",
      "20188/67600 (epoch 14), train_loss = 1.239, time/batch=0.114\n",
      "20189/67600 (epoch 14), train_loss = 1.203, time/batch=0.121\n",
      "20190/67600 (epoch 14), train_loss = 1.295, time/batch=0.105\n",
      "20191/67600 (epoch 14), train_loss = 1.282, time/batch=0.115\n",
      "20192/67600 (epoch 14), train_loss = 1.279, time/batch=0.132\n",
      "20193/67600 (epoch 14), train_loss = 1.211, time/batch=0.247\n",
      "20194/67600 (epoch 14), train_loss = 1.274, time/batch=0.134\n",
      "20195/67600 (epoch 14), train_loss = 1.189, time/batch=0.128\n",
      "20196/67600 (epoch 14), train_loss = 1.167, time/batch=0.122\n",
      "20197/67600 (epoch 14), train_loss = 1.224, time/batch=0.123\n",
      "20198/67600 (epoch 14), train_loss = 1.225, time/batch=0.119\n",
      "20199/67600 (epoch 14), train_loss = 1.158, time/batch=0.131\n",
      "20200/67600 (epoch 14), train_loss = 1.218, time/batch=0.261\n",
      "20201/67600 (epoch 14), train_loss = 1.207, time/batch=0.120\n",
      "20202/67600 (epoch 14), train_loss = 1.194, time/batch=0.115\n",
      "20203/67600 (epoch 14), train_loss = 1.239, time/batch=0.110\n",
      "20204/67600 (epoch 14), train_loss = 1.253, time/batch=0.131\n",
      "20205/67600 (epoch 14), train_loss = 1.231, time/batch=0.198\n",
      "20206/67600 (epoch 14), train_loss = 1.149, time/batch=0.119\n",
      "20207/67600 (epoch 14), train_loss = 1.171, time/batch=0.155\n",
      "20208/67600 (epoch 14), train_loss = 1.184, time/batch=0.121\n",
      "20209/67600 (epoch 14), train_loss = 1.210, time/batch=0.124\n",
      "20210/67600 (epoch 14), train_loss = 1.175, time/batch=0.118\n",
      "20211/67600 (epoch 14), train_loss = 1.229, time/batch=0.140\n",
      "20212/67600 (epoch 14), train_loss = 1.250, time/batch=0.124\n",
      "20213/67600 (epoch 14), train_loss = 1.209, time/batch=0.206\n",
      "20214/67600 (epoch 14), train_loss = 1.197, time/batch=0.152\n",
      "20215/67600 (epoch 14), train_loss = 1.269, time/batch=0.115\n",
      "20216/67600 (epoch 14), train_loss = 1.193, time/batch=0.131\n",
      "20217/67600 (epoch 14), train_loss = 1.248, time/batch=0.116\n",
      "20218/67600 (epoch 14), train_loss = 1.277, time/batch=0.119\n",
      "20219/67600 (epoch 14), train_loss = 1.246, time/batch=0.134\n",
      "20220/67600 (epoch 14), train_loss = 1.195, time/batch=0.219\n",
      "20221/67600 (epoch 14), train_loss = 1.203, time/batch=0.151\n",
      "20222/67600 (epoch 14), train_loss = 1.216, time/batch=0.112\n",
      "20223/67600 (epoch 14), train_loss = 1.211, time/batch=0.134\n",
      "20224/67600 (epoch 14), train_loss = 1.226, time/batch=0.121\n",
      "20225/67600 (epoch 14), train_loss = 1.236, time/batch=0.115\n",
      "20226/67600 (epoch 14), train_loss = 1.170, time/batch=0.129\n",
      "20227/67600 (epoch 14), train_loss = 1.244, time/batch=0.235\n",
      "20228/67600 (epoch 14), train_loss = 1.266, time/batch=0.143\n",
      "20229/67600 (epoch 14), train_loss = 1.227, time/batch=0.115\n",
      "20230/67600 (epoch 14), train_loss = 1.192, time/batch=0.116\n",
      "20231/67600 (epoch 14), train_loss = 1.216, time/batch=0.125\n",
      "20232/67600 (epoch 14), train_loss = 1.233, time/batch=0.106\n",
      "20233/67600 (epoch 14), train_loss = 1.158, time/batch=0.122\n",
      "20234/67600 (epoch 14), train_loss = 1.243, time/batch=0.247\n",
      "20235/67600 (epoch 14), train_loss = 1.237, time/batch=0.129\n",
      "20236/67600 (epoch 14), train_loss = 1.233, time/batch=0.118\n",
      "20237/67600 (epoch 14), train_loss = 1.228, time/batch=0.114\n",
      "20238/67600 (epoch 14), train_loss = 1.191, time/batch=0.122\n",
      "20239/67600 (epoch 14), train_loss = 1.203, time/batch=0.202\n",
      "20240/67600 (epoch 14), train_loss = 1.214, time/batch=0.136\n",
      "20241/67600 (epoch 14), train_loss = 1.283, time/batch=0.169\n",
      "20242/67600 (epoch 14), train_loss = 1.283, time/batch=0.114\n",
      "20243/67600 (epoch 14), train_loss = 1.232, time/batch=0.136\n",
      "20244/67600 (epoch 14), train_loss = 1.238, time/batch=0.123\n",
      "20245/67600 (epoch 14), train_loss = 1.252, time/batch=0.126\n",
      "20246/67600 (epoch 14), train_loss = 1.223, time/batch=0.179\n",
      "20247/67600 (epoch 14), train_loss = 1.194, time/batch=0.118\n",
      "20248/67600 (epoch 14), train_loss = 1.214, time/batch=0.120\n",
      "20249/67600 (epoch 14), train_loss = 1.210, time/batch=0.126\n",
      "20250/67600 (epoch 14), train_loss = 1.199, time/batch=0.107\n",
      "20251/67600 (epoch 14), train_loss = 1.219, time/batch=0.109\n",
      "20252/67600 (epoch 14), train_loss = 1.276, time/batch=0.263\n",
      "20253/67600 (epoch 14), train_loss = 1.213, time/batch=0.158\n",
      "20254/67600 (epoch 14), train_loss = 1.228, time/batch=0.126\n",
      "20255/67600 (epoch 14), train_loss = 1.209, time/batch=0.120\n",
      "20256/67600 (epoch 14), train_loss = 1.211, time/batch=0.124\n",
      "20257/67600 (epoch 14), train_loss = 1.228, time/batch=0.118\n",
      "20258/67600 (epoch 14), train_loss = 1.270, time/batch=0.107\n",
      "20259/67600 (epoch 14), train_loss = 1.263, time/batch=0.157\n",
      "20260/67600 (epoch 14), train_loss = 1.217, time/batch=0.242\n",
      "20261/67600 (epoch 14), train_loss = 1.199, time/batch=0.132\n",
      "20262/67600 (epoch 14), train_loss = 1.174, time/batch=0.114\n",
      "20263/67600 (epoch 14), train_loss = 1.243, time/batch=0.116\n",
      "20264/67600 (epoch 14), train_loss = 1.246, time/batch=0.109\n",
      "20265/67600 (epoch 14), train_loss = 1.229, time/batch=0.116\n",
      "20266/67600 (epoch 14), train_loss = 1.239, time/batch=0.124\n",
      "20267/67600 (epoch 14), train_loss = 1.211, time/batch=0.256\n",
      "20268/67600 (epoch 14), train_loss = 1.197, time/batch=0.129\n",
      "20269/67600 (epoch 14), train_loss = 1.221, time/batch=0.115\n",
      "20270/67600 (epoch 14), train_loss = 1.234, time/batch=0.130\n",
      "20271/67600 (epoch 14), train_loss = 1.220, time/batch=0.117\n",
      "20272/67600 (epoch 14), train_loss = 1.165, time/batch=0.198\n",
      "20273/67600 (epoch 14), train_loss = 1.221, time/batch=0.184\n",
      "20274/67600 (epoch 14), train_loss = 1.197, time/batch=0.107\n",
      "20275/67600 (epoch 14), train_loss = 1.222, time/batch=0.141\n",
      "20276/67600 (epoch 14), train_loss = 1.289, time/batch=0.119\n",
      "20277/67600 (epoch 14), train_loss = 1.310, time/batch=0.116\n",
      "20278/67600 (epoch 14), train_loss = 1.225, time/batch=0.108\n",
      "20279/67600 (epoch 14), train_loss = 1.244, time/batch=0.238\n",
      "20280/67600 (epoch 15), train_loss = 1.404, time/batch=0.088\n",
      "20281/67600 (epoch 15), train_loss = 1.171, time/batch=0.122\n",
      "20282/67600 (epoch 15), train_loss = 1.249, time/batch=0.116\n",
      "20283/67600 (epoch 15), train_loss = 1.208, time/batch=0.115\n",
      "20284/67600 (epoch 15), train_loss = 1.228, time/batch=0.124\n",
      "20285/67600 (epoch 15), train_loss = 1.245, time/batch=0.131\n",
      "20286/67600 (epoch 15), train_loss = 1.217, time/batch=0.242\n",
      "20287/67600 (epoch 15), train_loss = 1.224, time/batch=0.143\n",
      "20288/67600 (epoch 15), train_loss = 1.234, time/batch=0.118\n",
      "20289/67600 (epoch 15), train_loss = 1.212, time/batch=0.251\n",
      "20290/67600 (epoch 15), train_loss = 1.184, time/batch=0.109\n",
      "20291/67600 (epoch 15), train_loss = 1.192, time/batch=0.126\n",
      "20292/67600 (epoch 15), train_loss = 1.210, time/batch=0.124\n",
      "20293/67600 (epoch 15), train_loss = 1.273, time/batch=0.132\n",
      "20294/67600 (epoch 15), train_loss = 1.234, time/batch=0.121\n",
      "20295/67600 (epoch 15), train_loss = 1.211, time/batch=0.122\n",
      "20296/67600 (epoch 15), train_loss = 1.226, time/batch=0.115\n",
      "20297/67600 (epoch 15), train_loss = 1.230, time/batch=0.127\n",
      "20298/67600 (epoch 15), train_loss = 1.223, time/batch=0.107\n",
      "20299/67600 (epoch 15), train_loss = 1.210, time/batch=0.122\n",
      "20300/67600 (epoch 15), train_loss = 1.225, time/batch=0.268\n",
      "20301/67600 (epoch 15), train_loss = 1.153, time/batch=0.128\n",
      "20302/67600 (epoch 15), train_loss = 1.282, time/batch=0.114\n",
      "20303/67600 (epoch 15), train_loss = 1.251, time/batch=0.085\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20304/67600 (epoch 15), train_loss = 1.283, time/batch=0.138\n",
      "20305/67600 (epoch 15), train_loss = 1.150, time/batch=0.231\n",
      "20306/67600 (epoch 15), train_loss = 1.239, time/batch=0.128\n",
      "20307/67600 (epoch 15), train_loss = 1.249, time/batch=0.115\n",
      "20308/67600 (epoch 15), train_loss = 1.288, time/batch=0.129\n",
      "20309/67600 (epoch 15), train_loss = 1.213, time/batch=0.149\n",
      "20310/67600 (epoch 15), train_loss = 1.202, time/batch=0.097\n",
      "20311/67600 (epoch 15), train_loss = 1.282, time/batch=0.137\n",
      "20312/67600 (epoch 15), train_loss = 1.205, time/batch=0.203\n",
      "20313/67600 (epoch 15), train_loss = 1.271, time/batch=0.165\n",
      "20314/67600 (epoch 15), train_loss = 1.244, time/batch=0.118\n",
      "20315/67600 (epoch 15), train_loss = 1.229, time/batch=0.113\n",
      "20316/67600 (epoch 15), train_loss = 1.198, time/batch=0.132\n",
      "20317/67600 (epoch 15), train_loss = 1.234, time/batch=0.117\n",
      "20318/67600 (epoch 15), train_loss = 1.247, time/batch=0.114\n",
      "20319/67600 (epoch 15), train_loss = 1.224, time/batch=0.117\n",
      "20320/67600 (epoch 15), train_loss = 1.152, time/batch=0.227\n",
      "20321/67600 (epoch 15), train_loss = 1.256, time/batch=0.146\n",
      "20322/67600 (epoch 15), train_loss = 1.268, time/batch=0.106\n",
      "20323/67600 (epoch 15), train_loss = 1.242, time/batch=0.126\n",
      "20324/67600 (epoch 15), train_loss = 1.255, time/batch=0.119\n",
      "20325/67600 (epoch 15), train_loss = 1.222, time/batch=0.117\n",
      "20326/67600 (epoch 15), train_loss = 1.187, time/batch=0.128\n",
      "20327/67600 (epoch 15), train_loss = 1.226, time/batch=0.245\n",
      "20328/67600 (epoch 15), train_loss = 1.200, time/batch=0.123\n",
      "20329/67600 (epoch 15), train_loss = 1.189, time/batch=0.131\n",
      "20330/67600 (epoch 15), train_loss = 1.271, time/batch=0.092\n",
      "20331/67600 (epoch 15), train_loss = 1.196, time/batch=0.132\n",
      "20332/67600 (epoch 15), train_loss = 1.206, time/batch=0.123\n",
      "20333/67600 (epoch 15), train_loss = 1.295, time/batch=0.123\n",
      "20334/67600 (epoch 15), train_loss = 1.265, time/batch=0.254\n",
      "20335/67600 (epoch 15), train_loss = 1.224, time/batch=0.121\n",
      "20336/67600 (epoch 15), train_loss = 1.237, time/batch=0.130\n",
      "20337/67600 (epoch 15), train_loss = 1.231, time/batch=0.116\n",
      "20338/67600 (epoch 15), train_loss = 1.238, time/batch=0.135\n",
      "20339/67600 (epoch 15), train_loss = 1.232, time/batch=0.123\n",
      "20340/67600 (epoch 15), train_loss = 1.234, time/batch=0.107\n",
      "20341/67600 (epoch 15), train_loss = 1.210, time/batch=0.262\n",
      "20342/67600 (epoch 15), train_loss = 1.267, time/batch=0.135\n",
      "20343/67600 (epoch 15), train_loss = 1.264, time/batch=0.108\n",
      "20344/67600 (epoch 15), train_loss = 1.209, time/batch=0.126\n",
      "20345/67600 (epoch 15), train_loss = 1.208, time/batch=0.128\n",
      "20346/67600 (epoch 15), train_loss = 1.225, time/batch=0.160\n",
      "20347/67600 (epoch 15), train_loss = 1.242, time/batch=0.114\n",
      "20348/67600 (epoch 15), train_loss = 1.253, time/batch=0.120\n",
      "20349/67600 (epoch 15), train_loss = 1.251, time/batch=0.117\n",
      "20350/67600 (epoch 15), train_loss = 1.242, time/batch=0.110\n",
      "20351/67600 (epoch 15), train_loss = 1.248, time/batch=0.129\n",
      "20352/67600 (epoch 15), train_loss = 1.206, time/batch=0.183\n",
      "20353/67600 (epoch 15), train_loss = 1.284, time/batch=0.267\n",
      "20354/67600 (epoch 15), train_loss = 1.215, time/batch=0.110\n",
      "20355/67600 (epoch 15), train_loss = 1.265, time/batch=0.122\n",
      "20356/67600 (epoch 15), train_loss = 1.275, time/batch=0.131\n",
      "20357/67600 (epoch 15), train_loss = 1.351, time/batch=0.116\n",
      "20358/67600 (epoch 15), train_loss = 1.271, time/batch=0.122\n",
      "20359/67600 (epoch 15), train_loss = 1.201, time/batch=0.137\n",
      "20360/67600 (epoch 15), train_loss = 1.190, time/batch=0.244\n",
      "20361/67600 (epoch 15), train_loss = 1.240, time/batch=0.121\n",
      "20362/67600 (epoch 15), train_loss = 1.241, time/batch=0.120\n",
      "20363/67600 (epoch 15), train_loss = 1.216, time/batch=0.103\n",
      "20364/67600 (epoch 15), train_loss = 1.223, time/batch=0.129\n",
      "20365/67600 (epoch 15), train_loss = 1.220, time/batch=0.218\n",
      "20366/67600 (epoch 15), train_loss = 1.170, time/batch=0.164\n",
      "20367/67600 (epoch 15), train_loss = 1.278, time/batch=0.117\n",
      "20368/67600 (epoch 15), train_loss = 1.260, time/batch=0.138\n",
      "20369/67600 (epoch 15), train_loss = 1.255, time/batch=0.122\n",
      "20370/67600 (epoch 15), train_loss = 1.236, time/batch=0.118\n",
      "20371/67600 (epoch 15), train_loss = 1.260, time/batch=0.117\n",
      "20372/67600 (epoch 15), train_loss = 1.182, time/batch=0.245\n",
      "20373/67600 (epoch 15), train_loss = 1.202, time/batch=0.160\n",
      "20374/67600 (epoch 15), train_loss = 1.195, time/batch=0.111\n",
      "20375/67600 (epoch 15), train_loss = 1.143, time/batch=0.129\n",
      "20376/67600 (epoch 15), train_loss = 1.154, time/batch=0.119\n",
      "20377/67600 (epoch 15), train_loss = 1.234, time/batch=0.121\n",
      "20378/67600 (epoch 15), train_loss = 1.213, time/batch=0.130\n",
      "20379/67600 (epoch 15), train_loss = 1.250, time/batch=0.220\n",
      "20380/67600 (epoch 15), train_loss = 1.137, time/batch=0.162\n",
      "20381/67600 (epoch 15), train_loss = 1.214, time/batch=0.112\n",
      "20382/67600 (epoch 15), train_loss = 1.256, time/batch=0.112\n",
      "20383/67600 (epoch 15), train_loss = 1.155, time/batch=0.130\n",
      "20384/67600 (epoch 15), train_loss = 1.192, time/batch=0.105\n",
      "20385/67600 (epoch 15), train_loss = 1.233, time/batch=0.122\n",
      "20386/67600 (epoch 15), train_loss = 1.206, time/batch=0.236\n",
      "20387/67600 (epoch 15), train_loss = 1.236, time/batch=0.134\n",
      "20388/67600 (epoch 15), train_loss = 1.269, time/batch=0.123\n",
      "20389/67600 (epoch 15), train_loss = 1.233, time/batch=0.122\n",
      "20390/67600 (epoch 15), train_loss = 1.189, time/batch=0.123\n",
      "20391/67600 (epoch 15), train_loss = 1.234, time/batch=0.112\n",
      "20392/67600 (epoch 15), train_loss = 1.221, time/batch=0.112\n",
      "20393/67600 (epoch 15), train_loss = 1.250, time/batch=0.229\n",
      "20394/67600 (epoch 15), train_loss = 1.241, time/batch=0.151\n",
      "20395/67600 (epoch 15), train_loss = 1.186, time/batch=0.122\n",
      "20396/67600 (epoch 15), train_loss = 1.185, time/batch=0.139\n",
      "20397/67600 (epoch 15), train_loss = 1.218, time/batch=0.105\n",
      "20398/67600 (epoch 15), train_loss = 1.241, time/batch=0.104\n",
      "20399/67600 (epoch 15), train_loss = 1.239, time/batch=0.142\n",
      "20400/67600 (epoch 15), train_loss = 1.248, time/batch=0.274\n",
      "20401/67600 (epoch 15), train_loss = 1.243, time/batch=0.099\n",
      "20402/67600 (epoch 15), train_loss = 1.207, time/batch=0.140\n",
      "20403/67600 (epoch 15), train_loss = 1.188, time/batch=0.121\n",
      "20404/67600 (epoch 15), train_loss = 1.212, time/batch=0.122\n",
      "20405/67600 (epoch 15), train_loss = 1.144, time/batch=0.224\n",
      "20406/67600 (epoch 15), train_loss = 1.211, time/batch=0.157\n",
      "20407/67600 (epoch 15), train_loss = 1.257, time/batch=0.112\n",
      "20408/67600 (epoch 15), train_loss = 1.192, time/batch=0.120\n",
      "20409/67600 (epoch 15), train_loss = 1.212, time/batch=0.124\n",
      "20410/67600 (epoch 15), train_loss = 1.238, time/batch=0.123\n",
      "20411/67600 (epoch 15), train_loss = 1.213, time/batch=0.129\n",
      "20412/67600 (epoch 15), train_loss = 1.269, time/batch=0.159\n",
      "20413/67600 (epoch 15), train_loss = 1.200, time/batch=0.184\n",
      "20414/67600 (epoch 15), train_loss = 1.224, time/batch=0.144\n",
      "20415/67600 (epoch 15), train_loss = 1.223, time/batch=0.120\n",
      "20416/67600 (epoch 15), train_loss = 1.242, time/batch=0.113\n",
      "20417/67600 (epoch 15), train_loss = 1.236, time/batch=0.107\n",
      "20418/67600 (epoch 15), train_loss = 1.227, time/batch=0.129\n",
      "20419/67600 (epoch 15), train_loss = 1.205, time/batch=0.125\n",
      "20420/67600 (epoch 15), train_loss = 1.204, time/batch=0.246\n",
      "20421/67600 (epoch 15), train_loss = 1.181, time/batch=0.162\n",
      "20422/67600 (epoch 15), train_loss = 1.232, time/batch=0.097\n",
      "20423/67600 (epoch 15), train_loss = 1.188, time/batch=0.086\n",
      "20424/67600 (epoch 15), train_loss = 1.272, time/batch=0.112\n",
      "20425/67600 (epoch 15), train_loss = 1.310, time/batch=0.118\n",
      "20426/67600 (epoch 15), train_loss = 1.221, time/batch=0.120\n",
      "20427/67600 (epoch 15), train_loss = 1.206, time/batch=0.255\n",
      "20428/67600 (epoch 15), train_loss = 1.264, time/batch=0.129\n",
      "20429/67600 (epoch 15), train_loss = 1.163, time/batch=0.116\n",
      "20430/67600 (epoch 15), train_loss = 1.235, time/batch=0.123\n",
      "20431/67600 (epoch 15), train_loss = 1.182, time/batch=0.144\n",
      "20432/67600 (epoch 15), train_loss = 1.171, time/batch=0.109\n",
      "20433/67600 (epoch 15), train_loss = 1.234, time/batch=0.116\n",
      "20434/67600 (epoch 15), train_loss = 1.188, time/batch=0.196\n",
      "20435/67600 (epoch 15), train_loss = 1.238, time/batch=0.173\n",
      "20436/67600 (epoch 15), train_loss = 1.237, time/batch=0.122\n",
      "20437/67600 (epoch 15), train_loss = 1.254, time/batch=0.116\n",
      "20438/67600 (epoch 15), train_loss = 1.241, time/batch=0.126\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20439/67600 (epoch 15), train_loss = 1.202, time/batch=0.117\n",
      "20440/67600 (epoch 15), train_loss = 1.186, time/batch=0.219\n",
      "20441/67600 (epoch 15), train_loss = 1.175, time/batch=0.155\n",
      "20442/67600 (epoch 15), train_loss = 1.220, time/batch=0.122\n",
      "20443/67600 (epoch 15), train_loss = 1.205, time/batch=0.130\n",
      "20444/67600 (epoch 15), train_loss = 1.133, time/batch=0.112\n",
      "20445/67600 (epoch 15), train_loss = 1.215, time/batch=0.115\n",
      "20446/67600 (epoch 15), train_loss = 1.203, time/batch=0.129\n",
      "20447/67600 (epoch 15), train_loss = 1.184, time/batch=0.152\n",
      "20448/67600 (epoch 15), train_loss = 1.230, time/batch=0.133\n",
      "20449/67600 (epoch 15), train_loss = 1.238, time/batch=0.101\n",
      "20450/67600 (epoch 15), train_loss = 1.238, time/batch=0.124\n",
      "20451/67600 (epoch 15), train_loss = 1.185, time/batch=0.125\n",
      "20452/67600 (epoch 15), train_loss = 1.249, time/batch=0.111\n",
      "20453/67600 (epoch 15), train_loss = 1.197, time/batch=0.284\n",
      "20454/67600 (epoch 15), train_loss = 1.210, time/batch=0.125\n",
      "20455/67600 (epoch 15), train_loss = 1.167, time/batch=0.137\n",
      "20456/67600 (epoch 15), train_loss = 1.217, time/batch=0.115\n",
      "20457/67600 (epoch 15), train_loss = 1.257, time/batch=0.138\n",
      "20458/67600 (epoch 15), train_loss = 1.178, time/batch=0.141\n",
      "20459/67600 (epoch 15), train_loss = 1.193, time/batch=0.112\n",
      "20460/67600 (epoch 15), train_loss = 1.168, time/batch=0.259\n",
      "20461/67600 (epoch 15), train_loss = 1.164, time/batch=0.133\n",
      "20462/67600 (epoch 15), train_loss = 1.200, time/batch=0.113\n",
      "20463/67600 (epoch 15), train_loss = 1.305, time/batch=0.112\n",
      "20464/67600 (epoch 15), train_loss = 1.318, time/batch=0.113\n",
      "20465/67600 (epoch 15), train_loss = 1.276, time/batch=0.127\n",
      "20466/67600 (epoch 15), train_loss = 1.316, time/batch=0.125\n",
      "20467/67600 (epoch 15), train_loss = 1.217, time/batch=0.252\n",
      "20468/67600 (epoch 15), train_loss = 1.227, time/batch=0.105\n",
      "20469/67600 (epoch 15), train_loss = 1.212, time/batch=0.137\n",
      "20470/67600 (epoch 15), train_loss = 1.290, time/batch=0.124\n",
      "20471/67600 (epoch 15), train_loss = 1.258, time/batch=0.117\n",
      "20472/67600 (epoch 15), train_loss = 1.217, time/batch=0.195\n",
      "20473/67600 (epoch 15), train_loss = 1.257, time/batch=0.160\n",
      "20474/67600 (epoch 15), train_loss = 1.246, time/batch=0.139\n",
      "20475/67600 (epoch 15), train_loss = 1.224, time/batch=0.118\n",
      "20476/67600 (epoch 15), train_loss = 1.216, time/batch=0.132\n",
      "20477/67600 (epoch 15), train_loss = 1.213, time/batch=0.109\n",
      "20478/67600 (epoch 15), train_loss = 1.242, time/batch=0.110\n",
      "20479/67600 (epoch 15), train_loss = 1.187, time/batch=0.219\n",
      "20480/67600 (epoch 15), train_loss = 1.179, time/batch=0.130\n",
      "20481/67600 (epoch 15), train_loss = 1.156, time/batch=0.157\n",
      "20482/67600 (epoch 15), train_loss = 1.272, time/batch=0.122\n",
      "20483/67600 (epoch 15), train_loss = 1.226, time/batch=0.123\n",
      "20484/67600 (epoch 15), train_loss = 1.254, time/batch=0.122\n",
      "20485/67600 (epoch 15), train_loss = 1.159, time/batch=0.112\n",
      "20486/67600 (epoch 15), train_loss = 1.167, time/batch=0.170\n",
      "20487/67600 (epoch 15), train_loss = 1.184, time/batch=0.199\n",
      "20488/67600 (epoch 15), train_loss = 1.244, time/batch=0.139\n",
      "20489/67600 (epoch 15), train_loss = 1.267, time/batch=0.124\n",
      "20490/67600 (epoch 15), train_loss = 1.243, time/batch=0.115\n",
      "20491/67600 (epoch 15), train_loss = 1.285, time/batch=0.121\n",
      "20492/67600 (epoch 15), train_loss = 1.199, time/batch=0.119\n",
      "20493/67600 (epoch 15), train_loss = 1.208, time/batch=0.117\n",
      "20494/67600 (epoch 15), train_loss = 1.204, time/batch=0.258\n",
      "20495/67600 (epoch 15), train_loss = 1.251, time/batch=0.127\n",
      "20496/67600 (epoch 15), train_loss = 1.192, time/batch=0.115\n",
      "20497/67600 (epoch 15), train_loss = 1.202, time/batch=0.120\n",
      "20498/67600 (epoch 15), train_loss = 1.182, time/batch=0.122\n",
      "20499/67600 (epoch 15), train_loss = 1.167, time/batch=0.119\n",
      "20500/67600 (epoch 15), train_loss = 1.270, time/batch=0.117\n",
      "model saved to ./save/model.ckpt\n",
      "20501/67600 (epoch 15), train_loss = 1.193, time/batch=0.077\n",
      "20502/67600 (epoch 15), train_loss = 1.232, time/batch=0.081\n",
      "20503/67600 (epoch 15), train_loss = 1.223, time/batch=0.166\n",
      "20504/67600 (epoch 15), train_loss = 1.227, time/batch=0.169\n",
      "20505/67600 (epoch 15), train_loss = 1.196, time/batch=0.136\n",
      "20506/67600 (epoch 15), train_loss = 1.264, time/batch=0.134\n",
      "20507/67600 (epoch 15), train_loss = 1.180, time/batch=0.145\n",
      "20508/67600 (epoch 15), train_loss = 1.189, time/batch=0.135\n",
      "20509/67600 (epoch 15), train_loss = 1.196, time/batch=0.325\n",
      "20510/67600 (epoch 15), train_loss = 1.223, time/batch=0.169\n",
      "20511/67600 (epoch 15), train_loss = 1.222, time/batch=0.146\n",
      "20512/67600 (epoch 15), train_loss = 1.150, time/batch=0.144\n",
      "20513/67600 (epoch 15), train_loss = 1.154, time/batch=0.153\n",
      "20514/67600 (epoch 15), train_loss = 1.216, time/batch=0.292\n",
      "20515/67600 (epoch 15), train_loss = 1.215, time/batch=0.200\n",
      "20516/67600 (epoch 15), train_loss = 1.209, time/batch=0.130\n",
      "20517/67600 (epoch 15), train_loss = 1.213, time/batch=0.141\n",
      "20518/67600 (epoch 15), train_loss = 1.260, time/batch=0.131\n",
      "20519/67600 (epoch 15), train_loss = 1.236, time/batch=0.120\n",
      "20520/67600 (epoch 15), train_loss = 1.247, time/batch=0.253\n",
      "20521/67600 (epoch 15), train_loss = 1.174, time/batch=0.128\n",
      "20522/67600 (epoch 15), train_loss = 1.221, time/batch=0.119\n",
      "20523/67600 (epoch 15), train_loss = 1.227, time/batch=0.128\n",
      "20524/67600 (epoch 15), train_loss = 1.159, time/batch=0.131\n",
      "20525/67600 (epoch 15), train_loss = 1.227, time/batch=0.235\n",
      "20526/67600 (epoch 15), train_loss = 1.212, time/batch=0.137\n",
      "20527/67600 (epoch 15), train_loss = 1.225, time/batch=0.131\n",
      "20528/67600 (epoch 15), train_loss = 1.253, time/batch=0.149\n",
      "20529/67600 (epoch 15), train_loss = 1.185, time/batch=0.125\n",
      "20530/67600 (epoch 15), train_loss = 1.177, time/batch=0.142\n",
      "20531/67600 (epoch 15), train_loss = 1.273, time/batch=0.117\n",
      "20532/67600 (epoch 15), train_loss = 1.188, time/batch=0.237\n",
      "20533/67600 (epoch 15), train_loss = 1.219, time/batch=0.173\n",
      "20534/67600 (epoch 15), train_loss = 1.241, time/batch=0.122\n",
      "20535/67600 (epoch 15), train_loss = 1.284, time/batch=0.124\n",
      "20536/67600 (epoch 15), train_loss = 1.253, time/batch=0.102\n",
      "20537/67600 (epoch 15), train_loss = 1.266, time/batch=0.165\n",
      "20538/67600 (epoch 15), train_loss = 1.176, time/batch=0.316\n",
      "20539/67600 (epoch 15), train_loss = 1.177, time/batch=0.214\n",
      "20540/67600 (epoch 15), train_loss = 1.208, time/batch=0.212\n",
      "20541/67600 (epoch 15), train_loss = 1.191, time/batch=0.096\n",
      "20542/67600 (epoch 15), train_loss = 1.210, time/batch=0.151\n",
      "20543/67600 (epoch 15), train_loss = 1.218, time/batch=0.128\n",
      "20544/67600 (epoch 15), train_loss = 1.208, time/batch=0.388\n",
      "20545/67600 (epoch 15), train_loss = 1.197, time/batch=0.203\n",
      "20546/67600 (epoch 15), train_loss = 1.180, time/batch=0.231\n",
      "20547/67600 (epoch 15), train_loss = 1.229, time/batch=0.295\n",
      "20548/67600 (epoch 15), train_loss = 1.212, time/batch=0.176\n",
      "20549/67600 (epoch 15), train_loss = 1.188, time/batch=0.143\n",
      "20550/67600 (epoch 15), train_loss = 1.251, time/batch=0.130\n",
      "20551/67600 (epoch 15), train_loss = 1.210, time/batch=0.124\n",
      "20552/67600 (epoch 15), train_loss = 1.227, time/batch=0.137\n",
      "20553/67600 (epoch 15), train_loss = 1.250, time/batch=0.179\n",
      "20554/67600 (epoch 15), train_loss = 1.232, time/batch=0.297\n",
      "20555/67600 (epoch 15), train_loss = 1.216, time/batch=0.194\n",
      "20556/67600 (epoch 15), train_loss = 1.235, time/batch=0.146\n",
      "20557/67600 (epoch 15), train_loss = 1.191, time/batch=0.173\n",
      "20558/67600 (epoch 15), train_loss = 1.188, time/batch=0.222\n",
      "20559/67600 (epoch 15), train_loss = 1.239, time/batch=0.152\n",
      "20560/67600 (epoch 15), train_loss = 1.236, time/batch=0.112\n",
      "20561/67600 (epoch 15), train_loss = 1.190, time/batch=0.117\n",
      "20562/67600 (epoch 15), train_loss = 1.162, time/batch=0.119\n",
      "20563/67600 (epoch 15), train_loss = 1.247, time/batch=0.110\n",
      "20564/67600 (epoch 15), train_loss = 1.178, time/batch=0.125\n",
      "20565/67600 (epoch 15), train_loss = 1.295, time/batch=0.235\n",
      "20566/67600 (epoch 15), train_loss = 1.237, time/batch=0.160\n",
      "20567/67600 (epoch 15), train_loss = 1.215, time/batch=0.118\n",
      "20568/67600 (epoch 15), train_loss = 1.249, time/batch=0.152\n",
      "20569/67600 (epoch 15), train_loss = 1.242, time/batch=0.123\n",
      "20570/67600 (epoch 15), train_loss = 1.239, time/batch=0.105\n",
      "20571/67600 (epoch 15), train_loss = 1.231, time/batch=0.291\n",
      "20572/67600 (epoch 15), train_loss = 1.235, time/batch=0.118\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20573/67600 (epoch 15), train_loss = 1.211, time/batch=0.142\n",
      "20574/67600 (epoch 15), train_loss = 1.223, time/batch=0.122\n",
      "20575/67600 (epoch 15), train_loss = 1.232, time/batch=0.143\n",
      "20576/67600 (epoch 15), train_loss = 1.235, time/batch=0.226\n",
      "20577/67600 (epoch 15), train_loss = 1.205, time/batch=0.160\n",
      "20578/67600 (epoch 15), train_loss = 1.196, time/batch=0.098\n",
      "20579/67600 (epoch 15), train_loss = 1.258, time/batch=0.183\n",
      "20580/67600 (epoch 15), train_loss = 1.222, time/batch=0.116\n",
      "20581/67600 (epoch 15), train_loss = 1.241, time/batch=0.137\n",
      "20582/67600 (epoch 15), train_loss = 1.206, time/batch=0.140\n",
      "20583/67600 (epoch 15), train_loss = 1.244, time/batch=0.138\n",
      "20584/67600 (epoch 15), train_loss = 1.245, time/batch=0.348\n",
      "20585/67600 (epoch 15), train_loss = 1.259, time/batch=0.158\n",
      "20586/67600 (epoch 15), train_loss = 1.275, time/batch=0.122\n",
      "20587/67600 (epoch 15), train_loss = 1.250, time/batch=0.139\n",
      "20588/67600 (epoch 15), train_loss = 1.258, time/batch=0.187\n",
      "20589/67600 (epoch 15), train_loss = 1.250, time/batch=0.305\n",
      "20590/67600 (epoch 15), train_loss = 1.216, time/batch=0.157\n",
      "20591/67600 (epoch 15), train_loss = 1.184, time/batch=0.136\n",
      "20592/67600 (epoch 15), train_loss = 1.193, time/batch=0.340\n",
      "20593/67600 (epoch 15), train_loss = 1.254, time/batch=0.190\n",
      "20594/67600 (epoch 15), train_loss = 1.226, time/batch=0.152\n",
      "20595/67600 (epoch 15), train_loss = 1.298, time/batch=0.157\n",
      "20596/67600 (epoch 15), train_loss = 1.203, time/batch=0.207\n",
      "20597/67600 (epoch 15), train_loss = 1.242, time/batch=0.299\n",
      "20598/67600 (epoch 15), train_loss = 1.243, time/batch=0.139\n",
      "20599/67600 (epoch 15), train_loss = 1.253, time/batch=0.139\n",
      "20600/67600 (epoch 15), train_loss = 1.269, time/batch=0.093\n",
      "20601/67600 (epoch 15), train_loss = 1.226, time/batch=0.132\n",
      "20602/67600 (epoch 15), train_loss = 1.220, time/batch=0.160\n",
      "20603/67600 (epoch 15), train_loss = 1.199, time/batch=0.169\n",
      "20604/67600 (epoch 15), train_loss = 1.207, time/batch=0.241\n",
      "20605/67600 (epoch 15), train_loss = 1.187, time/batch=0.117\n",
      "20606/67600 (epoch 15), train_loss = 1.171, time/batch=0.138\n",
      "20607/67600 (epoch 15), train_loss = 1.247, time/batch=0.135\n",
      "20608/67600 (epoch 15), train_loss = 1.205, time/batch=0.192\n",
      "20609/67600 (epoch 15), train_loss = 1.221, time/batch=0.164\n",
      "20610/67600 (epoch 15), train_loss = 1.264, time/batch=0.144\n",
      "20611/67600 (epoch 15), train_loss = 1.180, time/batch=0.132\n",
      "20612/67600 (epoch 15), train_loss = 1.229, time/batch=0.108\n",
      "20613/67600 (epoch 15), train_loss = 1.217, time/batch=0.107\n",
      "20614/67600 (epoch 15), train_loss = 1.248, time/batch=0.146\n",
      "20615/67600 (epoch 15), train_loss = 1.255, time/batch=0.240\n",
      "20616/67600 (epoch 15), train_loss = 1.208, time/batch=0.164\n",
      "20617/67600 (epoch 15), train_loss = 1.193, time/batch=0.108\n",
      "20618/67600 (epoch 15), train_loss = 1.220, time/batch=0.135\n",
      "20619/67600 (epoch 15), train_loss = 1.271, time/batch=0.132\n",
      "20620/67600 (epoch 15), train_loss = 1.221, time/batch=0.134\n",
      "20621/67600 (epoch 15), train_loss = 1.209, time/batch=0.116\n",
      "20622/67600 (epoch 15), train_loss = 1.192, time/batch=0.255\n",
      "20623/67600 (epoch 15), train_loss = 1.186, time/batch=0.123\n",
      "20624/67600 (epoch 15), train_loss = 1.270, time/batch=0.136\n",
      "20625/67600 (epoch 15), train_loss = 1.287, time/batch=0.133\n",
      "20626/67600 (epoch 15), train_loss = 1.228, time/batch=0.127\n",
      "20627/67600 (epoch 15), train_loss = 1.225, time/batch=0.107\n",
      "20628/67600 (epoch 15), train_loss = 1.260, time/batch=0.131\n",
      "20629/67600 (epoch 15), train_loss = 1.265, time/batch=0.352\n",
      "20630/67600 (epoch 15), train_loss = 1.188, time/batch=0.147\n",
      "20631/67600 (epoch 15), train_loss = 1.172, time/batch=0.132\n",
      "20632/67600 (epoch 15), train_loss = 1.165, time/batch=0.140\n",
      "20633/67600 (epoch 15), train_loss = 1.182, time/batch=0.164\n",
      "20634/67600 (epoch 15), train_loss = 1.199, time/batch=0.150\n",
      "20635/67600 (epoch 15), train_loss = 1.256, time/batch=0.250\n",
      "20636/67600 (epoch 15), train_loss = 1.202, time/batch=0.112\n",
      "20637/67600 (epoch 15), train_loss = 1.215, time/batch=0.149\n",
      "20638/67600 (epoch 15), train_loss = 1.176, time/batch=0.123\n",
      "20639/67600 (epoch 15), train_loss = 1.294, time/batch=0.188\n",
      "20640/67600 (epoch 15), train_loss = 1.222, time/batch=0.199\n",
      "20641/67600 (epoch 15), train_loss = 1.179, time/batch=0.169\n",
      "20642/67600 (epoch 15), train_loss = 1.177, time/batch=0.138\n",
      "20643/67600 (epoch 15), train_loss = 1.264, time/batch=0.145\n",
      "20644/67600 (epoch 15), train_loss = 1.222, time/batch=0.103\n",
      "20645/67600 (epoch 15), train_loss = 1.210, time/batch=0.164\n",
      "20646/67600 (epoch 15), train_loss = 1.209, time/batch=0.219\n",
      "20647/67600 (epoch 15), train_loss = 1.155, time/batch=0.166\n",
      "20648/67600 (epoch 15), train_loss = 1.205, time/batch=0.129\n",
      "20649/67600 (epoch 15), train_loss = 1.289, time/batch=0.150\n",
      "20650/67600 (epoch 15), train_loss = 1.215, time/batch=0.192\n",
      "20651/67600 (epoch 15), train_loss = 1.212, time/batch=0.105\n",
      "20652/67600 (epoch 15), train_loss = 1.251, time/batch=0.316\n",
      "20653/67600 (epoch 15), train_loss = 1.222, time/batch=0.172\n",
      "20654/67600 (epoch 15), train_loss = 1.269, time/batch=0.171\n",
      "20655/67600 (epoch 15), train_loss = 1.302, time/batch=0.126\n",
      "20656/67600 (epoch 15), train_loss = 1.240, time/batch=0.188\n",
      "20657/67600 (epoch 15), train_loss = 1.218, time/batch=0.351\n",
      "20658/67600 (epoch 15), train_loss = 1.302, time/batch=0.127\n",
      "20659/67600 (epoch 15), train_loss = 1.307, time/batch=0.143\n",
      "20660/67600 (epoch 15), train_loss = 1.259, time/batch=0.149\n",
      "20661/67600 (epoch 15), train_loss = 1.203, time/batch=0.219\n",
      "20662/67600 (epoch 15), train_loss = 1.208, time/batch=0.318\n",
      "20663/67600 (epoch 15), train_loss = 1.260, time/batch=0.246\n",
      "20664/67600 (epoch 15), train_loss = 1.293, time/batch=0.163\n",
      "20665/67600 (epoch 15), train_loss = 1.232, time/batch=0.162\n",
      "20666/67600 (epoch 15), train_loss = 1.209, time/batch=0.345\n",
      "20667/67600 (epoch 15), train_loss = 1.217, time/batch=0.155\n",
      "20668/67600 (epoch 15), train_loss = 1.247, time/batch=0.146\n",
      "20669/67600 (epoch 15), train_loss = 1.244, time/batch=0.134\n",
      "20670/67600 (epoch 15), train_loss = 1.221, time/batch=0.135\n",
      "20671/67600 (epoch 15), train_loss = 1.210, time/batch=0.179\n",
      "20672/67600 (epoch 15), train_loss = 1.200, time/batch=0.119\n",
      "20673/67600 (epoch 15), train_loss = 1.237, time/batch=0.119\n",
      "20674/67600 (epoch 15), train_loss = 1.208, time/batch=0.138\n",
      "20675/67600 (epoch 15), train_loss = 1.220, time/batch=0.153\n",
      "20676/67600 (epoch 15), train_loss = 1.269, time/batch=0.312\n",
      "20677/67600 (epoch 15), train_loss = 1.281, time/batch=0.152\n",
      "20678/67600 (epoch 15), train_loss = 1.221, time/batch=0.162\n",
      "20679/67600 (epoch 15), train_loss = 1.201, time/batch=0.123\n",
      "20680/67600 (epoch 15), train_loss = 1.250, time/batch=0.123\n",
      "20681/67600 (epoch 15), train_loss = 1.310, time/batch=0.120\n",
      "20682/67600 (epoch 15), train_loss = 1.273, time/batch=0.131\n",
      "20683/67600 (epoch 15), train_loss = 1.236, time/batch=0.161\n",
      "20684/67600 (epoch 15), train_loss = 1.301, time/batch=0.263\n",
      "20685/67600 (epoch 15), train_loss = 1.260, time/batch=0.318\n",
      "20686/67600 (epoch 15), train_loss = 1.269, time/batch=0.272\n",
      "20687/67600 (epoch 15), train_loss = 1.197, time/batch=0.212\n",
      "20688/67600 (epoch 15), train_loss = 1.254, time/batch=0.136\n",
      "20689/67600 (epoch 15), train_loss = 1.257, time/batch=0.130\n",
      "20690/67600 (epoch 15), train_loss = 1.259, time/batch=0.144\n",
      "20691/67600 (epoch 15), train_loss = 1.192, time/batch=0.258\n",
      "20692/67600 (epoch 15), train_loss = 1.224, time/batch=0.250\n",
      "20693/67600 (epoch 15), train_loss = 1.233, time/batch=0.137\n",
      "20694/67600 (epoch 15), train_loss = 1.202, time/batch=0.140\n",
      "20695/67600 (epoch 15), train_loss = 1.269, time/batch=0.133\n",
      "20696/67600 (epoch 15), train_loss = 1.224, time/batch=0.165\n",
      "20697/67600 (epoch 15), train_loss = 1.256, time/batch=0.152\n",
      "20698/67600 (epoch 15), train_loss = 1.282, time/batch=0.351\n",
      "20699/67600 (epoch 15), train_loss = 1.203, time/batch=0.158\n",
      "20700/67600 (epoch 15), train_loss = 1.148, time/batch=0.141\n",
      "20701/67600 (epoch 15), train_loss = 1.173, time/batch=0.143\n",
      "20702/67600 (epoch 15), train_loss = 1.223, time/batch=0.198\n",
      "20703/67600 (epoch 15), train_loss = 1.170, time/batch=0.310\n",
      "20704/67600 (epoch 15), train_loss = 1.226, time/batch=0.135\n",
      "20705/67600 (epoch 15), train_loss = 1.195, time/batch=0.127\n",
      "20706/67600 (epoch 15), train_loss = 1.219, time/batch=0.117\n",
      "20707/67600 (epoch 15), train_loss = 1.227, time/batch=0.152\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20708/67600 (epoch 15), train_loss = 1.145, time/batch=0.278\n",
      "20709/67600 (epoch 15), train_loss = 1.191, time/batch=0.118\n",
      "20710/67600 (epoch 15), train_loss = 1.256, time/batch=0.123\n",
      "20711/67600 (epoch 15), train_loss = 1.188, time/batch=0.123\n",
      "20712/67600 (epoch 15), train_loss = 1.246, time/batch=0.139\n",
      "20713/67600 (epoch 15), train_loss = 1.250, time/batch=0.130\n",
      "20714/67600 (epoch 15), train_loss = 1.184, time/batch=0.116\n",
      "20715/67600 (epoch 15), train_loss = 1.288, time/batch=0.299\n",
      "20716/67600 (epoch 15), train_loss = 1.220, time/batch=0.132\n",
      "20717/67600 (epoch 15), train_loss = 1.236, time/batch=0.121\n",
      "20718/67600 (epoch 15), train_loss = 1.233, time/batch=0.128\n",
      "20719/67600 (epoch 15), train_loss = 1.210, time/batch=0.108\n",
      "20720/67600 (epoch 15), train_loss = 1.212, time/batch=0.245\n",
      "20721/67600 (epoch 15), train_loss = 1.243, time/batch=0.140\n",
      "20722/67600 (epoch 15), train_loss = 1.203, time/batch=0.123\n",
      "20723/67600 (epoch 15), train_loss = 1.186, time/batch=0.140\n",
      "20724/67600 (epoch 15), train_loss = 1.240, time/batch=0.106\n",
      "20725/67600 (epoch 15), train_loss = 1.272, time/batch=0.150\n",
      "20726/67600 (epoch 15), train_loss = 1.176, time/batch=0.110\n",
      "20727/67600 (epoch 15), train_loss = 1.186, time/batch=0.245\n",
      "20728/67600 (epoch 15), train_loss = 1.159, time/batch=0.163\n",
      "20729/67600 (epoch 15), train_loss = 1.188, time/batch=0.094\n",
      "20730/67600 (epoch 15), train_loss = 1.140, time/batch=0.128\n",
      "20731/67600 (epoch 15), train_loss = 1.246, time/batch=0.118\n",
      "20732/67600 (epoch 15), train_loss = 1.268, time/batch=0.128\n",
      "20733/67600 (epoch 15), train_loss = 1.169, time/batch=0.123\n",
      "20734/67600 (epoch 15), train_loss = 1.144, time/batch=0.264\n",
      "20735/67600 (epoch 15), train_loss = 1.180, time/batch=0.138\n",
      "20736/67600 (epoch 15), train_loss = 1.209, time/batch=0.134\n",
      "20737/67600 (epoch 15), train_loss = 1.222, time/batch=0.108\n",
      "20738/67600 (epoch 15), train_loss = 1.245, time/batch=0.160\n",
      "20739/67600 (epoch 15), train_loss = 1.220, time/batch=0.139\n",
      "20740/67600 (epoch 15), train_loss = 1.228, time/batch=0.263\n",
      "20741/67600 (epoch 15), train_loss = 1.177, time/batch=0.120\n",
      "20742/67600 (epoch 15), train_loss = 1.251, time/batch=0.143\n",
      "20743/67600 (epoch 15), train_loss = 1.224, time/batch=0.150\n",
      "20744/67600 (epoch 15), train_loss = 1.194, time/batch=0.098\n",
      "20745/67600 (epoch 15), train_loss = 1.210, time/batch=0.140\n",
      "20746/67600 (epoch 15), train_loss = 1.201, time/batch=0.131\n",
      "20747/67600 (epoch 15), train_loss = 1.251, time/batch=0.257\n",
      "20748/67600 (epoch 15), train_loss = 1.217, time/batch=0.160\n",
      "20749/67600 (epoch 15), train_loss = 1.184, time/batch=0.112\n",
      "20750/67600 (epoch 15), train_loss = 1.209, time/batch=0.126\n",
      "20751/67600 (epoch 15), train_loss = 1.213, time/batch=0.115\n",
      "20752/67600 (epoch 15), train_loss = 1.178, time/batch=0.322\n",
      "20753/67600 (epoch 15), train_loss = 1.231, time/batch=0.137\n",
      "20754/67600 (epoch 15), train_loss = 1.179, time/batch=0.127\n",
      "20755/67600 (epoch 15), train_loss = 1.161, time/batch=0.130\n",
      "20756/67600 (epoch 15), train_loss = 1.245, time/batch=0.144\n",
      "20757/67600 (epoch 15), train_loss = 1.172, time/batch=0.133\n",
      "20758/67600 (epoch 15), train_loss = 1.214, time/batch=0.193\n",
      "20759/67600 (epoch 15), train_loss = 1.225, time/batch=0.121\n",
      "20760/67600 (epoch 15), train_loss = 1.180, time/batch=0.123\n",
      "20761/67600 (epoch 15), train_loss = 1.216, time/batch=0.147\n",
      "20762/67600 (epoch 15), train_loss = 1.191, time/batch=0.112\n",
      "20763/67600 (epoch 15), train_loss = 1.172, time/batch=0.181\n",
      "20764/67600 (epoch 15), train_loss = 1.230, time/batch=0.348\n",
      "20765/67600 (epoch 15), train_loss = 1.228, time/batch=0.121\n",
      "20766/67600 (epoch 15), train_loss = 1.254, time/batch=0.093\n",
      "20767/67600 (epoch 15), train_loss = 1.233, time/batch=0.135\n",
      "20768/67600 (epoch 15), train_loss = 1.261, time/batch=0.161\n",
      "20769/67600 (epoch 15), train_loss = 1.245, time/batch=0.122\n",
      "20770/67600 (epoch 15), train_loss = 1.182, time/batch=0.271\n",
      "20771/67600 (epoch 15), train_loss = 1.218, time/batch=0.122\n",
      "20772/67600 (epoch 15), train_loss = 1.237, time/batch=0.122\n",
      "20773/67600 (epoch 15), train_loss = 1.189, time/batch=0.131\n",
      "20774/67600 (epoch 15), train_loss = 1.270, time/batch=0.124\n",
      "20775/67600 (epoch 15), train_loss = 1.229, time/batch=0.162\n",
      "20776/67600 (epoch 15), train_loss = 1.205, time/batch=0.349\n",
      "20777/67600 (epoch 15), train_loss = 1.229, time/batch=0.132\n",
      "20778/67600 (epoch 15), train_loss = 1.279, time/batch=0.102\n",
      "20779/67600 (epoch 15), train_loss = 1.215, time/batch=0.120\n",
      "20780/67600 (epoch 15), train_loss = 1.165, time/batch=0.163\n",
      "20781/67600 (epoch 15), train_loss = 1.177, time/batch=0.176\n",
      "20782/67600 (epoch 15), train_loss = 1.191, time/batch=0.157\n",
      "20783/67600 (epoch 15), train_loss = 1.236, time/batch=0.117\n",
      "20784/67600 (epoch 15), train_loss = 1.239, time/batch=0.123\n",
      "20785/67600 (epoch 15), train_loss = 1.257, time/batch=0.128\n",
      "20786/67600 (epoch 15), train_loss = 1.234, time/batch=0.142\n",
      "20787/67600 (epoch 15), train_loss = 1.238, time/batch=0.142\n",
      "20788/67600 (epoch 15), train_loss = 1.184, time/batch=0.211\n",
      "20789/67600 (epoch 15), train_loss = 1.212, time/batch=0.162\n",
      "20790/67600 (epoch 15), train_loss = 1.235, time/batch=0.129\n",
      "20791/67600 (epoch 15), train_loss = 1.223, time/batch=0.129\n",
      "20792/67600 (epoch 15), train_loss = 1.233, time/batch=0.090\n",
      "20793/67600 (epoch 15), train_loss = 1.202, time/batch=0.126\n",
      "20794/67600 (epoch 15), train_loss = 1.226, time/batch=0.116\n",
      "20795/67600 (epoch 15), train_loss = 1.257, time/batch=0.241\n",
      "20796/67600 (epoch 15), train_loss = 1.265, time/batch=0.141\n",
      "20797/67600 (epoch 15), train_loss = 1.250, time/batch=0.125\n",
      "20798/67600 (epoch 15), train_loss = 1.229, time/batch=0.124\n",
      "20799/67600 (epoch 15), train_loss = 1.168, time/batch=0.128\n",
      "20800/67600 (epoch 15), train_loss = 1.273, time/batch=0.122\n",
      "20801/67600 (epoch 15), train_loss = 1.272, time/batch=0.117\n",
      "20802/67600 (epoch 15), train_loss = 1.287, time/batch=0.248\n",
      "20803/67600 (epoch 15), train_loss = 1.237, time/batch=0.140\n",
      "20804/67600 (epoch 15), train_loss = 1.222, time/batch=0.106\n",
      "20805/67600 (epoch 15), train_loss = 1.229, time/batch=0.138\n",
      "20806/67600 (epoch 15), train_loss = 1.242, time/batch=0.107\n",
      "20807/67600 (epoch 15), train_loss = 1.196, time/batch=0.130\n",
      "20808/67600 (epoch 15), train_loss = 1.251, time/batch=0.233\n",
      "20809/67600 (epoch 15), train_loss = 1.217, time/batch=0.178\n",
      "20810/67600 (epoch 15), train_loss = 1.266, time/batch=0.121\n",
      "20811/67600 (epoch 15), train_loss = 1.254, time/batch=0.123\n",
      "20812/67600 (epoch 15), train_loss = 1.248, time/batch=0.196\n",
      "20813/67600 (epoch 15), train_loss = 1.196, time/batch=0.249\n",
      "20814/67600 (epoch 15), train_loss = 1.207, time/batch=0.171\n",
      "20815/67600 (epoch 15), train_loss = 1.177, time/batch=0.172\n",
      "20816/67600 (epoch 15), train_loss = 1.199, time/batch=0.137\n",
      "20817/67600 (epoch 15), train_loss = 1.220, time/batch=0.171\n",
      "20818/67600 (epoch 15), train_loss = 1.220, time/batch=0.151\n",
      "20819/67600 (epoch 15), train_loss = 1.221, time/batch=0.229\n",
      "20820/67600 (epoch 15), train_loss = 1.225, time/batch=0.189\n",
      "20821/67600 (epoch 15), train_loss = 1.169, time/batch=0.135\n",
      "20822/67600 (epoch 15), train_loss = 1.197, time/batch=0.120\n",
      "20823/67600 (epoch 15), train_loss = 1.190, time/batch=0.143\n",
      "20824/67600 (epoch 15), train_loss = 1.265, time/batch=0.118\n",
      "20825/67600 (epoch 15), train_loss = 1.221, time/batch=0.236\n",
      "20826/67600 (epoch 15), train_loss = 1.214, time/batch=0.188\n",
      "20827/67600 (epoch 15), train_loss = 1.213, time/batch=0.131\n",
      "20828/67600 (epoch 15), train_loss = 1.340, time/batch=0.109\n",
      "20829/67600 (epoch 15), train_loss = 1.254, time/batch=0.122\n",
      "20830/67600 (epoch 15), train_loss = 1.205, time/batch=0.177\n",
      "20831/67600 (epoch 15), train_loss = 1.261, time/batch=0.274\n",
      "20832/67600 (epoch 15), train_loss = 1.204, time/batch=0.146\n",
      "20833/67600 (epoch 15), train_loss = 1.210, time/batch=0.116\n",
      "20834/67600 (epoch 15), train_loss = 1.253, time/batch=0.132\n",
      "20835/67600 (epoch 15), train_loss = 1.212, time/batch=0.117\n",
      "20836/67600 (epoch 15), train_loss = 1.272, time/batch=0.149\n",
      "20837/67600 (epoch 15), train_loss = 1.220, time/batch=0.116\n",
      "20838/67600 (epoch 15), train_loss = 1.200, time/batch=0.254\n",
      "20839/67600 (epoch 15), train_loss = 1.154, time/batch=0.134\n",
      "20840/67600 (epoch 15), train_loss = 1.191, time/batch=0.117\n",
      "20841/67600 (epoch 15), train_loss = 1.208, time/batch=0.150\n",
      "20842/67600 (epoch 15), train_loss = 1.167, time/batch=0.164\n",
      "20843/67600 (epoch 15), train_loss = 1.214, time/batch=0.112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20844/67600 (epoch 15), train_loss = 1.185, time/batch=0.111\n",
      "20845/67600 (epoch 15), train_loss = 1.202, time/batch=0.280\n",
      "20846/67600 (epoch 15), train_loss = 1.219, time/batch=0.120\n",
      "20847/67600 (epoch 15), train_loss = 1.239, time/batch=0.114\n",
      "20848/67600 (epoch 15), train_loss = 1.231, time/batch=0.115\n",
      "20849/67600 (epoch 15), train_loss = 1.196, time/batch=0.136\n",
      "20850/67600 (epoch 15), train_loss = 1.179, time/batch=0.179\n",
      "20851/67600 (epoch 15), train_loss = 1.181, time/batch=0.109\n",
      "20852/67600 (epoch 15), train_loss = 1.205, time/batch=0.140\n",
      "20853/67600 (epoch 15), train_loss = 1.211, time/batch=0.146\n",
      "20854/67600 (epoch 15), train_loss = 1.228, time/batch=0.116\n",
      "20855/67600 (epoch 15), train_loss = 1.185, time/batch=0.322\n",
      "20856/67600 (epoch 15), train_loss = 1.237, time/batch=0.160\n",
      "20857/67600 (epoch 15), train_loss = 1.218, time/batch=0.093\n",
      "20858/67600 (epoch 15), train_loss = 1.247, time/batch=0.133\n",
      "20859/67600 (epoch 15), train_loss = 1.221, time/batch=0.113\n",
      "20860/67600 (epoch 15), train_loss = 1.252, time/batch=0.132\n",
      "20861/67600 (epoch 15), train_loss = 1.211, time/batch=0.107\n",
      "20862/67600 (epoch 15), train_loss = 1.175, time/batch=0.254\n",
      "20863/67600 (epoch 15), train_loss = 1.194, time/batch=0.133\n",
      "20864/67600 (epoch 15), train_loss = 1.212, time/batch=0.120\n",
      "20865/67600 (epoch 15), train_loss = 1.275, time/batch=0.116\n",
      "20866/67600 (epoch 15), train_loss = 1.195, time/batch=0.139\n",
      "20867/67600 (epoch 15), train_loss = 1.270, time/batch=0.112\n",
      "20868/67600 (epoch 15), train_loss = 1.188, time/batch=0.118\n",
      "20869/67600 (epoch 15), train_loss = 1.225, time/batch=0.269\n",
      "20870/67600 (epoch 15), train_loss = 1.271, time/batch=0.125\n",
      "20871/67600 (epoch 15), train_loss = 1.188, time/batch=0.131\n",
      "20872/67600 (epoch 15), train_loss = 1.187, time/batch=0.137\n",
      "20873/67600 (epoch 15), train_loss = 1.228, time/batch=0.101\n",
      "20874/67600 (epoch 15), train_loss = 1.170, time/batch=0.229\n",
      "20875/67600 (epoch 15), train_loss = 1.213, time/batch=0.148\n",
      "20876/67600 (epoch 15), train_loss = 1.231, time/batch=0.129\n",
      "20877/67600 (epoch 15), train_loss = 1.176, time/batch=0.116\n",
      "20878/67600 (epoch 15), train_loss = 1.214, time/batch=0.124\n",
      "20879/67600 (epoch 15), train_loss = 1.204, time/batch=0.115\n",
      "20880/67600 (epoch 15), train_loss = 1.240, time/batch=0.127\n",
      "20881/67600 (epoch 15), train_loss = 1.159, time/batch=0.237\n",
      "20882/67600 (epoch 15), train_loss = 1.218, time/batch=0.160\n",
      "20883/67600 (epoch 15), train_loss = 1.200, time/batch=0.115\n",
      "20884/67600 (epoch 15), train_loss = 1.232, time/batch=0.113\n",
      "20885/67600 (epoch 15), train_loss = 1.191, time/batch=0.132\n",
      "20886/67600 (epoch 15), train_loss = 1.267, time/batch=0.139\n",
      "20887/67600 (epoch 15), train_loss = 1.199, time/batch=0.117\n",
      "20888/67600 (epoch 15), train_loss = 1.282, time/batch=0.223\n",
      "20889/67600 (epoch 15), train_loss = 1.212, time/batch=0.226\n",
      "20890/67600 (epoch 15), train_loss = 1.241, time/batch=0.141\n",
      "20891/67600 (epoch 15), train_loss = 1.308, time/batch=0.124\n",
      "20892/67600 (epoch 15), train_loss = 1.219, time/batch=0.118\n",
      "20893/67600 (epoch 15), train_loss = 1.212, time/batch=0.144\n",
      "20894/67600 (epoch 15), train_loss = 1.249, time/batch=0.219\n",
      "20895/67600 (epoch 15), train_loss = 1.278, time/batch=0.158\n",
      "20896/67600 (epoch 15), train_loss = 1.231, time/batch=0.108\n",
      "20897/67600 (epoch 15), train_loss = 1.292, time/batch=0.123\n",
      "20898/67600 (epoch 15), train_loss = 1.222, time/batch=0.104\n",
      "20899/67600 (epoch 15), train_loss = 1.186, time/batch=0.133\n",
      "20900/67600 (epoch 15), train_loss = 1.171, time/batch=0.118\n",
      "20901/67600 (epoch 15), train_loss = 1.207, time/batch=0.298\n",
      "20902/67600 (epoch 15), train_loss = 1.223, time/batch=0.111\n",
      "20903/67600 (epoch 15), train_loss = 1.189, time/batch=0.117\n",
      "20904/67600 (epoch 15), train_loss = 1.220, time/batch=0.180\n",
      "20905/67600 (epoch 15), train_loss = 1.205, time/batch=0.095\n",
      "20906/67600 (epoch 15), train_loss = 1.253, time/batch=0.234\n",
      "20907/67600 (epoch 15), train_loss = 1.257, time/batch=0.100\n",
      "20908/67600 (epoch 15), train_loss = 1.254, time/batch=0.154\n",
      "20909/67600 (epoch 15), train_loss = 1.217, time/batch=0.125\n",
      "20910/67600 (epoch 15), train_loss = 1.259, time/batch=0.154\n",
      "20911/67600 (epoch 15), train_loss = 1.286, time/batch=0.104\n",
      "20912/67600 (epoch 15), train_loss = 1.203, time/batch=0.114\n",
      "20913/67600 (epoch 15), train_loss = 1.276, time/batch=0.132\n",
      "20914/67600 (epoch 15), train_loss = 1.264, time/batch=0.215\n",
      "20915/67600 (epoch 15), train_loss = 1.140, time/batch=0.148\n",
      "20916/67600 (epoch 15), train_loss = 1.308, time/batch=0.125\n",
      "20917/67600 (epoch 15), train_loss = 1.197, time/batch=0.116\n",
      "20918/67600 (epoch 15), train_loss = 1.158, time/batch=0.122\n",
      "20919/67600 (epoch 15), train_loss = 1.149, time/batch=0.137\n",
      "20920/67600 (epoch 15), train_loss = 1.223, time/batch=0.112\n",
      "20921/67600 (epoch 15), train_loss = 1.200, time/batch=0.241\n",
      "20922/67600 (epoch 15), train_loss = 1.252, time/batch=0.138\n",
      "20923/67600 (epoch 15), train_loss = 1.299, time/batch=0.126\n",
      "20924/67600 (epoch 15), train_loss = 1.271, time/batch=0.119\n",
      "20925/67600 (epoch 15), train_loss = 1.222, time/batch=0.115\n",
      "20926/67600 (epoch 15), train_loss = 1.255, time/batch=0.125\n",
      "20927/67600 (epoch 15), train_loss = 1.239, time/batch=0.118\n",
      "20928/67600 (epoch 15), train_loss = 1.269, time/batch=0.242\n",
      "20929/67600 (epoch 15), train_loss = 1.235, time/batch=0.146\n",
      "20930/67600 (epoch 15), train_loss = 1.273, time/batch=0.117\n",
      "20931/67600 (epoch 15), train_loss = 1.296, time/batch=0.120\n",
      "20932/67600 (epoch 15), train_loss = 1.217, time/batch=0.121\n",
      "20933/67600 (epoch 15), train_loss = 1.216, time/batch=0.123\n",
      "20934/67600 (epoch 15), train_loss = 1.243, time/batch=0.139\n",
      "20935/67600 (epoch 15), train_loss = 1.218, time/batch=0.251\n",
      "20936/67600 (epoch 15), train_loss = 1.208, time/batch=0.110\n",
      "20937/67600 (epoch 15), train_loss = 1.294, time/batch=0.085\n",
      "20938/67600 (epoch 15), train_loss = 1.238, time/batch=0.127\n",
      "20939/67600 (epoch 15), train_loss = 1.163, time/batch=0.117\n",
      "20940/67600 (epoch 15), train_loss = 1.212, time/batch=0.230\n",
      "20941/67600 (epoch 15), train_loss = 1.210, time/batch=0.132\n",
      "20942/67600 (epoch 15), train_loss = 1.140, time/batch=0.137\n",
      "20943/67600 (epoch 15), train_loss = 1.172, time/batch=0.116\n",
      "20944/67600 (epoch 15), train_loss = 1.257, time/batch=0.121\n",
      "20945/67600 (epoch 15), train_loss = 1.236, time/batch=0.138\n",
      "20946/67600 (epoch 15), train_loss = 1.248, time/batch=0.114\n",
      "20947/67600 (epoch 15), train_loss = 1.213, time/batch=0.174\n",
      "20948/67600 (epoch 15), train_loss = 1.277, time/batch=0.118\n",
      "20949/67600 (epoch 15), train_loss = 1.186, time/batch=0.101\n",
      "20950/67600 (epoch 15), train_loss = 1.139, time/batch=0.137\n",
      "20951/67600 (epoch 15), train_loss = 1.196, time/batch=0.115\n",
      "20952/67600 (epoch 15), train_loss = 1.136, time/batch=0.101\n",
      "20953/67600 (epoch 15), train_loss = 1.279, time/batch=0.232\n",
      "20954/67600 (epoch 15), train_loss = 1.267, time/batch=0.178\n",
      "20955/67600 (epoch 15), train_loss = 1.190, time/batch=0.133\n",
      "20956/67600 (epoch 15), train_loss = 1.227, time/batch=0.122\n",
      "20957/67600 (epoch 15), train_loss = 1.257, time/batch=0.133\n",
      "20958/67600 (epoch 15), train_loss = 1.273, time/batch=0.120\n",
      "20959/67600 (epoch 15), train_loss = 1.206, time/batch=0.106\n",
      "20960/67600 (epoch 15), train_loss = 1.221, time/batch=0.121\n",
      "20961/67600 (epoch 15), train_loss = 1.249, time/batch=0.275\n",
      "20962/67600 (epoch 15), train_loss = 1.249, time/batch=0.128\n",
      "20963/67600 (epoch 15), train_loss = 1.211, time/batch=0.106\n",
      "20964/67600 (epoch 15), train_loss = 1.194, time/batch=0.151\n",
      "20965/67600 (epoch 15), train_loss = 1.275, time/batch=0.137\n",
      "20966/67600 (epoch 15), train_loss = 1.244, time/batch=0.109\n",
      "20967/67600 (epoch 15), train_loss = 1.185, time/batch=0.133\n",
      "20968/67600 (epoch 15), train_loss = 1.227, time/batch=0.267\n",
      "20969/67600 (epoch 15), train_loss = 1.173, time/batch=0.122\n",
      "20970/67600 (epoch 15), train_loss = 1.219, time/batch=0.121\n",
      "20971/67600 (epoch 15), train_loss = 1.209, time/batch=0.148\n",
      "20972/67600 (epoch 15), train_loss = 1.202, time/batch=0.149\n",
      "20973/67600 (epoch 15), train_loss = 1.253, time/batch=0.187\n",
      "20974/67600 (epoch 15), train_loss = 1.229, time/batch=0.186\n",
      "20975/67600 (epoch 15), train_loss = 1.148, time/batch=0.118\n",
      "20976/67600 (epoch 15), train_loss = 1.239, time/batch=0.112\n",
      "20977/67600 (epoch 15), train_loss = 1.255, time/batch=0.129\n",
      "20978/67600 (epoch 15), train_loss = 1.246, time/batch=0.109\n",
      "20979/67600 (epoch 15), train_loss = 1.180, time/batch=0.156\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20980/67600 (epoch 15), train_loss = 1.222, time/batch=0.209\n",
      "20981/67600 (epoch 15), train_loss = 1.250, time/batch=0.138\n",
      "20982/67600 (epoch 15), train_loss = 1.212, time/batch=0.140\n",
      "20983/67600 (epoch 15), train_loss = 1.168, time/batch=0.122\n",
      "20984/67600 (epoch 15), train_loss = 1.219, time/batch=0.109\n",
      "20985/67600 (epoch 15), train_loss = 1.199, time/batch=0.125\n",
      "20986/67600 (epoch 15), train_loss = 1.208, time/batch=0.133\n",
      "20987/67600 (epoch 15), train_loss = 1.242, time/batch=0.220\n",
      "20988/67600 (epoch 15), train_loss = 1.234, time/batch=0.185\n",
      "20989/67600 (epoch 15), train_loss = 1.185, time/batch=0.093\n",
      "20990/67600 (epoch 15), train_loss = 1.223, time/batch=0.116\n",
      "20991/67600 (epoch 15), train_loss = 1.127, time/batch=0.126\n",
      "20992/67600 (epoch 15), train_loss = 1.214, time/batch=0.127\n",
      "20993/67600 (epoch 15), train_loss = 1.206, time/batch=0.219\n",
      "20994/67600 (epoch 15), train_loss = 1.205, time/batch=0.184\n",
      "20995/67600 (epoch 15), train_loss = 1.191, time/batch=0.110\n",
      "20996/67600 (epoch 15), train_loss = 1.164, time/batch=0.118\n",
      "20997/67600 (epoch 15), train_loss = 1.215, time/batch=0.109\n",
      "20998/67600 (epoch 15), train_loss = 1.196, time/batch=0.141\n",
      "20999/67600 (epoch 15), train_loss = 1.204, time/batch=0.129\n",
      "21000/67600 (epoch 15), train_loss = 1.211, time/batch=0.198\n",
      "model saved to ./save/model.ckpt\n",
      "21001/67600 (epoch 15), train_loss = 1.240, time/batch=0.096\n",
      "21002/67600 (epoch 15), train_loss = 1.214, time/batch=0.146\n",
      "21003/67600 (epoch 15), train_loss = 1.232, time/batch=0.095\n",
      "21004/67600 (epoch 15), train_loss = 1.224, time/batch=0.112\n",
      "21005/67600 (epoch 15), train_loss = 1.229, time/batch=0.118\n",
      "21006/67600 (epoch 15), train_loss = 1.222, time/batch=0.127\n",
      "21007/67600 (epoch 15), train_loss = 1.226, time/batch=0.118\n",
      "21008/67600 (epoch 15), train_loss = 1.243, time/batch=0.176\n",
      "21009/67600 (epoch 15), train_loss = 1.207, time/batch=0.213\n",
      "21010/67600 (epoch 15), train_loss = 1.229, time/batch=0.134\n",
      "21011/67600 (epoch 15), train_loss = 1.249, time/batch=0.131\n",
      "21012/67600 (epoch 15), train_loss = 1.235, time/batch=0.105\n",
      "21013/67600 (epoch 15), train_loss = 1.226, time/batch=0.123\n",
      "21014/67600 (epoch 15), train_loss = 1.223, time/batch=0.144\n",
      "21015/67600 (epoch 15), train_loss = 1.176, time/batch=0.113\n",
      "21016/67600 (epoch 15), train_loss = 1.279, time/batch=0.275\n",
      "21017/67600 (epoch 15), train_loss = 1.202, time/batch=0.125\n",
      "21018/67600 (epoch 15), train_loss = 1.179, time/batch=0.132\n",
      "21019/67600 (epoch 15), train_loss = 1.249, time/batch=0.138\n",
      "21020/67600 (epoch 15), train_loss = 1.161, time/batch=0.097\n",
      "21021/67600 (epoch 15), train_loss = 1.165, time/batch=0.159\n",
      "21022/67600 (epoch 15), train_loss = 1.159, time/batch=0.134\n",
      "21023/67600 (epoch 15), train_loss = 1.205, time/batch=0.299\n",
      "21024/67600 (epoch 15), train_loss = 1.236, time/batch=0.110\n",
      "21025/67600 (epoch 15), train_loss = 1.226, time/batch=0.130\n",
      "21026/67600 (epoch 15), train_loss = 1.202, time/batch=0.110\n",
      "21027/67600 (epoch 15), train_loss = 1.210, time/batch=0.236\n",
      "21028/67600 (epoch 15), train_loss = 1.225, time/batch=0.140\n",
      "21029/67600 (epoch 15), train_loss = 1.191, time/batch=0.123\n",
      "21030/67600 (epoch 15), train_loss = 1.148, time/batch=0.132\n",
      "21031/67600 (epoch 15), train_loss = 1.191, time/batch=0.113\n",
      "21032/67600 (epoch 15), train_loss = 1.206, time/batch=0.107\n",
      "21033/67600 (epoch 15), train_loss = 1.264, time/batch=0.130\n",
      "21034/67600 (epoch 15), train_loss = 1.207, time/batch=0.154\n",
      "21035/67600 (epoch 15), train_loss = 1.214, time/batch=0.159\n",
      "21036/67600 (epoch 15), train_loss = 1.279, time/batch=0.138\n",
      "21037/67600 (epoch 15), train_loss = 1.223, time/batch=0.111\n",
      "21038/67600 (epoch 15), train_loss = 1.199, time/batch=0.129\n",
      "21039/67600 (epoch 15), train_loss = 1.188, time/batch=0.121\n",
      "21040/67600 (epoch 15), train_loss = 1.204, time/batch=0.127\n",
      "21041/67600 (epoch 15), train_loss = 1.204, time/batch=0.134\n",
      "21042/67600 (epoch 15), train_loss = 1.200, time/batch=0.294\n",
      "21043/67600 (epoch 15), train_loss = 1.245, time/batch=0.105\n",
      "21044/67600 (epoch 15), train_loss = 1.267, time/batch=0.122\n",
      "21045/67600 (epoch 15), train_loss = 1.184, time/batch=0.107\n",
      "21046/67600 (epoch 15), train_loss = 1.226, time/batch=0.108\n",
      "21047/67600 (epoch 15), train_loss = 1.207, time/batch=0.111\n",
      "21048/67600 (epoch 15), train_loss = 1.247, time/batch=0.107\n",
      "21049/67600 (epoch 15), train_loss = 1.236, time/batch=0.240\n",
      "21050/67600 (epoch 15), train_loss = 1.201, time/batch=0.155\n",
      "21051/67600 (epoch 15), train_loss = 1.259, time/batch=0.104\n",
      "21052/67600 (epoch 15), train_loss = 1.227, time/batch=0.128\n",
      "21053/67600 (epoch 15), train_loss = 1.206, time/batch=0.108\n",
      "21054/67600 (epoch 15), train_loss = 1.251, time/batch=0.112\n",
      "21055/67600 (epoch 15), train_loss = 1.286, time/batch=0.110\n",
      "21056/67600 (epoch 15), train_loss = 1.253, time/batch=0.132\n",
      "21057/67600 (epoch 15), train_loss = 1.238, time/batch=0.211\n",
      "21058/67600 (epoch 15), train_loss = 1.213, time/batch=0.127\n",
      "21059/67600 (epoch 15), train_loss = 1.239, time/batch=0.114\n",
      "21060/67600 (epoch 15), train_loss = 1.278, time/batch=0.106\n",
      "21061/67600 (epoch 15), train_loss = 1.215, time/batch=0.112\n",
      "21062/67600 (epoch 15), train_loss = 1.206, time/batch=0.188\n",
      "21063/67600 (epoch 15), train_loss = 1.225, time/batch=0.109\n",
      "21064/67600 (epoch 15), train_loss = 1.207, time/batch=0.150\n",
      "21065/67600 (epoch 15), train_loss = 1.245, time/batch=0.117\n",
      "21066/67600 (epoch 15), train_loss = 1.212, time/batch=0.121\n",
      "21067/67600 (epoch 15), train_loss = 1.229, time/batch=0.107\n",
      "21068/67600 (epoch 15), train_loss = 1.237, time/batch=0.109\n",
      "21069/67600 (epoch 15), train_loss = 1.175, time/batch=0.122\n",
      "21070/67600 (epoch 15), train_loss = 1.214, time/batch=0.200\n",
      "21071/67600 (epoch 15), train_loss = 1.229, time/batch=0.138\n",
      "21072/67600 (epoch 15), train_loss = 1.190, time/batch=0.113\n",
      "21073/67600 (epoch 15), train_loss = 1.242, time/batch=0.109\n",
      "21074/67600 (epoch 15), train_loss = 1.222, time/batch=0.111\n",
      "21075/67600 (epoch 15), train_loss = 1.224, time/batch=0.112\n",
      "21076/67600 (epoch 15), train_loss = 1.293, time/batch=0.114\n",
      "21077/67600 (epoch 15), train_loss = 1.234, time/batch=0.113\n",
      "21078/67600 (epoch 15), train_loss = 1.269, time/batch=0.218\n",
      "21079/67600 (epoch 15), train_loss = 1.224, time/batch=0.142\n",
      "21080/67600 (epoch 15), train_loss = 1.231, time/batch=0.111\n",
      "21081/67600 (epoch 15), train_loss = 1.214, time/batch=0.110\n",
      "21082/67600 (epoch 15), train_loss = 1.188, time/batch=0.120\n",
      "21083/67600 (epoch 15), train_loss = 1.214, time/batch=0.110\n",
      "21084/67600 (epoch 15), train_loss = 1.195, time/batch=0.105\n",
      "21085/67600 (epoch 15), train_loss = 1.171, time/batch=0.138\n",
      "21086/67600 (epoch 15), train_loss = 1.217, time/batch=0.204\n",
      "21087/67600 (epoch 15), train_loss = 1.194, time/batch=0.115\n",
      "21088/67600 (epoch 15), train_loss = 1.140, time/batch=0.114\n",
      "21089/67600 (epoch 15), train_loss = 1.241, time/batch=0.123\n",
      "21090/67600 (epoch 15), train_loss = 1.182, time/batch=0.108\n",
      "21091/67600 (epoch 15), train_loss = 1.247, time/batch=0.121\n",
      "21092/67600 (epoch 15), train_loss = 1.239, time/batch=0.109\n",
      "21093/67600 (epoch 15), train_loss = 1.228, time/batch=0.162\n",
      "21094/67600 (epoch 15), train_loss = 1.265, time/batch=0.180\n",
      "21095/67600 (epoch 15), train_loss = 1.172, time/batch=0.124\n",
      "21096/67600 (epoch 15), train_loss = 1.256, time/batch=0.105\n",
      "21097/67600 (epoch 15), train_loss = 1.194, time/batch=0.123\n",
      "21098/67600 (epoch 15), train_loss = 1.195, time/batch=0.103\n",
      "21099/67600 (epoch 15), train_loss = 1.217, time/batch=0.108\n",
      "21100/67600 (epoch 15), train_loss = 1.153, time/batch=0.116\n",
      "21101/67600 (epoch 15), train_loss = 1.253, time/batch=0.207\n",
      "21102/67600 (epoch 15), train_loss = 1.213, time/batch=0.136\n",
      "21103/67600 (epoch 15), train_loss = 1.284, time/batch=0.116\n",
      "21104/67600 (epoch 15), train_loss = 1.228, time/batch=0.113\n",
      "21105/67600 (epoch 15), train_loss = 1.261, time/batch=0.115\n",
      "21106/67600 (epoch 15), train_loss = 1.351, time/batch=0.106\n",
      "21107/67600 (epoch 15), train_loss = 1.188, time/batch=0.155\n",
      "21108/67600 (epoch 15), train_loss = 1.215, time/batch=0.119\n",
      "21109/67600 (epoch 15), train_loss = 1.253, time/batch=0.112\n",
      "21110/67600 (epoch 15), train_loss = 1.296, time/batch=0.101\n",
      "21111/67600 (epoch 15), train_loss = 1.206, time/batch=0.101\n",
      "21112/67600 (epoch 15), train_loss = 1.216, time/batch=0.132\n",
      "21113/67600 (epoch 15), train_loss = 1.220, time/batch=0.287\n",
      "21114/67600 (epoch 15), train_loss = 1.192, time/batch=0.131\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21115/67600 (epoch 15), train_loss = 1.260, time/batch=0.110\n",
      "21116/67600 (epoch 15), train_loss = 1.123, time/batch=0.112\n",
      "21117/67600 (epoch 15), train_loss = 1.242, time/batch=0.110\n",
      "21118/67600 (epoch 15), train_loss = 1.157, time/batch=0.120\n",
      "21119/67600 (epoch 15), train_loss = 1.212, time/batch=0.121\n",
      "21120/67600 (epoch 15), train_loss = 1.271, time/batch=0.103\n",
      "21121/67600 (epoch 15), train_loss = 1.230, time/batch=0.238\n",
      "21122/67600 (epoch 15), train_loss = 1.226, time/batch=0.109\n",
      "21123/67600 (epoch 15), train_loss = 1.221, time/batch=0.113\n",
      "21124/67600 (epoch 15), train_loss = 1.217, time/batch=0.132\n",
      "21125/67600 (epoch 15), train_loss = 1.203, time/batch=0.093\n",
      "21126/67600 (epoch 15), train_loss = 1.198, time/batch=0.209\n",
      "21127/67600 (epoch 15), train_loss = 1.204, time/batch=0.191\n",
      "21128/67600 (epoch 15), train_loss = 1.237, time/batch=0.127\n",
      "21129/67600 (epoch 15), train_loss = 1.211, time/batch=0.125\n",
      "21130/67600 (epoch 15), train_loss = 1.221, time/batch=0.134\n",
      "21131/67600 (epoch 15), train_loss = 1.297, time/batch=0.114\n",
      "21132/67600 (epoch 15), train_loss = 1.294, time/batch=0.101\n",
      "21133/67600 (epoch 15), train_loss = 1.274, time/batch=0.171\n",
      "21134/67600 (epoch 15), train_loss = 1.219, time/batch=0.166\n",
      "21135/67600 (epoch 15), train_loss = 1.250, time/batch=0.135\n",
      "21136/67600 (epoch 15), train_loss = 1.223, time/batch=0.113\n",
      "21137/67600 (epoch 15), train_loss = 1.244, time/batch=0.111\n",
      "21138/67600 (epoch 15), train_loss = 1.241, time/batch=0.122\n",
      "21139/67600 (epoch 15), train_loss = 1.267, time/batch=0.109\n",
      "21140/67600 (epoch 15), train_loss = 1.217, time/batch=0.116\n",
      "21141/67600 (epoch 15), train_loss = 1.275, time/batch=0.205\n",
      "21142/67600 (epoch 15), train_loss = 1.293, time/batch=0.144\n",
      "21143/67600 (epoch 15), train_loss = 1.249, time/batch=0.112\n",
      "21144/67600 (epoch 15), train_loss = 1.191, time/batch=0.133\n",
      "21145/67600 (epoch 15), train_loss = 1.284, time/batch=0.118\n",
      "21146/67600 (epoch 15), train_loss = 1.268, time/batch=0.120\n",
      "21147/67600 (epoch 15), train_loss = 1.203, time/batch=0.115\n",
      "21148/67600 (epoch 15), train_loss = 1.229, time/batch=0.101\n",
      "21149/67600 (epoch 15), train_loss = 1.223, time/batch=0.224\n",
      "21150/67600 (epoch 15), train_loss = 1.222, time/batch=0.136\n",
      "21151/67600 (epoch 15), train_loss = 1.199, time/batch=0.118\n",
      "21152/67600 (epoch 15), train_loss = 1.254, time/batch=0.110\n",
      "21153/67600 (epoch 15), train_loss = 1.181, time/batch=0.118\n",
      "21154/67600 (epoch 15), train_loss = 1.223, time/batch=0.114\n",
      "21155/67600 (epoch 15), train_loss = 1.278, time/batch=0.101\n",
      "21156/67600 (epoch 15), train_loss = 1.270, time/batch=0.107\n",
      "21157/67600 (epoch 15), train_loss = 1.134, time/batch=0.220\n",
      "21158/67600 (epoch 15), train_loss = 1.226, time/batch=0.108\n",
      "21159/67600 (epoch 15), train_loss = 1.128, time/batch=0.119\n",
      "21160/67600 (epoch 15), train_loss = 1.180, time/batch=0.116\n",
      "21161/67600 (epoch 15), train_loss = 1.196, time/batch=0.098\n",
      "21162/67600 (epoch 15), train_loss = 1.198, time/batch=0.116\n",
      "21163/67600 (epoch 15), train_loss = 1.221, time/batch=0.120\n",
      "21164/67600 (epoch 15), train_loss = 1.193, time/batch=0.217\n",
      "21165/67600 (epoch 15), train_loss = 1.214, time/batch=0.140\n",
      "21166/67600 (epoch 15), train_loss = 1.194, time/batch=0.121\n",
      "21167/67600 (epoch 15), train_loss = 1.165, time/batch=0.112\n",
      "21168/67600 (epoch 15), train_loss = 1.285, time/batch=0.112\n",
      "21169/67600 (epoch 15), train_loss = 1.253, time/batch=0.107\n",
      "21170/67600 (epoch 15), train_loss = 1.276, time/batch=0.200\n",
      "21171/67600 (epoch 15), train_loss = 1.271, time/batch=0.158\n",
      "21172/67600 (epoch 15), train_loss = 1.238, time/batch=0.095\n",
      "21173/67600 (epoch 15), train_loss = 1.200, time/batch=0.129\n",
      "21174/67600 (epoch 15), train_loss = 1.236, time/batch=0.120\n",
      "21175/67600 (epoch 15), train_loss = 1.200, time/batch=0.106\n",
      "21176/67600 (epoch 15), train_loss = 1.225, time/batch=0.108\n",
      "21177/67600 (epoch 15), train_loss = 1.290, time/batch=0.115\n",
      "21178/67600 (epoch 15), train_loss = 1.253, time/batch=0.226\n",
      "21179/67600 (epoch 15), train_loss = 1.261, time/batch=0.137\n",
      "21180/67600 (epoch 15), train_loss = 1.232, time/batch=0.106\n",
      "21181/67600 (epoch 15), train_loss = 1.275, time/batch=0.114\n",
      "21182/67600 (epoch 15), train_loss = 1.273, time/batch=0.121\n",
      "21183/67600 (epoch 15), train_loss = 1.167, time/batch=0.114\n",
      "21184/67600 (epoch 15), train_loss = 1.212, time/batch=0.109\n",
      "21185/67600 (epoch 15), train_loss = 1.256, time/batch=0.139\n",
      "21186/67600 (epoch 15), train_loss = 1.211, time/batch=0.178\n",
      "21187/67600 (epoch 15), train_loss = 1.193, time/batch=0.143\n",
      "21188/67600 (epoch 15), train_loss = 1.277, time/batch=0.105\n",
      "21189/67600 (epoch 15), train_loss = 1.202, time/batch=0.111\n",
      "21190/67600 (epoch 15), train_loss = 1.221, time/batch=0.155\n",
      "21191/67600 (epoch 15), train_loss = 1.238, time/batch=0.140\n",
      "21192/67600 (epoch 15), train_loss = 1.218, time/batch=0.165\n",
      "21193/67600 (epoch 15), train_loss = 1.256, time/batch=0.174\n",
      "21194/67600 (epoch 15), train_loss = 1.274, time/batch=0.138\n",
      "21195/67600 (epoch 15), train_loss = 1.190, time/batch=0.106\n",
      "21196/67600 (epoch 15), train_loss = 1.218, time/batch=0.116\n",
      "21197/67600 (epoch 15), train_loss = 1.213, time/batch=0.111\n",
      "21198/67600 (epoch 15), train_loss = 1.228, time/batch=0.109\n",
      "21199/67600 (epoch 15), train_loss = 1.220, time/batch=0.125\n",
      "21200/67600 (epoch 15), train_loss = 1.255, time/batch=0.155\n",
      "21201/67600 (epoch 15), train_loss = 1.232, time/batch=0.195\n",
      "21202/67600 (epoch 15), train_loss = 1.238, time/batch=0.125\n",
      "21203/67600 (epoch 15), train_loss = 1.190, time/batch=0.110\n",
      "21204/67600 (epoch 15), train_loss = 1.181, time/batch=0.114\n",
      "21205/67600 (epoch 15), train_loss = 1.209, time/batch=0.110\n",
      "21206/67600 (epoch 15), train_loss = 1.201, time/batch=0.106\n",
      "21207/67600 (epoch 15), train_loss = 1.216, time/batch=0.116\n",
      "21208/67600 (epoch 15), train_loss = 1.198, time/batch=0.240\n",
      "21209/67600 (epoch 15), train_loss = 1.217, time/batch=0.130\n",
      "21210/67600 (epoch 15), train_loss = 1.171, time/batch=0.159\n",
      "21211/67600 (epoch 15), train_loss = 1.225, time/batch=0.217\n",
      "21212/67600 (epoch 15), train_loss = 1.193, time/batch=0.193\n",
      "21213/67600 (epoch 15), train_loss = 1.170, time/batch=0.171\n",
      "21214/67600 (epoch 15), train_loss = 1.206, time/batch=0.112\n",
      "21215/67600 (epoch 15), train_loss = 1.194, time/batch=0.105\n",
      "21216/67600 (epoch 15), train_loss = 1.245, time/batch=0.145\n",
      "21217/67600 (epoch 15), train_loss = 1.208, time/batch=0.288\n",
      "21218/67600 (epoch 15), train_loss = 1.194, time/batch=0.121\n",
      "21219/67600 (epoch 15), train_loss = 1.200, time/batch=0.120\n",
      "21220/67600 (epoch 15), train_loss = 1.213, time/batch=0.107\n",
      "21221/67600 (epoch 15), train_loss = 1.176, time/batch=0.154\n",
      "21222/67600 (epoch 15), train_loss = 1.159, time/batch=0.132\n",
      "21223/67600 (epoch 15), train_loss = 1.247, time/batch=0.109\n",
      "21224/67600 (epoch 15), train_loss = 1.207, time/batch=0.120\n",
      "21225/67600 (epoch 15), train_loss = 1.224, time/batch=0.232\n",
      "21226/67600 (epoch 15), train_loss = 1.192, time/batch=0.167\n",
      "21227/67600 (epoch 15), train_loss = 1.168, time/batch=0.111\n",
      "21228/67600 (epoch 15), train_loss = 1.226, time/batch=0.113\n",
      "21229/67600 (epoch 15), train_loss = 1.167, time/batch=0.120\n",
      "21230/67600 (epoch 15), train_loss = 1.245, time/batch=0.111\n",
      "21231/67600 (epoch 15), train_loss = 1.192, time/batch=0.111\n",
      "21232/67600 (epoch 15), train_loss = 1.236, time/batch=0.237\n",
      "21233/67600 (epoch 15), train_loss = 1.183, time/batch=0.128\n",
      "21234/67600 (epoch 15), train_loss = 1.154, time/batch=0.111\n",
      "21235/67600 (epoch 15), train_loss = 1.260, time/batch=0.115\n",
      "21236/67600 (epoch 15), train_loss = 1.233, time/batch=0.108\n",
      "21237/67600 (epoch 15), train_loss = 1.232, time/batch=0.199\n",
      "21238/67600 (epoch 15), train_loss = 1.179, time/batch=0.112\n",
      "21239/67600 (epoch 15), train_loss = 1.188, time/batch=0.152\n",
      "21240/67600 (epoch 15), train_loss = 1.178, time/batch=0.110\n",
      "21241/67600 (epoch 15), train_loss = 1.140, time/batch=0.114\n",
      "21242/67600 (epoch 15), train_loss = 1.145, time/batch=0.116\n",
      "21243/67600 (epoch 15), train_loss = 1.149, time/batch=0.118\n",
      "21244/67600 (epoch 15), train_loss = 1.148, time/batch=0.113\n",
      "21245/67600 (epoch 15), train_loss = 1.226, time/batch=0.363\n",
      "21246/67600 (epoch 15), train_loss = 1.216, time/batch=0.191\n",
      "21247/67600 (epoch 15), train_loss = 1.156, time/batch=0.202\n",
      "21248/67600 (epoch 15), train_loss = 1.171, time/batch=0.151\n",
      "21249/67600 (epoch 15), train_loss = 1.171, time/batch=0.118\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21250/67600 (epoch 15), train_loss = 1.208, time/batch=0.280\n",
      "21251/67600 (epoch 15), train_loss = 1.223, time/batch=0.130\n",
      "21252/67600 (epoch 15), train_loss = 1.162, time/batch=0.192\n",
      "21253/67600 (epoch 15), train_loss = 1.220, time/batch=0.229\n",
      "21254/67600 (epoch 15), train_loss = 1.254, time/batch=0.144\n",
      "21255/67600 (epoch 15), train_loss = 1.139, time/batch=0.269\n",
      "21256/67600 (epoch 15), train_loss = 1.152, time/batch=0.138\n",
      "21257/67600 (epoch 15), train_loss = 1.174, time/batch=0.134\n",
      "21258/67600 (epoch 15), train_loss = 1.225, time/batch=0.134\n",
      "21259/67600 (epoch 15), train_loss = 1.201, time/batch=0.146\n",
      "21260/67600 (epoch 15), train_loss = 1.216, time/batch=0.111\n",
      "21261/67600 (epoch 15), train_loss = 1.170, time/batch=0.106\n",
      "21262/67600 (epoch 15), train_loss = 1.195, time/batch=0.302\n",
      "21263/67600 (epoch 15), train_loss = 1.242, time/batch=0.185\n",
      "21264/67600 (epoch 15), train_loss = 1.194, time/batch=0.129\n",
      "21265/67600 (epoch 15), train_loss = 1.272, time/batch=0.117\n",
      "21266/67600 (epoch 15), train_loss = 1.205, time/batch=0.240\n",
      "21267/67600 (epoch 15), train_loss = 1.273, time/batch=0.198\n",
      "21268/67600 (epoch 15), train_loss = 1.181, time/batch=0.099\n",
      "21269/67600 (epoch 15), train_loss = 1.203, time/batch=0.138\n",
      "21270/67600 (epoch 15), train_loss = 1.233, time/batch=0.113\n",
      "21271/67600 (epoch 15), train_loss = 1.195, time/batch=0.145\n",
      "21272/67600 (epoch 15), train_loss = 1.247, time/batch=0.241\n",
      "21273/67600 (epoch 15), train_loss = 1.207, time/batch=0.197\n",
      "21274/67600 (epoch 15), train_loss = 1.190, time/batch=0.132\n",
      "21275/67600 (epoch 15), train_loss = 1.208, time/batch=0.127\n",
      "21276/67600 (epoch 15), train_loss = 1.201, time/batch=0.140\n",
      "21277/67600 (epoch 15), train_loss = 1.214, time/batch=0.121\n",
      "21278/67600 (epoch 15), train_loss = 1.179, time/batch=0.129\n",
      "21279/67600 (epoch 15), train_loss = 1.192, time/batch=0.252\n",
      "21280/67600 (epoch 15), train_loss = 1.206, time/batch=0.176\n",
      "21281/67600 (epoch 15), train_loss = 1.222, time/batch=0.142\n",
      "21282/67600 (epoch 15), train_loss = 1.185, time/batch=0.113\n",
      "21283/67600 (epoch 15), train_loss = 1.195, time/batch=0.092\n",
      "21284/67600 (epoch 15), train_loss = 1.150, time/batch=0.135\n",
      "21285/67600 (epoch 15), train_loss = 1.228, time/batch=0.116\n",
      "21286/67600 (epoch 15), train_loss = 1.212, time/batch=0.234\n",
      "21287/67600 (epoch 15), train_loss = 1.172, time/batch=0.152\n",
      "21288/67600 (epoch 15), train_loss = 1.210, time/batch=0.115\n",
      "21289/67600 (epoch 15), train_loss = 1.164, time/batch=0.113\n",
      "21290/67600 (epoch 15), train_loss = 1.192, time/batch=0.106\n",
      "21291/67600 (epoch 15), train_loss = 1.184, time/batch=0.141\n",
      "21292/67600 (epoch 15), train_loss = 1.146, time/batch=0.114\n",
      "21293/67600 (epoch 15), train_loss = 1.186, time/batch=0.261\n",
      "21294/67600 (epoch 15), train_loss = 1.177, time/batch=0.119\n",
      "21295/67600 (epoch 15), train_loss = 1.201, time/batch=0.118\n",
      "21296/67600 (epoch 15), train_loss = 1.178, time/batch=0.130\n",
      "21297/67600 (epoch 15), train_loss = 1.219, time/batch=0.138\n",
      "21298/67600 (epoch 15), train_loss = 1.206, time/batch=0.220\n",
      "21299/67600 (epoch 15), train_loss = 1.219, time/batch=0.163\n",
      "21300/67600 (epoch 15), train_loss = 1.192, time/batch=0.114\n",
      "21301/67600 (epoch 15), train_loss = 1.200, time/batch=0.133\n",
      "21302/67600 (epoch 15), train_loss = 1.196, time/batch=0.117\n",
      "21303/67600 (epoch 15), train_loss = 1.192, time/batch=0.115\n",
      "21304/67600 (epoch 15), train_loss = 1.192, time/batch=0.127\n",
      "21305/67600 (epoch 15), train_loss = 1.157, time/batch=0.174\n",
      "21306/67600 (epoch 15), train_loss = 1.236, time/batch=0.126\n",
      "21307/67600 (epoch 15), train_loss = 1.161, time/batch=0.102\n",
      "21308/67600 (epoch 15), train_loss = 1.241, time/batch=0.119\n",
      "21309/67600 (epoch 15), train_loss = 1.216, time/batch=0.125\n",
      "21310/67600 (epoch 15), train_loss = 1.242, time/batch=0.102\n",
      "21311/67600 (epoch 15), train_loss = 1.250, time/batch=0.303\n",
      "21312/67600 (epoch 15), train_loss = 1.225, time/batch=0.208\n",
      "21313/67600 (epoch 15), train_loss = 1.183, time/batch=0.161\n",
      "21314/67600 (epoch 15), train_loss = 1.205, time/batch=0.172\n",
      "21315/67600 (epoch 15), train_loss = 1.181, time/batch=0.110\n",
      "21316/67600 (epoch 15), train_loss = 1.178, time/batch=0.127\n",
      "21317/67600 (epoch 15), train_loss = 1.176, time/batch=0.321\n",
      "21318/67600 (epoch 15), train_loss = 1.212, time/batch=0.171\n",
      "21319/67600 (epoch 15), train_loss = 1.194, time/batch=0.107\n",
      "21320/67600 (epoch 15), train_loss = 1.216, time/batch=0.191\n",
      "21321/67600 (epoch 15), train_loss = 1.218, time/batch=0.131\n",
      "21322/67600 (epoch 15), train_loss = 1.245, time/batch=0.319\n",
      "21323/67600 (epoch 15), train_loss = 1.113, time/batch=0.114\n",
      "21324/67600 (epoch 15), train_loss = 1.200, time/batch=0.130\n",
      "21325/67600 (epoch 15), train_loss = 1.205, time/batch=0.124\n",
      "21326/67600 (epoch 15), train_loss = 1.208, time/batch=0.115\n",
      "21327/67600 (epoch 15), train_loss = 1.269, time/batch=0.224\n",
      "21328/67600 (epoch 15), train_loss = 1.241, time/batch=0.155\n",
      "21329/67600 (epoch 15), train_loss = 1.225, time/batch=0.131\n",
      "21330/67600 (epoch 15), train_loss = 1.204, time/batch=0.122\n",
      "21331/67600 (epoch 15), train_loss = 1.180, time/batch=0.126\n",
      "21332/67600 (epoch 15), train_loss = 1.207, time/batch=0.095\n",
      "21333/67600 (epoch 15), train_loss = 1.209, time/batch=0.130\n",
      "21334/67600 (epoch 15), train_loss = 1.226, time/batch=0.262\n",
      "21335/67600 (epoch 15), train_loss = 1.200, time/batch=0.135\n",
      "21336/67600 (epoch 15), train_loss = 1.134, time/batch=0.124\n",
      "21337/67600 (epoch 15), train_loss = 1.250, time/batch=0.120\n",
      "21338/67600 (epoch 15), train_loss = 1.286, time/batch=0.114\n",
      "21339/67600 (epoch 15), train_loss = 1.195, time/batch=0.118\n",
      "21340/67600 (epoch 15), train_loss = 1.228, time/batch=0.117\n",
      "21341/67600 (epoch 15), train_loss = 1.233, time/batch=0.252\n",
      "21342/67600 (epoch 15), train_loss = 1.209, time/batch=0.145\n",
      "21343/67600 (epoch 15), train_loss = 1.178, time/batch=0.214\n",
      "21344/67600 (epoch 15), train_loss = 1.219, time/batch=0.123\n",
      "21345/67600 (epoch 15), train_loss = 1.204, time/batch=0.204\n",
      "21346/67600 (epoch 15), train_loss = 1.207, time/batch=0.122\n",
      "21347/67600 (epoch 15), train_loss = 1.245, time/batch=0.351\n",
      "21348/67600 (epoch 15), train_loss = 1.170, time/batch=0.102\n",
      "21349/67600 (epoch 15), train_loss = 1.224, time/batch=0.138\n",
      "21350/67600 (epoch 15), train_loss = 1.245, time/batch=0.137\n",
      "21351/67600 (epoch 15), train_loss = 1.261, time/batch=0.153\n",
      "21352/67600 (epoch 15), train_loss = 1.216, time/batch=0.238\n",
      "21353/67600 (epoch 15), train_loss = 1.192, time/batch=0.161\n",
      "21354/67600 (epoch 15), train_loss = 1.169, time/batch=0.122\n",
      "21355/67600 (epoch 15), train_loss = 1.208, time/batch=0.126\n",
      "21356/67600 (epoch 15), train_loss = 1.257, time/batch=0.128\n",
      "21357/67600 (epoch 15), train_loss = 1.265, time/batch=0.213\n",
      "21358/67600 (epoch 15), train_loss = 1.256, time/batch=0.119\n",
      "21359/67600 (epoch 15), train_loss = 1.249, time/batch=0.161\n",
      "21360/67600 (epoch 15), train_loss = 1.265, time/batch=0.112\n",
      "21361/67600 (epoch 15), train_loss = 1.182, time/batch=0.131\n",
      "21362/67600 (epoch 15), train_loss = 1.240, time/batch=0.131\n",
      "21363/67600 (epoch 15), train_loss = 1.185, time/batch=0.116\n",
      "21364/67600 (epoch 15), train_loss = 1.178, time/batch=0.117\n",
      "21365/67600 (epoch 15), train_loss = 1.274, time/batch=0.229\n",
      "21366/67600 (epoch 15), train_loss = 1.249, time/batch=0.136\n",
      "21367/67600 (epoch 15), train_loss = 1.153, time/batch=0.128\n",
      "21368/67600 (epoch 15), train_loss = 1.190, time/batch=0.123\n",
      "21369/67600 (epoch 15), train_loss = 1.179, time/batch=0.141\n",
      "21370/67600 (epoch 15), train_loss = 1.222, time/batch=0.115\n",
      "21371/67600 (epoch 15), train_loss = 1.183, time/batch=0.129\n",
      "21372/67600 (epoch 15), train_loss = 1.250, time/batch=0.236\n",
      "21373/67600 (epoch 15), train_loss = 1.202, time/batch=0.131\n",
      "21374/67600 (epoch 15), train_loss = 1.210, time/batch=0.133\n",
      "21375/67600 (epoch 15), train_loss = 1.174, time/batch=0.113\n",
      "21376/67600 (epoch 15), train_loss = 1.215, time/batch=0.122\n",
      "21377/67600 (epoch 15), train_loss = 1.210, time/batch=0.117\n",
      "21378/67600 (epoch 15), train_loss = 1.175, time/batch=0.112\n",
      "21379/67600 (epoch 15), train_loss = 1.142, time/batch=0.255\n",
      "21380/67600 (epoch 15), train_loss = 1.208, time/batch=0.112\n",
      "21381/67600 (epoch 15), train_loss = 1.196, time/batch=0.133\n",
      "21382/67600 (epoch 15), train_loss = 1.184, time/batch=0.116\n",
      "21383/67600 (epoch 15), train_loss = 1.166, time/batch=0.111\n",
      "21384/67600 (epoch 15), train_loss = 1.291, time/batch=0.125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21385/67600 (epoch 15), train_loss = 1.187, time/batch=0.122\n",
      "21386/67600 (epoch 15), train_loss = 1.192, time/batch=0.249\n",
      "21387/67600 (epoch 15), train_loss = 1.225, time/batch=0.156\n",
      "21388/67600 (epoch 15), train_loss = 1.186, time/batch=0.096\n",
      "21389/67600 (epoch 15), train_loss = 1.216, time/batch=0.137\n",
      "21390/67600 (epoch 15), train_loss = 1.235, time/batch=0.118\n",
      "21391/67600 (epoch 15), train_loss = 1.202, time/batch=0.125\n",
      "21392/67600 (epoch 15), train_loss = 1.269, time/batch=0.111\n",
      "21393/67600 (epoch 15), train_loss = 1.260, time/batch=0.245\n",
      "21394/67600 (epoch 15), train_loss = 1.239, time/batch=0.148\n",
      "21395/67600 (epoch 15), train_loss = 1.305, time/batch=0.109\n",
      "21396/67600 (epoch 15), train_loss = 1.214, time/batch=0.139\n",
      "21397/67600 (epoch 15), train_loss = 1.250, time/batch=0.130\n",
      "21398/67600 (epoch 15), train_loss = 1.210, time/batch=0.174\n",
      "21399/67600 (epoch 15), train_loss = 1.307, time/batch=0.096\n",
      "21400/67600 (epoch 15), train_loss = 1.197, time/batch=0.121\n",
      "21401/67600 (epoch 15), train_loss = 1.249, time/batch=0.099\n",
      "21402/67600 (epoch 15), train_loss = 1.311, time/batch=0.137\n",
      "21403/67600 (epoch 15), train_loss = 1.227, time/batch=0.100\n",
      "21404/67600 (epoch 15), train_loss = 1.209, time/batch=0.334\n",
      "21405/67600 (epoch 15), train_loss = 1.208, time/batch=0.132\n",
      "21406/67600 (epoch 15), train_loss = 1.276, time/batch=0.126\n",
      "21407/67600 (epoch 15), train_loss = 1.218, time/batch=0.112\n",
      "21408/67600 (epoch 15), train_loss = 1.227, time/batch=0.124\n",
      "21409/67600 (epoch 15), train_loss = 1.225, time/batch=0.119\n",
      "21410/67600 (epoch 15), train_loss = 1.236, time/batch=0.117\n",
      "21411/67600 (epoch 15), train_loss = 1.239, time/batch=0.277\n",
      "21412/67600 (epoch 15), train_loss = 1.202, time/batch=0.119\n",
      "21413/67600 (epoch 15), train_loss = 1.268, time/batch=0.130\n",
      "21414/67600 (epoch 15), train_loss = 1.285, time/batch=0.120\n",
      "21415/67600 (epoch 15), train_loss = 1.285, time/batch=0.135\n",
      "21416/67600 (epoch 15), train_loss = 1.254, time/batch=0.119\n",
      "21417/67600 (epoch 15), train_loss = 1.226, time/batch=0.116\n",
      "21418/67600 (epoch 15), train_loss = 1.230, time/batch=0.185\n",
      "21419/67600 (epoch 15), train_loss = 1.279, time/batch=0.188\n",
      "21420/67600 (epoch 15), train_loss = 1.226, time/batch=0.123\n",
      "21421/67600 (epoch 15), train_loss = 1.219, time/batch=0.115\n",
      "21422/67600 (epoch 15), train_loss = 1.259, time/batch=0.119\n",
      "21423/67600 (epoch 15), train_loss = 1.259, time/batch=0.245\n",
      "21424/67600 (epoch 15), train_loss = 1.239, time/batch=0.146\n",
      "21425/67600 (epoch 15), train_loss = 1.196, time/batch=0.128\n",
      "21426/67600 (epoch 15), train_loss = 1.180, time/batch=0.128\n",
      "21427/67600 (epoch 15), train_loss = 1.175, time/batch=0.111\n",
      "21428/67600 (epoch 15), train_loss = 1.196, time/batch=0.116\n",
      "21429/67600 (epoch 15), train_loss = 1.207, time/batch=0.122\n",
      "21430/67600 (epoch 15), train_loss = 1.155, time/batch=0.173\n",
      "21431/67600 (epoch 15), train_loss = 1.249, time/batch=0.163\n",
      "21432/67600 (epoch 15), train_loss = 1.210, time/batch=0.167\n",
      "21433/67600 (epoch 15), train_loss = 1.195, time/batch=0.111\n",
      "21434/67600 (epoch 15), train_loss = 1.220, time/batch=0.127\n",
      "21435/67600 (epoch 15), train_loss = 1.199, time/batch=0.124\n",
      "21436/67600 (epoch 15), train_loss = 1.200, time/batch=0.128\n",
      "21437/67600 (epoch 15), train_loss = 1.151, time/batch=0.104\n",
      "21438/67600 (epoch 15), train_loss = 1.255, time/batch=0.253\n",
      "21439/67600 (epoch 15), train_loss = 1.250, time/batch=0.140\n",
      "21440/67600 (epoch 15), train_loss = 1.176, time/batch=0.127\n",
      "21441/67600 (epoch 15), train_loss = 1.186, time/batch=0.116\n",
      "21442/67600 (epoch 15), train_loss = 1.203, time/batch=0.104\n",
      "21443/67600 (epoch 15), train_loss = 1.167, time/batch=0.153\n",
      "21444/67600 (epoch 15), train_loss = 1.223, time/batch=0.101\n",
      "21445/67600 (epoch 15), train_loss = 1.174, time/batch=0.257\n",
      "21446/67600 (epoch 15), train_loss = 1.187, time/batch=0.144\n",
      "21447/67600 (epoch 15), train_loss = 1.222, time/batch=0.091\n",
      "21448/67600 (epoch 15), train_loss = 1.223, time/batch=0.146\n",
      "21449/67600 (epoch 15), train_loss = 1.141, time/batch=0.100\n",
      "21450/67600 (epoch 15), train_loss = 1.176, time/batch=0.122\n",
      "21451/67600 (epoch 15), train_loss = 1.178, time/batch=0.122\n",
      "21452/67600 (epoch 15), train_loss = 1.197, time/batch=0.326\n",
      "21453/67600 (epoch 15), train_loss = 1.208, time/batch=0.127\n",
      "21454/67600 (epoch 15), train_loss = 1.197, time/batch=0.113\n",
      "21455/67600 (epoch 15), train_loss = 1.212, time/batch=0.141\n",
      "21456/67600 (epoch 15), train_loss = 1.207, time/batch=0.163\n",
      "21457/67600 (epoch 15), train_loss = 1.203, time/batch=0.157\n",
      "21458/67600 (epoch 15), train_loss = 1.250, time/batch=0.160\n",
      "21459/67600 (epoch 15), train_loss = 1.300, time/batch=0.128\n",
      "21460/67600 (epoch 15), train_loss = 1.269, time/batch=0.120\n",
      "21461/67600 (epoch 15), train_loss = 1.228, time/batch=0.146\n",
      "21462/67600 (epoch 15), train_loss = 1.221, time/batch=0.101\n",
      "21463/67600 (epoch 15), train_loss = 1.210, time/batch=0.295\n",
      "21464/67600 (epoch 15), train_loss = 1.231, time/batch=0.129\n",
      "21465/67600 (epoch 15), train_loss = 1.136, time/batch=0.095\n",
      "21466/67600 (epoch 15), train_loss = 1.169, time/batch=0.090\n",
      "21467/67600 (epoch 15), train_loss = 1.260, time/batch=0.151\n",
      "21468/67600 (epoch 15), train_loss = 1.208, time/batch=0.117\n",
      "21469/67600 (epoch 15), train_loss = 1.174, time/batch=0.120\n",
      "21470/67600 (epoch 15), train_loss = 1.214, time/batch=0.106\n",
      "21471/67600 (epoch 15), train_loss = 1.187, time/batch=0.271\n",
      "21472/67600 (epoch 15), train_loss = 1.199, time/batch=0.122\n",
      "21473/67600 (epoch 15), train_loss = 1.210, time/batch=0.110\n",
      "21474/67600 (epoch 15), train_loss = 1.168, time/batch=0.131\n",
      "21475/67600 (epoch 15), train_loss = 1.181, time/batch=0.110\n",
      "21476/67600 (epoch 15), train_loss = 1.224, time/batch=0.117\n",
      "21477/67600 (epoch 15), train_loss = 1.235, time/batch=0.113\n",
      "21478/67600 (epoch 15), train_loss = 1.251, time/batch=0.277\n",
      "21479/67600 (epoch 15), train_loss = 1.191, time/batch=0.150\n",
      "21480/67600 (epoch 15), train_loss = 1.225, time/batch=0.136\n",
      "21481/67600 (epoch 15), train_loss = 1.185, time/batch=0.142\n",
      "21482/67600 (epoch 15), train_loss = 1.170, time/batch=0.117\n",
      "21483/67600 (epoch 15), train_loss = 1.181, time/batch=0.140\n",
      "21484/67600 (epoch 15), train_loss = 1.277, time/batch=0.169\n",
      "21485/67600 (epoch 15), train_loss = 1.199, time/batch=0.184\n",
      "21486/67600 (epoch 15), train_loss = 1.164, time/batch=0.112\n",
      "21487/67600 (epoch 15), train_loss = 1.211, time/batch=0.122\n",
      "21488/67600 (epoch 15), train_loss = 1.171, time/batch=0.105\n",
      "21489/67600 (epoch 15), train_loss = 1.173, time/batch=0.105\n",
      "21490/67600 (epoch 15), train_loss = 1.236, time/batch=0.229\n",
      "21491/67600 (epoch 15), train_loss = 1.183, time/batch=0.136\n",
      "21492/67600 (epoch 15), train_loss = 1.185, time/batch=0.110\n",
      "21493/67600 (epoch 15), train_loss = 1.224, time/batch=0.122\n",
      "21494/67600 (epoch 15), train_loss = 1.229, time/batch=0.163\n",
      "21495/67600 (epoch 15), train_loss = 1.197, time/batch=0.095\n",
      "21496/67600 (epoch 15), train_loss = 1.217, time/batch=0.101\n",
      "21497/67600 (epoch 15), train_loss = 1.223, time/batch=0.165\n",
      "21498/67600 (epoch 15), train_loss = 1.205, time/batch=0.137\n",
      "21499/67600 (epoch 15), train_loss = 1.207, time/batch=0.116\n",
      "21500/67600 (epoch 15), train_loss = 1.188, time/batch=0.110\n",
      "model saved to ./save/model.ckpt\n",
      "21501/67600 (epoch 15), train_loss = 1.193, time/batch=0.076\n",
      "21502/67600 (epoch 15), train_loss = 1.236, time/batch=0.079\n",
      "21503/67600 (epoch 15), train_loss = 1.191, time/batch=0.179\n",
      "21504/67600 (epoch 15), train_loss = 1.251, time/batch=0.113\n",
      "21505/67600 (epoch 15), train_loss = 1.229, time/batch=0.127\n",
      "21506/67600 (epoch 15), train_loss = 1.246, time/batch=0.120\n",
      "21507/67600 (epoch 15), train_loss = 1.213, time/batch=0.118\n",
      "21508/67600 (epoch 15), train_loss = 1.249, time/batch=0.116\n",
      "21509/67600 (epoch 15), train_loss = 1.189, time/batch=0.105\n",
      "21510/67600 (epoch 15), train_loss = 1.220, time/batch=0.108\n",
      "21511/67600 (epoch 15), train_loss = 1.223, time/batch=0.227\n",
      "21512/67600 (epoch 15), train_loss = 1.304, time/batch=0.135\n",
      "21513/67600 (epoch 15), train_loss = 1.262, time/batch=0.119\n",
      "21514/67600 (epoch 15), train_loss = 1.171, time/batch=0.112\n",
      "21515/67600 (epoch 15), train_loss = 1.208, time/batch=0.112\n",
      "21516/67600 (epoch 15), train_loss = 1.190, time/batch=0.111\n",
      "21517/67600 (epoch 15), train_loss = 1.226, time/batch=0.109\n",
      "21518/67600 (epoch 15), train_loss = 1.214, time/batch=0.108\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21519/67600 (epoch 15), train_loss = 1.192, time/batch=0.242\n",
      "21520/67600 (epoch 15), train_loss = 1.259, time/batch=0.110\n",
      "21521/67600 (epoch 15), train_loss = 1.191, time/batch=0.139\n",
      "21522/67600 (epoch 15), train_loss = 1.208, time/batch=0.107\n",
      "21523/67600 (epoch 15), train_loss = 1.243, time/batch=0.113\n",
      "21524/67600 (epoch 15), train_loss = 1.293, time/batch=0.201\n",
      "21525/67600 (epoch 15), train_loss = 1.226, time/batch=0.118\n",
      "21526/67600 (epoch 15), train_loss = 1.215, time/batch=0.142\n",
      "21527/67600 (epoch 15), train_loss = 1.199, time/batch=0.102\n",
      "21528/67600 (epoch 15), train_loss = 1.235, time/batch=0.122\n",
      "21529/67600 (epoch 15), train_loss = 1.208, time/batch=0.104\n",
      "21530/67600 (epoch 15), train_loss = 1.168, time/batch=0.115\n",
      "21531/67600 (epoch 15), train_loss = 1.274, time/batch=0.116\n",
      "21532/67600 (epoch 15), train_loss = 1.181, time/batch=0.197\n",
      "21533/67600 (epoch 15), train_loss = 1.261, time/batch=0.137\n",
      "21534/67600 (epoch 15), train_loss = 1.238, time/batch=0.129\n",
      "21535/67600 (epoch 15), train_loss = 1.256, time/batch=0.111\n",
      "21536/67600 (epoch 15), train_loss = 1.243, time/batch=0.100\n",
      "21537/67600 (epoch 15), train_loss = 1.232, time/batch=0.113\n",
      "21538/67600 (epoch 15), train_loss = 1.280, time/batch=0.115\n",
      "21539/67600 (epoch 15), train_loss = 1.211, time/batch=0.117\n",
      "21540/67600 (epoch 15), train_loss = 1.236, time/batch=0.210\n",
      "21541/67600 (epoch 15), train_loss = 1.202, time/batch=0.131\n",
      "21542/67600 (epoch 15), train_loss = 1.294, time/batch=0.108\n",
      "21543/67600 (epoch 15), train_loss = 1.277, time/batch=0.126\n",
      "21544/67600 (epoch 15), train_loss = 1.275, time/batch=0.107\n",
      "21545/67600 (epoch 15), train_loss = 1.208, time/batch=0.131\n",
      "21546/67600 (epoch 15), train_loss = 1.272, time/batch=0.108\n",
      "21547/67600 (epoch 15), train_loss = 1.187, time/batch=0.101\n",
      "21548/67600 (epoch 15), train_loss = 1.164, time/batch=0.238\n",
      "21549/67600 (epoch 15), train_loss = 1.219, time/batch=0.125\n",
      "21550/67600 (epoch 15), train_loss = 1.224, time/batch=0.113\n",
      "21551/67600 (epoch 15), train_loss = 1.153, time/batch=0.103\n",
      "21552/67600 (epoch 15), train_loss = 1.215, time/batch=0.115\n",
      "21553/67600 (epoch 15), train_loss = 1.205, time/batch=0.110\n",
      "21554/67600 (epoch 15), train_loss = 1.190, time/batch=0.117\n",
      "21555/67600 (epoch 15), train_loss = 1.236, time/batch=0.115\n",
      "21556/67600 (epoch 15), train_loss = 1.249, time/batch=0.232\n",
      "21557/67600 (epoch 15), train_loss = 1.229, time/batch=0.114\n",
      "21558/67600 (epoch 15), train_loss = 1.148, time/batch=0.109\n",
      "21559/67600 (epoch 15), train_loss = 1.166, time/batch=0.109\n",
      "21560/67600 (epoch 15), train_loss = 1.183, time/batch=0.115\n",
      "21561/67600 (epoch 15), train_loss = 1.206, time/batch=0.166\n",
      "21562/67600 (epoch 15), train_loss = 1.173, time/batch=0.170\n",
      "21563/67600 (epoch 15), train_loss = 1.227, time/batch=0.128\n",
      "21564/67600 (epoch 15), train_loss = 1.248, time/batch=0.122\n",
      "21565/67600 (epoch 15), train_loss = 1.203, time/batch=0.114\n",
      "21566/67600 (epoch 15), train_loss = 1.197, time/batch=0.114\n",
      "21567/67600 (epoch 15), train_loss = 1.267, time/batch=0.108\n",
      "21568/67600 (epoch 15), train_loss = 1.190, time/batch=0.115\n",
      "21569/67600 (epoch 15), train_loss = 1.244, time/batch=0.155\n",
      "21570/67600 (epoch 15), train_loss = 1.274, time/batch=0.113\n",
      "21571/67600 (epoch 15), train_loss = 1.243, time/batch=0.109\n",
      "21572/67600 (epoch 15), train_loss = 1.194, time/batch=0.108\n",
      "21573/67600 (epoch 15), train_loss = 1.204, time/batch=0.110\n",
      "21574/67600 (epoch 15), train_loss = 1.214, time/batch=0.110\n",
      "21575/67600 (epoch 15), train_loss = 1.211, time/batch=0.258\n",
      "21576/67600 (epoch 15), train_loss = 1.221, time/batch=0.104\n",
      "21577/67600 (epoch 15), train_loss = 1.234, time/batch=0.130\n",
      "21578/67600 (epoch 15), train_loss = 1.169, time/batch=0.111\n",
      "21579/67600 (epoch 15), train_loss = 1.241, time/batch=0.105\n",
      "21580/67600 (epoch 15), train_loss = 1.260, time/batch=0.119\n",
      "21581/67600 (epoch 15), train_loss = 1.222, time/batch=0.117\n",
      "21582/67600 (epoch 15), train_loss = 1.188, time/batch=0.104\n",
      "21583/67600 (epoch 15), train_loss = 1.213, time/batch=0.251\n",
      "21584/67600 (epoch 15), train_loss = 1.228, time/batch=0.117\n",
      "21585/67600 (epoch 15), train_loss = 1.157, time/batch=0.112\n",
      "21586/67600 (epoch 15), train_loss = 1.241, time/batch=0.123\n",
      "21587/67600 (epoch 15), train_loss = 1.236, time/batch=0.112\n",
      "21588/67600 (epoch 15), train_loss = 1.232, time/batch=0.118\n",
      "21589/67600 (epoch 15), train_loss = 1.225, time/batch=0.102\n",
      "21590/67600 (epoch 15), train_loss = 1.187, time/batch=0.102\n",
      "21591/67600 (epoch 15), train_loss = 1.201, time/batch=0.245\n",
      "21592/67600 (epoch 15), train_loss = 1.213, time/batch=0.109\n",
      "21593/67600 (epoch 15), train_loss = 1.282, time/batch=0.074\n",
      "21594/67600 (epoch 15), train_loss = 1.282, time/batch=0.111\n",
      "21595/67600 (epoch 15), train_loss = 1.229, time/batch=0.133\n",
      "21596/67600 (epoch 15), train_loss = 1.232, time/batch=0.106\n",
      "21597/67600 (epoch 15), train_loss = 1.248, time/batch=0.203\n",
      "21598/67600 (epoch 15), train_loss = 1.221, time/batch=0.152\n",
      "21599/67600 (epoch 15), train_loss = 1.191, time/batch=0.110\n",
      "21600/67600 (epoch 15), train_loss = 1.209, time/batch=0.106\n",
      "21601/67600 (epoch 15), train_loss = 1.205, time/batch=0.114\n",
      "21602/67600 (epoch 15), train_loss = 1.195, time/batch=0.109\n",
      "21603/67600 (epoch 15), train_loss = 1.217, time/batch=0.114\n",
      "21604/67600 (epoch 15), train_loss = 1.276, time/batch=0.109\n",
      "21605/67600 (epoch 15), train_loss = 1.210, time/batch=0.212\n",
      "21606/67600 (epoch 15), train_loss = 1.226, time/batch=0.156\n",
      "21607/67600 (epoch 15), train_loss = 1.207, time/batch=0.107\n",
      "21608/67600 (epoch 15), train_loss = 1.206, time/batch=0.111\n",
      "21609/67600 (epoch 15), train_loss = 1.223, time/batch=0.117\n",
      "21610/67600 (epoch 15), train_loss = 1.265, time/batch=0.112\n",
      "21611/67600 (epoch 15), train_loss = 1.261, time/batch=0.106\n",
      "21612/67600 (epoch 15), train_loss = 1.213, time/batch=0.163\n",
      "21613/67600 (epoch 15), train_loss = 1.195, time/batch=0.169\n",
      "21614/67600 (epoch 15), train_loss = 1.170, time/batch=0.126\n",
      "21615/67600 (epoch 15), train_loss = 1.241, time/batch=0.112\n",
      "21616/67600 (epoch 15), train_loss = 1.245, time/batch=0.116\n",
      "21617/67600 (epoch 15), train_loss = 1.227, time/batch=0.116\n",
      "21618/67600 (epoch 15), train_loss = 1.236, time/batch=0.114\n",
      "21619/67600 (epoch 15), train_loss = 1.206, time/batch=0.100\n",
      "21620/67600 (epoch 15), train_loss = 1.196, time/batch=0.228\n",
      "21621/67600 (epoch 15), train_loss = 1.219, time/batch=0.124\n",
      "21622/67600 (epoch 15), train_loss = 1.231, time/batch=0.127\n",
      "21623/67600 (epoch 15), train_loss = 1.217, time/batch=0.114\n",
      "21624/67600 (epoch 15), train_loss = 1.163, time/batch=0.109\n",
      "21625/67600 (epoch 15), train_loss = 1.218, time/batch=0.113\n",
      "21626/67600 (epoch 15), train_loss = 1.194, time/batch=0.123\n",
      "21627/67600 (epoch 15), train_loss = 1.217, time/batch=0.108\n",
      "21628/67600 (epoch 15), train_loss = 1.287, time/batch=0.256\n",
      "21629/67600 (epoch 15), train_loss = 1.307, time/batch=0.127\n",
      "21630/67600 (epoch 15), train_loss = 1.223, time/batch=0.093\n",
      "21631/67600 (epoch 15), train_loss = 1.241, time/batch=0.134\n",
      "21632/67600 (epoch 16), train_loss = 1.399, time/batch=0.140\n",
      "21633/67600 (epoch 16), train_loss = 1.169, time/batch=0.171\n",
      "21634/67600 (epoch 16), train_loss = 1.247, time/batch=0.149\n",
      "21635/67600 (epoch 16), train_loss = 1.206, time/batch=0.114\n",
      "21636/67600 (epoch 16), train_loss = 1.227, time/batch=0.137\n",
      "21637/67600 (epoch 16), train_loss = 1.242, time/batch=0.120\n",
      "21638/67600 (epoch 16), train_loss = 1.215, time/batch=0.121\n",
      "21639/67600 (epoch 16), train_loss = 1.221, time/batch=0.110\n",
      "21640/67600 (epoch 16), train_loss = 1.230, time/batch=0.226\n",
      "21641/67600 (epoch 16), train_loss = 1.207, time/batch=0.153\n",
      "21642/67600 (epoch 16), train_loss = 1.180, time/batch=0.116\n",
      "21643/67600 (epoch 16), train_loss = 1.186, time/batch=0.132\n",
      "21644/67600 (epoch 16), train_loss = 1.207, time/batch=0.118\n",
      "21645/67600 (epoch 16), train_loss = 1.270, time/batch=0.120\n",
      "21646/67600 (epoch 16), train_loss = 1.233, time/batch=0.099\n",
      "21647/67600 (epoch 16), train_loss = 1.207, time/batch=0.223\n",
      "21648/67600 (epoch 16), train_loss = 1.223, time/batch=0.155\n",
      "21649/67600 (epoch 16), train_loss = 1.227, time/batch=0.121\n",
      "21650/67600 (epoch 16), train_loss = 1.218, time/batch=0.116\n",
      "21651/67600 (epoch 16), train_loss = 1.207, time/batch=0.110\n",
      "21652/67600 (epoch 16), train_loss = 1.222, time/batch=0.121\n",
      "21653/67600 (epoch 16), train_loss = 1.149, time/batch=0.127\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21654/67600 (epoch 16), train_loss = 1.277, time/batch=0.250\n",
      "21655/67600 (epoch 16), train_loss = 1.249, time/batch=0.117\n",
      "21656/67600 (epoch 16), train_loss = 1.280, time/batch=0.131\n",
      "21657/67600 (epoch 16), train_loss = 1.147, time/batch=0.115\n",
      "21658/67600 (epoch 16), train_loss = 1.236, time/batch=0.129\n",
      "21659/67600 (epoch 16), train_loss = 1.244, time/batch=0.103\n",
      "21660/67600 (epoch 16), train_loss = 1.285, time/batch=0.127\n",
      "21661/67600 (epoch 16), train_loss = 1.212, time/batch=0.114\n",
      "21662/67600 (epoch 16), train_loss = 1.200, time/batch=0.255\n",
      "21663/67600 (epoch 16), train_loss = 1.278, time/batch=0.127\n",
      "21664/67600 (epoch 16), train_loss = 1.201, time/batch=0.111\n",
      "21665/67600 (epoch 16), train_loss = 1.267, time/batch=0.127\n",
      "21666/67600 (epoch 16), train_loss = 1.241, time/batch=0.120\n",
      "21667/67600 (epoch 16), train_loss = 1.224, time/batch=0.229\n",
      "21668/67600 (epoch 16), train_loss = 1.196, time/batch=0.138\n",
      "21669/67600 (epoch 16), train_loss = 1.231, time/batch=0.109\n",
      "21670/67600 (epoch 16), train_loss = 1.242, time/batch=0.128\n",
      "21671/67600 (epoch 16), train_loss = 1.221, time/batch=0.130\n",
      "21672/67600 (epoch 16), train_loss = 1.150, time/batch=0.114\n",
      "21673/67600 (epoch 16), train_loss = 1.254, time/batch=0.124\n",
      "21674/67600 (epoch 16), train_loss = 1.264, time/batch=0.142\n",
      "21675/67600 (epoch 16), train_loss = 1.241, time/batch=0.133\n",
      "21676/67600 (epoch 16), train_loss = 1.253, time/batch=0.126\n",
      "21677/67600 (epoch 16), train_loss = 1.219, time/batch=0.124\n",
      "21678/67600 (epoch 16), train_loss = 1.185, time/batch=0.115\n",
      "21679/67600 (epoch 16), train_loss = 1.223, time/batch=0.121\n",
      "21680/67600 (epoch 16), train_loss = 1.198, time/batch=0.297\n",
      "21681/67600 (epoch 16), train_loss = 1.187, time/batch=0.143\n",
      "21682/67600 (epoch 16), train_loss = 1.267, time/batch=0.130\n",
      "21683/67600 (epoch 16), train_loss = 1.194, time/batch=0.122\n",
      "21684/67600 (epoch 16), train_loss = 1.201, time/batch=0.114\n",
      "21685/67600 (epoch 16), train_loss = 1.290, time/batch=0.120\n",
      "21686/67600 (epoch 16), train_loss = 1.263, time/batch=0.105\n",
      "21687/67600 (epoch 16), train_loss = 1.219, time/batch=0.260\n",
      "21688/67600 (epoch 16), train_loss = 1.235, time/batch=0.126\n",
      "21689/67600 (epoch 16), train_loss = 1.230, time/batch=0.125\n",
      "21690/67600 (epoch 16), train_loss = 1.233, time/batch=0.128\n",
      "21691/67600 (epoch 16), train_loss = 1.232, time/batch=0.122\n",
      "21692/67600 (epoch 16), train_loss = 1.234, time/batch=0.216\n",
      "21693/67600 (epoch 16), train_loss = 1.207, time/batch=0.153\n",
      "21694/67600 (epoch 16), train_loss = 1.264, time/batch=0.117\n",
      "21695/67600 (epoch 16), train_loss = 1.260, time/batch=0.138\n",
      "21696/67600 (epoch 16), train_loss = 1.205, time/batch=0.121\n",
      "21697/67600 (epoch 16), train_loss = 1.203, time/batch=0.119\n",
      "21698/67600 (epoch 16), train_loss = 1.223, time/batch=0.115\n",
      "21699/67600 (epoch 16), train_loss = 1.237, time/batch=0.151\n",
      "21700/67600 (epoch 16), train_loss = 1.248, time/batch=0.215\n",
      "21701/67600 (epoch 16), train_loss = 1.250, time/batch=0.101\n",
      "21702/67600 (epoch 16), train_loss = 1.240, time/batch=0.133\n",
      "21703/67600 (epoch 16), train_loss = 1.247, time/batch=0.099\n",
      "21704/67600 (epoch 16), train_loss = 1.205, time/batch=0.128\n",
      "21705/67600 (epoch 16), train_loss = 1.281, time/batch=0.118\n",
      "21706/67600 (epoch 16), train_loss = 1.215, time/batch=0.107\n",
      "21707/67600 (epoch 16), train_loss = 1.261, time/batch=0.238\n",
      "21708/67600 (epoch 16), train_loss = 1.273, time/batch=0.173\n",
      "21709/67600 (epoch 16), train_loss = 1.350, time/batch=0.131\n",
      "21710/67600 (epoch 16), train_loss = 1.267, time/batch=0.098\n",
      "21711/67600 (epoch 16), train_loss = 1.200, time/batch=0.120\n",
      "21712/67600 (epoch 16), train_loss = 1.188, time/batch=0.123\n",
      "21713/67600 (epoch 16), train_loss = 1.238, time/batch=0.116\n",
      "21714/67600 (epoch 16), train_loss = 1.239, time/batch=0.240\n",
      "21715/67600 (epoch 16), train_loss = 1.214, time/batch=0.152\n",
      "21716/67600 (epoch 16), train_loss = 1.218, time/batch=0.114\n",
      "21717/67600 (epoch 16), train_loss = 1.218, time/batch=0.127\n",
      "21718/67600 (epoch 16), train_loss = 1.167, time/batch=0.109\n",
      "21719/67600 (epoch 16), train_loss = 1.276, time/batch=0.122\n",
      "21720/67600 (epoch 16), train_loss = 1.257, time/batch=0.128\n",
      "21721/67600 (epoch 16), train_loss = 1.254, time/batch=0.261\n",
      "21722/67600 (epoch 16), train_loss = 1.234, time/batch=0.130\n",
      "21723/67600 (epoch 16), train_loss = 1.257, time/batch=0.140\n",
      "21724/67600 (epoch 16), train_loss = 1.180, time/batch=0.109\n",
      "21725/67600 (epoch 16), train_loss = 1.200, time/batch=0.118\n",
      "21726/67600 (epoch 16), train_loss = 1.193, time/batch=0.123\n",
      "21727/67600 (epoch 16), train_loss = 1.141, time/batch=0.118\n",
      "21728/67600 (epoch 16), train_loss = 1.152, time/batch=0.252\n",
      "21729/67600 (epoch 16), train_loss = 1.232, time/batch=0.118\n",
      "21730/67600 (epoch 16), train_loss = 1.212, time/batch=0.126\n",
      "21731/67600 (epoch 16), train_loss = 1.247, time/batch=0.115\n",
      "21732/67600 (epoch 16), train_loss = 1.135, time/batch=0.118\n",
      "21733/67600 (epoch 16), train_loss = 1.211, time/batch=0.216\n",
      "21734/67600 (epoch 16), train_loss = 1.253, time/batch=0.165\n",
      "21735/67600 (epoch 16), train_loss = 1.154, time/batch=0.103\n",
      "21736/67600 (epoch 16), train_loss = 1.191, time/batch=0.123\n",
      "21737/67600 (epoch 16), train_loss = 1.228, time/batch=0.111\n",
      "21738/67600 (epoch 16), train_loss = 1.203, time/batch=0.114\n",
      "21739/67600 (epoch 16), train_loss = 1.231, time/batch=0.131\n",
      "21740/67600 (epoch 16), train_loss = 1.267, time/batch=0.134\n",
      "21741/67600 (epoch 16), train_loss = 1.230, time/batch=0.208\n",
      "21742/67600 (epoch 16), train_loss = 1.185, time/batch=0.155\n",
      "21743/67600 (epoch 16), train_loss = 1.233, time/batch=0.113\n",
      "21744/67600 (epoch 16), train_loss = 1.220, time/batch=0.113\n",
      "21745/67600 (epoch 16), train_loss = 1.246, time/batch=0.122\n",
      "21746/67600 (epoch 16), train_loss = 1.240, time/batch=0.129\n",
      "21747/67600 (epoch 16), train_loss = 1.183, time/batch=0.110\n",
      "21748/67600 (epoch 16), train_loss = 1.181, time/batch=0.233\n",
      "21749/67600 (epoch 16), train_loss = 1.217, time/batch=0.153\n",
      "21750/67600 (epoch 16), train_loss = 1.238, time/batch=0.123\n",
      "21751/67600 (epoch 16), train_loss = 1.235, time/batch=0.113\n",
      "21752/67600 (epoch 16), train_loss = 1.246, time/batch=0.142\n",
      "21753/67600 (epoch 16), train_loss = 1.237, time/batch=0.102\n",
      "21754/67600 (epoch 16), train_loss = 1.203, time/batch=0.127\n",
      "21755/67600 (epoch 16), train_loss = 1.185, time/batch=0.253\n",
      "21756/67600 (epoch 16), train_loss = 1.209, time/batch=0.135\n",
      "21757/67600 (epoch 16), train_loss = 1.142, time/batch=0.127\n",
      "21758/67600 (epoch 16), train_loss = 1.206, time/batch=0.117\n",
      "21759/67600 (epoch 16), train_loss = 1.255, time/batch=0.109\n",
      "21760/67600 (epoch 16), train_loss = 1.188, time/batch=0.122\n",
      "21761/67600 (epoch 16), train_loss = 1.210, time/batch=0.118\n",
      "21762/67600 (epoch 16), train_loss = 1.235, time/batch=0.250\n",
      "21763/67600 (epoch 16), train_loss = 1.208, time/batch=0.121\n",
      "21764/67600 (epoch 16), train_loss = 1.267, time/batch=0.119\n",
      "21765/67600 (epoch 16), train_loss = 1.197, time/batch=0.127\n",
      "21766/67600 (epoch 16), train_loss = 1.220, time/batch=0.121\n",
      "21767/67600 (epoch 16), train_loss = 1.219, time/batch=0.217\n",
      "21768/67600 (epoch 16), train_loss = 1.236, time/batch=0.161\n",
      "21769/67600 (epoch 16), train_loss = 1.234, time/batch=0.099\n",
      "21770/67600 (epoch 16), train_loss = 1.223, time/batch=0.136\n",
      "21771/67600 (epoch 16), train_loss = 1.202, time/batch=0.130\n",
      "21772/67600 (epoch 16), train_loss = 1.200, time/batch=0.112\n",
      "21773/67600 (epoch 16), train_loss = 1.179, time/batch=0.114\n",
      "21774/67600 (epoch 16), train_loss = 1.227, time/batch=0.180\n",
      "21775/67600 (epoch 16), train_loss = 1.185, time/batch=0.113\n",
      "21776/67600 (epoch 16), train_loss = 1.269, time/batch=0.125\n",
      "21777/67600 (epoch 16), train_loss = 1.307, time/batch=0.115\n",
      "21778/67600 (epoch 16), train_loss = 1.218, time/batch=0.131\n",
      "21779/67600 (epoch 16), train_loss = 1.199, time/batch=0.145\n",
      "21780/67600 (epoch 16), train_loss = 1.261, time/batch=0.256\n",
      "21781/67600 (epoch 16), train_loss = 1.160, time/batch=0.156\n",
      "21782/67600 (epoch 16), train_loss = 1.231, time/batch=0.122\n",
      "21783/67600 (epoch 16), train_loss = 1.179, time/batch=0.125\n",
      "21784/67600 (epoch 16), train_loss = 1.168, time/batch=0.102\n",
      "21785/67600 (epoch 16), train_loss = 1.230, time/batch=0.122\n",
      "21786/67600 (epoch 16), train_loss = 1.187, time/batch=0.140\n",
      "21787/67600 (epoch 16), train_loss = 1.237, time/batch=0.200\n",
      "21788/67600 (epoch 16), train_loss = 1.236, time/batch=0.161\n",
      "21789/67600 (epoch 16), train_loss = 1.249, time/batch=0.123\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21790/67600 (epoch 16), train_loss = 1.238, time/batch=0.113\n",
      "21791/67600 (epoch 16), train_loss = 1.201, time/batch=0.083\n",
      "21792/67600 (epoch 16), train_loss = 1.180, time/batch=0.096\n",
      "21793/67600 (epoch 16), train_loss = 1.171, time/batch=0.138\n",
      "21794/67600 (epoch 16), train_loss = 1.217, time/batch=0.101\n",
      "21795/67600 (epoch 16), train_loss = 1.202, time/batch=0.265\n",
      "21796/67600 (epoch 16), train_loss = 1.131, time/batch=0.127\n",
      "21797/67600 (epoch 16), train_loss = 1.215, time/batch=0.117\n",
      "21798/67600 (epoch 16), train_loss = 1.201, time/batch=0.122\n",
      "21799/67600 (epoch 16), train_loss = 1.181, time/batch=0.112\n",
      "21800/67600 (epoch 16), train_loss = 1.228, time/batch=0.218\n",
      "21801/67600 (epoch 16), train_loss = 1.236, time/batch=0.161\n",
      "21802/67600 (epoch 16), train_loss = 1.233, time/batch=0.130\n",
      "21803/67600 (epoch 16), train_loss = 1.182, time/batch=0.103\n",
      "21804/67600 (epoch 16), train_loss = 1.247, time/batch=0.135\n",
      "21805/67600 (epoch 16), train_loss = 1.195, time/batch=0.110\n",
      "21806/67600 (epoch 16), train_loss = 1.207, time/batch=0.126\n",
      "21807/67600 (epoch 16), train_loss = 1.163, time/batch=0.214\n",
      "21808/67600 (epoch 16), train_loss = 1.209, time/batch=0.173\n",
      "21809/67600 (epoch 16), train_loss = 1.257, time/batch=0.120\n",
      "21810/67600 (epoch 16), train_loss = 1.177, time/batch=0.117\n",
      "21811/67600 (epoch 16), train_loss = 1.190, time/batch=0.117\n",
      "21812/67600 (epoch 16), train_loss = 1.168, time/batch=0.126\n",
      "21813/67600 (epoch 16), train_loss = 1.161, time/batch=0.118\n",
      "21814/67600 (epoch 16), train_loss = 1.196, time/batch=0.220\n",
      "21815/67600 (epoch 16), train_loss = 1.301, time/batch=0.169\n",
      "21816/67600 (epoch 16), train_loss = 1.318, time/batch=0.112\n",
      "21817/67600 (epoch 16), train_loss = 1.272, time/batch=0.124\n",
      "21818/67600 (epoch 16), train_loss = 1.317, time/batch=0.112\n",
      "21819/67600 (epoch 16), train_loss = 1.213, time/batch=0.122\n",
      "21820/67600 (epoch 16), train_loss = 1.226, time/batch=0.143\n",
      "21821/67600 (epoch 16), train_loss = 1.209, time/batch=0.152\n",
      "21822/67600 (epoch 16), train_loss = 1.289, time/batch=0.202\n",
      "21823/67600 (epoch 16), train_loss = 1.254, time/batch=0.139\n",
      "21824/67600 (epoch 16), train_loss = 1.214, time/batch=0.118\n",
      "21825/67600 (epoch 16), train_loss = 1.253, time/batch=0.120\n",
      "21826/67600 (epoch 16), train_loss = 1.242, time/batch=0.120\n",
      "21827/67600 (epoch 16), train_loss = 1.223, time/batch=0.114\n",
      "21828/67600 (epoch 16), train_loss = 1.210, time/batch=0.103\n",
      "21829/67600 (epoch 16), train_loss = 1.210, time/batch=0.267\n",
      "21830/67600 (epoch 16), train_loss = 1.240, time/batch=0.116\n",
      "21831/67600 (epoch 16), train_loss = 1.185, time/batch=0.122\n",
      "21832/67600 (epoch 16), train_loss = 1.177, time/batch=0.126\n",
      "21833/67600 (epoch 16), train_loss = 1.154, time/batch=0.118\n",
      "21834/67600 (epoch 16), train_loss = 1.270, time/batch=0.240\n",
      "21835/67600 (epoch 16), train_loss = 1.227, time/batch=0.143\n",
      "21836/67600 (epoch 16), train_loss = 1.252, time/batch=0.129\n",
      "21837/67600 (epoch 16), train_loss = 1.157, time/batch=0.133\n",
      "21838/67600 (epoch 16), train_loss = 1.164, time/batch=0.116\n",
      "21839/67600 (epoch 16), train_loss = 1.183, time/batch=0.119\n",
      "21840/67600 (epoch 16), train_loss = 1.244, time/batch=0.106\n",
      "21841/67600 (epoch 16), train_loss = 1.263, time/batch=0.238\n",
      "21842/67600 (epoch 16), train_loss = 1.240, time/batch=0.144\n",
      "21843/67600 (epoch 16), train_loss = 1.283, time/batch=0.114\n",
      "21844/67600 (epoch 16), train_loss = 1.195, time/batch=0.107\n",
      "21845/67600 (epoch 16), train_loss = 1.203, time/batch=0.134\n",
      "21846/67600 (epoch 16), train_loss = 1.203, time/batch=0.117\n",
      "21847/67600 (epoch 16), train_loss = 1.250, time/batch=0.114\n",
      "21848/67600 (epoch 16), train_loss = 1.189, time/batch=0.164\n",
      "21849/67600 (epoch 16), train_loss = 1.199, time/batch=0.177\n",
      "21850/67600 (epoch 16), train_loss = 1.181, time/batch=0.146\n",
      "21851/67600 (epoch 16), train_loss = 1.162, time/batch=0.126\n",
      "21852/67600 (epoch 16), train_loss = 1.266, time/batch=0.113\n",
      "21853/67600 (epoch 16), train_loss = 1.194, time/batch=0.125\n",
      "21854/67600 (epoch 16), train_loss = 1.230, time/batch=0.098\n",
      "21855/67600 (epoch 16), train_loss = 1.221, time/batch=0.104\n",
      "21856/67600 (epoch 16), train_loss = 1.225, time/batch=0.230\n",
      "21857/67600 (epoch 16), train_loss = 1.194, time/batch=0.118\n",
      "21858/67600 (epoch 16), train_loss = 1.262, time/batch=0.111\n",
      "21859/67600 (epoch 16), train_loss = 1.180, time/batch=0.108\n",
      "21860/67600 (epoch 16), train_loss = 1.189, time/batch=0.107\n",
      "21861/67600 (epoch 16), train_loss = 1.194, time/batch=0.118\n",
      "21862/67600 (epoch 16), train_loss = 1.219, time/batch=0.117\n",
      "21863/67600 (epoch 16), train_loss = 1.220, time/batch=0.111\n",
      "21864/67600 (epoch 16), train_loss = 1.146, time/batch=0.223\n",
      "21865/67600 (epoch 16), train_loss = 1.151, time/batch=0.137\n",
      "21866/67600 (epoch 16), train_loss = 1.213, time/batch=0.125\n",
      "21867/67600 (epoch 16), train_loss = 1.214, time/batch=0.110\n",
      "21868/67600 (epoch 16), train_loss = 1.208, time/batch=0.110\n",
      "21869/67600 (epoch 16), train_loss = 1.214, time/batch=0.115\n",
      "21870/67600 (epoch 16), train_loss = 1.258, time/batch=0.109\n",
      "21871/67600 (epoch 16), train_loss = 1.235, time/batch=0.136\n",
      "21872/67600 (epoch 16), train_loss = 1.243, time/batch=0.226\n",
      "21873/67600 (epoch 16), train_loss = 1.175, time/batch=0.114\n",
      "21874/67600 (epoch 16), train_loss = 1.219, time/batch=0.121\n",
      "21875/67600 (epoch 16), train_loss = 1.225, time/batch=0.098\n",
      "21876/67600 (epoch 16), train_loss = 1.154, time/batch=0.113\n",
      "21877/67600 (epoch 16), train_loss = 1.221, time/batch=0.155\n",
      "21878/67600 (epoch 16), train_loss = 1.208, time/batch=0.111\n",
      "21879/67600 (epoch 16), train_loss = 1.223, time/batch=0.110\n",
      "21880/67600 (epoch 16), train_loss = 1.253, time/batch=0.115\n",
      "21881/67600 (epoch 16), train_loss = 1.180, time/batch=0.109\n",
      "21882/67600 (epoch 16), train_loss = 1.174, time/batch=0.105\n",
      "21883/67600 (epoch 16), train_loss = 1.270, time/batch=0.115\n",
      "21884/67600 (epoch 16), train_loss = 1.186, time/batch=0.254\n",
      "21885/67600 (epoch 16), train_loss = 1.214, time/batch=0.125\n",
      "21886/67600 (epoch 16), train_loss = 1.239, time/batch=0.100\n",
      "21887/67600 (epoch 16), train_loss = 1.281, time/batch=0.116\n",
      "21888/67600 (epoch 16), train_loss = 1.251, time/batch=0.106\n",
      "21889/67600 (epoch 16), train_loss = 1.266, time/batch=0.114\n",
      "21890/67600 (epoch 16), train_loss = 1.175, time/batch=0.111\n",
      "21891/67600 (epoch 16), train_loss = 1.173, time/batch=0.118\n",
      "21892/67600 (epoch 16), train_loss = 1.204, time/batch=0.230\n",
      "21893/67600 (epoch 16), train_loss = 1.190, time/batch=0.126\n",
      "21894/67600 (epoch 16), train_loss = 1.206, time/batch=0.111\n",
      "21895/67600 (epoch 16), train_loss = 1.214, time/batch=0.115\n",
      "21896/67600 (epoch 16), train_loss = 1.206, time/batch=0.110\n",
      "21897/67600 (epoch 16), train_loss = 1.196, time/batch=0.115\n",
      "21898/67600 (epoch 16), train_loss = 1.177, time/batch=0.118\n",
      "21899/67600 (epoch 16), train_loss = 1.228, time/batch=0.176\n",
      "21900/67600 (epoch 16), train_loss = 1.212, time/batch=0.175\n",
      "21901/67600 (epoch 16), train_loss = 1.185, time/batch=0.121\n",
      "21902/67600 (epoch 16), train_loss = 1.248, time/batch=0.112\n",
      "21903/67600 (epoch 16), train_loss = 1.208, time/batch=0.110\n",
      "21904/67600 (epoch 16), train_loss = 1.224, time/batch=0.108\n",
      "21905/67600 (epoch 16), train_loss = 1.247, time/batch=0.211\n",
      "21906/67600 (epoch 16), train_loss = 1.229, time/batch=0.141\n",
      "21907/67600 (epoch 16), train_loss = 1.212, time/batch=0.120\n",
      "21908/67600 (epoch 16), train_loss = 1.232, time/batch=0.122\n",
      "21909/67600 (epoch 16), train_loss = 1.189, time/batch=0.097\n",
      "21910/67600 (epoch 16), train_loss = 1.185, time/batch=0.110\n",
      "21911/67600 (epoch 16), train_loss = 1.238, time/batch=0.118\n",
      "21912/67600 (epoch 16), train_loss = 1.234, time/batch=0.115\n",
      "21913/67600 (epoch 16), train_loss = 1.187, time/batch=0.212\n",
      "21914/67600 (epoch 16), train_loss = 1.161, time/batch=0.149\n",
      "21915/67600 (epoch 16), train_loss = 1.243, time/batch=0.119\n",
      "21916/67600 (epoch 16), train_loss = 1.177, time/batch=0.102\n",
      "21917/67600 (epoch 16), train_loss = 1.292, time/batch=0.113\n",
      "21918/67600 (epoch 16), train_loss = 1.237, time/batch=0.111\n",
      "21919/67600 (epoch 16), train_loss = 1.211, time/batch=0.113\n",
      "21920/67600 (epoch 16), train_loss = 1.245, time/batch=0.166\n",
      "21921/67600 (epoch 16), train_loss = 1.238, time/batch=0.167\n",
      "21922/67600 (epoch 16), train_loss = 1.235, time/batch=0.132\n",
      "21923/67600 (epoch 16), train_loss = 1.230, time/batch=0.117\n",
      "21924/67600 (epoch 16), train_loss = 1.231, time/batch=0.110\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21925/67600 (epoch 16), train_loss = 1.207, time/batch=0.101\n",
      "21926/67600 (epoch 16), train_loss = 1.220, time/batch=0.119\n",
      "21927/67600 (epoch 16), train_loss = 1.231, time/batch=0.105\n",
      "21928/67600 (epoch 16), train_loss = 1.234, time/batch=0.156\n",
      "21929/67600 (epoch 16), train_loss = 1.200, time/batch=0.156\n",
      "21930/67600 (epoch 16), train_loss = 1.193, time/batch=0.124\n",
      "21931/67600 (epoch 16), train_loss = 1.256, time/batch=0.125\n",
      "21932/67600 (epoch 16), train_loss = 1.219, time/batch=0.108\n",
      "21933/67600 (epoch 16), train_loss = 1.237, time/batch=0.112\n",
      "21934/67600 (epoch 16), train_loss = 1.204, time/batch=0.107\n",
      "21935/67600 (epoch 16), train_loss = 1.242, time/batch=0.115\n",
      "21936/67600 (epoch 16), train_loss = 1.244, time/batch=0.242\n",
      "21937/67600 (epoch 16), train_loss = 1.256, time/batch=0.104\n",
      "21938/67600 (epoch 16), train_loss = 1.274, time/batch=0.112\n",
      "21939/67600 (epoch 16), train_loss = 1.247, time/batch=0.111\n",
      "21940/67600 (epoch 16), train_loss = 1.253, time/batch=0.090\n",
      "21941/67600 (epoch 16), train_loss = 1.249, time/batch=0.128\n",
      "21942/67600 (epoch 16), train_loss = 1.213, time/batch=0.196\n",
      "21943/67600 (epoch 16), train_loss = 1.181, time/batch=0.139\n",
      "21944/67600 (epoch 16), train_loss = 1.191, time/batch=0.136\n",
      "21945/67600 (epoch 16), train_loss = 1.251, time/batch=0.100\n",
      "21946/67600 (epoch 16), train_loss = 1.224, time/batch=0.109\n",
      "21947/67600 (epoch 16), train_loss = 1.297, time/batch=0.120\n",
      "21948/67600 (epoch 16), train_loss = 1.202, time/batch=0.115\n",
      "21949/67600 (epoch 16), train_loss = 1.240, time/batch=0.098\n",
      "21950/67600 (epoch 16), train_loss = 1.239, time/batch=0.225\n",
      "21951/67600 (epoch 16), train_loss = 1.250, time/batch=0.138\n",
      "21952/67600 (epoch 16), train_loss = 1.267, time/batch=0.107\n",
      "21953/67600 (epoch 16), train_loss = 1.223, time/batch=0.115\n",
      "21954/67600 (epoch 16), train_loss = 1.217, time/batch=0.110\n",
      "21955/67600 (epoch 16), train_loss = 1.194, time/batch=0.117\n",
      "21956/67600 (epoch 16), train_loss = 1.203, time/batch=0.114\n",
      "21957/67600 (epoch 16), train_loss = 1.186, time/batch=0.195\n",
      "21958/67600 (epoch 16), train_loss = 1.169, time/batch=0.184\n",
      "21959/67600 (epoch 16), train_loss = 1.240, time/batch=0.112\n",
      "21960/67600 (epoch 16), train_loss = 1.200, time/batch=0.124\n",
      "21961/67600 (epoch 16), train_loss = 1.219, time/batch=0.120\n",
      "21962/67600 (epoch 16), train_loss = 1.262, time/batch=0.111\n",
      "21963/67600 (epoch 16), train_loss = 1.179, time/batch=0.101\n",
      "21964/67600 (epoch 16), train_loss = 1.224, time/batch=0.125\n",
      "21965/67600 (epoch 16), train_loss = 1.211, time/batch=0.217\n",
      "21966/67600 (epoch 16), train_loss = 1.245, time/batch=0.130\n",
      "21967/67600 (epoch 16), train_loss = 1.253, time/batch=0.113\n",
      "21968/67600 (epoch 16), train_loss = 1.206, time/batch=0.106\n",
      "21969/67600 (epoch 16), train_loss = 1.191, time/batch=0.117\n",
      "21970/67600 (epoch 16), train_loss = 1.220, time/batch=0.104\n",
      "21971/67600 (epoch 16), train_loss = 1.269, time/batch=0.114\n",
      "21972/67600 (epoch 16), train_loss = 1.219, time/batch=0.113\n",
      "21973/67600 (epoch 16), train_loss = 1.206, time/batch=0.229\n",
      "21974/67600 (epoch 16), train_loss = 1.192, time/batch=0.103\n",
      "21975/67600 (epoch 16), train_loss = 1.183, time/batch=0.123\n",
      "21976/67600 (epoch 16), train_loss = 1.265, time/batch=0.107\n",
      "21977/67600 (epoch 16), train_loss = 1.280, time/batch=0.121\n",
      "21978/67600 (epoch 16), train_loss = 1.225, time/batch=0.108\n",
      "21979/67600 (epoch 16), train_loss = 1.222, time/batch=0.111\n",
      "21980/67600 (epoch 16), train_loss = 1.257, time/batch=0.215\n",
      "21981/67600 (epoch 16), train_loss = 1.261, time/batch=0.162\n",
      "21982/67600 (epoch 16), train_loss = 1.185, time/batch=0.108\n",
      "21983/67600 (epoch 16), train_loss = 1.168, time/batch=0.106\n",
      "21984/67600 (epoch 16), train_loss = 1.164, time/batch=0.112\n",
      "21985/67600 (epoch 16), train_loss = 1.180, time/batch=0.105\n",
      "21986/67600 (epoch 16), train_loss = 1.196, time/batch=0.167\n",
      "21987/67600 (epoch 16), train_loss = 1.250, time/batch=0.095\n",
      "21988/67600 (epoch 16), train_loss = 1.200, time/batch=0.124\n",
      "21989/67600 (epoch 16), train_loss = 1.211, time/batch=0.106\n",
      "21990/67600 (epoch 16), train_loss = 1.173, time/batch=0.124\n",
      "21991/67600 (epoch 16), train_loss = 1.293, time/batch=0.107\n",
      "21992/67600 (epoch 16), train_loss = 1.219, time/batch=0.170\n",
      "21993/67600 (epoch 16), train_loss = 1.178, time/batch=0.253\n",
      "21994/67600 (epoch 16), train_loss = 1.172, time/batch=0.114\n",
      "21995/67600 (epoch 16), train_loss = 1.265, time/batch=0.121\n",
      "21996/67600 (epoch 16), train_loss = 1.217, time/batch=0.115\n",
      "21997/67600 (epoch 16), train_loss = 1.206, time/batch=0.113\n",
      "21998/67600 (epoch 16), train_loss = 1.208, time/batch=0.121\n",
      "21999/67600 (epoch 16), train_loss = 1.155, time/batch=0.115\n",
      "22000/67600 (epoch 16), train_loss = 1.203, time/batch=0.236\n",
      "model saved to ./save/model.ckpt\n",
      "22001/67600 (epoch 16), train_loss = 1.285, time/batch=0.066\n",
      "22002/67600 (epoch 16), train_loss = 1.211, time/batch=0.088\n",
      "22003/67600 (epoch 16), train_loss = 1.209, time/batch=0.095\n",
      "22004/67600 (epoch 16), train_loss = 1.249, time/batch=0.102\n",
      "22005/67600 (epoch 16), train_loss = 1.220, time/batch=0.115\n",
      "22006/67600 (epoch 16), train_loss = 1.265, time/batch=0.116\n",
      "22007/67600 (epoch 16), train_loss = 1.298, time/batch=0.111\n",
      "22008/67600 (epoch 16), train_loss = 1.238, time/batch=0.237\n",
      "22009/67600 (epoch 16), train_loss = 1.217, time/batch=0.116\n",
      "22010/67600 (epoch 16), train_loss = 1.299, time/batch=0.140\n",
      "22011/67600 (epoch 16), train_loss = 1.304, time/batch=0.093\n",
      "22012/67600 (epoch 16), train_loss = 1.256, time/batch=0.127\n",
      "22013/67600 (epoch 16), train_loss = 1.200, time/batch=0.214\n",
      "22014/67600 (epoch 16), train_loss = 1.208, time/batch=0.138\n",
      "22015/67600 (epoch 16), train_loss = 1.259, time/batch=0.104\n",
      "22016/67600 (epoch 16), train_loss = 1.291, time/batch=0.124\n",
      "22017/67600 (epoch 16), train_loss = 1.230, time/batch=0.123\n",
      "22018/67600 (epoch 16), train_loss = 1.205, time/batch=0.115\n",
      "22019/67600 (epoch 16), train_loss = 1.212, time/batch=0.108\n",
      "22020/67600 (epoch 16), train_loss = 1.246, time/batch=0.110\n",
      "22021/67600 (epoch 16), train_loss = 1.240, time/batch=0.209\n",
      "22022/67600 (epoch 16), train_loss = 1.218, time/batch=0.141\n",
      "22023/67600 (epoch 16), train_loss = 1.208, time/batch=0.109\n",
      "22024/67600 (epoch 16), train_loss = 1.197, time/batch=0.110\n",
      "22025/67600 (epoch 16), train_loss = 1.235, time/batch=0.114\n",
      "22026/67600 (epoch 16), train_loss = 1.204, time/batch=0.113\n",
      "22027/67600 (epoch 16), train_loss = 1.217, time/batch=0.108\n",
      "22028/67600 (epoch 16), train_loss = 1.266, time/batch=0.109\n",
      "22029/67600 (epoch 16), train_loss = 1.278, time/batch=0.206\n",
      "22030/67600 (epoch 16), train_loss = 1.218, time/batch=0.145\n",
      "22031/67600 (epoch 16), train_loss = 1.199, time/batch=0.115\n",
      "22032/67600 (epoch 16), train_loss = 1.248, time/batch=0.112\n",
      "22033/67600 (epoch 16), train_loss = 1.308, time/batch=0.107\n",
      "22034/67600 (epoch 16), train_loss = 1.268, time/batch=0.107\n",
      "22035/67600 (epoch 16), train_loss = 1.234, time/batch=0.111\n",
      "22036/67600 (epoch 16), train_loss = 1.293, time/batch=0.118\n",
      "22037/67600 (epoch 16), train_loss = 1.256, time/batch=0.231\n",
      "22038/67600 (epoch 16), train_loss = 1.268, time/batch=0.144\n",
      "22039/67600 (epoch 16), train_loss = 1.196, time/batch=0.126\n",
      "22040/67600 (epoch 16), train_loss = 1.252, time/batch=0.122\n",
      "22041/67600 (epoch 16), train_loss = 1.256, time/batch=0.128\n",
      "22042/67600 (epoch 16), train_loss = 1.257, time/batch=0.105\n",
      "22043/67600 (epoch 16), train_loss = 1.190, time/batch=0.127\n",
      "22044/67600 (epoch 16), train_loss = 1.220, time/batch=0.266\n",
      "22045/67600 (epoch 16), train_loss = 1.229, time/batch=0.134\n",
      "22046/67600 (epoch 16), train_loss = 1.197, time/batch=0.104\n",
      "22047/67600 (epoch 16), train_loss = 1.265, time/batch=0.121\n",
      "22048/67600 (epoch 16), train_loss = 1.220, time/batch=0.125\n",
      "22049/67600 (epoch 16), train_loss = 1.252, time/batch=0.210\n",
      "22050/67600 (epoch 16), train_loss = 1.278, time/batch=0.159\n",
      "22051/67600 (epoch 16), train_loss = 1.201, time/batch=0.108\n",
      "22052/67600 (epoch 16), train_loss = 1.145, time/batch=0.143\n",
      "22053/67600 (epoch 16), train_loss = 1.172, time/batch=0.114\n",
      "22054/67600 (epoch 16), train_loss = 1.222, time/batch=0.112\n",
      "22055/67600 (epoch 16), train_loss = 1.167, time/batch=0.121\n",
      "22056/67600 (epoch 16), train_loss = 1.224, time/batch=0.167\n",
      "22057/67600 (epoch 16), train_loss = 1.192, time/batch=0.110\n",
      "22058/67600 (epoch 16), train_loss = 1.214, time/batch=0.122\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22059/67600 (epoch 16), train_loss = 1.223, time/batch=0.117\n",
      "22060/67600 (epoch 16), train_loss = 1.143, time/batch=0.132\n",
      "22061/67600 (epoch 16), train_loss = 1.190, time/batch=0.121\n",
      "22062/67600 (epoch 16), train_loss = 1.254, time/batch=0.279\n",
      "22063/67600 (epoch 16), train_loss = 1.184, time/batch=0.135\n",
      "22064/67600 (epoch 16), train_loss = 1.242, time/batch=0.128\n",
      "22065/67600 (epoch 16), train_loss = 1.245, time/batch=0.119\n",
      "22066/67600 (epoch 16), train_loss = 1.183, time/batch=0.125\n",
      "22067/67600 (epoch 16), train_loss = 1.286, time/batch=0.099\n",
      "22068/67600 (epoch 16), train_loss = 1.217, time/batch=0.127\n",
      "22069/67600 (epoch 16), train_loss = 1.234, time/batch=0.257\n",
      "22070/67600 (epoch 16), train_loss = 1.229, time/batch=0.137\n",
      "22071/67600 (epoch 16), train_loss = 1.210, time/batch=0.113\n",
      "22072/67600 (epoch 16), train_loss = 1.208, time/batch=0.126\n",
      "22073/67600 (epoch 16), train_loss = 1.239, time/batch=0.117\n",
      "22074/67600 (epoch 16), train_loss = 1.202, time/batch=0.130\n",
      "22075/67600 (epoch 16), train_loss = 1.187, time/batch=0.106\n",
      "22076/67600 (epoch 16), train_loss = 1.240, time/batch=0.150\n",
      "22077/67600 (epoch 16), train_loss = 1.274, time/batch=0.226\n",
      "22078/67600 (epoch 16), train_loss = 1.173, time/batch=0.115\n",
      "22079/67600 (epoch 16), train_loss = 1.183, time/batch=0.126\n",
      "22080/67600 (epoch 16), train_loss = 1.157, time/batch=0.119\n",
      "22081/67600 (epoch 16), train_loss = 1.188, time/batch=0.176\n",
      "22082/67600 (epoch 16), train_loss = 1.139, time/batch=0.165\n",
      "22083/67600 (epoch 16), train_loss = 1.243, time/batch=0.165\n",
      "22084/67600 (epoch 16), train_loss = 1.267, time/batch=0.126\n",
      "22085/67600 (epoch 16), train_loss = 1.168, time/batch=0.102\n",
      "22086/67600 (epoch 16), train_loss = 1.141, time/batch=0.131\n",
      "22087/67600 (epoch 16), train_loss = 1.177, time/batch=0.130\n",
      "22088/67600 (epoch 16), train_loss = 1.203, time/batch=0.153\n",
      "22089/67600 (epoch 16), train_loss = 1.220, time/batch=0.206\n",
      "22090/67600 (epoch 16), train_loss = 1.243, time/batch=0.150\n",
      "22091/67600 (epoch 16), train_loss = 1.217, time/batch=0.133\n",
      "22092/67600 (epoch 16), train_loss = 1.226, time/batch=0.115\n",
      "22093/67600 (epoch 16), train_loss = 1.175, time/batch=0.111\n",
      "22094/67600 (epoch 16), train_loss = 1.250, time/batch=0.120\n",
      "22095/67600 (epoch 16), train_loss = 1.220, time/batch=0.121\n",
      "22096/67600 (epoch 16), train_loss = 1.191, time/batch=0.224\n",
      "22097/67600 (epoch 16), train_loss = 1.209, time/batch=0.158\n",
      "22098/67600 (epoch 16), train_loss = 1.198, time/batch=0.124\n",
      "22099/67600 (epoch 16), train_loss = 1.249, time/batch=0.119\n",
      "22100/67600 (epoch 16), train_loss = 1.212, time/batch=0.126\n",
      "22101/67600 (epoch 16), train_loss = 1.184, time/batch=0.139\n",
      "22102/67600 (epoch 16), train_loss = 1.207, time/batch=0.119\n",
      "22103/67600 (epoch 16), train_loss = 1.210, time/batch=0.252\n",
      "22104/67600 (epoch 16), train_loss = 1.175, time/batch=0.113\n",
      "22105/67600 (epoch 16), train_loss = 1.229, time/batch=0.118\n",
      "22106/67600 (epoch 16), train_loss = 1.175, time/batch=0.128\n",
      "22107/67600 (epoch 16), train_loss = 1.160, time/batch=0.098\n",
      "22108/67600 (epoch 16), train_loss = 1.240, time/batch=0.147\n",
      "22109/67600 (epoch 16), train_loss = 1.166, time/batch=0.107\n",
      "22110/67600 (epoch 16), train_loss = 1.212, time/batch=0.254\n",
      "22111/67600 (epoch 16), train_loss = 1.222, time/batch=0.131\n",
      "22112/67600 (epoch 16), train_loss = 1.177, time/batch=0.113\n",
      "22113/67600 (epoch 16), train_loss = 1.214, time/batch=0.124\n",
      "22114/67600 (epoch 16), train_loss = 1.190, time/batch=0.114\n",
      "22115/67600 (epoch 16), train_loss = 1.170, time/batch=0.224\n",
      "22116/67600 (epoch 16), train_loss = 1.228, time/batch=0.140\n",
      "22117/67600 (epoch 16), train_loss = 1.225, time/batch=0.136\n",
      "22118/67600 (epoch 16), train_loss = 1.252, time/batch=0.126\n",
      "22119/67600 (epoch 16), train_loss = 1.230, time/batch=0.121\n",
      "22120/67600 (epoch 16), train_loss = 1.257, time/batch=0.132\n",
      "22121/67600 (epoch 16), train_loss = 1.241, time/batch=0.105\n",
      "22122/67600 (epoch 16), train_loss = 1.180, time/batch=0.229\n",
      "22123/67600 (epoch 16), train_loss = 1.214, time/batch=0.148\n",
      "22124/67600 (epoch 16), train_loss = 1.234, time/batch=0.123\n",
      "22125/67600 (epoch 16), train_loss = 1.186, time/batch=0.123\n",
      "22126/67600 (epoch 16), train_loss = 1.269, time/batch=0.125\n",
      "22127/67600 (epoch 16), train_loss = 1.224, time/batch=0.107\n",
      "22128/67600 (epoch 16), train_loss = 1.201, time/batch=0.114\n",
      "22129/67600 (epoch 16), train_loss = 1.226, time/batch=0.251\n",
      "22130/67600 (epoch 16), train_loss = 1.275, time/batch=0.150\n",
      "22131/67600 (epoch 16), train_loss = 1.212, time/batch=0.103\n",
      "22132/67600 (epoch 16), train_loss = 1.160, time/batch=0.125\n",
      "22133/67600 (epoch 16), train_loss = 1.174, time/batch=0.112\n",
      "22134/67600 (epoch 16), train_loss = 1.187, time/batch=0.119\n",
      "22135/67600 (epoch 16), train_loss = 1.235, time/batch=0.119\n",
      "22136/67600 (epoch 16), train_loss = 1.235, time/batch=0.122\n",
      "22137/67600 (epoch 16), train_loss = 1.252, time/batch=0.251\n",
      "22138/67600 (epoch 16), train_loss = 1.234, time/batch=0.141\n",
      "22139/67600 (epoch 16), train_loss = 1.235, time/batch=0.119\n",
      "22140/67600 (epoch 16), train_loss = 1.182, time/batch=0.117\n",
      "22141/67600 (epoch 16), train_loss = 1.208, time/batch=0.124\n",
      "22142/67600 (epoch 16), train_loss = 1.232, time/batch=0.113\n",
      "22143/67600 (epoch 16), train_loss = 1.220, time/batch=0.144\n",
      "22144/67600 (epoch 16), train_loss = 1.231, time/batch=0.266\n",
      "22145/67600 (epoch 16), train_loss = 1.200, time/batch=0.131\n",
      "22146/67600 (epoch 16), train_loss = 1.221, time/batch=0.112\n",
      "22147/67600 (epoch 16), train_loss = 1.254, time/batch=0.116\n",
      "22148/67600 (epoch 16), train_loss = 1.262, time/batch=0.167\n",
      "22149/67600 (epoch 16), train_loss = 1.249, time/batch=0.237\n",
      "22150/67600 (epoch 16), train_loss = 1.230, time/batch=0.126\n",
      "22151/67600 (epoch 16), train_loss = 1.167, time/batch=0.134\n",
      "22152/67600 (epoch 16), train_loss = 1.269, time/batch=0.128\n",
      "22153/67600 (epoch 16), train_loss = 1.270, time/batch=0.140\n",
      "22154/67600 (epoch 16), train_loss = 1.285, time/batch=0.124\n",
      "22155/67600 (epoch 16), train_loss = 1.234, time/batch=0.181\n",
      "22156/67600 (epoch 16), train_loss = 1.218, time/batch=0.105\n",
      "22157/67600 (epoch 16), train_loss = 1.226, time/batch=0.086\n",
      "22158/67600 (epoch 16), train_loss = 1.239, time/batch=0.122\n",
      "22159/67600 (epoch 16), train_loss = 1.192, time/batch=0.124\n",
      "22160/67600 (epoch 16), train_loss = 1.248, time/batch=0.133\n",
      "22161/67600 (epoch 16), train_loss = 1.216, time/batch=0.281\n",
      "22162/67600 (epoch 16), train_loss = 1.261, time/batch=0.149\n",
      "22163/67600 (epoch 16), train_loss = 1.250, time/batch=0.150\n",
      "22164/67600 (epoch 16), train_loss = 1.245, time/batch=0.128\n",
      "22165/67600 (epoch 16), train_loss = 1.195, time/batch=0.112\n",
      "22166/67600 (epoch 16), train_loss = 1.204, time/batch=0.120\n",
      "22167/67600 (epoch 16), train_loss = 1.177, time/batch=0.123\n",
      "22168/67600 (epoch 16), train_loss = 1.197, time/batch=0.270\n",
      "22169/67600 (epoch 16), train_loss = 1.218, time/batch=0.114\n",
      "22170/67600 (epoch 16), train_loss = 1.218, time/batch=0.125\n",
      "22171/67600 (epoch 16), train_loss = 1.219, time/batch=0.118\n",
      "22172/67600 (epoch 16), train_loss = 1.222, time/batch=0.131\n",
      "22173/67600 (epoch 16), train_loss = 1.167, time/batch=0.122\n",
      "22174/67600 (epoch 16), train_loss = 1.193, time/batch=0.109\n",
      "22175/67600 (epoch 16), train_loss = 1.188, time/batch=0.251\n",
      "22176/67600 (epoch 16), train_loss = 1.262, time/batch=0.126\n",
      "22177/67600 (epoch 16), train_loss = 1.219, time/batch=0.108\n",
      "22178/67600 (epoch 16), train_loss = 1.210, time/batch=0.121\n",
      "22179/67600 (epoch 16), train_loss = 1.210, time/batch=0.116\n",
      "22180/67600 (epoch 16), train_loss = 1.337, time/batch=0.194\n",
      "22181/67600 (epoch 16), train_loss = 1.251, time/batch=0.190\n",
      "22182/67600 (epoch 16), train_loss = 1.203, time/batch=0.152\n",
      "22183/67600 (epoch 16), train_loss = 1.256, time/batch=0.120\n",
      "22184/67600 (epoch 16), train_loss = 1.199, time/batch=0.111\n",
      "22185/67600 (epoch 16), train_loss = 1.207, time/batch=0.131\n",
      "22186/67600 (epoch 16), train_loss = 1.253, time/batch=0.121\n",
      "22187/67600 (epoch 16), train_loss = 1.211, time/batch=0.179\n",
      "22188/67600 (epoch 16), train_loss = 1.267, time/batch=0.185\n",
      "22189/67600 (epoch 16), train_loss = 1.216, time/batch=0.154\n",
      "22190/67600 (epoch 16), train_loss = 1.197, time/batch=0.105\n",
      "22191/67600 (epoch 16), train_loss = 1.155, time/batch=0.141\n",
      "22192/67600 (epoch 16), train_loss = 1.188, time/batch=0.136\n",
      "22193/67600 (epoch 16), train_loss = 1.205, time/batch=0.114\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22194/67600 (epoch 16), train_loss = 1.165, time/batch=0.247\n",
      "22195/67600 (epoch 16), train_loss = 1.210, time/batch=0.158\n",
      "22196/67600 (epoch 16), train_loss = 1.183, time/batch=0.110\n",
      "22197/67600 (epoch 16), train_loss = 1.202, time/batch=0.120\n",
      "22198/67600 (epoch 16), train_loss = 1.215, time/batch=0.121\n",
      "22199/67600 (epoch 16), train_loss = 1.238, time/batch=0.131\n",
      "22200/67600 (epoch 16), train_loss = 1.229, time/batch=0.110\n",
      "22201/67600 (epoch 16), train_loss = 1.193, time/batch=0.182\n",
      "22202/67600 (epoch 16), train_loss = 1.176, time/batch=0.207\n",
      "22203/67600 (epoch 16), train_loss = 1.178, time/batch=0.095\n",
      "22204/67600 (epoch 16), train_loss = 1.201, time/batch=0.136\n",
      "22205/67600 (epoch 16), train_loss = 1.208, time/batch=0.116\n",
      "22206/67600 (epoch 16), train_loss = 1.226, time/batch=0.137\n",
      "22207/67600 (epoch 16), train_loss = 1.183, time/batch=0.119\n",
      "22208/67600 (epoch 16), train_loss = 1.236, time/batch=0.093\n",
      "22209/67600 (epoch 16), train_loss = 1.216, time/batch=0.262\n",
      "22210/67600 (epoch 16), train_loss = 1.242, time/batch=0.131\n",
      "22211/67600 (epoch 16), train_loss = 1.217, time/batch=0.103\n",
      "22212/67600 (epoch 16), train_loss = 1.250, time/batch=0.133\n",
      "22213/67600 (epoch 16), train_loss = 1.207, time/batch=0.105\n",
      "22214/67600 (epoch 16), train_loss = 1.173, time/batch=0.230\n",
      "22215/67600 (epoch 16), train_loss = 1.191, time/batch=0.141\n",
      "22216/67600 (epoch 16), train_loss = 1.208, time/batch=0.118\n",
      "22217/67600 (epoch 16), train_loss = 1.273, time/batch=0.132\n",
      "22218/67600 (epoch 16), train_loss = 1.193, time/batch=0.113\n",
      "22219/67600 (epoch 16), train_loss = 1.267, time/batch=0.109\n",
      "22220/67600 (epoch 16), train_loss = 1.185, time/batch=0.131\n",
      "22221/67600 (epoch 16), train_loss = 1.222, time/batch=0.224\n",
      "22222/67600 (epoch 16), train_loss = 1.267, time/batch=0.155\n",
      "22223/67600 (epoch 16), train_loss = 1.186, time/batch=0.100\n",
      "22224/67600 (epoch 16), train_loss = 1.184, time/batch=0.086\n",
      "22225/67600 (epoch 16), train_loss = 1.227, time/batch=0.153\n",
      "22226/67600 (epoch 16), train_loss = 1.169, time/batch=0.111\n",
      "22227/67600 (epoch 16), train_loss = 1.211, time/batch=0.120\n",
      "22228/67600 (epoch 16), train_loss = 1.229, time/batch=0.137\n",
      "22229/67600 (epoch 16), train_loss = 1.171, time/batch=0.227\n",
      "22230/67600 (epoch 16), train_loss = 1.211, time/batch=0.140\n",
      "22231/67600 (epoch 16), train_loss = 1.203, time/batch=0.103\n",
      "22232/67600 (epoch 16), train_loss = 1.239, time/batch=0.149\n",
      "22233/67600 (epoch 16), train_loss = 1.157, time/batch=0.121\n",
      "22234/67600 (epoch 16), train_loss = 1.216, time/batch=0.106\n",
      "22235/67600 (epoch 16), train_loss = 1.197, time/batch=0.124\n",
      "22236/67600 (epoch 16), train_loss = 1.225, time/batch=0.247\n",
      "22237/67600 (epoch 16), train_loss = 1.187, time/batch=0.149\n",
      "22238/67600 (epoch 16), train_loss = 1.264, time/batch=0.136\n",
      "22239/67600 (epoch 16), train_loss = 1.195, time/batch=0.110\n",
      "22240/67600 (epoch 16), train_loss = 1.280, time/batch=0.141\n",
      "22241/67600 (epoch 16), train_loss = 1.211, time/batch=0.119\n",
      "22242/67600 (epoch 16), train_loss = 1.239, time/batch=0.261\n",
      "22243/67600 (epoch 16), train_loss = 1.306, time/batch=0.132\n",
      "22244/67600 (epoch 16), train_loss = 1.217, time/batch=0.125\n",
      "22245/67600 (epoch 16), train_loss = 1.209, time/batch=0.126\n",
      "22246/67600 (epoch 16), train_loss = 1.247, time/batch=0.130\n",
      "22247/67600 (epoch 16), train_loss = 1.273, time/batch=0.199\n",
      "22248/67600 (epoch 16), train_loss = 1.227, time/batch=0.190\n",
      "22249/67600 (epoch 16), train_loss = 1.288, time/batch=0.101\n",
      "22250/67600 (epoch 16), train_loss = 1.221, time/batch=0.135\n",
      "22251/67600 (epoch 16), train_loss = 1.185, time/batch=0.121\n",
      "22252/67600 (epoch 16), train_loss = 1.169, time/batch=0.125\n",
      "22253/67600 (epoch 16), train_loss = 1.203, time/batch=0.120\n",
      "22254/67600 (epoch 16), train_loss = 1.219, time/batch=0.173\n",
      "22255/67600 (epoch 16), train_loss = 1.188, time/batch=0.103\n",
      "22256/67600 (epoch 16), train_loss = 1.217, time/batch=0.126\n",
      "22257/67600 (epoch 16), train_loss = 1.204, time/batch=0.118\n",
      "22258/67600 (epoch 16), train_loss = 1.252, time/batch=0.133\n",
      "22259/67600 (epoch 16), train_loss = 1.253, time/batch=0.133\n",
      "22260/67600 (epoch 16), train_loss = 1.252, time/batch=0.291\n",
      "22261/67600 (epoch 16), train_loss = 1.215, time/batch=0.140\n",
      "22262/67600 (epoch 16), train_loss = 1.255, time/batch=0.145\n",
      "22263/67600 (epoch 16), train_loss = 1.283, time/batch=0.106\n",
      "22264/67600 (epoch 16), train_loss = 1.201, time/batch=0.111\n",
      "22265/67600 (epoch 16), train_loss = 1.273, time/batch=0.102\n",
      "22266/67600 (epoch 16), train_loss = 1.260, time/batch=0.126\n",
      "22267/67600 (epoch 16), train_loss = 1.139, time/batch=0.274\n",
      "22268/67600 (epoch 16), train_loss = 1.305, time/batch=0.135\n",
      "22269/67600 (epoch 16), train_loss = 1.195, time/batch=0.113\n",
      "22270/67600 (epoch 16), train_loss = 1.156, time/batch=0.121\n",
      "22271/67600 (epoch 16), train_loss = 1.144, time/batch=0.121\n",
      "22272/67600 (epoch 16), train_loss = 1.221, time/batch=0.122\n",
      "22273/67600 (epoch 16), train_loss = 1.198, time/batch=0.121\n",
      "22274/67600 (epoch 16), train_loss = 1.250, time/batch=0.270\n",
      "22275/67600 (epoch 16), train_loss = 1.296, time/batch=0.128\n",
      "22276/67600 (epoch 16), train_loss = 1.269, time/batch=0.128\n",
      "22277/67600 (epoch 16), train_loss = 1.218, time/batch=0.146\n",
      "22278/67600 (epoch 16), train_loss = 1.251, time/batch=0.117\n",
      "22279/67600 (epoch 16), train_loss = 1.236, time/batch=0.228\n",
      "22280/67600 (epoch 16), train_loss = 1.269, time/batch=0.190\n",
      "22281/67600 (epoch 16), train_loss = 1.234, time/batch=0.122\n",
      "22282/67600 (epoch 16), train_loss = 1.272, time/batch=0.149\n",
      "22283/67600 (epoch 16), train_loss = 1.295, time/batch=0.172\n",
      "22284/67600 (epoch 16), train_loss = 1.215, time/batch=0.246\n",
      "22285/67600 (epoch 16), train_loss = 1.212, time/batch=0.223\n",
      "22286/67600 (epoch 16), train_loss = 1.241, time/batch=0.161\n",
      "22287/67600 (epoch 16), train_loss = 1.212, time/batch=0.110\n",
      "22288/67600 (epoch 16), train_loss = 1.204, time/batch=0.202\n",
      "22289/67600 (epoch 16), train_loss = 1.293, time/batch=0.129\n",
      "22290/67600 (epoch 16), train_loss = 1.235, time/batch=0.128\n",
      "22291/67600 (epoch 16), train_loss = 1.159, time/batch=0.291\n",
      "22292/67600 (epoch 16), train_loss = 1.209, time/batch=0.200\n",
      "22293/67600 (epoch 16), train_loss = 1.205, time/batch=0.128\n",
      "22294/67600 (epoch 16), train_loss = 1.138, time/batch=0.162\n",
      "22295/67600 (epoch 16), train_loss = 1.170, time/batch=0.130\n",
      "22296/67600 (epoch 16), train_loss = 1.256, time/batch=0.308\n",
      "22297/67600 (epoch 16), train_loss = 1.235, time/batch=0.146\n",
      "22298/67600 (epoch 16), train_loss = 1.246, time/batch=0.108\n",
      "22299/67600 (epoch 16), train_loss = 1.210, time/batch=0.132\n",
      "22300/67600 (epoch 16), train_loss = 1.273, time/batch=0.109\n",
      "22301/67600 (epoch 16), train_loss = 1.185, time/batch=0.250\n",
      "22302/67600 (epoch 16), train_loss = 1.134, time/batch=0.315\n",
      "22303/67600 (epoch 16), train_loss = 1.194, time/batch=0.124\n",
      "22304/67600 (epoch 16), train_loss = 1.133, time/batch=0.205\n",
      "22305/67600 (epoch 16), train_loss = 1.279, time/batch=0.131\n",
      "22306/67600 (epoch 16), train_loss = 1.265, time/batch=0.230\n",
      "22307/67600 (epoch 16), train_loss = 1.189, time/batch=0.146\n",
      "22308/67600 (epoch 16), train_loss = 1.224, time/batch=0.117\n",
      "22309/67600 (epoch 16), train_loss = 1.254, time/batch=0.120\n",
      "22310/67600 (epoch 16), train_loss = 1.271, time/batch=0.145\n",
      "22311/67600 (epoch 16), train_loss = 1.203, time/batch=0.158\n",
      "22312/67600 (epoch 16), train_loss = 1.218, time/batch=0.173\n",
      "22313/67600 (epoch 16), train_loss = 1.246, time/batch=0.185\n",
      "22314/67600 (epoch 16), train_loss = 1.247, time/batch=0.156\n",
      "22315/67600 (epoch 16), train_loss = 1.206, time/batch=0.108\n",
      "22316/67600 (epoch 16), train_loss = 1.192, time/batch=0.120\n",
      "22317/67600 (epoch 16), train_loss = 1.272, time/batch=0.152\n",
      "22318/67600 (epoch 16), train_loss = 1.242, time/batch=0.126\n",
      "22319/67600 (epoch 16), train_loss = 1.185, time/batch=0.300\n",
      "22320/67600 (epoch 16), train_loss = 1.224, time/batch=0.154\n",
      "22321/67600 (epoch 16), train_loss = 1.169, time/batch=0.187\n",
      "22322/67600 (epoch 16), train_loss = 1.213, time/batch=0.119\n",
      "22323/67600 (epoch 16), train_loss = 1.205, time/batch=0.130\n",
      "22324/67600 (epoch 16), train_loss = 1.199, time/batch=0.095\n",
      "22325/67600 (epoch 16), train_loss = 1.250, time/batch=0.247\n",
      "22326/67600 (epoch 16), train_loss = 1.230, time/batch=0.156\n",
      "22327/67600 (epoch 16), train_loss = 1.146, time/batch=0.134\n",
      "22328/67600 (epoch 16), train_loss = 1.235, time/batch=0.148\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22329/67600 (epoch 16), train_loss = 1.253, time/batch=0.125\n",
      "22330/67600 (epoch 16), train_loss = 1.246, time/batch=0.229\n",
      "22331/67600 (epoch 16), train_loss = 1.178, time/batch=0.171\n",
      "22332/67600 (epoch 16), train_loss = 1.218, time/batch=0.110\n",
      "22333/67600 (epoch 16), train_loss = 1.247, time/batch=0.171\n",
      "22334/67600 (epoch 16), train_loss = 1.210, time/batch=0.118\n",
      "22335/67600 (epoch 16), train_loss = 1.165, time/batch=0.121\n",
      "22336/67600 (epoch 16), train_loss = 1.217, time/batch=0.110\n",
      "22337/67600 (epoch 16), train_loss = 1.197, time/batch=0.127\n",
      "22338/67600 (epoch 16), train_loss = 1.205, time/batch=0.119\n",
      "22339/67600 (epoch 16), train_loss = 1.238, time/batch=0.278\n",
      "22340/67600 (epoch 16), train_loss = 1.231, time/batch=0.116\n",
      "22341/67600 (epoch 16), train_loss = 1.182, time/batch=0.136\n",
      "22342/67600 (epoch 16), train_loss = 1.219, time/batch=0.125\n",
      "22343/67600 (epoch 16), train_loss = 1.123, time/batch=0.181\n",
      "22344/67600 (epoch 16), train_loss = 1.209, time/batch=0.127\n",
      "22345/67600 (epoch 16), train_loss = 1.203, time/batch=0.129\n",
      "22346/67600 (epoch 16), train_loss = 1.203, time/batch=0.104\n",
      "22347/67600 (epoch 16), train_loss = 1.188, time/batch=0.132\n",
      "22348/67600 (epoch 16), train_loss = 1.162, time/batch=0.132\n",
      "22349/67600 (epoch 16), train_loss = 1.212, time/batch=0.315\n",
      "22350/67600 (epoch 16), train_loss = 1.194, time/batch=0.133\n",
      "22351/67600 (epoch 16), train_loss = 1.204, time/batch=0.116\n",
      "22352/67600 (epoch 16), train_loss = 1.209, time/batch=0.126\n",
      "22353/67600 (epoch 16), train_loss = 1.236, time/batch=0.126\n",
      "22354/67600 (epoch 16), train_loss = 1.211, time/batch=0.131\n",
      "22355/67600 (epoch 16), train_loss = 1.230, time/batch=0.131\n",
      "22356/67600 (epoch 16), train_loss = 1.221, time/batch=0.328\n",
      "22357/67600 (epoch 16), train_loss = 1.225, time/batch=0.115\n",
      "22358/67600 (epoch 16), train_loss = 1.218, time/batch=0.143\n",
      "22359/67600 (epoch 16), train_loss = 1.224, time/batch=0.116\n",
      "22360/67600 (epoch 16), train_loss = 1.242, time/batch=0.138\n",
      "22361/67600 (epoch 16), train_loss = 1.204, time/batch=0.117\n",
      "22362/67600 (epoch 16), train_loss = 1.225, time/batch=0.289\n",
      "22363/67600 (epoch 16), train_loss = 1.247, time/batch=0.195\n",
      "22364/67600 (epoch 16), train_loss = 1.229, time/batch=0.151\n",
      "22365/67600 (epoch 16), train_loss = 1.223, time/batch=0.134\n",
      "22366/67600 (epoch 16), train_loss = 1.217, time/batch=0.271\n",
      "22367/67600 (epoch 16), train_loss = 1.172, time/batch=0.181\n",
      "22368/67600 (epoch 16), train_loss = 1.277, time/batch=0.130\n",
      "22369/67600 (epoch 16), train_loss = 1.199, time/batch=0.134\n",
      "22370/67600 (epoch 16), train_loss = 1.177, time/batch=0.132\n",
      "22371/67600 (epoch 16), train_loss = 1.245, time/batch=0.122\n",
      "22372/67600 (epoch 16), train_loss = 1.160, time/batch=0.151\n",
      "22373/67600 (epoch 16), train_loss = 1.161, time/batch=0.200\n",
      "22374/67600 (epoch 16), train_loss = 1.155, time/batch=0.186\n",
      "22375/67600 (epoch 16), train_loss = 1.206, time/batch=0.117\n",
      "22376/67600 (epoch 16), train_loss = 1.234, time/batch=0.127\n",
      "22377/67600 (epoch 16), train_loss = 1.223, time/batch=0.130\n",
      "22378/67600 (epoch 16), train_loss = 1.196, time/batch=0.127\n",
      "22379/67600 (epoch 16), train_loss = 1.204, time/batch=0.226\n",
      "22380/67600 (epoch 16), train_loss = 1.223, time/batch=0.166\n",
      "22381/67600 (epoch 16), train_loss = 1.186, time/batch=0.110\n",
      "22382/67600 (epoch 16), train_loss = 1.146, time/batch=0.111\n",
      "22383/67600 (epoch 16), train_loss = 1.189, time/batch=0.137\n",
      "22384/67600 (epoch 16), train_loss = 1.204, time/batch=0.106\n",
      "22385/67600 (epoch 16), train_loss = 1.262, time/batch=0.137\n",
      "22386/67600 (epoch 16), train_loss = 1.203, time/batch=0.166\n",
      "22387/67600 (epoch 16), train_loss = 1.211, time/batch=0.202\n",
      "22388/67600 (epoch 16), train_loss = 1.273, time/batch=0.140\n",
      "22389/67600 (epoch 16), train_loss = 1.221, time/batch=0.125\n",
      "22390/67600 (epoch 16), train_loss = 1.197, time/batch=0.127\n",
      "22391/67600 (epoch 16), train_loss = 1.186, time/batch=0.112\n",
      "22392/67600 (epoch 16), train_loss = 1.202, time/batch=0.132\n",
      "22393/67600 (epoch 16), train_loss = 1.203, time/batch=0.174\n",
      "22394/67600 (epoch 16), train_loss = 1.197, time/batch=0.194\n",
      "22395/67600 (epoch 16), train_loss = 1.243, time/batch=0.122\n",
      "22396/67600 (epoch 16), train_loss = 1.266, time/batch=0.118\n",
      "22397/67600 (epoch 16), train_loss = 1.179, time/batch=0.115\n",
      "22398/67600 (epoch 16), train_loss = 1.225, time/batch=0.276\n",
      "22399/67600 (epoch 16), train_loss = 1.204, time/batch=0.149\n",
      "22400/67600 (epoch 16), train_loss = 1.244, time/batch=0.126\n",
      "22401/67600 (epoch 16), train_loss = 1.234, time/batch=0.109\n",
      "22402/67600 (epoch 16), train_loss = 1.197, time/batch=0.127\n",
      "22403/67600 (epoch 16), train_loss = 1.256, time/batch=0.152\n",
      "22404/67600 (epoch 16), train_loss = 1.225, time/batch=0.128\n",
      "22405/67600 (epoch 16), train_loss = 1.203, time/batch=0.252\n",
      "22406/67600 (epoch 16), train_loss = 1.250, time/batch=0.159\n",
      "22407/67600 (epoch 16), train_loss = 1.283, time/batch=0.111\n",
      "22408/67600 (epoch 16), train_loss = 1.252, time/batch=0.147\n",
      "22409/67600 (epoch 16), train_loss = 1.237, time/batch=0.092\n",
      "22410/67600 (epoch 16), train_loss = 1.209, time/batch=0.143\n",
      "22411/67600 (epoch 16), train_loss = 1.238, time/batch=0.122\n",
      "22412/67600 (epoch 16), train_loss = 1.275, time/batch=0.234\n",
      "22413/67600 (epoch 16), train_loss = 1.211, time/batch=0.152\n",
      "22414/67600 (epoch 16), train_loss = 1.205, time/batch=0.133\n",
      "22415/67600 (epoch 16), train_loss = 1.225, time/batch=0.124\n",
      "22416/67600 (epoch 16), train_loss = 1.204, time/batch=0.107\n",
      "22417/67600 (epoch 16), train_loss = 1.243, time/batch=0.125\n",
      "22418/67600 (epoch 16), train_loss = 1.209, time/batch=0.122\n",
      "22419/67600 (epoch 16), train_loss = 1.224, time/batch=0.276\n",
      "22420/67600 (epoch 16), train_loss = 1.236, time/batch=0.136\n",
      "22421/67600 (epoch 16), train_loss = 1.172, time/batch=0.117\n",
      "22422/67600 (epoch 16), train_loss = 1.211, time/batch=0.137\n",
      "22423/67600 (epoch 16), train_loss = 1.227, time/batch=0.116\n",
      "22424/67600 (epoch 16), train_loss = 1.187, time/batch=0.123\n",
      "22425/67600 (epoch 16), train_loss = 1.240, time/batch=0.132\n",
      "22426/67600 (epoch 16), train_loss = 1.221, time/batch=0.269\n",
      "22427/67600 (epoch 16), train_loss = 1.222, time/batch=0.141\n",
      "22428/67600 (epoch 16), train_loss = 1.291, time/batch=0.128\n",
      "22429/67600 (epoch 16), train_loss = 1.231, time/batch=0.109\n",
      "22430/67600 (epoch 16), train_loss = 1.266, time/batch=0.129\n",
      "22431/67600 (epoch 16), train_loss = 1.222, time/batch=0.129\n",
      "22432/67600 (epoch 16), train_loss = 1.229, time/batch=0.305\n",
      "22433/67600 (epoch 16), train_loss = 1.212, time/batch=0.126\n",
      "22434/67600 (epoch 16), train_loss = 1.185, time/batch=0.109\n",
      "22435/67600 (epoch 16), train_loss = 1.212, time/batch=0.118\n",
      "22436/67600 (epoch 16), train_loss = 1.193, time/batch=0.153\n",
      "22437/67600 (epoch 16), train_loss = 1.171, time/batch=0.198\n",
      "22438/67600 (epoch 16), train_loss = 1.213, time/batch=0.143\n",
      "22439/67600 (epoch 16), train_loss = 1.190, time/batch=0.122\n",
      "22440/67600 (epoch 16), train_loss = 1.138, time/batch=0.115\n",
      "22441/67600 (epoch 16), train_loss = 1.239, time/batch=0.110\n",
      "22442/67600 (epoch 16), train_loss = 1.181, time/batch=0.301\n",
      "22443/67600 (epoch 16), train_loss = 1.245, time/batch=0.107\n",
      "22444/67600 (epoch 16), train_loss = 1.238, time/batch=0.134\n",
      "22445/67600 (epoch 16), train_loss = 1.225, time/batch=0.119\n",
      "22446/67600 (epoch 16), train_loss = 1.262, time/batch=0.125\n",
      "22447/67600 (epoch 16), train_loss = 1.167, time/batch=0.105\n",
      "22448/67600 (epoch 16), train_loss = 1.251, time/batch=0.122\n",
      "22449/67600 (epoch 16), train_loss = 1.192, time/batch=0.122\n",
      "22450/67600 (epoch 16), train_loss = 1.192, time/batch=0.256\n",
      "22451/67600 (epoch 16), train_loss = 1.215, time/batch=0.132\n",
      "22452/67600 (epoch 16), train_loss = 1.152, time/batch=0.148\n",
      "22453/67600 (epoch 16), train_loss = 1.250, time/batch=0.167\n",
      "22454/67600 (epoch 16), train_loss = 1.210, time/batch=0.126\n",
      "22455/67600 (epoch 16), train_loss = 1.277, time/batch=0.124\n",
      "22456/67600 (epoch 16), train_loss = 1.225, time/batch=0.319\n",
      "22457/67600 (epoch 16), train_loss = 1.259, time/batch=0.157\n",
      "22458/67600 (epoch 16), train_loss = 1.344, time/batch=0.152\n",
      "22459/67600 (epoch 16), train_loss = 1.184, time/batch=0.092\n",
      "22460/67600 (epoch 16), train_loss = 1.212, time/batch=0.248\n",
      "22461/67600 (epoch 16), train_loss = 1.250, time/batch=0.119\n",
      "22462/67600 (epoch 16), train_loss = 1.296, time/batch=0.201\n",
      "22463/67600 (epoch 16), train_loss = 1.203, time/batch=0.138\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22464/67600 (epoch 16), train_loss = 1.212, time/batch=0.139\n",
      "22465/67600 (epoch 16), train_loss = 1.220, time/batch=0.124\n",
      "22466/67600 (epoch 16), train_loss = 1.188, time/batch=0.180\n",
      "22467/67600 (epoch 16), train_loss = 1.257, time/batch=0.190\n",
      "22468/67600 (epoch 16), train_loss = 1.121, time/batch=0.161\n",
      "22469/67600 (epoch 16), train_loss = 1.239, time/batch=0.126\n",
      "22470/67600 (epoch 16), train_loss = 1.157, time/batch=0.135\n",
      "22471/67600 (epoch 16), train_loss = 1.209, time/batch=0.103\n",
      "22472/67600 (epoch 16), train_loss = 1.268, time/batch=0.131\n",
      "22473/67600 (epoch 16), train_loss = 1.228, time/batch=0.272\n",
      "22474/67600 (epoch 16), train_loss = 1.223, time/batch=0.148\n",
      "22475/67600 (epoch 16), train_loss = 1.219, time/batch=0.115\n",
      "22476/67600 (epoch 16), train_loss = 1.214, time/batch=0.131\n",
      "22477/67600 (epoch 16), train_loss = 1.200, time/batch=0.127\n",
      "22478/67600 (epoch 16), train_loss = 1.198, time/batch=0.160\n",
      "22479/67600 (epoch 16), train_loss = 1.199, time/batch=0.136\n",
      "22480/67600 (epoch 16), train_loss = 1.234, time/batch=0.235\n",
      "22481/67600 (epoch 16), train_loss = 1.209, time/batch=0.148\n",
      "22482/67600 (epoch 16), train_loss = 1.221, time/batch=0.100\n",
      "22483/67600 (epoch 16), train_loss = 1.296, time/batch=0.157\n",
      "22484/67600 (epoch 16), train_loss = 1.292, time/batch=0.169\n",
      "22485/67600 (epoch 16), train_loss = 1.271, time/batch=0.116\n",
      "22486/67600 (epoch 16), train_loss = 1.217, time/batch=0.308\n",
      "22487/67600 (epoch 16), train_loss = 1.248, time/batch=0.138\n",
      "22488/67600 (epoch 16), train_loss = 1.221, time/batch=0.174\n",
      "22489/67600 (epoch 16), train_loss = 1.241, time/batch=0.201\n",
      "22490/67600 (epoch 16), train_loss = 1.237, time/batch=0.338\n",
      "22491/67600 (epoch 16), train_loss = 1.265, time/batch=0.179\n",
      "22492/67600 (epoch 16), train_loss = 1.214, time/batch=0.148\n",
      "22493/67600 (epoch 16), train_loss = 1.273, time/batch=0.146\n",
      "22494/67600 (epoch 16), train_loss = 1.290, time/batch=0.178\n",
      "22495/67600 (epoch 16), train_loss = 1.247, time/batch=0.361\n",
      "22496/67600 (epoch 16), train_loss = 1.188, time/batch=0.150\n",
      "22497/67600 (epoch 16), train_loss = 1.283, time/batch=0.145\n",
      "22498/67600 (epoch 16), train_loss = 1.266, time/batch=0.154\n",
      "22499/67600 (epoch 16), train_loss = 1.200, time/batch=0.154\n",
      "22500/67600 (epoch 16), train_loss = 1.228, time/batch=0.286\n",
      "model saved to ./save/model.ckpt\n",
      "22501/67600 (epoch 16), train_loss = 1.220, time/batch=0.077\n",
      "22502/67600 (epoch 16), train_loss = 1.221, time/batch=0.076\n",
      "22503/67600 (epoch 16), train_loss = 1.197, time/batch=0.109\n",
      "22504/67600 (epoch 16), train_loss = 1.255, time/batch=0.364\n",
      "22505/67600 (epoch 16), train_loss = 1.181, time/batch=0.146\n",
      "22506/67600 (epoch 16), train_loss = 1.221, time/batch=0.147\n",
      "22507/67600 (epoch 16), train_loss = 1.278, time/batch=0.126\n",
      "22508/67600 (epoch 16), train_loss = 1.269, time/batch=0.248\n",
      "22509/67600 (epoch 16), train_loss = 1.133, time/batch=0.165\n",
      "22510/67600 (epoch 16), train_loss = 1.225, time/batch=0.125\n",
      "22511/67600 (epoch 16), train_loss = 1.125, time/batch=0.154\n",
      "22512/67600 (epoch 16), train_loss = 1.178, time/batch=0.142\n",
      "22513/67600 (epoch 16), train_loss = 1.193, time/batch=0.100\n",
      "22514/67600 (epoch 16), train_loss = 1.198, time/batch=0.110\n",
      "22515/67600 (epoch 16), train_loss = 1.219, time/batch=0.279\n",
      "22516/67600 (epoch 16), train_loss = 1.190, time/batch=0.153\n",
      "22517/67600 (epoch 16), train_loss = 1.213, time/batch=0.119\n",
      "22518/67600 (epoch 16), train_loss = 1.191, time/batch=0.138\n",
      "22519/67600 (epoch 16), train_loss = 1.163, time/batch=0.138\n",
      "22520/67600 (epoch 16), train_loss = 1.285, time/batch=0.131\n",
      "22521/67600 (epoch 16), train_loss = 1.252, time/batch=0.244\n",
      "22522/67600 (epoch 16), train_loss = 1.273, time/batch=0.136\n",
      "22523/67600 (epoch 16), train_loss = 1.269, time/batch=0.116\n",
      "22524/67600 (epoch 16), train_loss = 1.234, time/batch=0.119\n",
      "22525/67600 (epoch 16), train_loss = 1.197, time/batch=0.115\n",
      "22526/67600 (epoch 16), train_loss = 1.235, time/batch=0.108\n",
      "22527/67600 (epoch 16), train_loss = 1.197, time/batch=0.150\n",
      "22528/67600 (epoch 16), train_loss = 1.223, time/batch=0.307\n",
      "22529/67600 (epoch 16), train_loss = 1.289, time/batch=0.149\n",
      "22530/67600 (epoch 16), train_loss = 1.251, time/batch=0.116\n",
      "22531/67600 (epoch 16), train_loss = 1.257, time/batch=0.108\n",
      "22532/67600 (epoch 16), train_loss = 1.230, time/batch=0.144\n",
      "22533/67600 (epoch 16), train_loss = 1.274, time/batch=0.107\n",
      "22534/67600 (epoch 16), train_loss = 1.269, time/batch=0.163\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-6c3ccfbde0c1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0mfeed\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitial_state\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m             \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinal_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m             print(\"{}/{} (epoch {}), train_loss = {:.3f}, time/batch={:.3f}\".format(\n",
      "\u001b[0;32m~/anaconda/envs/py36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/py36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1122\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1124\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1125\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/py36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1321\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/py36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1325\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/py36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1304\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1305\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1306\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1308\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "num_epochs = 10\n",
    "learning_rate = 0.002\n",
    "decay_rate = 0.97\n",
    "save_dir = \"./save/\"\n",
    "save_every = 500\n",
    "\n",
    "\n",
    "tf.reset_default_graph()\n",
    "model = Model() \n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())   \n",
    "    saver = tf.train.Saver(tf.global_variables())\n",
    "\n",
    "    for e in range(num_epochs):\n",
    "        sess.run(tf.assign(model.lr, learning_rate*(decay_rate ** e)))\n",
    "        # reset the pointer to load from the beginning\n",
    "        pointer = 0\n",
    "        state = sess.run(model.initial_state)\n",
    "        for b in range(num_batches):\n",
    "            start = time.time()\n",
    "            x, y = x_batches[pointer], y_batches[pointer]\n",
    "            pointer += 1\n",
    "            feed = {model.input_data: x, model.output_data: y}\n",
    "            feed[model.initial_state] = state\n",
    "                \n",
    "            train_loss, state, _ = sess.run([model.cost, model.final_state, model.train_op], feed)\n",
    "            end = time.time()\n",
    "            print(\"{}/{} (epoch {}), train_loss = {:.3f}, time/batch={:.3f}\".format(\n",
    "                e * num_batches + b, num_epochs * num_batches, e, train_loss, end-start))\n",
    "            \n",
    "            if ( e * num_batches + b ) % save_every == 0 or ( \n",
    "                e == num_epochs - 1 and b == num_batches - 1):\n",
    "                checkpoint_path = os.path.join(save_dir, \"model.ckpt\")\n",
    "                saver.save(sess, checkpoint_path, global_step=e*num_batches + b)\n",
    "                print(\"model saved to {}\".format(checkpoint_path))\n",
    "                \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "saver.saver_def.filename_tensor_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 产生一些句子试一试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./save/model.ckpt-500\n",
      "b' and interess.\"\\n\\n     \"Louted-rooked to thone co we-with foo hervers the deadper, deroubn, for the tage.\\n\\n     \"Boordinathere whot stanted an\\n     nenlifer, frabobing and feong to ond\\n     the\\n     tell offred tushingow It rage wh\\n     his musuppleds threr is gin come\\'s the kevericelds, and a redorness, and a dees\\n     rearse\\n     pfors a saged and thrred to With on\\n     the poring the wimed th he pater of mary he \"What he glought upond upon cloopen ofred heriging up. To the strateen to the paces'\n"
     ]
    }
   ],
   "source": [
    "n = 500\n",
    "prime = \" \"\n",
    "\n",
    "tf.reset_default_graph()\n",
    "model = Model(training=False)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    tf.global_variables_initializer().run()\n",
    "    saver = tf.train.Saver(tf.global_variables())\n",
    "    ckpt = tf.train.get_checkpoint_state(save_dir)\n",
    "    if ckpt and ckpt.model_checkpoint_path:\n",
    "        saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "        print(model.sample(sess, chars, vocab, n, prime).encode(\"utf-8\"))\n",
    "\n",
    "\n",
    "# with open(os.path.join(save_dir, \"config.pkl\"), \"rb\") as f:\n",
    "#     saved_args = cPickle.load(f)\n",
    "# with open(os.path.join(save_dir, \"chars_vocab.pkl\"), \"rb\") as f:\n",
    "#     chars, vocab = cPickle.load(f)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
